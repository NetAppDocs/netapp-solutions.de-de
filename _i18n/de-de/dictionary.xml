<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">Diese Nutzungsmöglichkeit basiert auf einem Kunden des Fernsehnetzwerks. Der Kunde wollte die Backup-Dateien des Oracle Recovery Manager (RMAN) in die Cloud migrieren und die Oracle E-Business Suite (EBS) Applikation mithilfe der Software Azure NetApp Files mit Pacemaker ausführen. Der Kunde wollte außerdem seine Datenbank-Backup-Dateien auf On-Demand-Cloud-Storage migrieren und große Dateien (im Bereich von jeweils 25 GB bis 50 GB) nach Azure übertragen.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">Mit dem XCP Data Mover können Sie große Dateien migrieren</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">Früher: Mit dem XCP Data Mover Millionen von kleinen Dateien auf flexiblen Speicher migrieren.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">Die folgende Abbildung zeigt die Datenmigration von lokalen Systemen zu Azure NetApp Files für große Dateien.</block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover-Lösung: Vor Ort zur Cloud</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">Weitere Informationen finden Sie im<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> blog:</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">Als Nächstes: Doppelte Dateien.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">Die Migration umfasst verschiedene Phasen, um die Migration besser planen und abschließen zu können. Um Daten von NAS Storage anderer Hersteller oder von direkt angeschlossenen NAS-Storage mit NetApp XCP zu migrieren, befolgen Sie die in diesem Abschnitt angegebenen Migrationsrichtlinien.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">Migrations-Workflow</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">Früher NetApp XCP:</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">Die folgende Abbildung zeigt den Migrations-Workflow von jedem NAS zu NetApp NAS.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Fehler: Fehlendes Grafikbild</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">On-Premises</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">Der Migrations-Workflow von jedem NAS auf NetApp NAS umfasst die folgenden Schritte:</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">NAS-Freigaben und Daten ermitteln</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">Scannen Sie die Daten und erstellen Sie einen Bericht, um das Layout der Daten zu finden.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">Erstellen Sie eine Baseline, indem Sie den Befehl XCP Copy ausführen. Wählen Sie für schnellere Migrationen weitere XCP-Instanzen aus, und teilen Sie den Workload auf Unterordnerebene auf, um parallele Migrationsaufgaben zu initiieren.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">Verwenden Sie für inkrementelle Updates XCP Sync, bis die Änderungsrate für das Umstellungsfenster niedrig ist.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">Markieren Sie die Quelle als schreibgeschützt, um eine abschließende Synchronisierung durchzuführen, indem Sie den XCP Sync-Befehl ausführen, um die Migration abzuschließen.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">Vergleichen Sie die Quelle und das Ziel, indem Sie das ausführen, um zu überprüfen, ob die übertragenen Daten korrekt übertragen wurden<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="section-title">Cloud</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">In der Cloud können Sie einen ähnlichen Workflow zur On-Premises-Migration nutzen, wenn die Verbindung zwischen On-Premises- und Cloud-Lösung eine direkte Verbindung (AWS), ExpressRoute (Azure) oder Cloud Interconnect (GCP) bietet.</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">Die folgende Abbildung zeigt den Migrations-Workflow von lokalen Speicherorten in die Cloud.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">Falls keine direkte Internetverbindung zwischen lokalen Systemen und der Cloud besteht, müssen die Daten über eine Methode für den Offline-Datentransport wie den Truck von der lokalen Umgebung in die Cloud übertragen werden. Jeder Cloud-Service-Provider verfügt über eine andere Methode mit einer unterschiedlichen Terminologie, um die Daten in sein Datacenter zu verschieben.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">Die folgende Abbildung zeigt den Data Mover-Lösung für On-Premises-Systeme mit Azure ohne ExpressRoute.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">Sie können eine ähnliche Architektur mit den jeweiligen Komponenten der verschiedenen Cloud-Service-Provider verwenden.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">Weiter: Dateianalysen.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">Über die NetApp XCP Dateianalyse-GUI können Filesystem-Scans mithilfe von XCP im Back-End ausgeführt und Statistiken wie Diagramme und Ansichten für jedes NAS-Filesystem (NFS, SMB) visualisiert werden.</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">Dateianalysen</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">Früher: Migrations-Workflow.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">Über die NetApp XCP Dateianalyse-GUI können Filesystem-Scans mithilfe von XCP im Back-End ausgeführt und Statistiken wie Diagramme und Ansichten für jedes NAS-Filesystem (NFS, SMB) visualisiert werden. Ab 1.6 kann XCP als Service mit einfachen Implementierungsschritten unter Verwendung der Optionen Configure und systemctl ausgeführt werden. Die Option XCP Configure führt Sie zur Installation und Konfiguration von Postgres und einem Webserver sowie zum Sammeln von Anmeldeinformationen. Die Option systemctl führt XCP als Service für DIE REST-API-Kommunikation von der GUI aus.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">Die folgende Abbildung zeigt den Ablauf der XCP-Dateianalyse.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 bietet Verbesserungen bei Open File Analytics und Infrastruktur</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">Weitere Informationen zur grundlegenden Architektur von XCP-Dateianalysen, GUI-basierten Dashboard-Ansichten wie Statistikansicht und Details zur Dateiverteilung finden Sie im Blog-Beitrag<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">In XCP 1.6 gibt es eine eingeschränkte GUI für angepasste Grafiken. Zum Erstellen der erforderlichen Diagramme können Sie die CLI verwenden, um die auszuführen<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> Scan-Befehl mit übereinstimmenden Filtern. Sehen Sie sich die folgenden Beispiele an.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">Erstellen Sie mit eine Liste von Dateien, die nach einem Jahr geändert wurden<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block> Und das<block ref="af7e4e4bdf56fd6022afd2b0cf443794" prefix=" " category="inline-code"></block> Filtern Sie nach dem verbrauchten Speicherplatz.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">Suchen Sie den Platz, der von Dateien verwendet wird, die mehr als ein Jahr alt sind.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">Suchen Sie nach der Gesamtgröße und grafischen Ansicht von Daten, die vor mehr als einem Jahr geändert wurden.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">Der folgende Bericht ist ein benutzerdefinierter Beispiel für den Scan von Dateien, die vor mehr als einem Jahr geändert wurden.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">Als Nächstes: Implementierungsschritte.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">Dieser Abschnitt enthält einige der Tuning-Parameter, die zur Verbesserung der Leistung von XCP-Operationen beitragen.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">Performance-Optimierung</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">Zurück: Dimensionierungsrichtlinien.</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">Dieser Abschnitt enthält einige der Tuning-Parameter, die zur Verbesserung der Leistung von XCP-Operationen beitragen:</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">Zur besseren Skalierung und Verteilung des Workloads auf mehrere XCP-Instanzen verteilen Sie die Unterordner für jede XCP-Instanz für die Migration und den Datentransfer.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP kann maximale CPU-Ressourcen nutzen – je mehr CPU-Kerne, desto besser ist die Leistung. Deshalb sollten Sie mehr CPUs im XCP-Server haben. Wir haben im Lab 128 GB RAM und 48 x Core CPUs getestet, welche eine bessere Performance boten als 8 x CPUs und 8 GB RAM.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">XCP-Kopie mit dem<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> Die Option basiert auf der Anzahl der CPUs. Die Standardanzahl paralleler Threads (sieben) reicht manchmal für die meisten XCP-Datenübertragungs- und Migrationsvorgänge aus. Bei XCP Windows ist standardmäßig die Anzahl der parallelen Prozesse gleich der Anzahl der CPUs. Die maximale Anzahl für die<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> Die Option sollte kleiner als oder gleich der Anzahl der Kerne sein.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10GbE ist ein guter Start für den Datentransfer. Wir haben jedoch die Tests mit 25 GbE und 100 GbE durchgeführt, die für einen besseren Datentransfer sorgen und für den Transfer großer Dateien empfohlen werden.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Für Azure NetApp Files variiert die Performance je nach Service-Level. Weitere Informationen finden Sie in der folgenden Tabelle, in der die Service-Level und Performance-Details von Azure NetApp Files aufgeführt sind.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">Service-Level</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">Ultra</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">Durchsatz</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16 Mbit/s/Terabyte (TB)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64 Mbit/s/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128 MB/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">Workload-Typen</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">Universelle Dateifreigaben, E-Mail und Web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS, Datenbanken und Applikationen</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">Latenzkritische Applikationen</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">Erklärte Performance</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">Standard-Performance: 1,000 IOPS pro TB (16.000 I/O) und 16 MB/s/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">Premium-Performance: 4,000 IOPS pro TB (16.000 I/O) und 64 MB/s/TB</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">Extreme Performance: 8,000 IOPS pro TB (16 KB I/O) und 128 MB/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">Sie müssen das richtige Service Level basierend auf Durchsatz und Workload-Typen auswählen. Die meisten Kunden beginnen mit der Premium-Stufe und ändern je nach Workload den Service-Level.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">Dann: Kundenszenarien</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">Dieser Nutzungsfall basiert auf dem größten Kunden der NetApp Tourismusbranche, der für die Migration von Millionen kleiner vor-Ort-Dateien in die Cloud arbeitet.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">Mit dem XCP Data Mover können Millionen von kleinen Dateien auf flexiblen Speicher migriert werden</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">Früher: High-Performance Computing für ONTAP NFS.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">Dieser Anwendungsfall basiert auf dem größten Kunden der Tourismusbranche von NetApp, wenn es um Datenmigration vor Ort in die Cloud geht. Da COVID-19 die Nachfrage in der Reisebranche reduziert hat, möchten Kunden ihre Investitionskosten für High-End-Storage in ihrer On-Premises-Umgebung für die Demand-Preisapplikation senken. Dieser Kunde verfügt über ein knappes SLA zur Migration von Millionen kleiner Dateien in die Cloud.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">Die folgende Abbildung zeigt die Datenmigration von On-Premises-Systemen zu Azure NetApp Files für kleine Dateien.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">Weiter: Mit dem XCP Data Mover große Dateien migrieren.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">Dieser Anwendungsfall basiert auf dem größten Proof of Concept (CPOC) eines Finanzkunden, den wir erreicht haben. Mit dem NetApp in-Place-Analysemodul (NIPAM) verschieben wir Analysedaten in die NetApp ONTAP AI. Aufgrund von jüngsten Verbesserungen und der verbesserten Performance von NetApp XCP und dem einzigartigen Ansatz der NetApp Data Mover-Lösung haben wir die Datenmigration mithilfe von NetApp XCP neu veröffentlicht.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">Data Lake zu ONTAP-NFS</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Früher: Kundenszenarien.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">Herausforderungen und Anforderungen des Kunden</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">Zu den folgenden Herausforderungen und Anforderungen des Kunden zählen:</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">Kunden haben unterschiedliche Datentypen, darunter strukturierte, unstrukturierte und halbstrukturierte Daten, Protokolle, Und Machine-to-Machine-Daten in Data Lakes. KI-Systeme setzen all diese Datentypen für die Verarbeitung von Vorhersagevorgängen voraus. Wenn sich Daten in einem nativen Data-Lake-Filesystem befinden, ist die Verarbeitung schwierig.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">Die KI-Architektur des Kunden ist nicht in der Lage, auf Daten aus Hadoop Distributed File System (HDFS) und Hadoop Compatible File System (HCFS) zuzugreifen, so dass die Daten nicht für AI-Operationen zur Verfügung stehen. Für die KI müssen Daten in einem verständlichen File-Systemformat wie NFS vorliegen.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">Für das Verschieben von Daten aus dem Data Lake sind einige spezielle Prozesse erforderlich, da große Datenmengen und hoher Durchsatz erforderlich sind. Um die Daten in das KI-System zu verschieben, ist eine kostengünstige Methode erforderlich.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Data Mover-Lösung</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">In dieser Lösung wird das MapR Filesystem (MapR-FS) aus lokalen Festplatten im MapR Cluster erstellt. Das MapR NFS Gateway wird auf jedem Daten-Node mit virtuellen IPs konfiguriert. Der Fileserver-Service speichert und managt die MapR-FS-Daten. NFS Gateway ermöglicht den Zugriff auf Map-FS Daten vom NFS-Client über die virtuelle IP. Auf jedem MapR Daten-Node wird eine XCP Instanz ausgeführt, um die Daten vom Map NFS Gateway zu NetApp ONTAP NFS zu übertragen. Jede XCP-Instanz überträgt einen bestimmten Satz von Quellordnern an den Zielspeicherort.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">Die folgende Abbildung zeigt die NetApp Data Mover-Lösung für MapR Cluster mit XCP.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">Nutzung von XCP, um Daten von einem Data Lake und High-Performance-Computing zu ONTAP NFS zu verschieben</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">Detaillierte Anwendungsfälle, aufgezeichnete Demos und Testergebnisse finden Sie im<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog:</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732: Big Data Analytics Data to Artificial Intelligence</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">Detaillierte Schritte zum Verschieben von MapR-FS-Daten in ONTAP-NFS mithilfe von NetApp XCP finden Sie in Anhang B in<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">Weiter: High-Performance-Computing für ONTAP NFS.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">Dieses Dokument enthält Best Practice-Richtlinien für NetApp XCP sowie eine auf Testszenarios basierende Lösung. Diese Best Practices umfassen den Migrations-Workflow für On-Premises- sowie Cloud-Umgebungen, Dateisystemanalysen, Fehlerbehebung und Performance-Tuning des XCP.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863: Best-Practice Guidelines for NetApp XCP - Data Mover, File Migration und Analytics</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">Dieses Dokument enthält Best Practice-Richtlinien für NetApp XCP sowie eine auf Testszenarios basierende Lösung. Diese Best Practices umfassen den Migrations-Workflow für On-Premises- sowie Cloud-Umgebungen, Dateisystemanalysen, Fehlerbehebung und Performance-Tuning von XCP. In dem Abschnitt zum Testszenario werden Nutzungsfälle und Anforderungen des Kunden erläutert, die NetApp Lösung mit XCP sowie Vorteile für den Kunden.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">Weiter: NetApp XCP.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">Versionsverlauf</block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Früher: Wo zusätzliche Informationen zu finden.</block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Version</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Datum</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Versionsverlauf des Dokuments</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Version 1.0</block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">Oktober 2020</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">Erste Version.</block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">Diese Lösung basiert auf einem Kunden, der Daten basierend auf einem bestimmten Datum kopieren muss.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">Spezifischer datentbasierter Scan und Kopie von Daten</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">Früher: Doppelte Dateien.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">Diese Lösung basiert auf einem Kunden, der Daten basierend auf einem bestimmten Datum kopieren muss. Überprüfen Sie folgende Details:</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">Als Nächstes: Erstellen einer CSV-Datei aus SMB/CIFS-Freigabe.</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">Dieser Abschnitt enthält Anleitungen zur Fehlerbehebung für die Datenmigration mit NetApp XCP.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Fehlerbehebung</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Früher: Best Practice-Richtlinien und -Empfehlungen.</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">Fehler 1: XCP fehlgeschlagen mit nfs3 Fehler 70: Inaktivität von Dateihandle Fehler in der xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">*Grund und Anleitung.*</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">Mounten Sie den Quellordner und überprüfen Sie, ob der Ordner vorhanden ist. Wenn es nicht existiert oder entfernt wurde, erhalten Sie ein<block ref="00b68e4b07be7b89e91e391a70e312d1" prefix=" " category="inline-code"></block> Fehler, in diesem Fall können Sie den Fehler ignorieren.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">Fehler 2: NetApp NFS Ziel-Volume hat Platz, aber XCP ist fehlgeschlagen mit nfs3 Fehler 28: Kein Speicherplatz mehr auf dem Gerät</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">Überprüfen Sie den Speicherplatz des NFS-Ziel-Volumes, indem Sie das ausführen<block ref="eff7d5dba32b4da32d9a67a519434d3f" prefix=" " category="inline-code"></block> Befehl oder Prüfung des Speichers.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">Überprüfen Sie die Inodes im Speicher-Controller.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">Wenn Inode verwendet wird, erhöhen Sie die Anzahl von Inodes, indem Sie den folgenden Befehl ausführen:</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">Weiter: Wo finden Sie zusätzliche Informationen.</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">Beim NetApp XCP werden Daten mithilfe von Multithreads und anpassbaren Funktionen übertragen. Es wurde für drei große Anwendungsfälle entwickelt: Datenverschiebung oder -Migration, Dateisystemanalysen und schnelles Löschen von Verzeichnisbäumen.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="doc">NetApp XCP</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">Zurück: Einführung.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">Beim NetApp XCP werden Daten mithilfe von Multithreads und anpassbaren Funktionen übertragen. Es ist für drei große Anwendungsfälle gedacht: Datenverschiebung oder -Migration, Dateisystemanalysen und schnelles Löschen von Verzeichnisbäumen.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">Datenverschiebung oder -Migration</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">Bei NetApp XCP werden Daten von jedem beliebigen NAS zu NetApp NAS übertragen. Dieser Prozess setzt sich aus vier Hauptvorgängen zusammen: Scannen, Kopieren, Synchronisieren und Verifizieren. Einige weitere Funktionen unterstützen das Monitoring und Übertragen von Daten:</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">*Scan.* bietet ein Layout von NAS- und MapR/HDFS-Daten auf hoher Ebene.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">*Copy.* führt einen Basistransfer der Daten durch.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">*Sync.* führt die inkrementelle Datenübertragung durch.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* Verify.* führt eine gründliche Überprüfung des Ziels durch.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">*Zeige (optional).* ermittelt NAS-Freigaben.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">Die folgende Abbildung zeigt die XCP-Datenmigration und Replikationsvorgänge.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">Filesystem-Analysen</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">Mit NetApp XCP können Sie unstrukturierte Daten nativ identifizieren, prüfen und analysieren und so Erkenntnisse gewinnen. Das ist eine wichtige Anforderung für Enterprise-Kunden, die diese Erkenntnisse für eine bessere Planung, den Betrieb hochwertiger digitaler Ressourcen und für Data Governance durch Berichterstellung und Bewertung nutzen möchten.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">Kunden, die sensible Daten verwenden, können mit NetApp XCP typische betriebliche Fragen beantworten, beispielsweise die folgenden:</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">Wo befinden sich meine Daten?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">Wie viele Daten und welche Arten von Dateien haben wir?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">Welche Daten werden aktiv genutzt und wie viele Daten inaktiv sind?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">Die folgende Abbildung zeigt die Kommunikation zwischen NetApp XCP-Dateianalysen von der GUI.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">Löschen</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">Storage-Teams und EDA (Electronic Design Automation)-Workloads können große Verzeichnisse vor eine enorme Herausforderung stellen, ganz gleich, ob es sich um veraltete Daten oder um Testdaten handelt, die bereinigt werden müssen, um Speicherplatz freizugeben. XCP bietet eine Funktion zum schnellen Löschen, mit der eine vollständige Verzeichnisstruktur gelöscht werden kann. Die NetApp XCP Delete Funktion entfernt Dateien und Ordner aus einem bestimmten NAS-Pfad. Sie können die Match-Filter nutzen, um bestimmte Dateien und Ordner zu löschen. Für eine große Anzahl von Dateien und Ordnern können Sie die Option Kraft verwenden, die keine Bestätigung zum Löschen erfordert.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">Live Source Migration Support</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">Die Live Source Migration unterstützt XCP 1.7 und ermöglicht die Migration von einer Datenquelle, die in aktiver Verwendung ist (Lese- und Schreibaktivität). XCP verlässt Dateien, die während des Migrationsauftrags verwendet werden, wie zum Beispiel das Kopieren und Synchronisieren, und übersprungene Dateien werden im XCP-Protokoll erfasst.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">Diese Funktion unterstützt Änderungen an der Quelle, unterstützt jedoch keine Änderungen am Ziel. Während der Migration sollte das Ziel nicht aktiv sein. Der Support für die Live-Source-Migration ist nur für NFS-Migrationen verfügbar.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">Für Live-Source-Migrationen sind keine besonderen Einstellungen erforderlich.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">Voraussetzungen für XCP</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">Vor der Implementierung von NetApp XCP müssen die folgenden Voraussetzungen erfüllt sein:</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">Überprüfen Sie die vom NFS-Server verwendeten NFS-Ports, indem Sie folgenden Befehl ausführen:</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">Um Zugriff auf den Speicherort zu erhalten, an dem Sie die XCP Vorgänge ausführen, z. B. On-Premises- oder Cloud-Instanzen (z. B. Azure, AWS oder Google Virtual Machine [VM] Instanzen), öffnen Sie die Firewall-Ports für die NFS-Ports.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">Überprüfen Sie, ob der NFS-Port über den XCP-Server mit dem Telnet-Befehl erreichbar ist<block ref="450e3ef5096f09acecd7b33e07b6e190" prefix=" " category="inline-code"></block>. Der Standardport ist 2049. Wenn Ihre Umgebung einen anderen Port hat, verwenden Sie diese IP.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">Stellen Sie für NFS sicher, dass über den XCP-Server auf die Freigaben zugegriffen werden kann. Verwenden Sie dazu die<block ref="3c4a3208b8bf46e9aa41c950ec1a73ba" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">Erhöhen Sie die Anzahl von Inodes auf dem Zielvolume auf mehr als die Anzahl der Dateien (Anzahl der Dateien) auf den Quelldateien.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP Lizenzportal</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">Laden Sie die XCP-Lizenz von der herunter<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">Sie benötigen ein NetApp Konto in mysupport.netapp.com oder Sie können sich kostenlos registrieren.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">Laden Sie die Lizenz herunter, und lassen Sie sie sich vorbereiten.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Erstellen Sie für jedes Azure NetApp Volume vor Ort eine NFS-Freigabe oder für den Cloud Volume Service (Premium-Service-Level) in der Cloud für den XCP-Katalog.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">Erstellen Sie ein NAS-Volume, und konfigurieren Sie die Freigabe für das Datenziel.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">Für mehrere XCP-Instanzen müssen Sie über einen oder mehrere Server oder Cloud-Instanzen verfügen, um die Daten von mehreren Quellordnern oder Dateien an das Ziel zu übertragen.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">Die maxdir-Größe (Standard ist 308 MB) definiert die maximale Dateianzahl (ca. eine Million) in einem einzigen Ordner. Erhöhen Sie den maxdir-Größenwert, um die Anzahl der Dateien zu erhöhen. Eine Erhöhung des Werts hat Auswirkungen auf zusätzliche CPU-Zyklen.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">In der Cloud empfiehlt NetApp die Verwendung von ExpressRoute (Azure), Direct Connect (AWS) oder Cloud Interconnect (GCP) zwischen On-Premises und der Cloud.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">Als Nächstes: Migrations-Workflow.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp erhielt die Anforderung, nach mehrfach vorhandenen Dateien auf einzelnen Volumes oder mehreren Volumes zu suchen. NetApp hat folgende Lösung bereitgestellt.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">Dateien sind doppelt vorhanden</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">Zurück: Mit dem XCP Data Mover große Dateien migrieren.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">Führen Sie für ein einzelnes Volume die folgenden Befehle aus:</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">Führen Sie für mehrere Volumes die folgenden Befehle aus:</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Weiter: Spezifische datumbasierte Scan und Kopie von Daten.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">In diesem Abschnitt wird die ungefähre Zeit zur Durchführung der XCP-Kopiervorgänge und der XCP-Synchronisierung mit einer anderen Dateigröße von einer Million Dateien für NFS erläutert.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">Richtlinien für die Dimensionierung</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">Zurück – Implementierungsschritte.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">Zeitschätzung basierend auf Tests</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">Bei den Tests für die XCP-Kopier- und Synchronisierungsvorgänge wurde dieselbe Testumgebung verwendet, die für die Implementierung verwendet wurde. Eine Million Dateien mit drei Sets von 8K-, 16K- und 1-MB-Dateien wurden erstellt und die Änderungen wurden in Echtzeit durchgeführt. Die XCP-Synchronisationsfunktion führte die differenziellen inkrementellen Updates von der Quelle zum Ziel auf Dateiebene durch. Die inkrementelle Aktualisierung ist eine oder mehrere der folgenden vier Vorgänge: Benennen Sie vorhandene Dateien und Ordner um, fügen Sie Daten an vorhandene Dateien an, löschen Sie Dateien und Ordner und enthalten zusätzliche Hard-, Soft- und Multilinks. Zu Testzwecken konzentrieren wir uns auf die Vorgänge Umbenennen, Anhängen, Löschen und Links. Mit anderen Worten: Für eine Million Dateien wurden Änderungsvorgänge wie Umbenennen, Anhängen und Löschen mit einer Änderungsrate von 10 % bis 90 % durchgeführt.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">Die folgende Abbildung zeigt die Ergebnisse des XCP-Kopiervorgangs.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">Die folgende Abbildung zeigt die Ergebnisse der XCP Sync-Umbenennung und -Verknüpfung.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">Die Dateigröße ist nicht propositionell zum<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Die Zeit zum Abschluss der Übertragung der umbenannten Quelldateien; die Diagramme sind linear.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">Die Verbindungstypen sind Soft Links, Hard Links und Multi-Links. Soft Links gelten als normale Dateien. Die Größe der Dateien ist für die Zeit zum Abschließen des XCP-Synchronisierungsvorgangs nicht relevant.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">Die folgenden Abbildungen zeigen die Ergebnisse der XCP-Sync-Prozesse zum Anhängen und Löschen.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">Beim Anhängen- und Löschvorgang nehmen große Dateigrößen mehr Zeit in Anspruch als kleine Dateigrößen. Die Zeit zum Abschließen des Vorgangs ist linear zum Prozentsatz der Änderungen an Anhängen und Löschen.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">Vergleich von XCP 1.6.1 mit XCP 1.5</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">Im Vergleich zu früheren Versionen bietet XCP 1.6.3 und 1.7 eine verbesserte Leistung. Der folgende Abschnitt zeigt einen synchronen Leistungsvergleich zwischen XCP 1.6.3 und 1.7 für 8K-, 16K- und 1MB-Größen von einer Million Dateien.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">Die folgenden Abbildungen zeigen die Ergebnisse der XCP-Synchronleistung für XCP 1.6.3 gegenüber 1.7 (mit einer Größe von 8K einer Million Dateien).</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">Die folgende Abbildung zeigt die Ergebnisse der XCP-Synchronleistung für XCP 1.6.1 gegenüber 1.5 (mit einer Größe von 16.000 Dateien).</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">Die folgende Abbildung zeigt die Ergebnisse der XCP-Sync-Leistung für XCP 1.6.1 gegenüber 1.5 mit einer Größe von 1 MB für eine Million Dateien.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">Im Durchschnitt verbesserte sich die XCP 1.7-Leistung an oder war ähnlich wie bei XCP 1.6.3 für die<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Differenzielles inkrementelles Update: Benennen, Anhängen, Verknüpfen und Löschen von Vorgängen mit einer Größe von 1 MB mit einer Million Dateien um.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">Aufgrund dieser Performance-Validierung empfiehlt NetApp den Einsatz von XCP 1.7 für die Datenmigration vor Ort und in der Cloud.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">Weiter: Performance-Tuning.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">Der Befehl in diesem Abschnitt lädt die Daten im CSV-Format ab. Sie können die Spalte „Größe“ zusammenfassen, um die Gesamtgröße der Daten zu erhalten.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">Erstellen einer CSV-Datei aus SMB/CIFS-Freigabe</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Zurück: Spezifische datumbasierte Scan und Kopie von Daten.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">Mit dem folgenden Befehl werden Daten im CSV-Format ablädt. Sie können die Spalte „Größe“ zusammenfassen, um die Gesamtgröße der Daten zu erhalten.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">Die Ausgabe sollte ähnlich wie bei diesem Beispiel aussehen:</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">Um bis in die Tiefe von drei Unterverzeichnissen zu scannen und das Ergebnis in Sortierreihenfolge bereitzustellen, führen Sie den aus<block ref="cadccce7ea0e7fd5923a57bff135b0f1" prefix=" " category="inline-code"></block> Befehl und Dump der Größe auf jeder Verzeichnisebene bis in die Tiefe von drei Unterverzeichnissen.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">Zum Sortieren geben Sie die Informationen in eine CSV-Datei ein und sortieren die Informationen.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">Dieser benutzerdefinierte Bericht verwendet den<block ref="3c8468c40f21d7ea04242771207b5d3e" prefix=" " category="inline-code"></block> Befehl. Er scannt alle Verzeichnisse und lädt den Namen des Verzeichnisses, Pfads und der Größe des Verzeichnisses in eine CSV-Datei ein. Sie können die Spalte Größe aus der Tabellenkalkulationsanwendung sortieren.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">Weiter: Datenmigration von 7-Mode zu ONTAP.</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Wo Sie weitere Informationen finden</block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">Zurück: Fehlerbehebung.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Daten finden Sie in den folgenden Dokumenten bzw. auf den folgenden Websites:</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP Blogs<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">Benutzerhandbuch für NetApp XCP<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">BigData Analytics-Daten an künstliche Intelligenz – Data Mover-Lösung für KI<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">Weiter: Versionsverlauf.</block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">Überblick</block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Früher: Performance Tuning.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">In diesem Abschnitt werden Kundenszenarien und ihre Architekturen beschrieben.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">In der nächsten Richtung: Data Lake auf ONTAP NFS</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">Dieser Abschnitt enthält ausführliche Schritte zur Migration der Daten von NetApp Data ONTAP im 7-Mode zu ONTAP.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">Datenmigration von 7-Mode zu ONTAP</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">Früher: Erstellen einer CSV-Datei aus SMB/CIFS-Freigabe.</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">Umstieg von 7-Mode NFSv3 Storage auf ONTAP für NFS-Daten</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">Dieser Abschnitt enthält die Schritt-für-Schritt-Anweisungen in der folgenden Tabelle für die Transition eines 7-Mode-Quellexports auf ein ONTAP-System.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp geht davon aus, dass das 7-Mode NFSv3 Quell-Volume exportiert und auf dem Client-System gemountet wird und dass XCP bereits auf einem Linux System installiert ist.</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">Vergewissern Sie sich, dass das Ziel-ONTAP-System ordnungsgemäß ist.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">Vergewissern Sie sich, dass mindestens ein nicht-Root-Aggregat im Zielsystem vorhanden ist. Das Aggregat ist normal.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">Wenn es kein Daten-Aggregat gibt, erstellen Sie mit dem ein neues<block ref="b83f9c30c432b834d5aa4c7b46881164" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">Erstellen einer Storage Virtual Machine (SVM) auf dem Ziel-Cluster-System</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">Entfernen Sie die Protokolle FCP, iSCSI, NDMP und CIDS aus der Ziel-SVM.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">Überprüfen Sie, ob NFS das zulässige Protokoll für diese SVM ist.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">Erstellung eines neuen Daten-Volumes für Lese- und Schreibvorgänge auf der Ziel-SVM Vergewissern Sie sich, dass der Sicherheitsstil, die Spracheinstellungen und die Kapazitätsanforderungen dem Quell-Volume entsprechen.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">Erstellen Sie eine Daten-LIF, um NFS-Client-Anforderungen bereitzustellen.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">Vergewissern Sie sich, dass das LIF erfolgreich erstellt wurde.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">Erstellen Sie bei Bedarf eine statische Route mit der SVM.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">Überprüfen Sie, ob die Route erfolgreich erstellt wurde.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">Das Ziel-NFS-Daten-Volume wird im SVM Namespace gemountet.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">Vergewissern Sie sich, dass das Volume erfolgreich angehängt ist.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">Sie können auch Mount-Optionen für Volumes (Verbindungspfad) mit dem festlegen<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">Starten Sie den NFS-Service für die Ziel-SVM.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">Stellen Sie sicher, dass der Dienst gestartet und ausgeführt wird.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">Vergewissern Sie sich, dass die standardmäßige NFS-Exportrichtlinie auf die Ziel-SVM angewendet wurde.</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">Falls erforderlich, erstellen Sie eine neue benutzerdefinierte Exportrichtlinie für die Ziel-SVM.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">Überprüfen Sie, ob die neue benutzerdefinierte Exportrichtlinie erfolgreich erstellt wurde.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">Ändern Sie die Exportrichtlinien, um den Zugriff auf NFS-Clients zu ermöglichen.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">Vergewissern Sie sich, dass der Client Zugriff auf das Volume gestattet ist.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Stellen Sie eine Verbindung zum Linux-NFS-Server her. Erstellen eines Mount-Punkts für das exportierte NFS-Volume</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">Mounten Sie das exportierte Ziel-NFSv3-Volume an diesem Bereitstellungspunkt.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">Die NFSv3 Volumes sollten exportiert, aber nicht unbedingt vom NFS Server gemountet werden. Wenn sie gemountet werden können, mountet der XCP Linux-Host-Client diese Volumes.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">Überprüfen Sie, ob der Bereitstellungspunkt erfolgreich erstellt wurde.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">Erstellen Sie eine Testdatei auf dem über NFS exportierten Mount-Punkt, um den Lese-/Schreibzugriff zu ermöglichen.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">Nachdem der Lese-/Schreib-Test abgeschlossen ist, löschen Sie die Datei vom Ziel-NFS-Bereitstellungspunkt.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">Stellen Sie eine Verbindung zum Linux-Client-System her, in dem XCP installiert ist. Navigieren Sie zum XCP-Installationspfad.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">Abfrage der 7-Mode-NFSv3-Exporte durch Ausführen des<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Befehl auf dem XCP Linux-Client-Host-System.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">Scannen Sie die exportierten Quellenpfade von NFSv3 und drucken Sie die Statistiken ihrer Dateistruktur.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">NetApp empfiehlt, die NFSv3 Exporte aus der Quelle während xcp in einen schreibgeschützten Modus zu versetzen<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, und<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> Betrieb:</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">Kopieren Sie die 7-Mode NFSv3 Exporte in NFSv3 Exporte auf dem ONTAP Ziel-System.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">Überprüfen Sie nach Abschluss der Kopie, ob die NFSv3 Exporte von Quelle und Ziel identische Daten haben. Führen Sie die aus<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">Wenn<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> Findet Unterschiede zwischen Quell- und Zieldaten, dann den Fehler<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> Wird in der Zusammenfassung gemeldet. Um dieses Problem zu beheben, führen Sie den aus<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Befehl zum Kopieren der Änderungen an der Quelle auf das Ziel.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">Führen Sie vor und während der Umstellung einen Durchlauf durch<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Ein weiteres Jahr in der Wenn die Quelle über neue oder aktualisierte Daten verfügt, führen Sie inkrementelle Updates durch. Führen Sie die aus<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">Um einen zuvor unterbrochenen Kopiervorgang fortzusetzen, führen Sie den aus<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">Nachher<block ref="69f2afc2390cec954f7c208b07212d39" prefix=" " category="inline-code"></block> Beendet das Kopieren von Dateien, Ausführen<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Auch hier sehen Sie wieder, dass Quell- und Ziel-Storage identische Daten haben.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">Der NFSv3 Client-Host muss die vom 7-Mode Storage bereitgestellten NFSv3 Quellexporte lösen und die Ziel-NFSv3-Exporte von ONTAP mounten. Bei der Umstellung ist ein Ausfall erforderlich.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">Umstieg von Volume Snapshot Kopien im 7-Mode auf ONTAP</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">In diesem Abschnitt wird das Verfahren zum Wechsel von NetApp Snapshot Kopien des 7-Mode Quell-Volumes zu ONTAP beschrieben.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp geht davon aus, dass das Quell-7-Mode Volume exportiert und auf dem Client-System gemountet wird und dass XCP bereits auf einem Linux System installiert ist. Eine Snapshot Kopie ist ein zeitpunktgenaues Image eines Volumes, das inkrementelle Änderungen seit der letzten Snapshot Kopie aufzeichnet. Verwenden Sie die<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Option mit einem 7-Mode System als Quelle.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">*Warnung:* behalten Sie die Basis-Snapshot Kopie. Löschen Sie die Snapshot-Basiskopie nicht, wenn die Basiskopie abgeschlossen ist. Für weitere Synchronisierungsvorgänge ist die Snapshot Basiskopie erforderlich.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">Erstellen einer SVM auf dem Ziel-Cluster-System</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">Entfernen Sie die Protokolle FCP, iSCSI, NDMP und CIFS aus der Ziel-SVM.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">Erstellen Sie bei Bedarf eine statische Route mit der SVM.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">Überprüfen Sie, ob das Volume erfolgreich angehängt wurde.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">Sie können auch die Mount-Optionen für Volumes (Verbindungspfad) mit dem festlegen<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">Vergewissern Sie sich, dass die standardmäßige NFS-Exportrichtlinie auf die Ziel-SVM angewendet wird.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">Ändern Sie die Exportrichtlinien, um den Zugriff auf NFS-Clients auf dem Zielsystem zu ermöglichen.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">Vergewissern Sie sich, dass der Client Zugriff auf das Ziel-Volume hat.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">NetApp empfiehlt, die Quell-NFSv3-Exporte während des Lese-Modus zu aktivieren<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, und<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> Betrieb: In<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> Operation, müssen Sie die übergeben<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Option mit einem entsprechenden Wert.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">Kopieren Sie den 7-Mode NFSv3 Snapshot (Basis) aus dem Quell-ONTAP-Zielsystem in NFSv3-Exporte.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">Nutzen Sie diesen Basis-Snapshot für weitere Synchronisierungsvorgänge.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">Nach Abschluss der Kopie überprüfen Sie, ob die Quell- und Ziel-NFSv3-Exporte identische Daten haben. Führen Sie die aus<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">Wenn<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Findet Unterschiede zwischen Quell- und Zieldaten, dann den Fehler<block ref="dc84cf44b83b105281c2d7846f1ed44f" prefix=" " category="inline-code"></block> Befehl zum Kopieren der Änderungen an der Quelle auf das Ziel.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">Führen Sie vor und während der Umstellung einen Durchlauf durch<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Ein weiteres Jahr in der Wenn die Quelle über neue oder aktualisierte Daten verfügt, führen Sie inkrementelle Updates durch. Wenn inkrementelle Änderungen vorliegen, erstellen Sie für diese Änderungen eine neue Snapshot Kopie und übergeben Sie diesen Snapshot-Pfad mit der<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Option für Synchronisierungsvorgänge.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">Führen Sie die aus<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Befehl mit dem<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Option und Snapshot Pfad.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">Für diesen Vorgang ist der Basis-Snapshot erforderlich.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">Der NFSv3 Client-Host muss die vom 7-Mode Storage bereitgestellten NFSv3 Quellexporte lösen und die Ziel-NFSv3-Exporte von ONTAP mounten. Diese Umstellung erfordert einen Ausfall.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">Migration von ACLv4 von NetApp 7-Mode zu einem NetApp Storage-System</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">In diesem Abschnitt wird das Schritt-für-Schritt-Verfahren zum Übergang eines NFSv4-Quellexports auf ein ONTAP-System beschrieben.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp geht davon aus, dass das NFSv4-Quell-Volume exportiert und auf dem Client-System gemountet wird und dass XCP bereits auf einem Linux-System installiert ist. Die Quelle sollte ein NetApp 7-Mode System sein, das ACLs unterstützt. Die ACL-Migration wird nur von NetApp zu NetApp unterstützt. Um Dateien mit einem besonderen Zeichen im Namen zu kopieren, stellen Sie sicher, dass die Quelle und das Ziel UTF-8 kodierte Sprache unterstützen.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">Voraussetzungen für die Migration eines NFSv4-Quellexports auf ONTAP</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">Bevor Sie einen NFSv4-Quellexport nach ONTAP migrieren, müssen die folgenden Voraussetzungen erfüllt sein:</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">Das Zielsystem muss NFSv4 konfigurieren.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">Die NFSv4-Quelle und das Ziel müssen auf dem XCP-Host gemountet werden. Wählen Sie NFS v4.0 aus, um den Quell- und Ziel-Storage anzupassen, und überprüfen Sie, ob die ACLs auf dem Quell- und Zielsystem aktiviert sind.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP erfordert, dass der Quell-/Zielpfad auf dem XCP-Host für die ACL-Verarbeitung gemountet wird.im folgenden Beispiel:<block ref="d07c77c05891b869ab2111118b006bed" prefix=" " category="inline-code"></block> Auf dem montiert ist<block ref="dfecb62ab540058a212419f33235e6da" prefix=" " category="inline-code"></block> Pfad:</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">Optionen für Unterverzeichnisse</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">Die zwei Optionen zur Arbeit mit Unterverzeichnissen sind wie folgt:</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">Damit XCP an einem Unterverzeichnis arbeiten kann<block ref="9ce87e1289284ccca8cf788db9dd7804" prefix=" " category="inline-code"></block>), montieren Sie den kompletten Weg <block ref="58753164ce38e8977360bb376dda6e76" prefix="(" category="inline-code"></block>) Auf dem XCP-Host.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">Wenn der komplette Pfad nicht angehängt ist, meldet XCP den folgenden Fehler:</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">Verwenden Sie die Syntax des Unterverzeichnisses <block ref="ca6c8952cf206b58c7fc63aa1552d665" prefix="(" category="inline-code"></block>), wie im folgenden Beispiel dargestellt:</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">Führen Sie die folgenden Schritte aus, um ACLv4 von NetApp 7-Mode auf ein NetApp Storage-System zu migrieren.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">Vergewissern Sie sich, dass die SVM erfolgreich erstellt wurde.</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">Vergewissern Sie sich, dass die standardmäßige NFS-Exportrichtlinie auf die Ziel-SVM angewendet wird.</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">Überprüfen Sie, ob die Richtlinienregeln geändert wurden.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">Mounten Sie das exportierte Ziel-Volume NFSv4 an diesem Bereitstellungspunkt.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">Die NFSv4-Volumes sollten exportiert, aber nicht unbedingt vom NFS-Server gemountet werden. Wenn sie gemountet werden können, mountet der XCP Linux-Host-Client diese Volumes.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">Überprüfen Sie, ob die Datei erstellt wurde.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">Fragen Sie die NFSv4-Quellexporte, indem Sie das ausführen<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Befehl auf dem XCP Linux-Client-Host-System.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">Scannen Sie die exportierten Quellpfade von NFSv4 und drucken Sie die Statistiken ihrer Dateistruktur.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">NetApp empfiehlt, die Quell-NFSv4-Exporte in den reinen Lese-Modus zu versetzen<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, und<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> Betrieb:</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">Quelle kopieren NFSv4-Exporte in NFSv4-Exporte auf dem Ziel-ONTAP-System.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">Nachher<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Vollständig ist. Überprüfen Sie, ob die Quell- und Ziel-NFSv4-Exporte identische Daten haben. Führen Sie die aus<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">Wenn<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Findet Unterschiede zwischen Quell- und Zieldaten, dann den Fehler<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> Wird in der Zusammenfassung gemeldet. Um dieses Problem zu beheben, führen Sie den aus<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Befehl zum Kopieren der Änderungen an der Quelle auf das Ziel.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">Für diesen Vorgang ist der Name oder die Nummer des vorherigen Kopie-Index erforderlich.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">Um einen zuvor unterbrochenen wieder aufzunehmen<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Führen Sie den aus<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">Umstieg von 7-Mode SMB Storage auf ONTAP für CIFS Daten</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">In diesem Abschnitt wird die Schritt-für-Schritt-Methode zum Wechsel einer 7-Mode SMB-Quell-Freigabe auf ein ONTAP System erläutert.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp geht davon aus, dass 7-Mode und ONTAP Systeme über eine SMB-Lizenz verfügen. Die Ziel-SVM wird erstellt, die SMB-Quell- und Ziel-Shares werden exportiert und XCP installiert und lizenziert.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">Scannen Sie die SMB-Freigaben für Dateien und Verzeichnisse.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">Kopieren Sie die Dateien (mit oder ohne ACL) von der Quelle in die SMB-Zielfreigabe. Das folgende Beispiel zeigt eine Kopie mit ACL.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">Wenn es kein Daten-Aggregat gibt, erstellen Sie ein neues unter Verwendung des Storage<block ref="a3c52ca282dcb77dd824f54a7b270068" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">Synchronisieren Sie die Dateien auf Quelle und Ziel.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">Überprüfen Sie, ob die Dateien korrekt kopiert wurden.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">Als Nächstes: CIFS-Datenmigration mit ACLs von einer Quell-Storage-Box zu ONTAP.</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">In diesem Abschnitt wird Schritt-für-Schritt-Verfahren zur Migration von CIFS-Daten mit Sicherheitsinformationen von einer Quelle auf ein ONTAP Ziel-System erläutert.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">CIFS-Datenmigration mit ACLs von einer Quell-Storage-Box zu ONTAP</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Früher: Datenmigration von 7-Mode zu ONTAP.</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">Erstellen Sie eine Daten-LIF, um SMB-Client-Anforderungen zu erfüllen.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">Mounten des Ziel-Daten-Volumes im SVM Namespace</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">Starten Sie den CIFS-Service auf der Ziel-SVM.</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">Vergewissern Sie sich, dass die standardmäßige Exportrichtlinie auf die Ziel-SVM angewendet wird.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">Ändern Sie die Regeln für die Exportrichtlinie, um den Zugriff auf CIFS-Clients zu ermöglichen.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">Überprüfen Sie, ob die Richtlinienregeln geändert werden.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">Stellen Sie eine Verbindung zum Windows-Client-System her, auf dem XCP installiert ist. Navigieren Sie zum XCP-Installationspfad.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">Fragen Sie den SMB-Export des Quell-Knotens ab, indem Sie den ausführen<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Befehl auf dem XCP Windows-Client-Host-System.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">Führen Sie die aus<block ref="657f8b8da628ef83cf69101b6817150a" prefix=" " category="inline-code"></block> Befehl für Kopie.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">Im ONTAP-Zielsystem erhalten Sie eine Liste der lokalen Benutzer- und lokalen Gruppennamen, die Sie als Werte für die angeben müssen<block ref="7a80adbcbc4a0b2e96e8eb2710f30c85" prefix=" " category="inline-code"></block> Und<block ref="8d03d04d9c44ec2988a893826753f985" prefix=" " category="inline-code"></block> Argumente Pfad.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">Um die CIFS-Daten mit ACLs von Quelle zu Ziel zu migrieren, führen Sie den aus<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Befehl mit dem<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> Und<block ref="a72a6079b50973fd59860e6635a4ea62" prefix=" " category="inline-code"></block> Optionen:</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">Für das<block ref="a3fe89370a4bb214c60bfe40074b2c43" prefix=" " category="inline-code"></block> Optionen: Geben Sie einen beliebigen Benutzer oder eine Gruppe an, der in Active Directory oder lokalen Benutzern/Gruppen zum Zielsystem gefunden werden kann.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">Wenn<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Die Fehlermeldung wird angezeigt<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block>, Fügen Sie das Zielfeld in die Hosts-Datei hinzu <block ref="803976de87f6862821bd3c4d94e0ff2b" prefix="(" category="inline-code"></block>).</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">Verwenden Sie das folgende Format für die Eingabe des Speicherzielfelds.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">Wenn Sie immer noch die Fehlermeldung erhalten<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block> Nach dem Hinzufügen des Zielfeld-Eintrags in den Hosts-Dateien ist der Benutzer/die Gruppe nicht im Zielsystem vorhanden.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">Nutzung<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> CIFS-Daten mit ACLs migrieren (mit oder ohne den Stammordner).</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">Führen Sie ohne den Stammordner folgende Befehle aus:</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">Führen Sie im Stammordner folgende Befehle aus:</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">Als Nächstes: Best Practice-Richtlinien und -Empfehlungen.</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">Dieser Abschnitt enthält Best Practices, Richtlinien und Empfehlungen für die Datenmigration mit NetApp XCP.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">Best Practice-Richtlinien und -Empfehlungen</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">Früher: CIFS-Datenmigration mit ACLs von einer Quell-Storage Box zu ONTAP.</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">Verwenden Sie das XCP-Client-Betriebssystem, das von IMT unterstützt wird. Der von IMT unterstützte Client wird von NetApp qualifiziert.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Führen Sie XCP als Root-Benutzer im Linux-Betriebssystem aus, um die Migration durchzuführen. Sie können den xcp-Befehl als Sudo-Benutzer ausführen, er wird jedoch nicht von XCP unterstützt.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">Führen Sie nur eine Instanz von XCP pro Client aus. Technisch können Sie mehrere Versionen von XCP auf demselben Host von einem anderen Standort aus ausführen, dies ist jedoch keine unterstützte Vorgehensweise. In der Tat kann das Ausführen vieler Instanzen zu einem Ausfall führen.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">In der aktuellen XCP-Version wird Live Source nicht unterstützt. Wenn das NetApp Quell-Volume aktiv ist und fortlaufend durch Applikationen und Benutzer geändert wird, sollten Sie einen Snapshot des Quell-Volumes erstellen, um eine Migration durchzuführen.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">Als Best Practice empfiehlt es sich, einen neuen Snapshot mit einem anderen Namen für jede inkrementelle Synchronisierung zu erstellen, sodass es einfach ist, einen inkrementellen Migrationspfad basierend auf dem Snapshot-Namen bei Ausfall zu erstellen.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Wenn Sie eine Snapshot-basierte Migration durchführen, empfiehlt es sich, die Snapshot-basierte Migration bis zur Umstellung fortzusetzen.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">Wenn Sie mehr als 10 Millionen Dateien haben und eine inkrementelle Datenänderung von mehr als 50 % haben, empfiehlt es sich, eine höhere Anzahl an Kernen und mehr Speicher zu verwenden als die minimale Empfehlung im Installations- und Administrationshandbuch.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">Weiter: Fehlerbehebung.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">Zur Migration der Daten von GPFS zu NFS verwendeten wir NetApp XCP, sodass GPUs die Daten verarbeiten können. Die KI verarbeitet typischerweise Daten aus einem Netzwerkdateisystem.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">High-Performance-Computing für ONTAP NFS</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">Früher: Data Lake auf ONTAP NFS.</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">Dieser Nutzungsfall basiert auf Anfragen von Field Organisations. Einige NetApp Kunden besitzen ihre Daten in einer High-Performance-Computing-Umgebung, die Datenanalysen für Trainingsmodelle bietet und Forschungseinrichtungen dabei unterstützt, mehr Einblicke und ein besseres Verständnis für große Mengen digitaler Daten zu gewinnen. NetApp Field Engineers benötigen ein detailliertes Verfahren, um die Daten aus IBM GPFS zu NFS zu extrahieren. Zur Migration der Daten von GPFS zu NFS verwendeten wir NetApp XCP, sodass GPUs die Daten verarbeiten können. Die KI verarbeitet typischerweise Daten aus einem Netzwerkdateisystem.</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">Weitere Informationen zum Anwendungsfall „High-Performance Computing für ONTAP NFS“, eine aufgezeichnete Demo und Testergebnisse finden Sie im<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog:</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">Detaillierte Schritte zum Verschieben von MapR-FS-Daten in ONTAP-NFS mithilfe von NetApp XCP finden Sie in Anhang A: GPFS zu NFS―Detaillierte Schritte in<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">Weiter: Mit dem XCP Data Mover migrieren Sie Millionen von kleinen Dateien auf flexiblen Speicher.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">Dieser Abschnitt behandelt die Implementierungsschritte für NetApp XCP für den Datentransfer.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">Implementierungsschritte</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">Früher: Dateianalysen.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">Angaben zum Testbett</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">Die folgende Tabelle enthält Details zur Testumgebung, die für diese Implementierung und zur Performance-Validierung verwendet wurde.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Lösungskomponenten</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Details</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP Version 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Ein Linux-Server – Linux (RHEL 7.9 oder RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Ein Windows-Server – Windows Server 2019-Standard</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">NetApp AFF Storage Array HA-Paar für das Quell-Volume</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="list-text">NetApp ONTAP 9</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS-Protokoll</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">NetApp AFF Storage Array HA-Paar für Ziel-Volume</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="list-text">AFF A800</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 Server</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">Jeweils mit * 48 CPUs * Intel Xeon * 256 GB physischer Speicher * 10 GbE Dual Port</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Netzwerkbetrieb</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10 GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">Implementierungsschritte – NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">NetApp XCP - Benutzerhandbuch</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">Um NetApp XCP für den Datentransfer zu implementieren, installieren und aktivieren Sie zuerst die XCP-Software am Zielspeicherort. Sie können die Details im anzeigen<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. Um das zu tun, führen Sie folgende Schritte aus:</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">„Voraussetzungen für XCP“.</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">Erfüllen Sie die im Abschnitt beschriebenen Voraussetzungen <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">Seite „NetApp XCP“ (Downloads</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">Laden Sie die XCP-Software aus dem herunter<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">Kopieren Sie die heruntergeladenen XCP tar-Dateien auf den XCP-Server.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">Enttar die Tarfile.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">Laden Sie die Lizenz von herunter<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> Und auf den XCP-Server kopieren.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">Aktivieren Sie die Lizenz.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">Suchen Sie den NFS-Quell-Port und den Ziel-NFS-Server. Der Standardport ist 2049.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">Überprüfen Sie die NFS-Verbindung. Prüfen Sie den NFS-Server (Quelle und Ziel) über Telnet auf den NFS-Server-Port.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">Konfigurieren Sie den Katalog.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">NFS-Volume erstellen und NFS für den XCP-Katalog exportieren Sie können auch den NFS-Export des Betriebssystems für den XCP-Katalog nutzen.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">Überprüfen Sie den NFS-Export.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">Aktualisierung<block ref="d509f49d5d9a07934f91eefcf45a7334" prefix=" " category="inline-code"></block>.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">Finden Sie die NAS-Quellexporte mithilfe von<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block>. Achten Sie auf:</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(Optional) Scannen Sie die NAS-Quell-Daten.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">Durch das Scannen der NAS-Quelldaten können Sie das Datenlayout verstehen und mögliche Probleme bei der Migration erkennen. Die XCP-Scanbetriebszeit ist proportional zur Anzahl der Dateien und der Verzeichnistiefe. Sie können diesen Schritt überspringen, wenn Sie mit Ihren NAS-Daten vertraut sind.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">Prüfen Sie den von erstellten Bericht<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>. Suchen Sie hauptsächlich nach unlesbaren Ordnern und unlesbaren Dateien.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(Optional) Ändern Sie die Inode. Zeigen Sie die Anzahl der Inodes an, und ändern Sie die Zahl basierend auf der Anzahl der zu migrierenden Dateien oder für Katalog- und Zielvolumes (falls erforderlich).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">Scannen Sie das Zielvolumen.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">Überprüfen Sie den Speicherplatz des Quell- und Zielvolumens.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">Kopieren Sie die Daten von der Quelle zum Ziel mithilfe von<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Und prüfen Sie die Zusammenfassung.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">Standardmäßig erstellt XCP sieben parallele Prozesse zum Kopieren der Daten. Das kann abgestimmt werden.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">NetApp empfiehlt, das Quell-Volume nur mit Lesezugriff zu verwenden. In Echtzeit ist das Quell-Volume ein aktives, aktives File-System. Der<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Der Betrieb kann fehlschlagen, da NetApp XCP keine Live-Quelle unterstützt, die fortlaufend von einer Applikation geändert wird.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Für Linux benötigt XCP eine Index-ID, da XCP Linux Katalogisierung durchführt.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(Optional) Prüfen Sie die Inodes auf dem NetApp Ziel-Volume.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">Führen Sie die inkrementelle Aktualisierung mithilfe von durch<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">Für dieses Dokument wurden zur Simulation in Echtzeit die einer Million Dateien in den Quelldaten umbenannt und die aktualisierten Dateien mit auf das Ziel kopiert<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>. Für Windows benötigt XCP sowohl Quell- als auch Zielpfade.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">Validieren des Datentransfers Sie können überprüfen, ob Quell- und Zielspeicherort die gleichen Daten aufweisen, indem Sie sie mit verwenden<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block>.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">Die XCP-Dokumentation bietet für das mehrere Optionen (mit Beispielen)<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>,<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block>, und<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> Betrieb: Weitere Informationen finden Sie im<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows Kunden sollten die Daten mithilfe von Zugriffssteuerungslisten kopieren. NetApp empfiehlt, den Befehl zu verwenden<block ref="1b5d03dc1e4b5c3623897fd210394888" prefix=" " category="inline-code"></block>. Um eine maximale Performance zu gewährleisten, muss es sich bei dem Quell-Volume mit SMB-Daten mit ACL und den für NFS und SMB zugänglichen Daten um ein NTFS-Volume handelt. Kopieren Sie die Daten mithilfe von XCP (NFS-Version) vom Linux-Server, und führen Sie die XCP-Synchronisierung (SMB-Version) mit dem aus<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> Und<block ref="0e638f18c7569b1e062f20f430b0a5fc" prefix=" " category="inline-code"></block> Optionen vom Windows Server zum Kopieren der ACLs aus Quelldaten in die SMB Zieldaten</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">Konfigurieren der Richtlinie „Manage Auditing and Security Log“</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">Ausführliche Schritte finden Sie unter<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">Implementierungsschritte – HDFS/MapRFS Datenmigration</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">In diesem Abschnitt gehen wir auf die neue XCP Funktion Hadoop Filesystem Data Transfer to NAS ein, die Daten von HDFS/MapRFS zu NFS migriert und umgekehrt.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Voraussetzungen</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">Für die MapRFS/HDFS-Funktion müssen Sie in einer nicht-Root-Benutzerumgebung das folgende Verfahren ausführen. Normalerweise ist der nicht-Root-Benutzer hdfs, mapr oder ein Benutzer, der über die Berechtigung verfügt, Änderungen im HDFS- und MapRFS-Dateisystem vorzunehmen.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">Legen Sie die Variablen CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH und NHDFS_LIBHDFS_PATH in der CLI oder in der .bahrc-Datei zusammen mit dem fest<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_PATH zeigt auf die Datei libhdfs.so. Diese Datei bietet HDFS APIs zum Interagieren und Bearbeiten von HDFS/MapRFS-Dateien und Dateisystemen im Rahmen der Hadoop-Distribution.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH zeigt auf die Datei libjvm.so. Dies ist eine gemeinsam genutzte JAVA Virtual Machine Library im jre-Speicherort.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH weist auf alle JARS-Dateien hin, die (Hadoop classpath –glob) Werte verwenden.</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_LIBRARY_PATH weist auf den Ordner für die native Hadoop Bibliothek hin.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Das folgende Beispiel basiert auf einem Cloudera Cluster.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">In dieser Version unterstützen wir XCP-Scans, Kopieren und Verifizierung der Betriebsabläufe und Datenmigration von HDFS zu NFS. Daten können von einem Data Lake Cluster mit einem einzelnen Worker-Node und mehreren Worker-Nodes übertragen werden. In Version 1.8 können Root-Benutzer und Benutzer anderer Benutzer Daten migrieren.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">Implementierungsschritte – nicht-Root-Benutzer migrieren HDFS/MaprFS-Daten zu NetApp NFS</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">Folgen Sie den gleichen Schritten, die aus 1-9 Schritten im Abschnitt zur Implementierung genannt wurden.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">Im folgenden Beispiel migriert der Benutzer Daten von HDFS zu NFS.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">Erstellen Sie einen Ordner und Dateien (mit<block ref="f45bd8fcd9fdd879ec3b59c5cb0cf396" prefix=" " category="inline-code"></block>) In HDFS.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">Prüfen Sie die Berechtigungen im HDFS-Ordner.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">Erstellen Sie einen Ordner in NFS und prüfen Sie die Berechtigungen.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">Kopieren Sie die Dateien von HDFS zu NFS mithilfe von XCP, und prüfen Sie die Berechtigungen.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">Als Nächstes: Richtlinien zur Dimensionierung.</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">NetApp Lösungen sind eine Reihe von strategischen und technologischen Funktionen, die das NetApp Portfolio an Produkten und Services herausstellen, um die wichtigsten geschäftlichen Anforderungen unserer Kunden zu unterstützen.</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">NetApp Lösungen</block>
  <block id="a479dadc1f089681ec4db29c16fec163" category="doc">TR-4810: NetApp ONTAP und Lenovo ThinkSystem SR670 für KI- und ML-Modell Training-Workloads</block>
  <block id="5ebb854a0e7b0964891f587bfc1d231a" category="paragraph">Karthikeyan Nagalingam, NetApp Miroslav Hodak, Lenovo</block>
  <block id="17f161066b709ea249da0f86319938b3" category="paragraph">TR-4810 beschreibt eine kostengünstige Computing- und Storage-Architektur der Einstiegsklasse zur Implementierung von GPU-basiertem künstlicher Intelligenz (KI) Training auf NetApp Storage-Controllern und Lenovo ThinkSystem Servern. Das Setup dient als gemeinsam genutzte Ressource für kleine bis mittlere Teams, die mehrere Trainingsaufträge parallel ausführen.</block>
  <block id="44daeb1185bf6a8c6c548cc1df101795" category="paragraph">TR-4810 bietet Performance-Daten für die branchenübliche MLPerf-Benchmark, bei der das Training zur Bildklassifizierung mit TensorFlow auf V100 GPUs bewertet wird. Zur Messung der Performance haben wir ResNet50 mit dem ImageNet-Datensatz, einer Batch-Größe von 512, Half Precision, CUDA und cuDNN verwendet. Wir haben diese Analyse mit SR670 Servern mit vier GPUs und einem NetApp Storage-System der Einstiegsklasse durchgeführt. Die Ergebnisse zeigen eine äußerst effiziente Performance über die hier getesteten Anwendungsbeispiele―gemeinsam genutzte, Multiuser- und Multijob-Fälle, wobei einzelne Jobs auf bis zu vier Server skaliert werden. Große Scale-out-Jobs waren weniger effizient, aber dennoch machbar</block>
  <block id="6f6e299cb7d6645bd11115fbed7ce551" category="inline-link-macro"><block ref="6f6e299cb7d6645bd11115fbed7ce551" category="inline-link-rx"></block></block>
  <block id="8eaaf4ccaaaec94b575ee16254ad49c1" category="paragraph"><block ref="8eaaf4ccaaaec94b575ee16254ad49c1" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">Das NetApp DataOps Toolkit für Kubernetes abstrahiert Storage-Ressourcen und Kubernetes-Workloads bis auf die Ebene des Data Science Workspace. Diese Funktionen sind in einer einfachen, benutzerfreundlichen Oberfläche zusammengestellt, die für Data Scientists und Data Engineers konzipiert wurde.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">Datensatz- und Modellversionierung mit NetApp DataOps Toolkit</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">Früher: Monitor Dask and RAPIDS mit Prometheus und Grafana.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">Das NetApp DataOps Toolkit für Kubernetes abstrahiert Storage-Ressourcen und Kubernetes-Workloads bis auf die Ebene des Data Science Workspace. Diese Funktionen sind in einer einfachen, benutzerfreundlichen Oberfläche zusammengestellt, die für Data Scientists und Data Engineers konzipiert wurde. Mit der bekannten Form eines Python-Programms ermöglicht das Toolkit Data Scientists und Ingenieuren die Bereitstellung und Zerstörung von JupyterLab-Arbeitsbereichen in nur wenigen Sekunden. Diese Workspaces können Storage-Kapazität im Terabyte- oder sogar Petabyte-Bereich enthalten. Data Scientists können all ihre Trainingsdatensätze direkt in ihren Projektarbeitsbereichen speichern. Die Tage für das separate Management von Workspaces und Daten-Volumes sind vorbei.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub Repository</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">Weitere Informationen finden Sie im Toolkit<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">Weiter: Fazit.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="doc">Installation Von Trident</block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">Früher: Peer AKS vnet und Azure NetApp Files vnet.</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">So installieren Sie Trident mithilfe von Helm:</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">Quelle</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Installieren Sie Helm (Installationsanweisungen finden Sie im<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>).</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Laden Sie das Trident 20.01.1-Installationsprogramm herunter und extrahieren Sie es.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">Ändern Sie das Verzeichnis in<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block>.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">Kopieren<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> In ein Verzeichnis im System<block ref="b6aef5812b57b2270b8146870910b1d3" prefix=" " category="inline-code"></block>.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Installation von Trident auf dem Kubernetes (K8s) Cluster mit Helm (<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>):</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">Ändern Sie das Verzeichnis in<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> Verzeichnis.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Installation Von Trident:</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Überprüfen Sie den Status von Trident Pods.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">Wenn alle Pods betriebsbereit sind, ist Trident installiert und Sie können weitergehen.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">Richten Sie das Azure NetApp Files Backend und die Speicherklasse für AKS ein.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Erstellen eines Azure-Service-Prinzips.</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">Der Service-Principal ist die Art, wie Trident mit Azure kommuniziert, um die Azure NetApp Files-Ressourcen zu manipulieren.</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">Die Ausgabe sollte wie im folgenden Beispiel aussehen:</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Erstellen einer json-Datei mit dem Trident-Back-End, Beispielname<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block>.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">Füllen Sie mithilfe Ihres bevorzugten Texteditors die folgenden Felder im aus<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">Ersetzen Sie die folgenden Felder:</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text"><block ref="8c443e170595ba0feac007ffb92cb49a" prefix="" category="inline-code"></block>. Ihre Azure Abonnement-ID.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text"><block ref="bc54592d6183695b841c6d1880ec0bf8" prefix="" category="inline-code"></block>. Ihre Azure Mandanten-ID von der Ausgabe von<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> Im vorherigen Schritt.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text"><block ref="93c5bebdea9c94a0740fe6fd9bb250f0" prefix="" category="inline-code"></block>. Ihre appID von der Ausgabe von<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> Im vorherigen Schritt.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text"><block ref="2b53761249254ce6b502f521e5cc0683" prefix="" category="inline-code"></block>. Ihr Kennwort für die Ausgabe von<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> Im vorherigen Schritt.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">Weisen Sie Trident an, das Azure NetApp Files-Backend im zu erstellen<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> Namespace mit<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> Als Konfigurationsdatei:</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">Erstellen Sie eine Speicherklasse. Kubernetes Benutzer stellen Volumes mithilfe von PVCs bereit, die eine Storage-Klasse nach Namen angeben. Weisen Sie K8s an, eine Speicherklasse zu erstellen<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Damit wird auf das im vorherigen Schritt erstellte Trident Back-End Bezug gezogen.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">Erstellen Sie ein YAML <block ref="330e60441e96769dd29fd0a282d4f84a" prefix="(" category="inline-code"></block>) Datei für Speicherklasse und kopieren.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">Überprüfen Sie, ob die Speicherklasse erstellt wurde.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">Als Nächstes: „Dask with RAPIDS Deployment“ auf AKS mit Helm einrichten.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Um einen Single-Node-KI- und -ML-Job in Ihrem Kubernetes-Cluster auszuführen, führen Sie die Aufgaben auf dieser Seite vom Bereitstellungs-Jump-Host aus.</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">Single-Node-KI-Workload ausführen</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Um einen Single-Node-KI- und -ML-Job in Ihrem Kubernetes-Cluster auszuführen, führen Sie die folgenden Aufgaben vom Bereitstellungs-Jump-Host aus: Mit Trident lässt sich ein Daten-Volume schnell und einfach erstellen, das möglicherweise mehrere Petabyte an Daten enthält und damit für Kubernetes-Workloads zugänglich ist. Wenn ein solches Daten-Volume über einen Kubernetes Pod zugänglich sein soll, geben Sie in der Pod-Definition einfach ein PVC an. Dieser Schritt ist ein nativer Kubernetes-Betrieb. Es ist kein NetApp Fachwissen erforderlich.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">In diesem Abschnitt wird vorausgesetzt, dass Sie bereits den spezifischen KI- und ML-Workload in einem Container (im Docker Container-Format) bereitstellen, den Sie in Ihrem Kubernetes-Cluster ausführen möchten.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet-Website</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">Die folgenden Beispielbefehle zeigen die Erstellung eines Kubernetes-Jobs für einen TensorFlow Benchmark-Workload, bei dem der ImageNet-Datensatz verwendet wird. Weitere Informationen zum ImageNet-Datensatz finden Sie im<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Dieses Beispieljob fordert acht GPUs an und kann daher auf einem einzelnen GPU-Worker-Node mit acht oder mehr GPUs ausgeführt werden. Dieser Beispieljob kann in einem Cluster eingereicht werden, für den ein Worker-Node mit acht oder mehr GPUs nicht vorhanden ist oder derzeit mit einem anderen Workload belegt ist. Wenn dies der Fall ist, bleibt der Job in einem ausstehenden Status, bis ein solcher Worker-Node verfügbar ist.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Offizielle Kubernetes-Dokumentation</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">Zusätzlich wird das Volume, das die erforderlichen Trainingsdaten enthält, zur Maximierung der Storage-Bandbreite zweimal innerhalb des POD angehängt, das diesen Job erstellt. Ein weiteres Volume wird ebenfalls im POD gemountet. Dieses zweite Volume wird zur Speicherung der Ergebnisse und Kennzahlen verwendet. Diese Volumes werden in der Jobdefinition unter Verwendung der Namen der VES referenziert. Weitere Informationen zu Kubernetes-Jobs finden Sie im<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">An<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Volumen mit einem<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> Der Wert von<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> Ist in angehängt<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> In dem POD, den dieser Beispieljob erzeugt. Die Standardgröße des<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Das virtuelle Volume, das automatisch durch die Docker Container-Laufzeit erstellt wird, kann manchmal nicht ausreichen, um die Anforderungen von TensorFlow zu erfüllen. Montage an<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Das Volumen wie im folgenden Beispiel bietet eine ausreichend große Menge<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Virtuelles Volume: Finden Sie weitere Informationen zu<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> Volumes, siehe<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Der einzelne Container, der in dieser Beispieljobdefinition angegeben wird, wird als angegeben<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> Der Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Dieser Wert bedeutet, dass der Container effektiv Root-Zugriff auf dem Host hat. Diese Annotation wird in diesem Fall verwendet, da der spezifische Workload ausgeführt wird und den Root-Zugriff erfordert. Insbesondere für einen Vorgang mit klarem Cache, der von dem Workload ausgeführt wird, ist ein Root-Zugriff erforderlich. Ob oder nicht<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> Eine Anmerkung ist erforderlich, abhängig von den Anforderungen des spezifischen Workloads, die Sie ausführen.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Vergewissern Sie sich, dass der in Schritt 1 erstellte Job korrekt ausgeführt wird. Der folgende Beispielbefehl bestätigt, dass für den Job ein einzelner Pod erstellt wurde, wie in der Jobdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Worker-Nodes ausgeführt wird.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Bestätigen Sie, dass der in Schritt 1 erstellte Job erfolgreich abgeschlossen wurde. Mit den folgenden Beispielbefehlen wird bestätigt, dass der Job erfolgreich abgeschlossen wurde.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Optional:* Aufräumen von Auftragsartefakten. Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 1 erstellten Jobobjekts.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Wenn Sie das Jobobjekt löschen, löscht Kubernetes automatisch alle zugehörigen Pods.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">Als Nächstes: Synchronen, verteilten KI-Workload ausführen</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">Zuweisung von fraktionalen GPUs für weniger anspruchsvolle oder interaktive Workloads</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">Wenn Forscher und Entwickler an ihren Modellen arbeiten, sei es in der Entwicklung, im Hyperparameter-Tuning oder in der Debugging-Phase, sind für solche Workloads in der Regel weniger Computing-Ressourcen erforderlich. Daher ist es effizienter, fraktionale GPU und Speicher so bereitzustellen, dass dieselbe GPU gleichzeitig anderen Workloads zugewiesen werden kann. Run:die KI-Orchestrierungslösung bietet ein fraktionaler GPU-Sharing-System für Container-Workloads auf Kubernetes. Das System unterstützt Workloads mit CUDA-Programmen und eignet sich insbesondere für schlanke KI-Aufgaben wie Inferenz und Modellbau. Das fraktionale GPU-System ermöglicht Data-Science- und KI-Engineering-Teams die gleichzeitige Ausführung mehrerer Workloads auf einer einzelnen GPU. Auf diese Weise können Unternehmen mehr Workloads ausführen, wie Computervision, Spracherkennung und natürliche Sprachverarbeitung auf derselben Hardware, wodurch sich die Kosten senken lassen.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">Run:das fraktionale GPU-System von AI erstellt effektiv virtualisierte logische GPUs mit eigenem Speicher und Computerraum, den Container nutzen und so zugreifen können, als wären sie eigenständige Prozessoren. So können mehrere Workloads in Containern parallel auf derselben GPU ausgeführt werden, ohne dass sie sich gegenseitig stören. Die Lösung ist transparent, einfach und tragbar und erfordert keine Änderungen an den Containern selbst.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">Eine typische Usease könnte zwei bis acht Jobs auf derselben GPU sehen, was bedeutet, dass Sie die achtfache Arbeit mit der gleichen Hardware erledigen können.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">Für den Job<block ref="9ee74d566135099889c5305d14349d44" prefix=" " category="inline-code"></block> Zu Projekt gehören<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Die folgende Abbildung zeigt, dass die Anzahl der zugewiesenen GPUs 0.50 war. Dies wird weiter durch die überprüft<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Befehl, der zeigt, dass der für den Container verfügbare GPU-Speicher 16,255 MB betrug: Die Hälfte der 32 GB pro V100 GPU im DGX-1-Node.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">Nächster Schritt: Hohe Cluster-Auslastung mit GPU-Zuweisung über Kontingente</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Dieser Abschnitt erläutert die Validierungsumgebung für das Lösungsdesign.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Testkonfiguration</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">Früher: Test- und Validierungsplan.</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">In folgender Tabelle wird die Validierungsumgebung für das Lösungsdesign beschrieben.</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Komponente</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">CSI-Treiber von NetApp Astra Trident</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">NetApp DataOps Toolkit für Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="cell">NVIDIA Triton Inferenz Server</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">Weiter: Testverfahren.</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Zusammenfassung</block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">Dieser technische Bericht bietet Richtlinien für Kunden mit kleinen bis großen Data-Science-/Engineering-Teams, um die Kubernetes-Cluster- und GPU-Auslastung über die Run:AI CLI und das System-Dashboard auf NetApp ONTAP AI zu optimieren. Dazu gehören u. a. Run:AI-Plattforminstallationsinformationen, Testszenarien und detaillierte Befehle für validierte Testfälle. Die Run:KI-Orchestrierungslösung beschleunigt gemeinsam mit der NetApp KI Control Plane die Innovationsgeschwindigkeit und steigert die Produktivität der Entwickler durch optimale Ressourcenauslastung.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">Weiter: Zusammenfassung</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis-Bereitstellung</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis Early Access-Programm</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">Sie können sich anmelden für<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> Um Zugriff auf Jarvis-Container auf NVIDIA GPU Cloud (NGC) zu erhalten. Nachdem Sie die Anmeldedaten von NVIDIA erhalten haben, können Sie Jarvis mithilfe der folgenden Schritte bereitstellen:</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">Anmelden bei NGC</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">Setzen Sie Ihr Unternehmen auf NGC:<block ref="7aa2b5d0d3058d0080d19281dc9d071c" prefix=" " category="inline-code"></block>.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Lokalisieren Sie Jarvis EA v0.2 Assets: Jarvis Container sind in<block ref="57383b3fa3bf1fe40b83355ea69945df" prefix=" " category="inline-code"></block> &gt;<block ref="15ce31151446746acfe9a6cb94ac5cbe" prefix=" " category="inline-code"></block>.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">Wählen Sie Jarvis: Navigieren Sie zu<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> Und klicken<block ref="29a846043a00b3f8b78a15edcb8ac726" prefix=" " category="inline-code"></block></block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">Überprüfen Sie, ob alle Ressourcen ordnungsgemäß funktionieren.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">Finden Sie die Dokumentation zum Erstellen Ihrer eigenen Anwendungen: PDFs finden Sie unter<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> &gt;<block ref="4ce995c78680dc78d6a0745744c2811b" prefix=" " category="inline-code"></block> &gt;<block ref="b8c128190e09e6c57a1df2180e8c73fb" prefix=" " category="inline-code"></block>.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">Weiter: Passen Sie die Staaten und Abläufe für den Einzelhandel an</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Sie können das für die Validierung verwendete Setup an andere Anwendungsfälle anpassen.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Optionen zur Dimensionierung der Architektur</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">Zurück: Testergebnisse.</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Computing Server</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Wir haben eine Intel Xeon D-2123IT CPU mit vier physischen Kernen und 60 W TDP verwendet, die in SE350 die niedrigste CPU-Stufe unterstützt. Der Server unterstützt zwar keinen Austausch von CPUs, kann aber mit einer leistungsstärkeren CPU bestellt werden. Die wichtigste unterstützte CPU ist Intel Xeon D-2183IT mit 16 Kernen, 100 W mit 2,20 GHz. Dadurch erhöht sich die CPU-Rechenleistung erheblich. Während die CPU keinen Engpass mehr für die Ausführung der Inferenz-Workloads darstellt, hilft sie bei der Datenverarbeitung und anderen Vorgänge im Zusammenhang mit Inferenz. Derzeit ist NVIDIA T4 die einzige GPU für Edge-Anwendungsfälle und ist daher derzeit keine Möglichkeit, die GPU zu aktualisieren oder herunterzustufen.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Shared Storage</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">Das NetApp AFF C190 System mit einer maximalen Storage-Kapazität von 50,5 TB, einem Durchsatz von 4,4 GB/s bei sequenziellem Lesen und 230.000 IOPS für kleine zufällige Lesevorgänge wurde in diesem Dokument eingesetzt. Es hat sich als gut für Edge-Inferenz-Workloads erwiesen.</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="inline-link">NetApp AFF A250</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">Wenn Sie jedoch mehr Storage-Kapazität oder schnellere Netzwerkgeschwindigkeiten benötigen, sollten Sie das NetApp AFF A220 oder<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> Storage-Systeme. Außerdem wurde das NetApp EF280 System mit einer maximalen Kapazität von 1,5 PB und einer Bandbreite von 10 GB/s im Rahmen dieser Lösungsvalidierung ebenfalls verwendet. Wenn Sie mehr Storage-Kapazität mit höherer Bandbreite bevorzugen,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> Kann verwendet werden.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Weitere Informationen</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">Folgende Ressourcen enthalten ausführlichere Informationen zu den Angaben in diesem Dokument:</block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, V100 GPU, GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX Station<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor Core GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="list-text">NVIDIA Jarvis Multimodal Framework</block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis Early Access<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="list-text">NVIDIA Nemo</block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">Entwicklerhandbuch<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">NetApp AFF Systeme</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A-Series – Datenblatt<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">NetApp Flash Advantage für All Flash FAS<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 Informationsbibliothek<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">Technischer Bericht zu NetApp ONTAP FlexGroup Volumes<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="list-text">NetApp ONTAP AI</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Cisco Networking<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">ONTAP AI mit DGX-1 und Cisco Networking Deployment Guide<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Mellanox Networking<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-2<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise with NetApp and VMware – Technology Overview</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Technologischer Überblick</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA AI Enterprise</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise ist eine End-to-End-Suite mit Cloud-nativer KI- und Datenanalyse-Software, die von NVIDIA für die Ausführung auf VMware vSphere mit NVIDIA-zertifizierten Systemen optimiert, zertifiziert und unterstützt wird. Diese Software vereinfacht die einfache und schnelle Implementierung, das einfache Management und die Skalierung von KI-Workloads in modernen Hybrid-Cloud-Umgebungen.</block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU CLOUD (NGC)</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC hostet einen Katalog GPU-optimierter Software für KI-Fachleute, um ihre KI-Lösungen zu entwickeln. Zudem bietet die Lösung Zugriff auf verschiedene KI-Services wie NVIDIA Base Command für das Modelltraining, NVIDIA Fleet Command für die Implementierung und das Monitoring von Modellen sowie die NGC Private Registry, die einen sicheren Zugriff auf und Management proprietärer KI-Software ermöglicht. Zudem können NVIDIA KI Enterprise-Kunden Support über das NGC-Portal anfordern.</block>
  <block id="8887a9a417a1629326acdb917d224337" category="section-title">VMware vSphere</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere ist die Virtualisierungsplattform von VMware, die Datacenter in aggregierte Computing-Infrastrukturen umwandelt, und zwar mit CPU-, Storage- und Netzwerkressourcen. VSphere verwaltet diese Infrastrukturen als einheitliche Betriebsumgebung und stellt Administratoren die Tools zum Management der an dieser Umgebung teilnehmenden Datacenter bereit.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Die beiden Kernkomponenten von vSphere sind ESXi und vCenter Server. ESXi ist die Virtualisierungsplattform, auf der Administratoren Virtual Machines und virtuelle Appliances erstellen und ausführen. VCenter Server ist der Service, über den Administratoren mehrere Hosts managen können, die in einem Netzwerk und einem Pool von Host-Ressourcen verbunden sind.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, die jüngste Generation der Storage-Managementsoftware von NetApp, ermöglicht Unternehmen eine Modernisierung der Infrastruktur und den Übergang zu einem Cloud-fähigen Datacenter. Dank der erstklassigen Datenmanagementfunktionen lassen sich mit ONTAP sämtliche Daten mit einem einzigen Toolset managen und schützen, ganz gleich, wo sich diese Daten befinden. Zudem können Sie die Daten problemlos dorthin verschieben, wo sie benötigt werden: Zwischen Edge, Core und Cloud. ONTAP 9 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, geschäftskritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation über Hybrid-Cloud-Architekturen hinweg ermöglichen.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Vereinfachtes Datenmanagement</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">Für den Enterprise IT-Betrieb und die Data Scientists spielt Datenmanagement eine zentrale Rolle, damit für KI-Applikationen die entsprechenden Ressourcen zum Training von KI/ML-Datensätzen verwendet werden. Die folgenden zusätzlichen Informationen über NetApp Technologien sind bei dieser Validierung nicht im Umfang enthalten, können jedoch je nach Ihrer Implementierung relevant sein.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Die ONTAP Datenmanagement-Software umfasst die folgenden Funktionen, um den Betrieb zu optimieren und zu vereinfachen und damit Ihre Gesamtbetriebskosten zu senken:</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Inline-Data-Compaction und erweiterte Deduplizierung: Data-Compaction reduziert den ungenutzten Speicherplatz in Storage-Blöcken, während Deduplizierung die effektive Kapazität deutlich steigert. Dies gilt für lokal gespeicherte Daten und für Daten-Tiering in die Cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Minimale, maximale und adaptive Quality of Service (AQoS): Durch granulare QoS-Einstellungen (Quality of Service) können Unternehmen ihre Performance-Level für kritische Applikationen auch in Umgebungen mit vielen unterschiedlichen Workloads garantieren.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: FabricPool Best Practices</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool: Bietet automatisches Tiering von „kalten“ Daten in Private- und Public-Cloud-Storage-Optionen, einschließlich Amazon Web Services (AWS), Azure und NetApp StorageGRID Storage-Lösung. Weitere Informationen zu FabricPool finden Sie unter<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Beschleunigung und Sicherung von Daten</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP bietet überdurchschnittliche Performance und Datensicherung, erweitert diese Funktionen auf folgende Weise:</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Performance und niedrige Latenz: ONTAP bietet höchstmöglichen Durchsatz bei geringstmöglicher Latenz.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Datensicherung ONTAP verfügt über integrierte Funktionen für die Datensicherung mit zentralem Management über alle Plattformen hinweg.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp Volume Encryption (NVE) ONTAP bietet native Verschlüsselung auf Volume-Ebene und unterstützt sowohl Onboard- als auch externes Verschlüsselungsmanagement.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Multi-Faktor- und Multi-Faktor-Authentifizierung – ONTAP ermöglicht die gemeinsame Nutzung von Infrastrukturressourcen mit höchstmöglicher Sicherheit.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Zukunftssichere Infrastruktur</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP bietet folgende Funktionen, um anspruchsvolle und sich ständig ändernde Geschäftsanforderungen zu erfüllen:</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Nahtlose Skalierung und unterbrechungsfreier Betrieb. Mit ONTAP sind das Hinzufügen von Kapazitäten zu bestehenden Controllern und das Scale-out von Clustern unterbrechungsfrei möglich. Kunden können Upgrades auf die neuesten Technologien wie NVMe und 32 GB FC ohne teure Datenmigrationen oder Ausfälle durchführen.</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">Cloud-Anbindung: ONTAP ist die Storage-Managementsoftware mit der umfassendsten Cloud-Integration und bietet Optionen für softwaredefinierten Storage (ONTAP Select) und Cloud-native Instanzen (NetApp Cloud Volumes Service) in allen Public Clouds.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Integration in moderne Applikationen: ONTAP bietet Datenservices der Enterprise-Klasse für Plattformen und Applikationen der neuesten Generation, wie autonome Fahrzeuge, Smart Citys und Industrie 4.0, auf derselben Infrastruktur, die bereits vorhandene Unternehmensanwendungen unterstützt.</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="section-title">NetApp DataOps Toolkit</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">Das NetApp DataOps Toolkit ist ein Python-basiertes Tool zur Vereinfachung des Managements von Entwicklungs-/Trainings-Workspaces und Inferenzservern, die durch hochleistungsfähigen, horizontal skalierbaren NetApp Storage gesichert werden. Die wichtigsten Funktionen:</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Schnelle Bereitstellung neuer JupyterLab Workspaces mit hoher Kapazität, die durch hochperformanten horizontal skalierbaren NetApp Storage unterstützt werden</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Schnelle Bereitstellung neuer NVIDIA Triton Inferenz Server Instanzen, die durch NetApp Storage der Enterprise-Klasse unterstützt werden</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Klonen Sie JupyterLab Workspaces mit hoher Kapazität in nahezu instandem Tempo, um Experimente oder schnelle Iterationen zu ermöglichen.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Speichern Sie nahezu instandlich Snapshots von JupyterLab Workspaces mit hoher Kapazität für Backup und/oder Rückverfolgbarkeit/Baselining.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Provisionieren, Klonen und Snapshot High-Capacity-High-Performance-Daten-Volumes gleichzeitig</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">Als Nächstes: Architektur.</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">In diesem Dokument wird eine validierte Design-Lösung unter drei verschiedenen Szenarien mit und ohne Imageverschleierung beschrieben, die für den Datenschutz und die Implementierung einer verantwortungsvollen KI-Lösung relevant ist.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: Verantwortungsvolle KI und vertrauliche Inferenz - NetApp AI mit Protopia Image und Data Transformation</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Visuelle Interpretationen sind zu einem integralen Bestandteil der Kommunikation mit dem Aufkommen von Bildaufnahme und Bildverarbeitung geworden. Künstliche Intelligenz (KI) in der digitalen Bildverarbeitung bietet neue Geschäftsmöglichkeiten, beispielsweise im medizinischen Bereich zur Identifizierung von Krebs oder anderen Krankheiten, in geospatialen visuellen Analysen zur Untersuchung von Umweltgefahren, in der Mustererkennung, in der Videoverarbeitung zur Kriminalitätsbekämpfung usw. Diese Gelegenheit bringt aber auch außerordentliche Verantwortung mit sich.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Je mehr Entscheidungen Unternehmen mit KI in die Hände geraten, desto größer sind ihre Risiken in Bezug auf Datenschutz, -Sicherheit sowie rechtliche, ethische und regulatorische Probleme. Dabei ermöglicht verantwortungsvolle KI Unternehmen und Behörden, Vertrauen und Governance aufzubauen, die für skalierbare KI in Großunternehmen entscheidend sind. Dieses Dokument beschreibt eine von NetApp im Rahmen von drei verschiedenen Szenarien validierte Lösung zur KI-Inferenz, indem NetApp Datenmanagement-Technologien mit Protopia Datenobfuskationssoftware eingesetzt werden, um sensible Daten zu privatisieren und Risiken sowie ethische Bedenken zu verringern.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Jeden Tag werden Millionen von Bildern mit verschiedenen digitalen Geräten von Kunden und Geschäftseinheiten erzeugt. Die Folge der enormen Zunahme von Daten und Computing-Workloads sind Unternehmen, die zu Cloud-Computing-Plattformen für Skalierbarkeit und Effizienz wechseln. Gleichzeitig ergeben sich bei der Übertragung in eine Public Cloud Bedenken hinsichtlich der Vertraulichkeit der vertraulichen Informationen in Bilddaten. Der Mangel an Sicherheit und Datenschutz wird zum Haupthindernis für die Implementierung bildverarbeitender KI-Systeme.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">Recht auf Löschung</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Datenschutzgesetz</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">Darüber hinaus gibt es das<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> Gemäß der DSGVO ist ein Unternehmen berechtigt, alle personenbezogenen Daten zu löschen. Da ist auch der<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>, Die einen Code fairer Informationspraktiken festlegt. Digitale Bilder wie Fotografien können als personenbezogene Daten gemäß der DSGVO gelten, die regelt, wie Daten erhoben, verarbeitet und gelöscht werden müssen. Andernfalls muss die DSGVO nicht eingehalten werden, was zu hohen Geldstrafen führen kann, um Compliance-Vorschriften zu widerstehen, die Unternehmen ernsthaft beschädigen können. Datenschutzgrundsätze sind eines der Rückgrat der Implementierung einer verantwortungsvollen KI, die für Gerechtigkeit bei den Modellprognosen für Machine Learning (ML) und Deep Learning (DL) sorgt und die Risiken im Zusammenhang mit der Verletzung von Datenschutz oder gesetzlicher Vorschriften verringert.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">In diesem Dokument wird eine validierte Design-Lösung unter drei verschiedenen Szenarien mit und ohne Imageverschleierung beschrieben, die für den Datenschutz relevant ist und eine verantwortungsvolle KI-Lösung implementiert.</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Szenario 1.* On-Demand Inferenz innerhalb von Jupyter Notebook.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Szenario 2.* Batch Inferenz auf Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Szenario 3.* NVIDIA Triton Inferenzserver.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Für diese Lösung verwenden wir den Face Detection Data Set und Benchmark (FDDB), einen Datensatz von Gesichtsregionen, die für die Untersuchung des Problems der uneingeschränkten Gesichtserkennung konzipiert wurden, kombiniert mit dem PyTorch Machine Learning Framework zur Implementierung von FaceBoxes. Dieser Datensatz enthält die Anmerkungen für 5171 Gesichter in einem Satz von 2845 Bildern verschiedener Auflösungen. Der technische Bericht enthält zudem einige Lösungsbereiche und relevante Nutzungsfälle, die von NetApp Kunden und Field Engineers in Situationen erfasst wurden, in denen diese Lösung sinnvoll ist.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">Zielgruppe</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Dieser technische Bericht richtet sich an folgende Zielgruppen:</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Führungskräfte und Enterprise-Architekten, die eine verantwortungsvolle KI entwickeln und implementieren und Probleme hinsichtlich der Datensicherung und des Datenschutzes bei der Verarbeitung von Gesichts-Images in öffentlichen Bereichen lösen möchten.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Data Scientists, Data Engineers, KI-/ml-Forscher (Machine Learning) und Entwickler von KI/ML-Systemen, die den Datenschutz schützen und bewahren möchten.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Enterprise-Architekten, die Datenverschleisslösungen für KI/ML-Modelle und Applikationen entwerfen, die gesetzliche Standards wie DSGVO, CCPA oder den Datenschutzgesetz des US-Verteidigungsministeriums (DoD) und Regierungseinrichtungen erfüllen.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Data Scientists und KI-Ingenieure suchen nach effizienten Möglichkeiten, Deep-Learning- (DL) und KI/ML/DL-Inferenzmodelle zu implementieren, die sensible Informationen sichern.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Edge-Geräte-Manager und Edge-Serveradministratoren, die für die Implementierung und das Management von Edge-Inferenzmodellen verantwortlich sind</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Lösungsarchitektur</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Diese Lösung wurde entwickelt, um KI-Workloads in Echtzeit- und Batch-Inferenz auf großen Datensätzen zu verarbeiten. Dabei wird die Verarbeitungsleistung von GPUs neben herkömmlichen CPUs eingesetzt. Diese Validierung beweist, dass die Inferenz für ML geschützt ist und für Unternehmen, die einen verantwortlichen KI-Einsatz benötigen, optimales Datenmanagement erforderlich ist. Diese Lösung bietet eine Architektur für Kubernetes-Plattformen mit einzelnen oder mehreren Nodes für Edge- und Cloud-Computing und ist so mit NetApp ONTAP AI als zentrale On-Premises-Plattform, dem NetApp DataOps Toolkit und der Protopia Obfuscation Software über Jupyter Lab- und CLI-Schnittstellen verbunden. Die folgende Abbildung zeigt den Überblick über die logische Architektur der Data Fabric Vision von NetApp mit dem DataOps Toolkit und Protopia.</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Die Protopia Obfuscation Software wird nahtlos auf das NetApp DataOps Toolkit ausgeführt und verändert die Daten, bevor der Storage Server verlassen wird.</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">Als Nächstes: Lösungsbereiche.</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">Persistent Volume Claim Definieren</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">Speichern Sie die folgende YAML in einer Datei, um ein PVC vom Typ Basic zu erstellen.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Wenden Sie die YAML-Datei auf Ihr Iguazio Kubernetes-Cluster an.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Weisen Sie NetApp Volume dem Jupyter Notebook zu</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio Übersicht über Anwendungsdienste und -Tools</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio bietet verschiedene Managed Services, um Data Scientists einen vollständigen End-to-End-Stack für die Entwicklung und Implementierung von KI/ML-Applikationen bereitzustellen. Weitere Informationen zu diesen Komponenten finden Sie unter<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">Einer der Managed Services ist Jupyter Notebook. Jeder Entwickler erhält seinen eigenen Einsatz eines Notebook-Containers mit den nötigen Ressourcen für die Entwicklung. Um ihnen Zugriff auf das NetApp Cloud Volume zu geben, können Sie das Volume ihrem Container zuweisen und die Ressourcenzuweisung, den laufenden Benutzer sowie die Einstellungen für Umgebungsvariablen für Persistent Volume Claims nutzen. Das folgende Bild ist dargestellt:</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">Informationen zu einer On-Premises-Konfiguration finden Sie unter<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Bei dem Setup von Trident sind die Datenmanagementfunktionen von NetApp ONTAP aktiviert, wie z. B. die Erstellung von Snapshot Kopien Ihrer Daten oder des Modells zur Versionierung. Fügen Sie in Ihrer Trident Back-End-Konfigurationsdatei die folgende Zeile ein, um Snapshot Verzeichnisse sichtbar zu machen:</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident-Befehl</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">Sie müssen eine Back-End-Konfigurationsdatei von Trident im JSON-Format erstellen und dann Folgendes ausführen<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> So verwenden Sie sie:</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">Weiter: Bereitstellung der Anwendung</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">In diesem Abschnitt wird die technologische Grundlage dieser KI-Lösung beschrieben.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Technologieüberblick</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Mit den hochmodernen NetApp AFF-Storage-Systemen können KI-Inferenz-Implementierungen im Edge-Bereich erfolgen. Die Enterprise-Storage-Anforderungen werden mit branchenführender Performance, überlegener Flexibilität, Cloud-Integration und erstklassigem Datenmanagement erfüllt. NetApp AFF Systeme wurden speziell für Flash entwickelt. Sie helfen geschäftskritische Daten zu beschleunigen, zu managen und zu sichern.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Die NetApp AFF Storage-Systeme der Einstiegsklasse basieren auf der FAS2750 Hardware und SSD-Flash-Medien</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Zwei Controller in HA-Konfiguration</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp Storage-Systeme der Einstiegsklasse AFF C190 unterstützen die folgenden Funktionen:</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">1 maximale Laufwerksanzahl: 24 x 960-GB-SSDs</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Zwei mögliche Konfigurationen:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10 GbE): 4 x 10GBASE-T-Ports (RJ-45</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unified (16 GB FC oder 10 GbE): 4 x Unified Target Adapter 2 (UTA2)-Ports</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Maximal 50,5 TB effektive Kapazität</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Bei NAS-Workloads unterstützt ein einzelnes AFF C190 Einstiegssystem einen Durchsatz von 4,4 GB/s bei sequenziellem Lesen und 230.000 IOPS bei kleinen zufälligen Lesevorgängen mit einer Latenz von 1 ms oder weniger.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp bietet außerdem andere Storage-Systeme der Einstiegsklasse an, die eine höhere Performance und Skalierbarkeit für größere Implementierungen bieten. Für NAS-Workloads unterstützt ein einzelnes AFF A220 Einstiegssystem:</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Durchsatz von 6,2 GB/s bei sequenziellem Lesen</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375.000 IOPS für kleine zufällige Lesevorgänge bei einer Latenz von maximal 1 ms</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Maximale Laufwerksanzahl: 144 x 960 GB, 3,8 TB oder 7,6 TB SSDs</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 kann auf eine effektive Kapazität von mehr als 1 PB skaliert werden</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">Maximale effektive Kapazität: 35 PB mit maximal horizontal skalierbarer 2-24 Nodes (12 HA-Paare)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Performance-Steigerung um ≥ 45 % im Vergleich zu AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440.000 IOPS zufälliger Lesezugriff @1 ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basiert auf der neuesten ONTAP-Version von NetApp: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Zwei 25-GB-Ethernet für HA und Cluster Interconnect</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Die NetApp E-Series EF Systeme</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">Die EF-Series ist eine Produktfamilie aus All-Flash-SAN-Storage-Arrays der Einstiegsklasse und für den Midrange-Bereich, die den Zugriff auf Ihre Daten beschleunigen und mit der NetApp SANtricity Software den maximalen Nutzen aus ihren Daten ziehen können. Diese Systeme bieten sowohl SAS- als auch NVMe-Flash-Storage und bieten kostengünstige bis extreme IOPS, Reaktionszeiten von unter 100 Mikrosekunden und eine Bandbreite von bis zu 44 GB/s. Dadurch eignen sie sich ideal für heterogene Workloads und anspruchsvolle Applikationen wie KI-Inferenz und High-Performance-Computing (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">Die folgende Abbildung zeigt das NetApp EF280 Storage-System.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Unterstützung von 32 GB/16 GB FC, 25 GB/10 GB iSCSI und 12 GB SAS</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">Die maximale effektive Kapazität beträgt 96 Laufwerke mit einer Gesamtleistung von 1,5 PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Durchsatz von 10 GB/s (sequenzielle Lesevorgänge)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300.000 IOPS (zufällige Lesevorgänge)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">Die NetApp EF280 ist das kostengünstigste All-Flash-Array (AFA) im NetApp Portfolio</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 x NVMe-SSD-Laufwerke für eine Gesamtkapazität von 367 TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Erweiterungsoptionen mit insgesamt 240x NL-SAS HDDs, 96 x SAS SSDs oder einer Kombination aus diesen Optionen</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100-GB-NVMe/IB, NVMe/RoCE, iSER/IB und SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32-GB-NVME/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25 GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbit/s (sequenzielle Lesevorgänge)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670.000 IOPS (wahlfreie Lesevorgänge)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF-Series All-Flash-Arrays der NetApp EF-Series, F300, EF570 und EF280 Datenblatt</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Weitere Informationen finden Sie im<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, die neueste Generation der Storage-Managementsoftware von NetApp, ermöglicht Unternehmen, ihre Infrastruktur zu modernisieren und auf ein Cloud-fähiges Datacenter zu wechseln. Dank der erstklassigen Datenmanagementfunktionen lassen sich mit ONTAP sämtliche Daten mit einem einzigen Toolset managen und schützen, ganz gleich, wo sich diese Daten befinden. Zudem können Sie die Daten problemlos dorthin verschieben, wo sie benötigt werden: Zwischen Edge, Core und Cloud. ONTAP 9.8.1 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, geschäftskritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation über Hybrid-Cloud-Architekturen hinweg ermöglichen.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">Für den Enterprise-IT-Betrieb spielt Datenmanagement eine zentrale Rolle, da es Applikationen und Datensätzen die richtigen Ressourcen zuweist. ONTAP umfasst die folgenden Funktionen, um den Betrieb zu optimieren und zu vereinfachen und damit die Gesamtbetriebskosten zu senken:</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*Inline-Data-Compaction und erweiterte Deduplizierung.* Data-Compaction reduziert den ungenutzten Speicherplatz in Storage-Blöcken, während Deduplizierung die effektive Kapazität deutlich steigert. Dies gilt für lokal gespeicherte Daten und für Daten-Tiering in die Cloud.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Minimum, Maximum und Adaptive Quality of Service (AQoS).* durch granulare QoS-Kontrollen (Quality of Service) können Performance-Level für kritische Applikationen in Umgebungen mit hohen gemeinsam genutzten Ressourcen aufrechterhalten werden.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">*NetApp FabricPool.* Diese Funktion bietet automatisches Tiering von weniger häufig benötigten Daten in Public- und Private-Cloud-Storage-Optionen, einschließlich Amazon Web Services (AWS), Azure und NetApp StorageGRID Storage-Lösung. Weitere Informationen zu FabricPool finden Sie unter <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 bietet überdurchschnittliche Performance und Datensicherung, erweitert diese Funktionen auf folgende Weise:</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*Performance und geringere Latenz.* ONTAP bietet den höchstmöglichen Durchsatz bei geringstmöglicher Latenz.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Datensicherung.* ONTAP bietet integrierte Datensicherungsfunktionen mit einem einheitlichen Management über alle Plattformen hinweg.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">*NetApp Volume Encryption (NVE).* ONTAP bietet native Verschlüsselung auf Volume-Ebene mit integrierter und externer Unterstützung für das Verschlüsselungsmanagement.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Mandantenfähigkeit und Multi-Faktor-Authentifizierung.* ONTAP ermöglicht die gemeinsame Nutzung von Infrastrukturressourcen mit einem Höchstmaß an Sicherheit.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 bietet die folgenden Funktionen, um Unternehmen auf ständig wechselnde Geschäftsanforderungen zu reagieren:</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Nahtlose Skalierung und unterbrechungsfreier Betrieb.* ONTAP unterstützt das unterbrechungsfreie Hinzufügen von Kapazitäten zu bestehenden Controllern sowie das Scale-out von Clustern. Kunden können Upgrades auf die neuesten Technologien wie NVMe und 32 GB FC ohne teure Datenmigrationen oder Ausfälle durchführen.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">*Cloud Connection.* ONTAP ist die Storage-Managementsoftware mit der umfassendsten Cloud-Integration und bietet Optionen für softwaredefinierten Storage (ONTAP Select) und Cloud-native Instanzen (NetApp Cloud Volumes Service) in allen Public Clouds.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Integration in moderne Applikationen.* ONTAP bietet Datenservices der Enterprise-Klasse für Plattformen und Anwendungen der nächsten Generation, wie autonome Fahrzeuge, Smart Cities und Industrie 4.0, mit derselben Infrastruktur, die bereits bestehende Enterprise-Apps unterstützt.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E-Series SANtricity Software – Datenblatt</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity wurde entwickelt, um für Hybrid-Flash- und EF-Series All-Flash-Arrays eine branchenführende Performance, Zuverlässigkeit und Einfachheit zu bieten. Erzielen Sie maximale Performance und Auslastung Ihrer E-Series Hybrid-Flash- und EF-Series All-Flash-Arrays für anspruchsvolle Workloads, einschließlich Datenanalysen, Videoüberwachung sowie Backup und Recovery. Mit SANtricity können Einstellungen, Wartung, Kapazitätserweiterung und andere Aufgaben abgeschlossen werden, ohne dass der Storage online bleibt. SANtricity bietet zudem erstklassige Datensicherung, proaktives Monitoring und zertifizierte Sicherheit – alles ist über die benutzerfreundliche, integrierte System Manager Schnittstelle zugänglich. Weitere Informationen finden Sie im<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Performance-Optimierung</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Die Performance-optimierte SANtricity Software stellt Daten für alle Ihre Datenanalyse-, Videoüberwachungs- und Backup-Applikationen bereit – mit hohen IOPS, hohem Durchsatz und niedriger Latenz. Performance-Steigerung für Applikationen mit hohen IOPS und niedriger Latenz sowie für Applikationen mit hoher Bandbreite und hohem Durchsatz</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Maximale Verfügbarkeit</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Durchführung Ihrer gesamten Managementaufgaben, während der Storage online bleibt. Ganz gleich, ob Sie Konfigurationen anpassen, Wartungsaufgaben durchführen oder die Kapazität erweitern – der I/O-Betrieb wird nicht unterbrochen Hervorragende Zuverlässigkeit dank automatisierter Funktionen, Online-Konfiguration, hochmoderner Dynamic Disk Pools (DPP)-Technologie und mehr</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Keine leichte Aufgabe</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity Software bietet erstklassige Datensicherung, proaktives Monitoring und zertifizierte Sicherheit – alles über die benutzerfreundliche, integrierte System Manager Schnittstelle. Vereinfachung von Storage-Managementaufgaben. Sie erhalten die Flexibilität, die Sie zum fortschrittlichen Tuning aller E-Series Storage-Systeme benötigen. Sie können Ihr NetApp E-Series System jederzeit und überall managen. Unsere integrierte, webbasierte Schnittstelle optimiert Ihren Management-Workflow.</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="section-title">NetApp Trident</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> NetApp ist ein Open-Source-Orchestrator für den dynamischen Storage von Docker und Kubernetes, das die Erstellung, das Management und die Nutzung von persistentem Storage vereinfacht. Die native Kubernetes-Applikation Trident läuft direkt in einem Kubernetes Cluster. Trident ermöglicht Kunden die nahtlose Implementierung von DL-Container-Images auf NetApp Storage und bietet eine Erfahrung der Enterprise-Klasse für den Einsatz von KI-Containern. Kubernetes-Benutzer (WIE ML-Entwickler und Data Scientists) können die Orchestrierung und das Klonen erstellen, managen und automatisieren, um von den erweiterten Datenmanagement-Funktionen von NetApp Technologie zu profitieren.</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud-Synchronisierung</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Ist ein NetApp Service für schnelle und sichere Datensynchronisierung. Unabhängig davon, ob Sie Dateien zwischen On-Premises-NFS oder SMB-Dateifreigaben übertragen müssen: NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage Oder IBM Cloud Object Storage: Cloud Sync verschiebt Dateien schnell und sicher dorthin, wo sie benötigt werden. Nach der Übertragung stehen die Daten an der Quelle und am Ziel vollständig zur Verfügung. Cloud Sync synchronisiert kontinuierlich die Daten, die auf Ihrem vordefinierten Zeitplan basieren, um nur die Deltawerte zu verschieben. So werden Zeit und Geld für die Datenreplizierung minimiert. Cloud Sync ist ein Software-as-a-Service-Tool (SaaS), das extrem einfach einzurichten und zu verwenden ist. Von Cloud Sync ausgelöste Datentransfers werden durch Data Makler durchgeführt. Cloud Sync-Datenmanager können in AWS, Azure, Google Cloud Platform oder vor Ort implementiert werden.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Lenovo ThinkSystem-Server</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Lenovo ThinkSystem Server verfügen über innovative Hardware, Software und Services, die die Herausforderungen der Kunden von heute lösen und einen evolutionären, zweckbezogenen, modularen Designansatz bieten, um den Herausforderungen von morgen gerecht zu werden. Diese Server profitieren von erstklassigen, Industriestandard-Technologien in Verbindung mit differenzierten Lenovo Innovationen, um die größtmögliche Flexibilität bei x86-Servern zu bieten.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Zu den wichtigsten Vorteilen der Bereitstellung von Lenovo ThinkSystem Servern gehören:</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Hochskalierbare und modulare Designs, die mit dem Unternehmen wachsen können</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">Branchenführende Ausfallsicherheit und dadurch Zeitersparnis von Stunden mit teuren, ungeplanten Ausfallzeiten</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Schnelle Flash-Technologien für kürzere Latenzen, schnellere Reaktionszeiten und intelligentes Datenmanagement in Echtzeit</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Im KI-Bereich verfolgt Lenovo einen praktischen Ansatz, der Unternehmen dabei hilft, die Vorteile VON ML und KI für ihre Workloads zu verstehen und einzuführen. Lenovo Kunden können die KI-Angebote von Lenovo in Lenovo AI Innovation Centers testen und auswerten, um den Wert für ihren jeweiligen Anwendungsfall zu verstehen. Dieser kundenorientierte Ansatz bietet Kunden ein Proof of Concept für Lösungsplattformen, die sofort einsatzbereit und für KI optimiert sind, zur Verbesserung der Amortisierung.</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Lenovo ThinkSystem SE350 Edge Server</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">Edge Computing ermöglicht die Analyse von Daten von IoT-Geräten am Edge des Netzwerks, bevor sie an das Datacenter oder die Cloud gesendet werden. Das Lenovo ThinkSystem SE350, wie in der Abbildung unten dargestellt, ist für die einzigartigen Anforderungen an den Einsatz am Rand konzipiert, mit dem Schwerpunkt auf Flexibilität, Konnektivität, Sicherheit und Fernverwaltung in einem kompakten robusten und umweltverträglichen Formfaktor.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Mit dem Intel Xeon D Prozessor und der Flexibilität, die Beschleunigung von Edge-KI-Workloads zu unterstützen, wurde der SE350 speziell für die Bewältigung der Herausforderungen von Serverbereitstellungen in verschiedenen Umgebungen außerhalb des Rechenzentrums entwickelt.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf-Inferenz v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf ist eine branchenführende Benchmark-Suite zur Evaluierung der KI-Performance. Sie deckt zahlreiche Bereiche der angewandten KI ab, darunter Bildklassifizierung, Objekterkennung, medizinische Bildgebung und natürliche Sprachverarbeitung (NLP). In dieser Validierung verwendeten wir Inferenz v0.7 Workloads, was die neueste Version von MLPerf-Inferenz beim Abschluss dieser Validierung ist. Der<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> Die Suite enthält vier neue Benchmarks für Datacenter und Edge-Systeme:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.* bidirektionale Encoder-Darstellung von Transformatoren (BERT) optimiert für die Beantwortung von Fragen mit Hilfe des Kader-Datensatzes.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.* Deep Learning Recommendation Model (DLRM) ist ein Personalisierungs- und Empfehlungsmodell, das zur Optimierung der Klickraten (CTR) trainiert wird.</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.* die 3D U-Net-Architektur wird auf dem Datensatz Brain Tumor Segmentation (Briats) trainiert.</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* Rezidiver Neural Network Transducer (RNN-T) ist ein ASR-Modell (Automatic Speech Rezidicted Speech Receed), das auf einer Untergruppe von LibriSpeech trainiert wird. MLPerf-Inferenz-Ergebnisse und -Code sind öffentlich verfügbar und unter Apache-Lizenz veröffentlicht. MLPerf-Inferenz verfügt über eine Edge-Abteilung, die die folgenden Szenarien unterstützt:</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Single Stream.* Dieses Szenario imitiert Systeme, bei denen die Reaktionsfähigkeit ein entscheidender Faktor ist, wie Offline-KI-Abfragen, die auf Smartphones durchgeführt werden. Einzelne Abfragen werden an das System gesendet und Reaktionszeiten werden aufgezeichnet. Die 90. Perzentillatenz aller Antworten wird als Ergebnis gemeldet.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multistream.* dieser Benchmark ist für Systeme, die Input von mehreren Sensoren verarbeiten. Während des Tests werden Abfragen in einem festen Zeitintervall gesendet. Eine QoS-Einschränkung (maximal zulässige Latenz) wurde gestellt. Der Test meldet die Anzahl der Datenströme, die das System verarbeiten kann, während die QoS-Bedingung erfüllt wird.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Offline.* Dies ist das einfachste Szenario für Batch-Anwendungen und die Metrik ist der Durchsatz in Proben pro Sekunde. Alle Daten stehen dem System zur Verfügung und der Benchmark misst die Zeit, die für die Verarbeitung aller Proben benötigt wird.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo hat MLPerf Inference Scores für SE350 mit T4 veröffentlicht, dem Server, der in diesem Dokument verwendet wird. Weitere Informationen finden Sie unter<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> Im Abschnitt „Kante, geschlossene Abteilung“ in Eintrag #0.7-145.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">Als Nächstes: Testplan</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Bevor Sie Trident zur dynamischen Bereitstellung von Storage-Ressourcen innerhalb Ihres Kubernetes-Clusters verwenden können, müssen Sie ein oder mehrere Trident Back-Ends erstellen. Die Beispiele auf dieser Seite stellen verschiedene Arten von Backend-Typen dar, die Sie möglicherweise erstellen möchten, wenn Sie die NetApp AI Control Plane Lösung auf einem ONTAP AI POD implementieren.</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="doc">Beispiel Trident Back-Ends für ONTAP KI-Implementierungen</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident Dokumentation</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Bevor Sie Trident zur dynamischen Bereitstellung von Storage-Ressourcen innerhalb Ihres Kubernetes-Clusters verwenden können, müssen Sie ein oder mehrere Trident Back-Ends erstellen. Die folgenden Beispiele stellen unterschiedliche Arten von Backend dar, die erstellt werden sollten, wenn Sie die NetApp AI Control Plane Lösung auf einem ONTAP AI POD implementieren. Weitere Informationen zu Backends finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp empfiehlt die Erstellung eines FlexGroup-fähigen Trident-Back-End für jede Daten-LIF (logische Netzwerkschnittstelle mit Datenzugriff), die Sie auf Ihrem NetApp AFF System verwenden möchten. So können Sie einen Ausgleich von Volume-Mounts über LIFs hinweg erzielen</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">Die folgenden Beispielbefehle zeigen die Erstellung von zwei FlexGroup-fähigen Trident Back-Ends für zwei unterschiedliche Daten-LIFs, die mit der gleichen ONTAP Storage Virtual Machine (SVM) verbunden sind. Diese Backends verwenden den<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Storage-Treiber: ONTAP unterstützt zwei wesentliche Daten-Volume-Typen: FlexVol und FlexGroup. Die Größe von FlexVol-Volumes ist begrenzt (ab diesem Schreibvorgang hängt die maximale Größe von der spezifischen Implementierung ab). FlexGroup Volumes hingegen lassen sich linear auf bis zu 20 PB und 400 Milliarden Dateien skalieren und sorgen in einem Single Namespace für eine erhebliche Vereinfachung des Datenmanagements. Daher sind FlexGroup-Volumes optimal für AI- und ML-Workloads, die auf große Datenmengen basieren.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Wenn Sie mit einer geringen Menge an Daten arbeiten und statt FlexGroup Volumes FlexVol Volumes verwenden möchten, können Sie Trident Back-Ends erstellen, die den verwenden<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> Storage-Treiber statt des<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Storage-Treiber:</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">NetApp empfiehlt außerdem, ein oder mehrere FlexVol-fähige Trident Back-Ends zu erstellen. Wenn Sie FlexGroup Volumes für das Training von Datensatz-Storage verwenden, könnten Sie FlexVol Volumes für die Speicherung von Ergebnissen, Ausgabe, Debug-Informationen usw. verwenden. Falls Sie FlexVol Volumes verwenden möchten, müssen Sie ein oder mehrere FlexVol-aktivierte Trident-Backends erstellen. Die folgenden Beispielbefehle zeigen die Erstellung eines einzelnen FlexVol-fähigen Trident Back-End, das eine einzelne Daten-LIF verwendet.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">Als Nächstes: Beispiel Kubernetes Storageclasses für ONTAP KI-Implementierungen.</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Schlussfolgerung</block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp und cnvrg.io bieten ihren Kunden eine umfassende Datenmanagement-Lösung für DIE ML- und DL-Softwareentwicklung. ONTAP AI bietet High-Performance-Computing und -Storage für alle Betriebsabläufe. Die Software cnvrg.io optimiert Datenwissenschaftler und verbessert die Ressourcenauslastung.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">Weiter: Danksagungen</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">Fallübersicht zu Anwendungsfall und Problembeschreibung</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">Datensätze und Datensatzversionen befinden sich normalerweise in einem Data Lake, wie z. B. objektbasierter NetApp StorageGRID Storage, der geringere Kosten und andere betriebliche Vorteile bietet. Die Data Scientists erhalten diese Datensätze in mehreren Schritten, um sie für das Training mit einem bestimmten Modell vorzubereiten. Oft erstellen sie dabei mehrere Versionen. Im nächsten Schritt muss der Data Scientist optimierte Computing-Ressourcen (GPUs, High-End-CPU-Instanzen, On-Premises-Cluster usw.) auswählen, um das Modell auszuführen. Die folgende Abbildung zeigt den Mangel an Dataset-Nähe in einer ML-Computing-Umgebung.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">Mehrere Trainingsversuche müssen jedoch parallel in verschiedenen Computing-Umgebungen ausgeführt werden, von denen jeder einen Download des Datensatzes aus dem Data Lake erfordert, was ein kostspieliger und zeitaufwendiger Prozess ist. Die Nähe des Datensatzes zur Computing-Umgebung (insbesondere bei einer Hybrid Cloud) ist nicht garantiert. Außerdem müssen andere Teammitglieder, die ihre eigenen Experimente mit demselben Datensatz durchführen, denselben mühsamen Prozess durchlaufen. Neben dem offensichtlichen langsamen Datenzugriff sind Probleme bei der Nachverfolgung von Datensatzversionen, der Datensatzfreigabe, der Zusammenarbeit und der Reproduzierbarkeit zu überwinden.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">Kundenanforderungen</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">Die Kundenanforderungen können variieren, um bei effizienter Nutzung von Ressourcen hochperformante ML-Durchläufe zu erreichen. Kunden benötigen beispielsweise Folgendes:</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">Schneller Zugriff auf Datensätze von jeder Computing-Instanz, die das Trainingsmodell ausführt, ohne dass teure Downloads und der Datenzugriff komplexer werden</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">Die Verwendung von Compute-Instanzen (GPU oder CPU) in der Cloud oder lokal, ohne sich um den Speicherort der Datensätze zu kümmern</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">Höhere Effizienz und Produktivität, da mehrere Trainingsversuche parallel mit unterschiedlichen Computing-Ressourcen auf demselben Datensatz durchgeführt werden können ohne unnötige Verzögerungen und Datenlatenz</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">Minimale Kosten für Computing-Instanzen</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">Verbesserte Reproduzierbarkeit mit Tools, mit denen Datensätze, deren Herkunft, Versionen und andere Metadatendetails aufgezeichnet werden können</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">Verbessertes Sharing und Zusammenarbeit, sodass autorisierte Teammitglieder auf die Datensätze zugreifen und Experimente ausführen können</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">Zur Implementierung von Datensatz-Caching mit NetApp ONTAP Datenmanagement-Software müssen Kunden die folgenden Aufgaben durchführen:</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">Konfigurieren Sie den NFS-Storage, der den Computing-Ressourcen am nächsten ist, und legen Sie ihn fest.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">Bestimmen Sie, welche Datensätze und Version im Cache gespeichert werden sollen.</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">Überwachen Sie den gesamten Arbeitsspeicher, der in Cache-Datensätzen gespeichert ist, und wie viel NFS-Speicher für zusätzliche Cache-Commits zur Verfügung steht (beispielsweise Cache-Management).</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">Alter aus Datensätzen im Cache, wenn sie in einer bestimmten Zeit nicht verwendet wurden. Die Standardeinstellung ist ein Tag; weitere Konfigurationsoptionen sind verfügbar.</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">Weiter: Lösungsübersicht</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">Optimale Cluster- und GPU-Auslastung bei Run:AI</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Lösungsüberblick</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">In diesem Abschnitt werden eine konventionelle Datenwissenschaftspipeline und ihre Nachteile überprüft. Sie stellt außerdem die Architektur der vorgeschlagenen Lösung für das Datensatz-Caching dar.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">Herkömmliche Data Science-Pipeline und Nachteile</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">Eine typische Sequenz der ENTWICKLUNG und Bereitstellung VON ML-Modellen umfasst iterative Schritte, die Folgendes beinhalten:</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">Datenaufnahme</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">Datenvorverarbeitung (Erstellung mehrerer Versionen der Datensätze)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">Durchführung mehrerer Experimente mit Hyperparameter-Optimierung, verschiedenen Modellen usw.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="list-text">Einsatz</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io hat eine umfassende Plattform entwickelt, um alle Aufgaben von der Forschung bis zur Bereitstellung zu automatisieren. In der folgenden Abbildung ist ein kleiner Ausschnitt von Dashboard-Screenshots zu der Pipeline dargestellt.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">In der Handhabung sind mehrere Datensätze häufig aus öffentlichen Repositorys und privaten Daten wiedergegeben. Darüber hinaus verfügt jeder Datensatz wahrscheinlich über mehrere Versionen, die sich aus der Datenbereinigung oder dem Feature Engineering ergeben. Eine Konsole, die einen Datensatz-Hub und einen VersionHub bereitstellt, ist erforderlich, um sicherzustellen, dass dem Team Collaboration- und Konsistenztools zur Verfügung stehen, wie in der folgenden Abbildung zu sehen sind.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">Der nächste Schritt in der Pipeline ist das Training. Es erfordert mehrere parallele Instanzen von Trainingsmodellen, die jeweils mit einem Datensatz und einer bestimmten Computing-Instanz verknüpft sind. Die Bindung eines Datensatzes an ein bestimmtes Experiment mit einer bestimmten Computing-Instanz ist eine Herausforderung, da es möglich ist, dass einige Experimente mit GPU-Instanzen von Amazon Web Services (AWS) durchgeführt werden, während andere Experimente vor Ort durch DGX-1 oder DGX-2-Instanzen durchgeführt werden. Andere Experimente können auf den CPU-Servern in GCP ausgeführt werden, während der Speicherort des Datensatzes nicht in angemessenem Umfang zu den Computing-Ressourcen liegt, die das Training durchführen. In angemessener Nähe wären volle 10 GbE oder mehr Konnektivität mit niedriger Latenz vom Datensatz-Storage zur Computing-Instanz.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">Data Scientists können den Datensatz in die Computing-Instanz herunterladen, die das Training durchführt und das Experiment ausführt. Allerdings gibt es bei diesem Ansatz mehrere potenzielle Probleme:</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">Wenn der Data Scientist den Datensatz auf eine Computing-Instanz herunterlädt, gibt es keine Garantie für eine hohe Performance des integrierten Computing-Storage (ein Beispiel für ein hochperformantes System wäre die ONTAP AFF A800 NVMe Lösung).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">Wenn sich der heruntergeladene Datensatz in einem Computing-Node befindet, kann Storage zum Engpass werden, wenn verteilte Modelle über mehrere Nodes ausgeführt werden (im Gegensatz zu dem hochperformanten verteilten ONTAP Storage von NetApp).</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">Die nächste Iteration des Trainingsexperiments kann in einer anderen Computing-Instanz aufgrund von Warteschlangenkonflikten oder Prioritäten durchgeführt werden, was erneut zu einer beträchtlichen Netzwerkdistanz vom Datensatz zum Computing-Standort führt.</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">Andere Teammitglieder, die Trainingsexperimente auf demselben Computing Cluster ausführen, können diesen Datensatz nicht gemeinsam nutzen. Jeder einzelne von einem beliebigen Ort aus kann den (kostspieligen) Download des Datensatzes durchführen.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">Wenn andere Datensätze oder Versionen desselben Datensatzes für die nachfolgenden Trainingsaufgaben benötigt werden, müssen die Datenanalysten erneut den (teuren) Download des Datensatzes auf die Computing-Instanz durchführen, die die training.NetApp und cnvrg.io ausführt, eine neue Caching-Lösung für Datensätze erstellt haben, die diese Hürden beseitigt. Die Lösung sorgt für eine schnellere Ausführung der ML-Pipeline und speichert häufig abgerufene Datensätze auf dem hochperformanten ONTAP Storage-System. Bei ONTAP NFS werden die Datensätze nur einmal (und nur einmal) in einer Data Fabric von NetApp (wie AFF A800) zwischengespeichert, die mit den Computing-Ressourcen verbunden ist. Da der Hochgeschwindigkeits-Storage NetApp ONTAP NFS mehrere ML-Computing-Nodes verarbeiten kann, wird die Performance der Trainingsmodelle optimiert. Dadurch können dem Unternehmen Kosteneinsparungen, Produktivität und betriebliche Effizienz erzielt werden.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Lösungsarchitektur</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">Diese Lösung von NetApp und cnvrg.io bietet Datensatz-Caching, wie in der folgenden Abbildung dargestellt. Beim Datensatz-Caching können Data Scientists einen gewünschten Datensatz oder eine Datensatzversion auswählen und diesen in den ONTAP NFS-Cache verschieben, der sich in der Nähe des ML-Computing-Clusters befindet. Der Data Scientist kann nun mehrere Experimente ausführen, ohne dass es zu Verzögerungen oder Downloads kommt. Zudem können alle gemeinsam genutzten Engineers denselben Datensatz mit dem angeschlossenen Computing-Cluster verwenden (bei freier Auswahl eines beliebigen Nodes), ohne dass weitere Downloads aus dem Data Lake erforderlich sind. Die Data Scientists erhalten ein Dashboard, das alle Datensätze und Versionen überwacht und eine Ansicht darüber liefert, welche Datensätze im Cache gespeichert wurden.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">Die cnvrg.io-Plattform erkennt automatisch ältere Datensätze, die für eine bestimmte Zeit nicht verwendet wurden, und entfernt sie aus dem Cache. Diese behält freien NFS-Cache-Speicherplatz für häufiger verwendete Datensätze bei. Hierbei ist zu beachten, dass das Datensatz-Caching mit ONTAP in der Cloud und on-Premises funktioniert und somit maximale Flexibilität bietet.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">Weiter: Konzepte und Komponenten</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">Dieser Abschnitt enthält Beispiele für verschiedene hochperformante Jobs, die ausgeführt werden können, wenn Kubernetes auf einem ONTAP AI POD implementiert wird.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">Beispiele für hochperformante Jobs für ONTAP KI-Implementierungen</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">Next: Führen Sie einen Single-Node-KI-Workload aus.</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">NetApp Artificial Intelligence Solutions sind eine Reihe strategischer und technischer Lösungen, die die Fähigkeiten von NetApp Storage im gesamten KI/ML-Bereich demonstrieren.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">NetApp Artificial Intelligence-Lösungen</block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">Auf dieser Seite werden die Schritte beschrieben, die zum Erstellen eines delegierten Subnetzes für Azure NetApp Files erforderlich sind.</block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="doc">Erstellen Sie ein delegiertes Subnetz für Azure NetApp Files</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">Früher: Installieren und einrichten Sie den AKS-Cluster.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Gehen Sie wie folgt vor, um ein delegiertes Subnetz für Azure NetApp Files zu erstellen:</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Navigieren Sie im Azure-Portal zu Virtual Networks. Suchen Sie Ihr neu erstelltes virtuelles Netzwerk. Er sollte ein Präfix wie haben<block ref="a3f69ea034ab8b71fed9b8fc221db9b4" prefix=" " category="inline-code"></block>.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">Klicken Sie auf den Namen des vnet.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">Klicken Sie auf Subnetze, und klicken Sie in der oberen Symbolleiste auf +Subnetz.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">Geben Sie dem Subnetz einen Namen an, z. B.<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Und wählen Sie unter der Überschrift Subnet Delegation die Option aus<block ref="0c20a1ae75c1cc4efae31193e0d47718" prefix=" " category="inline-code"></block>. Ändern Sie nichts anderes. Klicken Sie auf OK.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files Volumes werden dem Applikations-Cluster zugewiesen und als persistente Volume-Forderungen (PVCs) in Kubernetes genutzt. Dieser Prozess bietet Ihnen wiederum die Flexibilität, sie verschiedenen Services wie Jupyter Notebooks, serverlosen Funktionen usw. zuzuordnen.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">Benutzer von Services können Storage auf unterschiedliche Weise von der Plattform aus nutzen. Während dieser technische Bericht über NFSs behandelt, stehen die wichtigsten Vorteile von Azure NetApp Files im Mittelpunkt:</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">Benutzern die Möglichkeit zur Verwendung von Snapshot Kopien bieten</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">Ermöglicht Benutzern die Speicherung großer Datenmengen auf Azure NetApp Files Volumes.</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">Nutzung der Performance-Vorteile von Azure NetApp Files Volumes bei Ausführung ihrer Modelle auf großen Dateiansätzen.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">Weiter: Peer AKS vnet und Azure NetApp Files vnet.</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="doc">Erweitern Sie die Intent-Modelle mit Nemo Training</block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo ist ein von NVIDIA entwickeltes Toolkit für die Erstellung von umgangssprachlichen KI-Applikationen. Dieses Toolkit enthält vortrainierte Module für ASR, NLP und TTS, mit denen Forscher und Datenwissenschaftler komplexe neuronale Netzarchitekturen leicht erstellen und sich stärker auf die Entwicklung ihrer eigenen Anwendungen konzentrieren können.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">Wie im vorherigen Beispiel gezeigt, kann NARA nur eine begrenzte Art von Fragen verarbeiten. Denn das vortrainierte NLP-Modell trainiert nur bei diesen Fragen. Wenn NARA in der Lage ist, ein breiteres Spektrum von Fragen zu beantworten, müssen wir diese mit unseren eigenen Datensätzen neu Schulen. So zeigen wir hier, wie wir mit Nemo das NLP-Modell erweitern können, um den Anforderungen gerecht zu werden. Wir beginnen damit, das aus NARA gesammelte Protokoll in das Format für Nemo umzuwandeln und dann mit dem Datensatz zu trainieren, um das NLP-Modell zu verbessern.</block>
  <block id="a559b87068921eec05086ce5485e9784" category="section-title">Modell</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">Unser Ziel ist ES, NARA in die Lage zu versetzen, die Elemente anhand der Benutzereinstellungen zu sortieren. Zum Beispiel könnten wir NARA bitten, das beste Sushi-Restaurant zu empfehlen oder MÖCHTEN, DASS NARA die Jeans mit dem niedrigsten Preis nachschlagen kann. Dazu verwenden wir das in Nemo bereitgestellte Absichtserkennungs- und Steckplatzfüllmodell als Trainingsmodell. Mit diesem Modell KANN NARA den Zweck der Suchpräferenz verstehen.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">Datenvorbereitung</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">Um das Modell zu trainieren, sammeln wir den Datensatz für diese Art von Frage und konvertieren ihn in das Nemo-Format. Hier haben wir die Dateien aufgelistet, die wir für das Training des Modells verwenden.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">Diese Datei enthält alle Absichten, die wir von Nemo verstehen möchten. Hier haben wir zwei primäre Absichten und eine Absicht, die nur zur Kategorisierung der Fragen verwendet werden, die nicht in eine der primären Absichten passen.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">Diese Datei enthält alle Slots, die wir bei unseren Trainingsfragen kennzeichnen können.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">Zug.tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">Dies ist der Haupt-Trainingsdatensatz. Jede Zeile beginnt mit der Frage nach der Liste der Absichtskategorie in der Datei dict.intent.csv. Die Bezeichnung wird ab Null aufgezählt.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">Train_slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">Trainieren Sie das Modell</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">Wir verwenden dann den folgenden Befehl, um den Container zu starten. In diesem Befehl begrenzen wir den Container auf eine einzelne GPU (GPU-ID = 1), da es sich hierbei um eine leichte Trainingsübung handelt. Wir ordnen unseren lokalen Arbeitsbereich /Workspace/nemo/ auch dem Ordner im Container /nemo zu.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">Im Container können wir, wenn wir von dem ursprünglich vortrainierten BERT-Modell starten möchten, den folgenden Befehl verwenden, um das Training zu starten. Data_dir ist das Argument, um den Pfad der Trainingsdaten einzurichten. Mit Work_dir können Sie festlegen, wo Sie die Checkpoint-Dateien speichern möchten.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">Wenn wir neue Trainingsdatensätze haben und das vorherige Modell verbessern möchten, können wir mit dem folgenden Befehl fortfahren, nachdem wir das Ende gestoppt haben. Checkpoint_dir führt den Pfad zum Ordner frühere Checkpoints.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">Inferenz: Das Modell</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">Wir müssen die Performance des trainierten Modells nach einer bestimmten Anzahl von Epoch-Durchläufen validieren. Mit dem folgenden Befehl können wir die Abfrage One-by-One testen. In diesem Befehl möchten wir beispielsweise überprüfen, ob unser Modell die Absicht der Abfrage richtig identifizieren kann<block ref="fe494faf7f8c52514a674b8162027072" prefix=" " category="inline-code"></block>.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">Dann ist die Ausgabe des Inferenz unten. In der Ausgabe sehen wir, dass unser trainiertes Modell die Absicht Find_the_Store richtig vorhersagen kann und die Schlüsselworte, die wir interessieren, zurückgeben kann. Mit diesen Stichwörtern ermöglichen wir dem NARA, nach dem zu suchen, was der Benutzer wünscht, und führen eine präzisere Suche durch.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">Weiter: Fazit</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Beispiel Für Trident-Vorgänge</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Dieser Abschnitt enthält Beispiele für verschiedene Vorgänge, die Sie mit Trident durchführen können.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importieren eines vorhandenen Volumes</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Wenn bereits vorhandene Volumes auf dem NetApp Storage-System/auf der Plattform vorhanden sind, die Sie in Containern innerhalb des Kubernetes Clusters einbinden möchten, die jedoch nicht an PVCs im Cluster gebunden sind, müssen Sie diese Volumes importieren. Sie können diese Volumes mit der Trident-Funktion für den Volume-Import importieren.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">Die folgenden Beispielbefehle zeigen den Import des gleichen Volumes mit dem Namen<block ref="716577bd9ec46fd219326b2aa7404103" prefix=" " category="inline-code"></block> Zweimal einmal pro Trident Back-End, das im Beispiel im Abschnitt erstellt wurde <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 1. Wenn Sie dasselbe Volume zweimal auf diese Weise importieren, können Sie das Volume (ein vorhandenes FlexGroup Volume) mehrmals zwischen verschiedenen LIFs mounten, wie im Abschnitt beschrieben <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 1. Weitere Informationen zu PVCs finden Sie im<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. Weitere Informationen zur Importfunktion des Volumes finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> Der Wert von<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> Ist in den Beispiel-PVC-Spezifikationsdateien angegeben. Weitere Informationen zum<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> Feld, siehe<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">Beispiel: Kubernetes StorageClasses für ONTAP KI-Implementierungen</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">Die Backend-Namen, die in den folgenden Beispiel-Importbefehlen angegeben sind, entsprechen den Backends, die im Beispiel im Abschnitt erstellt wurden <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 1. Die StorageClass-Namen, die im folgenden Beispiel PVC-Definitionsdateien angegeben sind, entsprechen den StorageClasses, die im Beispiel im Abschnitt erstellt wurden <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, Schritt 1.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Bereitstellung eines neuen Volumes</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Mit Trident können Sie ein neues Volume auf Ihrem NetApp Storage-System oder Ihrer NetApp Plattform bereitstellen. Mit den folgenden Beispielbefehlen wird die Bereitstellung eines neuen FlexVol Volumes angezeigt. In diesem Beispiel wird das Volume mit der StorageClass bereitgestellt, die im Beispiel im Abschnitt erstellt wurde <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, Schritt 2.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> Der Wert von<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> Wird in der folgenden Beispiel-PVC-Definitionsdatei angegeben. Weitere Informationen zum<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> Feld, siehe<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">Weiter: Übersicht über hochperformante Jobs für ONTAP KI-Implementierungen</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">Ein echtes Conversational KI-System engagiert sich in einem menschlichen Dialog, versteht Kontext und bietet intelligente Antworten. Solche KI-Modelle sind oft riesig und sehr komplex. Mit NVIDIA GPUs und NetApp Storage können große, moderne Sprachmodelle trainiert und optimiert werden, um Inferenz schnell auszuführen. Dies ist ein wichtiger Schritt in Richtung einer Beendigung des Handels zwischen einem KI-Modell, das schnell ist, als ein großes und komplexes Modell. GPU-optimierte Modelle zur Sprachverständnisfunktion können für Branchen wie Gesundheitswesen, Einzelhandel und Finanzdienstleistungen in KI-Applikationen integriert werden und unterstützen digitale Sprachassistenten in intelligenten Lautsprechern und Kundenservices. Diese hochwertigen konvergenten KI-Systeme ermöglichen Unternehmen in verschiedenen Branchen, ihren Kundeneinbezug als bisher unerreichbare, personalisierte Services bereitzustellen.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis ermöglicht die Bereitstellung von Anwendungsbeispielen wie virtuellen Assistenten, digitalen Avataren, multimodalen Sensor Fusion (CV fusioned with ASR/NLP/TTS) oder jedem ASR/NLP/TTS/CV-Einzelanwendungsfall, wie z.B. Transkription. Wir haben einen virtuellen Einzelhandelsassistent aufgebaut, der Fragen zu Wetter, Points of Interest und Bestandspreisen beantworten kann. Wir haben auch demonstriert, wie sich das natürliche Sprachverständnis des konvergenten KI-Systems verbessern lässt, indem wir die Gesprächsgeschichte mit Cloud Sync archivieren und Nemo-Modelle mit neuen Daten trainieren.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">Lösungstechnologie</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">Hardware- und Software-Anforderungen</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">In diesem Abschnitt werden die Technologieanforderungen für die ONTAP AI Lösung erläutert.</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">Hardwareanforderungen</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI Website</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">Obwohl die Hardwareanforderungen von bestimmten Kunden-Workloads abhängen, kann ONTAP AI in jedem Umfang für das Data Engineering, das Modelltraining und die Produktionserwartung von einer einzelnen GPU bis zu Rack-Scale-Konfigurationen für umfangreiche ML/DL-Operationen implementiert werden. Weitere Informationen zu ONTAP AI finden Sie im<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">Diese Lösung wurde mit einem DGX-1-System für Computing, einem NetApp AFF A800 Storage-System und Cisco Nexus 3232C für die Netzwerk-Konnektivität validiert. Die in dieser Validierung verwendete AFF A800 kann bis zu 10 DGX-1-Systeme für die meisten ML/DL-Workloads unterstützen. Die folgende Abbildung zeigt die in dieser Validierung verwendete ONTAP KI-Topologie für das Modelltraining.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">Um diese Lösung auf eine Public Cloud zu erweitern, lässt sich Cloud Volumes ONTAP zusammen mit Cloud-GPU-Computing-Ressourcen implementieren und in eine Hybrid Cloud Data Fabric integrieren. Damit können Kunden die für jeden Workload geeigneten Ressourcen verwenden.</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">Softwareanforderungen</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">In der folgenden Tabelle sind die spezifischen Softwareversionen aufgeführt, die in dieser Lösungsvalidierung verwendet werden.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX-BETRIEBSSYSTEM</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="142f782bb2b326679982208fe40cec31" category="cell">NVIDIA DeepOps</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Helm</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">Cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">Kubernetes wurde für diese Lösungsvalidierung als Single-Node-Cluster auf dem DGX-1-System implementiert. Bei groß angelegten Implementierungen sollten unabhängige Kubernetes-Master-Nodes implementiert werden, um für Hochverfügbarkeit der Managementservices zu sorgen und wertvolle DGX-Ressourcen für ML- und DL-Workloads zu reservieren.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">Weiter – Details zur Lösungsimplementierung und -Validierung</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">Diese Lösung wurde mit einem NetApp AFF A800 System, zwei DGX-1-Servern und zwei Cisco Nexus 3232C 100-GbE-Switches implementiert. Jeder DGX-1-Server ist über vier 100-GbE-Verbindungen mit den Nexus-Switches verbunden. Letztere werden mittels RDMA (Remote Direct Memory Access) over Converged Ethernet (RoCE) für die Kommunikation zwischen GPUs eingesetzt. Über diese Links erfolgt auch die herkömmliche IP-Kommunikation für den NFS-Storage-Zugriff. Jeder Storage-Controller ist über vier 100-GbE-Links mit den Netzwerk-Switches verbunden. Die folgende Abbildung zeigt die in diesem technischen Bericht verwendete ONTAP AI Lösungsarchitektur für alle Testszenarien.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">In dieser Lösung verwendete Hardware</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">Diese Lösung wurde mit der ONTAP AI Referenzarchitektur zwei DGX-1-Nodes und einem AFF A800 Storage-System validiert. Siehe<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> Weitere Informationen zur in dieser Validierung verwendeten Infrastruktur</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">In der folgenden Tabelle werden die Hardwarekomponenten aufgeführt, die für die Implementierung der getesteten Lösung erforderlich sind.</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Trennt</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Menge</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1-Systeme</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Switches der Nexus 3232C-Serie</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">Diese Lösung wurde mit einer grundlegenden Kubernetes-Implementierung validiert, bei der der Run:AI Operator installiert ist. Kubernetes wurde mit dem implementiert<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> Deployment Engine: Hier werden alle erforderlichen Komponenten für eine produktionsbereite Umgebung implementiert. DeepOps wird automatisch implementiert<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Zur persistenten Storage-Integration in die Umgebung k8s wurden StandardStorage-Klassen erstellt, sodass Container Storage aus dem AFF A800 Storage-System nutzen können. Weitere Informationen zu Trident mit Kubernetes zu ONTAP AI finden Sie unter<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">In der folgenden Tabelle werden die Softwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Software</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">Version oder sonstige Informationen</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP Datenmanagement-Software</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9,6p4</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS Switch-Firmware</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3)I6(1)</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 – Ubuntu 18.04 LTS</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes-Version</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident Version</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">Ausführen:AI-CLI</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">V2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">Run:AI Orchestration Kubernetes Operator Version</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker-Container-Plattform</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-ce [e68fc7a]</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">Run:AI-GPU-Cluster-Voraussetzungen</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">Weitere Software-Anforderungen für Run:AI finden Sie unter<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">Nächste: Optimale Cluster- und GPU-Auslastung mit KI-Einsatz</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="e889531653bc3baae2aadf3bee46a54f" category="doc">NVA-1156-DEPLOY: NetApp EF-Series AI mit NVIDIA DGX A100 Systems und BeeGFS</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick und David Arnette, NetApp</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">In diesem Dokument werden eine NetApp Verified Architecture für Machine-Learning- (ML) und AI-Workloads (künstliche Intelligenz) mit NetApp EF600 NVMe-Storage-Systemen, das ThinkParQ BeeGFS Parallel Filesystem, NVIDIA DGX A100-Systeme und NVIDIA Mellanox Quantum QM8700 200 Gbps InfiniBand (IB)-Switches beschrieben. Dieses Dokument enthält außerdem Anweisungen zur Ausführung von Validierungstests nach Abschluss der Implementierung.</block>
  <block id="58f81dbff2cc92916b8e184779ecf9ad" category="inline-link-macro"><block ref="58f81dbff2cc92916b8e184779ecf9ad" category="inline-link-rx"></block></block>
  <block id="e032117163a7b2e48c80c9a423ff17b8" category="paragraph"><block ref="e032117163a7b2e48c80c9a423ff17b8" category="inline-link-macro-rx"></block></block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">Die folgende Abbildung zeigt die vorgeschlagene umgangssprachlichen KI-Systemarchitektur. Sie können mit dem System entweder mit Sprachsignal- oder Texteingabe interagieren. Wenn gesprochene Eingabe erkannt wird, führt Jarvis AI-as-Service (AIAAS) ASR aus, um Text für Dialog Manager zu erstellen. Dialog Manager speichert die Zustände der Konversation, leitet Text zu den entsprechenden Diensten weiter und leitet Befehle an Fulfillment Engine weiter. Jarvis NLP Service nimmt Text ein, erkennt Intents und Entities und gibt diese Intents und Entity Slots zurück an Dialog Manager, der dann Aktion an Fulfillment Engine sendet. Fulfillment Engine besteht aus Drittanbieter-APIs oder SQL-Datenbanken, die Benutzeranfragen beantworten. Nach Erhalt der Ergebnisse von Fulfillment Engine leitet Dialogue Manager Text an Jarvis TTS AIAaS weiter, um eine Audioantwort für den Endbenutzer zu erstellen. Wir können Gesprächsverlauf archivieren, Sätze mit Intents und Slots für Nemo-Schulungen annotieren, so dass der NLP-Service verbessert wird, wenn mehr Benutzer mit dem System interagieren.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">Diese Lösung wurde mit einer DGX-Station und einem AFF A220 Storage-System validiert. Jarvis benötigt entweder eine T4 oder V100 GPU zur Durchführung einer tiefen neuronalen Netzwerkcompuation.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 ODER V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX Station</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis Framework</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">Nvcr.io/nvidia/nemo:v0.10</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">Weiter: Erstellen Sie einen virtuellen Assistenten mit Jarvis, Cloud Sync, und Nemo Übersicht</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">Auf dieser Seite werden die Bibliotheken und Frameworks aufgeführt, die zum Erstellen dieser Aufgabe verwendet wurden. Alle diese Komponenten wurden vollständig in die rollenbasierte Zugriffs- und Sicherheitskontrolle von Azure integriert.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">Bibliotheken für die Datenverarbeitung und das Modelltraining</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">Früher: Azure NetApp Files Performance Tiers.</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">In der folgenden Tabelle sind die Bibliotheken und Frameworks aufgeführt, die zum Erstellen dieser Aufgabe verwendet wurden. Alle diese Komponenten wurden vollständig in die rollenbasierte Zugriffs- und Sicherheitskontrolle von Azure integriert.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">Bibliotheken/Framework</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Beschreibung</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">Fragen Sie die CuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">CuML-Bibliothek</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">Für ML zur Arbeit an GPU, das<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Bietet Zugriff auf DAS RAPIDS CuML-Paket mit DASK. RAPIDS CuML implementiert gängige ML-Algorithmen wie Clustering, Dimensionierungsreduzierung und Regression. Hochperformante GPU-basierte Implementierungen ermöglichen eine bis zu 100-fache Geschwindigkeit gegenüber CPU-basierten Ansätzen.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Fragen Sie nach cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">Dask-cudf Bibliothek</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF umfasst verschiedene andere Funktionen, die GPU-beschleunigte Extraktion, Transformation, Last (ETL) unterstützen, wie z. B. Untersetzung von Daten, Transformationen, One-Hot-Codierung und mehr. Das Team VON RAPIDS unterhält eine<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> Dazu gehören Hilfsmethoden für die Verwendung von Fragen und CuDF.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Ischikit Lernen</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">kostenplaner</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">Fit</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn bietet Dutzende von integrierten Algorithmen und Modellen für maschinelles Lernen an, die als Schätzer bezeichnet werden. Beide<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> Kann mit dem an einige Daten angepasst werden<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> Methode.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">Zum Vergleich haben wir zwei Notebooks für DIE ERSTELLUNG der ML-Pipelines eingesetzt, eines ist der konventionelle Pandas-Scikit-Learn-Ansatz, und das andere ist Distributed Training mit RAPIDS und Dask. Jedes Notebook kann einzeln getestet werden, um die Leistung in Bezug auf Zeit und Umfang zu sehen. Wir decken jedes Notebook einzeln ab, um die Vorteile des Distributed Trainings mit RAPIDS und Dask zu demonstrieren.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">Nächster: Lade Criteo Click Logs Tag 15 in Pandas und trainiere ein scikit-Learn Zufallswaldmodell.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">Auf dieser Seite werden die Aufgaben beschrieben, die Sie abschließen müssen, um NetApp Trident in Ihrem Kubernetes Cluster zu installieren und zu konfigurieren.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">Implementierung und Konfiguration von NetApp Trident</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie abschließen müssen, um NetApp Trident in Ihrem Kubernetes Cluster zu installieren und zu konfigurieren.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Bereitstellungsaufgaben ausführen, gehen wir davon aus, dass Sie bereits die folgenden Aufgaben ausgeführt haben:</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Sie verfügen bereits über ein funktionierendes Kubernetes Cluster und führen eine von Trident unterstützte Version von Kubernetes aus. Eine Liste der unterstützten Versionen finden Sie im<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>.</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Sie verfügen bereits über eine funktionierende NetApp Storage Appliance, softwaredefinierte Instanz oder Cloud-Storage-Service, die von Trident unterstützt wird.</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Um NetApp Trident in Ihrem Kubernetes-Cluster zu installieren und zu konfigurieren, führen Sie die folgenden Aufgaben über den Jump-Host der Implementierung aus:</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Trident lässt sich mit einer der folgenden Methoden implementieren:</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident Implementierungsanleitungen</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">Wenn Sie zur Implementierung Ihres Kubernetes-Clusters NVIDIA DeepOps verwendet haben, können Sie Trident auch mit NVIDIA DeepOps in Ihrem Kubernetes-Cluster implementieren. Folgen Sie zur Implementierung von Trident mit DeepOps dem<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">Implementierungsanleitungen</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">Back-Ends</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">StorageClasses</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">Wenn Sie NVIDIA DeepOps nicht zur Implementierung Ihres Kubernetes-Clusters verwendet haben oder Trident einfach manuell implementieren möchten, können Sie Trident anhand der implementieren<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> In der Trident Dokumentation. Erstellen Sie mindestens ein Trident Back-End und mindestens eine Kubernetes StorageClass. Sie erhalten weitere Informationen zur Konfiguration<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> Und<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> Siehe verlinkte Unterabschnitte bei NetApp Docs.</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">Beispiel: Kubernetes Storageclasses für ONTAP AI Implementierungen</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">Wenn Sie die NetApp AI Control Plane Lösung auf einem ONTAP AI POD implementieren, lesen Sie <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> Beispiele für verschiedene Trident Back-Ends, die Sie möglicherweise erstellen möchten, und <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> Für einige Beispiele für verschiedene Kubernetes StorageClasses, die Sie vielleicht erstellen möchten.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">Als Nächstes: Trident Back-Ends für ONTAP KI-Implementierungen.</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Bevor Trident zur dynamischen Provisionierung von Storage-Ressourcen innerhalb Ihres Kubernetes-Clusters verwendet werden kann, müssen Sie einen oder mehrere Kubernetes StorageClasses erstellen. Die Beispiele auf dieser Seite stellen verschiedene Arten von StorageClasses dar, die Sie möglicherweise erstellen möchten, wenn Sie die NetApp AI Control Plane Lösung auf einem ONTAP AI Pod implementieren.</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Bevor Trident zur dynamischen Provisionierung von Storage-Ressourcen innerhalb Ihres Kubernetes-Clusters verwendet werden kann, müssen Sie einen oder mehrere Kubernetes StorageClasses erstellen. Die folgenden Beispiele stellen verschiedene Arten von StorageClasses dar, die Sie möglicherweise erstellen möchten, wenn Sie die NetApp AI Control Plane Lösung auf einem ONTAP AI POD implementieren. Weitere Informationen zu StorageClasses finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp empfiehlt, für jedes FlexGroup-fähige Trident Back-End, das Sie im Abschnitt erstellt haben, eine separate StorageClass zu erstellen <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 1. Mit diesen granularen StorageClasses können Sie NFS-Mounts hinzufügen, die bestimmten LIFs entsprechen (die LIFs, die Sie beim Erstellen der Trident Back-Ends angegeben haben), als ein bestimmtes Back-End, das in der StorageClass Spec-Datei angegeben ist. Die folgenden Beispielbefehle zeigen die Erstellung von zwei StorageClasses, die den beiden Beispiel Backends entsprechen, die im Abschnitt erstellt wurden <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 1. Weitere Informationen zu StorageClasses finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes-Dokumentation</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">Damit ein anhaltendes Volume nicht gelöscht wird, wenn das entsprechende PersistenzVolumeClaim (PVC) gelöscht wird, verwendet das folgende Beispiel ein<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> Der Wert von<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>. Weitere Informationen zum<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> Feld, siehe den offiziellen<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">NetApp empfiehlt außerdem die Erstellung einer StorageClass, die dem FlexVol-fähigen Trident Back-End entspricht, das Sie im Abschnitt erstellt haben <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, Schritt 2. Die folgenden Beispielbefehle zeigen die Erstellung einer einzelnen StorageClass für FlexVol Volumes.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">Im folgenden Beispiel wird in der StorageClass-Definitionsdatei kein bestimmtes Back-End angegeben, da nur ein FlexVol-fähiges Trident-Backend erstellt wurde. Wenn Sie Volumes mit Kubernetes verwalten, die diese StorageClass verwenden, versucht Trident, jedes verfügbare Backend zu verwenden, das den verwendet<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> Treiber.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">NetApp empfiehlt außerdem, eine generische StorageClass für FlexGroup Volumes zu erstellen. Die folgenden Beispielbefehle zeigen die Erstellung eines einzelnen allgemeinen StorageClass für FlexGroup Volumes.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">Beachten Sie, dass in der StorageClass-Definitionsdatei kein bestimmtes Backend angegeben ist. Wenn Sie daher Kubernetes für die Administration von Volumes verwenden, die diese StorageClass verwenden, versucht Trident, jedes verfügbare Back-End zu verwenden, das die verwendet<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Treiber.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">Weiter: Übersicht Über Die Kubeflow Deployment.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="0046f5684030ae3e0fe25061bf411059" category="doc">NVA-1153-DESIGN: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">David Arnette und Sung-Han Lin, NetApp</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">NVA-1153-DESIGN beschreibt eine NetApp Verifizierte Architektur für Machine-Learning- (ML) und AI-Workloads (künstliche Intelligenz) mit NetApp AFF A800 Storage-Systemen, NVIDIA DGX A100-Systemen und NVIDIA Mellanox Spectrum SN3700V 200-GB-Ethernet-Switches. Dieses Design verfügt über RDMA over Converged Ethernet (RoCE) für die Compute-Cluster Interconnect-Fabric und bietet Unternehmen eine vollständig ethernet-basierte Architektur für hochperformante Workloads. Dieses Dokument enthält außerdem Benchmark-Testergebnisse für die implementierte Architektur.</block>
  <block id="7b6f81cfdb86a2e75cd90e7b2397b5c5" category="inline-link-macro"><block ref="7b6f81cfdb86a2e75cd90e7b2397b5c5" category="inline-link-rx"></block></block>
  <block id="12e9f3f9d266156ccfbbb4ea8f21eb86" category="paragraph"><block ref="12e9f3f9d266156ccfbbb4ea8f21eb86" category="inline-link-macro-rx"></block></block>
  <block id="53abcff00f0617502a70da8730cab6c0" category="doc">TR-4811: NetApp ONTAP AI Referenzarchitektur für das Gesundheitswesen: Diagnostische Bildgebung – Lösungsdesign</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang, Sung-Han Lin, Sathish Thyagarajan, NetApp Jacci Cenci, NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">Diese Referenzarchitektur bietet Richtlinien für Kunden, die eine KI-Infrastruktur (künstliche Intelligenz) mit NVIDIA DGX-2-Systemen und NetApp AFF-Storage für Anwendungsfälle im Gesundheitswesen aufbauen. Sie enthält Informationen zu den grundlegenden Workflows, die bei der Entwicklung von DL-Modellen (Deep Learning) für medizinische diagnostische Bildgebung verwendet werden, validierte Testfälle und Ergebnisse. Außerdem enthält sie Empfehlungen zur Dimensionierung für Kundenimplementierungen.</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link-macro"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="f6e5955fac81d01e271cb733c3163cba" category="paragraph"><block ref="f6e5955fac81d01e271cb733c3163cba" category="inline-link-macro-rx"></block></block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">In den folgenden Abschnitten finden Sie Einzelheiten zum Durchlauf:AI-Installation, Testszenarien und Ergebnisse, die bei dieser Validierung durchgeführt wurden.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">Betrieb und Performance dieses Systems haben wir mithilfe von Industriestandard-Benchmark-Tools, einschließlich TensorFlow Benchmarks, validiert. Mit dem ImageNet-Datensatz wurde ResNet-50 trainiert, ein berühmtes Convolutional Neural Network (CNN) DL-Modell für die Bildklassifizierung. ResNet-50 liefert ein präzises Trainingsergebnis mit einer schnelleren Verarbeitungszeit, wodurch wir eine ausreichende Nachfrage nach dem Storage-System erhöhen können.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">Weiter: Führen Sie AI Installation aus</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="doc">Testdetails für Abschnitt 4.9</block>
  <block id="c83553858a60514501e9751c0747dea0" category="inline-link-macro">Gerechtigkeit Bei Der Grundlegenden Ressourcenzuweisung</block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">Dieser Abschnitt enthält Testdetails für den Abschnitt <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">Senden von Jobs in folgender Reihenfolge:</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">Projekt</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell"># GPUs</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">Gesamt</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Kommentar</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">Team d</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">Workload zwischen Team und b/c wird angehalten und wird verschoben<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8/8</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">Andere Team-Workloads (b/c) unterbrechen und verschieben sich in<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">Die folgende ausgeführte Befehlssequenz ist zu beachten:</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">An dieser Stelle sollten Sie folgende Zustände haben:</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPUs zugewiesen</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">Workloads In Die Warteschlange</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">Team A</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4/4</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">Keine</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">Team b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">Team c</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">Siehe Abschnitt <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> Für eine Diskussion über das Fortsetzen des Testszenarios.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">Weiter: Testdetails für Abschnitt 4.10</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">Erreichen Einer Hohen Cluster-Auslastung</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="inline-link-macro">ResNet-50 mit ImageNet-Datensatz Benchmark-Zusammenfassung</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">In diesem Abschnitt emulieren wir ein realistisches Szenario, in dem vier Data-Science-Teams jeweils ihre eigenen Workloads einreichen, um die Run:KI-Orchestrierungslösung vorzuführen. Diese Lösung erzielt eine hohe Cluster-Auslastung, während Priorisierung beibehalten und GPU-Ressourcen ausgeglichen werden. Wir beginnen mit dem im Abschnitt beschriebenen ResNet-50-Benchmark <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">Wir führten den gleichen ResNet-50-Benchmark wie in aus<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. Wir haben die Flagge benutzt<block ref="f4fdcbb99cb8e39e4706115c80cb3968" prefix=" " category="inline-code"></block> Für Container, die sich nicht im öffentlichen Docker-Repository befinden. Wir haben die Verzeichnisse angehängt<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> Und<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Auf dem Host DGX-1-Node zu<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> Und<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Zum Behälter bzw.. Der Datensatz befindet sich bei NetApp AFFA800 mit dem<block ref="a64503025c7495ecf42633d117f8b536" prefix=" " category="inline-code"></block> Argument, das auf das Verzeichnis verweist. Beides<block ref="96dbae4bbcb6841c17bc66f858d93982" prefix=" " category="inline-code"></block> Und<block ref="a78db0f035a543e24e7b038d359b5e74" prefix=" " category="inline-code"></block> Meinen, dass wir eine GPU für diesen Job zuweisen. Ersteres ist ein Argument für das<block ref="6e38f16215ae91c11fc5c54b74c66d54" prefix=" " category="inline-code"></block> Skript, während letzteres eine Flagge für die ist<block ref="7897d57a96444dff260ef2bf8a0589b1" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">Die folgende Abbildung zeigt ein Dashboard mit Systemübersicht mit einer GPU-Auslastung von 97 % und allen sechzehn verfügbaren GPUs. Im Balkendiagramm der GPUs können Sie leicht sehen, wie viele GPUs jedem Team zugewiesen sind. Im Bereich laufende Jobs werden die aktuell ausgeführten Jobnamen, Projekte, Benutzer, Typ, Knoten, angezeigt. GPUs – verbrauchte, Laufzeit, Fortschritt und Auslastungsdetails Eine Liste der Workloads in der Warteschlange mit deren Wartezeit wird unter Ausstehende Jobs angezeigt. Schließlich bietet die Box Nodes GPU-Nummern und Auslastung für einzelne DGX-1-Nodes im Cluster.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">Nächste: Fraktionale GPU-Zuweisung für weniger anspruchsvolle oder interaktive Workloads</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Dieser Abschnitt beschreibt die Testverfahren zur Validierung dieser Lösung.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Testverfahren</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">Zurück: Testkonfiguration.</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">In dieser Validierung haben wir folgendes Testverfahren verwendet.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Einrichtung von Betriebssystem und KI-Inferenz</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">Codieren</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Für AFF C190 haben wir Ubuntu 18.04 mit NVIDIA-Treibern und Docker mit Unterstützung für NVIDIA-GPUs verwendet und MLPerf verwendet<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Erhältlich als Teil der Lenovo Vorlage an MLPerf Inferenz v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Für EF280 haben wir Ubuntu 20.04 mit NVIDIA-Treibern und Docker mit Unterstützung für NVIDIA-GPUs und MLPerf verwendet<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Verfügbar als Teil der Lenovo Vorlage für MLPerf Inferenz v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Zur Einrichtung des KI-Inferenz führen Sie folgende Schritte aus:</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Laden Sie Datensätze herunter, für die eine Registrierung erforderlich ist, den ImageNet 2012 Validation-Satz, den Criteo Terabyte-Datensatz und den Briats 2019-Trainingssatz, und entpacken Sie die Dateien.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Erstellen Sie ein Arbeitsverzeichnis mit mindestens 1 TB und definieren Sie die Umgebungsvariable<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> Bezug auf das Verzeichnis.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Sie sollten dieses Verzeichnis im gemeinsam genutzten Speicher für den Netzwerkspeicherfall oder die lokale Festplatte beim Testen mit lokalen Daten freigeben.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Führen Sie das Make-in-Management<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> Befehl, mit dem der Docker-Container für die erforderlichen Inferenzaufgaben erstellt und gestartet wird.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Die folgenden Befehle werden alle im laufenden Docker-Container ausgeführt:</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Laden Sie vortrainierte KI-Modelle für MLPerf-Inferenz-Aufgaben herunter:<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Laden Sie zusätzliche Datensätze herunter, die kostenlos heruntergeladen werden können:<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Daten vorverarbeiten: Make<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Ausführen:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block>.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Aufbau der für die GPU optimierten Inferenz-Engines in Computing-Servern:<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Führen Sie zum Ausführen von Inferenz-Workloads den folgenden Befehl aus (ein Befehl):</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">KI-Inferenz wird ausgeführt</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Es wurden drei Läufe ausgeführt:</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">KI-Inferenz eines einzelnen Servers mit lokalem Storage</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">KI-Inferenz eines einzelnen Servers mittels Netzwerk-Storage</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Multi-Server-KI-Inferenz mit Netzwerk-Storage</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">Weiter: Testergebnisse.</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Erstellen Sie einen virtuellen Assistenten mit Jarvis, Cloud Sync und Nemo</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">Weiter: Erstellen Sie einen virtuellen Assistenten mit Jarvis, Cloud Sync, und Nemo Übersicht</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="07bb9ea92d477ff776a5a9f59a55e75c" category="doc">TR-4799-DESIGN: NetApp ONTAP AI Referenzarchitektur für Workloads für das autonome Fahren</block>
  <block id="697dbe2a012e27540eab2481a9572ec4" category="paragraph">Die NVIDIA DGX-Systemfamilie ist die weltweit erste integrierte Plattform für künstliche Intelligenz (KI), die speziell für Enterprise-KI entwickelt wurde. NetApp AFF Storage-Systeme bieten extrem hohe Performance und branchenführende Funktionen für das Hybrid-Cloud-Datenmanagement. NetApp und NVIDIA haben gemeinsam die NetApp ONTAP AI Referenzarchitektur entwickelt, um Kunden eine sofort einsatzbereite Lösung zur Unterstützung von KI- und ML-Workloads (Machine Learning) mit Performance, Zuverlässigkeit und Support der Enterprise-Klasse zu bieten.</block>
  <block id="ae4f0cd83b874dc6ee1f3d15fbcde464" category="inline-link-macro"><block ref="ae4f0cd83b874dc6ee1f3d15fbcde464" category="inline-link-rx"></block></block>
  <block id="db2c2e1615c8876019da15e39f1c3ce4" category="paragraph"><block ref="db2c2e1615c8876019da15e39f1c3ce4" category="inline-link-macro-rx"></block></block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">In diesem Abschnitt zeigen wir das, wann<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Fragt nach mehr GPUs (sie sind unter ihrem Kontingent), unterbricht das System die Workloads von<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Und bewegt sie in einen auslaufenden Staat auf faire Weise.</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">Details, einschließlich Stellenausschreibungen, verwendete Container-Images und ausgeführte Befehlssequenzen, finden Sie im Abschnitt <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">Die folgende Abbildung zeigt die resultierende Cluster-Auslastung, die pro Team zugewiesenen GPUs und ausstehende Aufgaben aufgrund von automatischem Lastausgleich und präventivem Scheduling. Wir können beobachten, dass, wenn die Gesamtzahl der GPUs, die von allen Team-Workloads angefordert werden, die Gesamtzahl der verfügbaren GPUs im Cluster übersteigt, Run:der interne Fairness-Algorithmus von AI für jeden einen Job unterbricht<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Weil sie ihre Projektquote erreicht haben. So lässt sich eine insgesamt hohe Cluster-Auslastung erzielen, während Data-Science-Teams nach wie vor unter von einem Administrator festgelegten Ressourcenbeschränkungen arbeiten.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">Die Ergebnisse dieses Testszenarios zeigen Folgendes:</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">*Automatischer Lastenausgleich.* das System gleicht die Quote der GPUs automatisch aus, so dass jedes Team jetzt seine Quote nutzt. Die Workloads, die angehalten wurden, gehören zu Teams, die ihr Kontingent überschreiten.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">*Fair Share Pause.* das System wählt, die Arbeitsbelastung eines Teams zu stoppen, das über seiner Quote war und dann die Arbeitsbelastung des anderen Teams zu stoppen. Run:AI hat interne Fairness-Algorithmen.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">Weiter: Gerechtigkeit Wegen Überquoten</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Dieser Abschnitt bietet einen Überblick über die drei in dieser Lösung validierten Szenarien.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Test- und Validierungsplan</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">Zurück: Technologieübersicht.</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Für dieses Lösungsdesign wurden die folgenden drei Szenarien validiert:</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Eine Inferenz mit und ohne Protopia obfuscation in einem JupyterLab Workspace, der mithilfe des NetApp DataOps Toolkit für Kubernetes orchestriert wurde.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Einen Job zur Batch-Inferenz mit und ohne Protopia obfuscation auf Kubernetes mit einem Daten-Volume, das mithilfe des NetApp DataOps Toolkit für Kubernetes orchestriert wurde.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Ein Inferenz-Task unter Verwendung einer NVIDIA Triton Inferenz Server-Instanz, die mit dem NetApp DataOps Toolkit für Kubernetes orchestriert wurde. Vor dem Aufruf der Triton-Inferenz-API haben wir Protopia-Obfuscation auf das Bild angewendet, um die allgemeine Anforderung zu simulieren, dass alle über das Netzwerk übertragenen Daten obfuscated werden müssen. Dieser Workflow eignet sich für Anwendungsfälle, in denen Daten in einer vertrauenswürdigen Zone erfasst, jedoch zur Inferenz außerhalb dieser vertrauenswürdigen Zone weitergeleitet werden müssen. Ohne Protopia Obfuscation ist es nicht möglich, diese Art von Workflow ohne sensible Daten zu implementieren, die die vertrauenswürdige Zone verlassen.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">Als Nächstes: Testkonfiguration.</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">Zusammenfassung</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Verschiedene neue Applikationsszenarien, etwa durch erweiterte Treiberassistenzsysteme (ADAS), Industrie 4.0, Smart Cities und Internet of Things (IoT), erfordern die Verarbeitung von kontinuierlichen Datenströmen bei nahezu null Latenz. In diesem Dokument wird eine Computing- und Storage-Architektur beschrieben, um GPU-basierte Inferenz (KI) auf NetApp Storage-Controllern und Lenovo ThinkSystem Servern in einer Edge-Umgebung zu implementieren, die diese Anforderungen erfüllt. Dieses Dokument bietet auch Performance-Daten für die branchenübliche MLPerf Inferenz-Benchmark. Hierbei werden verschiedene Inferenzaufgaben auf Edge-Servern mit NVIDIA T4-GPUs evaluiert. Wir untersuchen die Performance von Offline-, Single-Stream- und Multistream-Inferenzszenarien und zeigen, dass die Architektur mit einem kostengünstigen Shared-Networked Storage-System eine hohe Performance aufweist und einen zentralen Datenstandort- und Modellmanagement für mehrere Edge-Server ermöglicht.</block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">Wie bereits im vorherigen Abschnitt erwähnt, werden Fehler innerhalb der Pipeline verbreitet, wenn immer zwei oder mehr Modelle für maschinelles Lernen nacheinander ausgeführt werden. Für diese Lösung ist die Stimmung des Satzes der wichtigste Faktor bei der Messung des Aktienrisikos des Unternehmens. Das sprach-zu-Text-Modell, obwohl wesentlich für die Pipeline, dient als Vorverarbeitung, bevor die Gefühle vorhergesagt werden können.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">Validierungsergebnisse</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">Zurück: Bereitstellung von Sentimentanalysen im Support-Center.</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">Wie bereits im vorherigen Abschnitt erwähnt, werden Fehler innerhalb der Pipeline verbreitet, wenn immer zwei oder mehr Modelle für maschinelles Lernen nacheinander ausgeführt werden. Für diese Lösung ist die Stimmung des Satzes der wichtigste Faktor bei der Messung des Aktienrisikos des Unternehmens. Das sprach-zu-Text-Modell, obwohl wesentlich für die Pipeline, dient als Vorverarbeitung, bevor die Gefühle vorhergesagt werden können. Was wirklich zählt, ist der Unterschied in der Stimmung zwischen den Urteile der Wahrheit und den vorhergesagten Sätzen. Dies dient als Proxy für die Wortfehlerrate (WER). Die sprach-zu-Text-Genauigkeit ist wichtig, aber der WER wird nicht direkt in der endgültigen Pipeline-Metrik verwendet.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">Diese Sentimentmetriken können für den F1-Score, den Rückruf und die Präzision jedes Satzes berechnet werden. Die Ergebnisse können anschließend zusammengefasst und in einer Durcheinander-Matrix sowie den Konfidenzintervallen für jede Metrik angezeigt werden.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">Der Vorteil des Lernens bei Übertragungen besteht in einer höheren Modellleistung zu einem Bruchteil der Datenanforderungen, der Trainingszeit und der Kosten. Außerdem sollten die fein abgestimmten Modelle mit ihren Basismodellen verglichen werden, um sicherzustellen, dass das Transferlernen die Leistung verbessert, anstatt sie zu beeinträchtigen. Mit anderen Worten: Das fein abgestimmte Modell sollte die Leistung im Support Center besser erbringen als das vortrainierte Modell.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">Pipeline-Bewertung</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">Testfall</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">Testnummer</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">Kennzahl für Einschätzung der Pipeline</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">Testvoraussetzungen</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">Fein abgestimmte Modelle für Speech-to-Text- und Sentiment-Analysemodelle</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">Erwartetes Ergebnis</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">Die Sentimentmetrik des fein abgestimmten Modells liefert eine bessere Leistung als das ursprüngliche vortrainierte Modell.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">Berechnen Sie die Sentimentmetrik für das Basismodell.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">Berechnen Sie die Sentimentmetrik für das fein abgestimmte Modell.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">Berechnen Sie die Differenz zwischen diesen Metriken.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">Die Unterschiede in allen Sätzen sind durchschnittlich.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">Als Nächstes: Videos und Demos.</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI Control Plane:</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">Technischer Bericht: NetApp AI Control Plane</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">Persistenter NetApp Storage für Container:</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML-Rahmen und Werkzeuge:</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow: Ein Open-Source Machine Learning Framework für alle<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">Kubeflow</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter Notebook Server</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio Data Science Platform</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio Data Science Platform Dokumentation</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Serverlose Nuclio-Funktion</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun opensource Pipeline-Orchestrierungs-Framework</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1-Systeme</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor Core GPU</block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU Cloud</block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF Datenblatt</block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">NetApp Flash Advantage für AFF</block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x Dokumentation</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">Technischer Bericht von NetApp FlexGroup</block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Cisco Networking</block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">ONTAP AI mit DGX-1 und Cisco Networking Deployment Guide</block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Mellanox Networking</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP KI-Netzwerke</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Switches der Cisco Nexus 3232C-Serie</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox Scale-out SN2000 Ethernet Switch-Serie</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie zur Implementierung von Airflow in Ihrem Kubernetes-Cluster ausführen müssen.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow Deployment</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">NetApp empfiehlt, Apache Airflow zusätzlich zu Kubernetes auszuführen. In diesem Abschnitt werden die Aufgaben beschrieben, die Sie zur Implementierung von Airflow in Ihrem Kubernetes-Cluster ausführen müssen.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Es ist möglich, Airflow auf anderen Plattformen als Kubernetes bereitzustellen. Die Implementierung von Airflow auf anderen Plattformen als Kubernetes ist nicht im Umfang dieser Lösung enthalten.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Sie verfügen bereits über einen funktionierenden Kubernetes-Cluster.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">Sie haben NetApp Trident bereits in Ihrem Kubernetes Cluster installiert und konfiguriert, wie im Abschnitt „NetApp Trident Deployment and Configuration“ beschrieben.</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Installieren Sie Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">Installationsanweisungen</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Der Luftstrom wird über Helm, einen beliebten Paketmanager für Kubernetes, implementiert. Bevor Sie Airflow bereitstellen, müssen Sie Helm auf dem Bereitstellungs-Jump-Host installieren. Um Helm auf dem Sprunghost für die Bereitstellung zu installieren, folgen Sie dem<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> In der offiziellen Helm-Dokumentation.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Standard-Kubernetes StorageClass festlegen</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow Deployment</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">Bevor Sie Airflow bereitstellen, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes-Cluster zuweisen. Der Airflow-Implementierungsprozess versucht, mithilfe der Standard-StorageClass neue persistente Volumes bereitzustellen. Wenn keine StorageClass als Standard-StorageClass festgelegt ist, schlägt die Bereitstellung fehl. Befolgen Sie die Anweisungen im Abschnitt, um eine Standard-StorageClass in Ihrem Cluster festzulegen <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. Wenn Sie bereits eine Standard-StorageClass innerhalb Ihres Clusters festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Verwenden Sie Helm zum Bereitstellen des Luftstroms</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Um Airflow mithilfe von Helm in Ihren Kubernetes-Cluster zu implementieren, führen Sie die folgenden Aufgaben vom Bereitstellungs-Jump-Host aus:</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Setzen Sie den Luftstrom mithilfe von Helm ein, indem Sie den folgen<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Für das offizielle Airflow-Diagramm auf dem Artefakt-Hub. Die folgenden Beispielbefehle zeigen die Bereitstellung von Airflow mit Helm. Ändern, Hinzufügen und/oder Entfernen von Werten im<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> Datei nach Bedarf, abhängig von Ihrer Umgebung und der gewünschten Konfiguration.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Vergewissern Sie sich, dass alle Airflow-Pods betriebsbereit sind. Es kann ein paar Minuten dauern, bis alle Pods beginnen.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Rufen Sie die URL des Airflow Webservice ab, indem Sie die Anweisungen befolgen, die bei der Bereitstellung von Airflow mit Hilfe von Helm in Schritt 1 an der Konsole gedruckt wurden.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Vergewissern Sie sich, dass Sie auf den Airflow Webservice zugreifen können.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">Weiter: Beispiel Apache Airflow Workflows.</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Übersicht über NetApp</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp ist die Instanz für Daten in der Hybrid Cloud. Mit einem Portfolio an Hybrid Cloud Data Services, die das Management von Applikationen und Daten über Cloud- und On-Premises-Umgebungen hinweg vereinfachen, beschleunigt NetApp den digitalen Wandel. Gemeinsam mit Partnern hilft NetApp Unternehmen weltweit, das volle Potenzial ihrer Daten auszuschöpfen und so Touchpoints zu Kunden auszubauen, Innovationen voranzutreiben und Betriebsabläufe zu optimieren.</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">Mit NetApp ONTAP AI mit Unterstützung von NVIDIA DGX Systemen und NetApp All-Flash-Storage mit Cloud-Integration optimieren Sie den Datenfluss zuverlässig und beschleunigen Analysen, Training und Inferenz über Ihre Data-Fabric-Architektur im gesamten Datacenter (Edge-, Core- und Cloud-Bereich). Sie bietet IT-Abteilungen eine Architektur mit folgenden Vorteilen:</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Sie vereinfacht das Design</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Computing und Storage können unabhängig voneinander skaliert werden</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Kunden können mit einer kleinen Konfiguration starten und nahtlos skalieren</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">Bietet eine Reihe von Storage-Optionen für verschiedene Performance- und KostennutzungNetApp ONTAP AI bietet konvergente Infrastruktur-Stacks mit NVIDIA DGX-1, einem KI-System im Petaflop-Bereich und NVIDIA Mellanox High-Performance-Ethernet-Switches, um KI-Workloads zu vereinheitlichen, die Implementierung zu vereinfachen und den ROI zu beschleunigen. Für diesen technischen Bericht haben wir ONTAP AI mit einem DGX-1 und einem NetApp AFF A800 Storage-System genutzt. Das folgende Bild zeigt die Topologie von ONTAP AI mit dem in dieser Validierung verwendeten DGX-1-System.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI Control Plane</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">Die NetApp AI Control Plane ermöglicht Ihnen die optimale Nutzung von KI- und ML-Applikationen mit einer Lösung, die höchste Skalierbarkeit, optimierte Implementierung und ununterbrochene Datenverfügbarkeit bietet. Die AI Control Plane Lösung integriert Kubernetes und Kubeflow in die Data-Fabric-Strategie von NetApp. Kubernetes, die standardmäßige Container-Orchestrierungsplattform der Branche für Cloud-native Bereitstellungen, bietet Skalierbarkeit und Portabilität von Workloads. Kubeflow ist eine Open-Source Machine Learning-Plattform, die Management und Bereitstellung vereinfacht und Entwicklern ermöglicht, mehr Datenwissenschaft in weniger Zeit zu leisten. Eine Data-Fabric-Strategie von NetApp bietet Datenverfügbarkeit und -Portabilität ohne Kompromisse. So wird sichergestellt, dass Ihre Daten in der gesamten Pipeline (Edge, Core, Cloud) aufgerufen werden können. Dieser technische Bericht verwendet die NetApp AI Control Plane in einer MLRun-Pipeline. Das folgende Bild zeigt die Kubernetes-Cluster-Managementseite, auf der Sie unterschiedliche Endpunkte für jedes Cluster haben können. Wir haben persistente NFS-Volumes mit dem Kubernetes-Cluster verbunden. Die folgenden Images zeigen ein persistentes Volume, das mit dem Cluster verbunden ist<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> Unterstützung für persistenten Storage und Datenmanagementfunktionen</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio Übersicht</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Die Iguazio Data Science Platform ist eine vollständig integrierte und sichere Plattform für Data-Science-Dienste (PaaS), die die Entwicklung vereinfacht, die Performance beschleunigt, die Zusammenarbeit erleichtert und betriebliche Herausforderungen bewältigt. Diese Plattform umfasst die folgenden Komponenten, und die Iguazio Data Science Platform wird im folgenden Bild dargestellt:</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Eine Data-Science-Umgebung mit Jupyter Notebooks, integrierten Analyse-Engines und Python-Paketen</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">Modellmanagement mit Experimentierverfolgung und automatisierten Pipeline-Funktionen</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">Gemanagt von Daten und ML-Services über ein skalierbares Kubernetes-Cluster</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nuclio, ein Framework ohne Server in Echtzeit</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">Eine extrem schnelle und sichere Datenschicht, die SQL, NoSQL, Zeitreihen-Datenbanken, Dateien (einfache Objekte) und Streaming unterstützt</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">Integration mit Datenquellen von Drittanbietern wie NetApp, Amazon S3, HDFS, SQL Datenbanken sowie Streaming- und Messaging-Protokollen</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Echtzeit-Dashboards auf Basis von Grafana</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">Als Nächstes: Software- und Hardware-Anforderungen</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">Sehen Sie sich die folgenden Dokumente und Websites an, um mehr über die in diesem Dokument beschriebenen Informationen zu erfahren.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">Weitere Informationen</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Sehen Sie sich die folgenden Dokumente und/oder Websites an, um mehr über die in diesem Dokument beschriebenen Informationen zu erfahren:</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">Datensatz: TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">Deep Learning Network Architecture: Räumliches Convolutional Neural Network</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">Distributed Deep Learning Training Framework: Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">AUSFÜHRUNG: KI-Container-Orchestrierungslösung: RUN: KI-Produkteinführung</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">AUSFÜHREN: KI-Installationsdokumentation</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">Einsenden von Jobs in AUSFÜHRUNG: AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure Cloud-Ressourcen als Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes Service</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKUs</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Azure VM mit GPU-SKUs</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">Data Fabric von NetApp</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp Produktdokumentation</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">Run:KI-Plattform zur Orchestrierung von KI-Workloads</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">Schnellere Innovationen Mithilfe von Run:KI-Ressourcen-Pooling, Warteschlangen und Priorisierungsmechanismen werden zusammen mit dem NetApp Storage-System Forscher nicht mehr von den Problemen beim Infrastruktur-Management befreit und können sich ausschließlich auf die Datenwissenschaft konzentrieren. Run:KI und NetApp Kunden steigern die Produktivität, indem sie genau so viele Workloads ohne Engpässe bei Computing oder Daten-Pipeline ausführen.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">Höhere Teamproduktivität – Run:AI Fairness-Algorithmen garantieren, dass alle Benutzer und Teams einen gerechten Anteil an Ressourcen erhalten. Richtlinien für vorrangige Projekte können voreingestellt werden, und die Plattform ermöglicht die dynamische Zuweisung von Ressourcen von einem Benutzerteam zum anderen, sodass Benutzer rechtzeitig auf begehrte GPU-Ressourcen zugreifen können.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">Verbesserte GPU-Auslastung. Run:AI Scheduler ermöglicht Benutzern das einfache Verwenden von fraktionalen GPUs, Integer-GPUs und mehreren Nodes von GPUs für verteiltes Training auf Kubernetes. Auf diese Weise werden KI-Workloads je nach Anforderungen und nicht nach Kapazität ausgeführt. Data-Science-Teams können mehr KI-Experimente in der gleichen Infrastruktur ausführen.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">Als Nächstes: Lösungstechnologie</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">Die digitale Bildverarbeitung bietet zahlreiche Vorteile, sodass viele Unternehmen das Beste aus ihren Daten in Verbindung mit visuellen Darstellungen machen können. Diese Lösung von NetApp und Protopia bietet ein einzigartiges Design zur KI-Inferenz zum Schutz und zur Privatisierung von KI/ML-Daten im ml/DL-Lebenszyklus. Kunden können damit die Kontrolle über sensible Daten behalten, Skalierungsmodelle und Effizienz in Public oder Hybrid-Cloud-Umgebungen nutzen, indem sie Bedenken im Zusammenhang mit dem Datenschutz ausräumen und die KI-Inferenz im Edge-Bereich implementieren.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="doc">Lösungsbereiche</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">Zurück: Übersicht.</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Umweltbewusstsein</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Es gibt viele Möglichkeiten, wie Branchen die Vorteile der Geospatialanalytik in den Bereichen der Umweltgefahren nutzen können. Regierungen und das Ministerium für öffentliche Arbeiten können nützliche Einblicke in die öffentliche Gesundheit und die Wetterbedingungen erhalten, um die Öffentlichkeit bei einer Pandemie oder einer Naturkatastrophe wie Waldbränden besser beraten zu können. So können Sie beispielsweise einen COVID-positiven Patienten in öffentlichen Räumen, wie Flughäfen oder Krankenhäusern, identifizieren, ohne die Privatsphäre der betroffenen Person zu beeinträchtigen und die jeweiligen Behörden und die Öffentlichkeit in der Umgebung auf notwendige Sicherheitsmaßnahmen aufmerksam zu machen.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Tragbare Geräte am Edge</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Im Militär und auf Schlachtfeldern können Sie mithilfe der KI-Inferenz am Rand als tragbare Geräte den Status von Soldaten verfolgen, das Fahrverhalten überwachen und Behörden über die Sicherheit und die damit verbundenen Risiken im Zusammenhang mit der Annäherung an Militärfahrzeuge informieren, während die Privatsphäre von Soldaten geschützt und geschützt wird. Die Zukunft des Militärs wird mit dem Internet of Battlefield Things (IoBT) und dem Internet of Military Things (IoMT) High-Tech für tragbare Kampfausrüstung, die Soldaten helfen, Feinde zu identifizieren und besser im Kampf durch schnelle Edge-Computing. Der Schutz und der Schutz visueller Daten, die von Edge-Geräten wie Drohnen und tragbaren Getrieben erfasst werden, ist von entscheidender Bedeutung, um Hacker und Gegner vor Schach zu halten.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Nicht kämpferische Evakuierungsvorgänge</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Nichtkämpferische Evakuierungsmaßnahmen (NEO) werden vom DoD durchgeführt, um bei der Evakuierung von US-Bürgern und Staatsangehörigen, ziviler DoD-Mitarbeiter und designierten Personen (HN) und Drittstaatsangehörigen (TCNs) zu helfen, deren Leben in Gefahr für einen geeigneten sicheren Hafen sind. Die vorhandenen administrativen Kontrollen nutzen weitgehend manuelle Evakuierungsverfahren. Jedoch könnte die Genauigkeit, Sicherheit und Geschwindigkeit der Evakuierung von ee-Identifizierung, Evakuierung von ee-Tracking und Bedrohungsabschirmung durch den Einsatz hochautomatisierter KI/ML-Tools in Kombination mit AI/ML-Videobfuskationstechnologien verbessert werden.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Gesundheitswesen und biomedizinische Forschung</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">Mithilfe der Bildverarbeitung werden Pathologien für die chirurgische Planung anhand von 3D-Bildern aus der Computertomographie (CT) oder der Magnetresonanztomographie (MRT) diagnostiziert. Die HIPAA-Datenschutzregeln regeln regeln die Art und Weise, in der Daten von Unternehmen für alle persönlichen Informationen und digitalen Bilder wie Fotos gesammelt, verarbeitet und gelöscht werden müssen. Damit die Daten gemäß den HIPAA Safe Harbor-Bestimmungen als teilbar gelten, müssen Fotos mit voller Fläche und vergleichbare Bilder entfernt werden. Automatisierte Techniken wie De-Identification oder Skull‐Abisolieralgorithmen, die zur Obscrung der Gesichtszüge eines Einzelnen aus strukturellen CT/MR-Bildern verwendet werden, sind zu einem wesentlichen Bestandteil des Datenfreigabeprozesses für biomedizinische Forschungseinrichtungen geworden.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Cloud-Migration von KI/ML-Analysen</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">Datensicherung</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Enterprise-Kunden haben bisher KI/ML-Modelle lokal geschult und implementiert. Aus Skaleneffekten und Effizienzgründen erweitern diese Kunden zunehmend KI/ML-Funktionen in Public-, Hybrid- oder Multi-Cloud-Implementierungen. Sie sind jedoch an die gebunden, welche Daten anderen Infrastrukturen zugänglich sein können. NetApp Lösungen erfüllen die Anforderungen einer Reihe von Cybersicherheitsbedrohungen, die für erforderlich sind<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> Die Sicherheitsbewertung und minimieren in Kombination mit der Protopia Datentransformation die Risiken, die mit der Migration von KI/ML-Workloads für die Bildverarbeitung in die Cloud verbunden sind.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886 KI-Inferenzierung am Edge</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">Intelligenz und Datenschutz</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">Weitere Anwendungsfälle für Edge-Computing und KI-Inferenz in anderen Branchen finden Sie unter<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> Mit dem NetApp AI Blog<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>.</block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">Weiter: Technologische Übersicht.</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">Testdetails für Abschnitt 4.8</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link-macro">Erreichen einer hohen Cluster-Auslastung mit GPU-Zuweisung über ein Kontingent</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">Dieser Abschnitt enthält die Testdetails für den Abschnitt <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">Bild</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">NetApp</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">Run:AI</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">Mit allen ihren Quoten</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">Fraktionale GPU</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4/2</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">Zwei über Kontingente</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">Eins über Kontingent</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">Mit der Hälfte ihrer Quote</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">Befehlsstruktur:</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">Tatsächliche Befehlssequenz, die beim Testen verwendet wird:</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 (weiche Quote/ist-Zuweisung)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Hohe Cluster-Auslastung durch GPU-Zuweisung über Uota</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">Siehe Abschnitt <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> Für Diskussionen über das Fortsetzen des Testszenarios.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">Weiter: Testdetails für Abschnitt 4.9</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI Implementierung</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-DEPLOY: NetApp ONTAP AI, Powered by NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">Für die Implementierung von ONTAP AI sind die Installation und Konfiguration von Netzwerk-, Computing- und Storage-Hardware erforderlich. Spezifische Anweisungen für die Implementierung der ONTAP AI-Infrastruktur liegen nicht im Umfang dieses Dokuments vor. Detaillierte Informationen zur Bereitstellung finden Sie unter<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">Für diese Lösungsvalidierung wurde ein einzelnes Volume erstellt und auf dem DGX-1-System gemountet. Dieser Mount-Punkt wurde dann in die Container eingebunden, um die Daten für das Training zugänglich zu machen. Bei umfangreichen Implementierungen automatisiert NetApp Trident die Erstellung und das Mounten von Volumes, um den administrativen Overhead zu beseitigen und Ressourcen für Endbenutzer zu managen.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">Weiter: Kubernetes Deployment</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">Auf dieser Seite werden die Aufgaben beschrieben, die Sie für die Bereitstellung von Kubeflow in Ihrem Kubernetes-Cluster abschließen müssen.</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die Sie zur Bereitstellung von Kubeflow in Ihrem Kubernetes-Cluster abschließen müssen.</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Offizielle Dokumentation von Kubeflow</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Sie haben bereits einen funktionierenden Kubernetes-Cluster und führen eine Version von Kubernetes aus, die von Kubeflow unterstützt wird. Eine Liste der unterstützten Versionen finden Sie im<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Implementierung und Konfiguration von Trident</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">Sie haben NetApp Trident bereits in Ihrem Kubernetes Cluster installiert und konfiguriert, wie in beschrieben <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Bevor Sie Kubeflow implementieren, müssen Sie eine Standard-StorageClass in Ihrem Kubernetes Cluster zuweisen. Der Kubeflow Implementierungsprozess versucht, neue persistente Volumes mit der Standard-StorageClass bereitzustellen. Wenn keine StorageClass als Standard-StorageClass festgelegt ist, schlägt die Bereitstellung fehl. Um eine Standard-StorageClass innerhalb des Clusters festzulegen, führen Sie die folgende Aufgabe vom Sprunghost für die Bereitstellung aus. Wenn Sie bereits eine Standard-StorageClass innerhalb Ihres Clusters festgelegt haben, können Sie diesen Schritt überspringen.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">Weisen Sie einen Ihrer vorhandenen StorageClasses als Standard-StorageClass zu. Die folgenden Beispielbefehle zeigen die Bezeichnung einer StorageClass mit dem Namen an<block ref="b3e01914c123afcd317121eb293386c4" prefix=" " category="inline-code"></block> Als Standard-StorageClass.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">Der<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Der Trident Back-End-Typ hat eine ziemlich große PVC-Mindestgröße. Standardmäßig versucht Kubeflow, PVCs bereitzustellen, die nur wenige GB groß sind. Daher sollten Sie keine StorageClass angeben, die den verwendet<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Back-End-Typ als Standard StorageClass für die Zwecke der Kubeflow-Bereitstellung.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">Verwenden Sie NVIDIA DeepOps zur Implementierung von Kubeflow</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NetApp empfiehlt, das von NVIDIA DeepOps zur Verfügung gestellte Kubeflow Implementierungs-Tool zu verwenden. Um Kubeflow in Ihren Kubernetes-Cluster mit dem DeepOps-Implementierungstool zu implementieren, führen Sie die folgenden Aufgaben auf dem Sprunghost der Bereitstellung aus.</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">Alternativ können Sie Kubeflow manuell bereitstellen, indem Sie dem folgen<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> In der offiziellen Kubeflow Dokumentation</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Anweisungen zur Bereitstellung von Kubeflow</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">Implementieren Sie Kubeflow in Ihrem Cluster, indem Sie den folgen<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Beachten Sie unten die URL des Kubeflow Dashboard, die vom DeepOps Kubeflow Bereitstellungs-Tool ausgegeben wird.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Vergewissern Sie sich, dass alle im Kubeflow Namespace bereitgestellten Pods A zeigen<block ref="5f241c8c8f985b3c51e05d39cf030f4c" prefix=" " category="inline-code"></block> Von<block ref="5bda814c4aedb126839228f1a3d92f09" prefix=" " category="inline-code"></block> Und vergewissern Sie sich, dass sich keine im Namespace bereitgestellten Komponenten in einem Fehlerzustand befinden. Es kann mehrere Minuten dauern, bis alle Pods beginnen.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">Rufen Sie in Ihrem Webbrowser das zentrale Kubeflow Dashboard auf, indem Sie zur URL navigieren, die Sie in Schritt 2 angegeben haben.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">Der Standardbenutzername lautet<block ref="e0fb0c8707d7da1341e171401e7c9e14" prefix=" " category="inline-code"></block>, Und das Standardpasswort lautet<block ref="ed2b1f468c5f915f3f1cf75d7068baae" prefix=" " category="inline-code"></block>. Um weitere Benutzer zu erstellen, befolgen Sie die Anweisungen im<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">Weiter: Beispiel Kubeflow Operations und Tasks.</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">Demonstration des NetApp Retail Assistant</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">Dieser Link</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">Wir haben ein Demovideo zu dem NetApp Retail Assistant (NARA) aufgenommen. Klicken Sie Auf<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> So öffnen Sie die folgende Abbildung und geben die Videovorführung wieder.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">Als Nächstes: Verwenden Sie NetApp Cloud Sync zur Archivierung des Gesprächsverlaufs</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">Bei der Entwicklung dieses technischen Berichts hat NetApp AI gemeinsam mit SEINER RUN KI die einzigartigen Funktionen der Azure NetApp Files zusammen mit einer KI-Plattform zur Vereinfachung der Orchestrierung von KI-Workloads demonstriert.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp und RUN: KI haben bei der Erstellung dieses technischen Berichts gemeinsam die einzigartigen Funktionen der Azure NetApp Files zusammen MIT DER RUN-KI-Plattform zur Vereinfachung der Orchestrierung von KI-Workloads demonstriert. Dieser technische Bericht enthält eine Referenzarchitektur zur Optimierung des Prozesses von Daten-Pipelines und Workload-Orchestrierung für Distributed Lane-Erkennungstrainings.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">Fazit: Was verteiltes Training nach Maß angeht (insbesondere in einer Public Cloud-Umgebung), ist die Ressourcenorchestrierung und die Storage-Komponente ein wesentlicher Bestandteil der Lösung. Sicherstellen, dass das Datenmanagement nie die Verarbeitung mehrerer GPUs beeinträchtigt, führt daher zu einer optimalen Auslastung der GPU-Zyklen. Damit wird das System für große verteilte Schulungszwecke so kosteneffizient wie möglich.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">Mit der Data Fabric von NetApp können Data Scientists und Data Engineers On-Premises- und Cloud-Ressourcen miteinander verbinden, um synchrone Daten zu speichern – ohne manuelle Eingriffe. Mit anderen Worten: Die Data-Fabric-Infrastruktur gestaltet das Management von KI-Workflows, die über mehrere Standorte verteilt sind, reibungslos. Es erleichtert zudem die bedarfsgerechte Datenverfügbarkeit, indem die Daten näher an das Computing übertragen und Analysen, Training und Validierungen durchgeführt werden – wo und wann immer dies erforderlich ist. Dies ermöglicht nicht nur die Datenintegration, sondern auch Schutz und Sicherheit der gesamten Datenpipeline.</block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise ist eine End-to-End-Suite, in der Cloud-native KI- und Datenanalysesoftware integriert ist, die für den erfolgreichen Einsatz von KI im Unternehmen optimiert ist.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise with NetApp and VMware</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Für IT-Architekten und -Administratoren sind KI-Tools häufig kompliziert und können nicht kenne. Viele KI-Plattformen sind darüber hinaus nicht für die Enterprise-Klasse ausgelegt. NVIDIA AI Enterprise mit Unterstützung von NetApp und VMware wurde entwickelt, um eine optimierte KI-Architektur der Enterprise-Klasse bereitzustellen.</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise ist eine End-to-End-Suite mit Cloud-nativer KI- und Datenanalyse-Software, die von NVIDIA für die Ausführung auf VMware vSphere mit NVIDIA-zertifizierten Systemen optimiert, zertifiziert und unterstützt wird. Diese Software vereinfacht die einfache und schnelle Implementierung, das einfache Management und die Skalierung von KI-Workloads in modernen Hybrid-Cloud-Umgebungen. NVIDIA AI Enterprise mit NetApp und VMware bietet KI-Workload und Datenmanagement der Enterprise-Klasse in einem einfachen, vertrauten Paket.</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">Weiter: Technologischer Überblick.</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">Software- und Hardware-Anforderungen erfüllt</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">Netzwerkkonfiguration</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">Die folgende Netzwerkkonfigurationsanforderung für die Einrichtung in der Cloud:</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Das Iguazio Cluster und NetApp Cloud Volumes müssen sich in der gleichen virtuellen Private Cloud befinden.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">Der Cloud-Manager muss Zugriff auf Port 6443 auf den Iguazio-App-Nodes haben.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">In diesem technischen Bericht haben wir Amazon Web Services genutzt. Anwender haben jedoch die Möglichkeit, die Lösung bei jedem Cloud-Provider zu implementieren.für lokale Tests in ONTAP AI mit NVIDIA DGX-1 haben wir den gehosteten DNS-Service von Iguazio verwendet.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">Clients müssen auf dynamisch erstellte DNS-Domänen zugreifen können. Auf Wunsch können Kunden ihr eigenes DNS verwenden.</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">Sie können Iguazio vor Ort in Ihrem eigenen Cluster installieren. Wir haben die Lösung in NetApp ONTAP AI mit einem NVIDIA DGX-1-System verifiziert. In der folgenden Tabelle ist die Hardware aufgeführt, die zum Testen dieser Lösung verwendet wird.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 System</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1 Hochverfügbarkeitspaar (HA), umfasst 2 Controller und 48 NVMe-SSDs (3,8 TB oder höher)</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Netzwerk-Switches der Cisco Nexus 3232C-Serie</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">In der folgenden Tabelle sind die erforderlichen Softwarekomponenten für lokale Tests aufgeführt:</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 – Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">Container-Version</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tf1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">Framework für Machine Learning</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">Iguazio</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">Version 2.8 Oder Höher</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX Server</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">Die Lösung wurde mit Iguazio Version 2.5 und NetApp Cloud Volumes ONTAP für AWS vollständig getestet. Das Iguazio Cluster und die NetApp Software werden beide auf AWS ausgeführt.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">Version oder Typ</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">App-Node</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xlarge</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">Daten-Node</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.4xlarge</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">Weiter: Network Device Failure Prediction Use Case Summary</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">Seit Mai 2019 bietet Microsoft einen nativen Portal-Service auf Basis von Azure für NFS- und SMB-Fileservices der Enterprise-Klasse basierend auf NetApp ONTAP Technologie.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896: Distributed Training in Azure: Lane Detection - Lösungsdesign</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad und Verron Martina, NetApp Ronen dar, RUN:AI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">Seit Mai 2019 bietet Microsoft einen nativen Portal-Service auf Basis von Azure für NFS- und SMB-Fileservices der Enterprise-Klasse basierend auf NetApp ONTAP Technologie. Ziel dieser Entwicklung ist eine strategische Partnerschaft zwischen Microsoft und NetApp, mit der auch die Ausweitung der Reichweite erstklassiger ONTAP-Datenservices auf Azure möglich ist.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">NetApp, ein führender Anbieter von Cloud-Datenservices, hat sich zusammengeschlossen: KI, ein Unternehmen, das KI-Infrastruktur virtualisiert, ermöglicht schnellere KI-Experimente mit voller GPU-Auslastung. Dank dieser Partnerschaft können Teams die KI beschleunigen, indem sie zahlreiche Experimente parallel ausführen und dabei schnell auf Daten zugreifen – und dabei grenzenlose Computing-Ressourcen nutzen. RUN: KI ermöglicht volle GPU-Auslastung durch automatisiertes Ressourcenzuweisung. Mit der bewährten Architektur von Azure NetApp Files kann jedes Experiment mit maximaler Geschwindigkeit ausgeführt werden, indem die Hindernisse für die Datenpipeline beseitigt werden.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp und RUN: KI haben gemeinsam ihre Kräfte vereint und bieten Kunden eine zukunftssichere Plattform für ihren KI-Einsatz in Azure. Von Analysen und High-Performance-Computing (HPC) bis hin zu autonomen Entscheidungen (bei denen Kunden ihre IT-Investitionen optimieren können, indem sie nur das zahlen, was sie benötigen, und zwar zum richtigen Zeitpunkt), bietet die Allianz zwischen NetApp und RUN: KI ermöglicht ein einheitliches Arbeiten in der Azure Cloud.</block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">Verwenden Sie das NetApp Cloud Sync zur Archivierung des Gesprächsverlaufs</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">Indem wir einmal täglich den Gesprächsverlauf in eine CSV-Datei einschütten, können wir die Protokolldateien mithilfe von Cloud Sync in den lokalen Speicher herunterladen. Die folgende Abbildung zeigt, mit der Jarvis on-Premises und in Public Clouds implementiert und gleichzeitig mithilfe von Cloud Sync die Gesprächshistorie für das Nemo Training sendet. Einzelheiten zum Nemo Training finden Sie im Abschnitt <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">Weiter: Erweitern Sie Intent-Modelle mit Nemo Training</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">KI-gestützte Automatisierung und Edge-Computing sind eine führende Vorgehensweise, um Unternehmen bei der digitalen Transformation zu unterstützen und ihre betriebliche Effizienz und Sicherheit zu maximieren. Mithilfe von Edge Computing werden Daten wesentlich schneller verarbeitet, da sie nicht mehr zum und von einem Datacenter entfernt werden müssen. Somit sinken die Kosten für den Datentransfer in Datacenter oder in die Cloud.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">Früher: Optionen zur Dimensionierung der Architektur.</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">KI-gestützte Automatisierung und Edge-Computing sind eine führende Vorgehensweise, um Unternehmen bei der digitalen Transformation zu unterstützen und ihre betriebliche Effizienz und Sicherheit zu maximieren. Mithilfe von Edge Computing werden Daten wesentlich schneller verarbeitet, da sie nicht mehr zum und von einem Datacenter entfernt werden müssen. Somit sinken die Kosten für den Datentransfer in Datacenter oder in die Cloud. Niedrigere Latenz und eine höhere Geschwindigkeit können von Vorteil sein, wenn Unternehmen Entscheidungen mithilfe von im Edge-Bereich bereitgestellten KI-Inferenzmodellen in nahezu Echtzeit treffen müssen.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp Storage-Systeme bieten die gleiche oder eine bessere Performance wie lokaler SSD-Storage und bieten Data Scientists, Data Engineers, KI/ML-Entwickler und Business- oder IT-Entscheidungsträger die folgenden Vorteile:</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Problemlose gemeinsame Nutzung von Daten zwischen KI-Systemen, Big-Data-Analysen und anderen geschäftskritischen Systemen Diese gemeinsame Nutzung von Daten verringert den Infrastruktur-Overhead, verbessert die Performance und optimiert das Datenmanagement im gesamten Unternehmen.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Unabhängig skalierbare Computing- und Storage-Ressourcen minimieren Kosten und verbessern die Ressourcenauslastung.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Optimierte Entwicklungs- und Implementierungs-Workflows mithilfe integrierter Snapshot Kopien und Klone für sofortige und platzsparende Benutzer-Workspaces, integrierte Versionskontrolle und automatisierte Implementierung</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Datensicherung der Enterprise-Klasse für Disaster Recovery und Business Continuity Die in diesem Dokument vorgestellte NetApp und Lenovo Lösung ist eine flexible Scale-out-Architektur, die sich ideal für Edge-Implementierungen von KI-Inferenz der Enterprise-Klasse eignet.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Danksagungen</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger, Sr Manager, HPC &amp; AI Solutions, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, Technical Marketing Engineer, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, Tech Lead E-Series KI-Lösungen, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, QA Engineer, NetApp</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Produktseite zu NetApp AFF A-Series Arrays</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP Datenmanagement-Software: Informationsbibliothek unter ONTAP 9</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: NetApp EF-Series Introduction</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E-Series SANtricity Software Datenblatt</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetApp persistenter Storage für Container – NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow-Benchmark</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F Unified Flash Storage Array</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">März 2021</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Erste Version</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Version 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Oktober 2021</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">Aktualisiert mit EF und MLPerf Inferenz v1.1</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">Als Nächstes: Softwareanforderungen</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">Gerechtigkeit Wegen Zu Viel Quoten</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">In diesem Abschnitt und in den Abschnitten <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, und <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, Wir haben erweiterte Testszenarien entwickelt, um die Funktionen der Run:KI-Orchestrierung für komplexes Workload-Management, automatisches präventiv Planen und GPU-Bereitstellung über Kontingente zu demonstrieren. Ziel war es, eine hohe Cluster-Ressourcen-Auslastung zu erzielen und die Produktivität des Data Science-Teams der Enterprise-Klasse in einer ONTAP KI-Umgebung zu optimieren.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">Legen Sie für diese drei Abschnitte die folgenden Projekte und Quoten fest:</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">Kontingente</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">Zusätzlich werden für diese drei Abschnitte folgende Container verwendet:</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter Notebook:<block ref="71f36d3504ef6b5a0ba9f34fe1143008" prefix=" " category="inline-code"></block></block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run:AI quickstart:<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block></block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">Für dieses Testszenario setzen wir folgende Ziele:</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">Zeigen Sie die Einfachheit der Ressourcenbereitstellung und wie Ressourcen von Benutzern abstrahiert werden</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">Zeigen Sie, wie Benutzer Fraktionen einer GPU und einer ganzen Zahl von GPUs einfach bereitstellen können</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">Zeigen Sie, wie das System Compute-Engpässe beseitigt, indem es Teams oder Benutzern ermöglicht, ihre Ressourcenkontingente zu überziehen, wenn es kostenlose GPUs im Cluster gibt</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">Zeigen Sie, wie Engpässe bei der Datenpipeline mithilfe der NetApp Lösung bei rechenintensiven Aufgaben wie dem NetApp Container beseitigt werden</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">Darstellung der Ausführung mehrerer Container mithilfe des Systems</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter Notebook</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">Run:AI Container</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">Zeigt eine hohe Auslastung an, wenn das Cluster voll ist</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">Einzelheiten zur tatsächlichen Befehlsfolge, die während des Tests ausgeführt wurde, finden Sie unter <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">Wenn alle 13 Workloads übermittelt werden, wird eine Liste der zugewiesenen Containernamen und -GPUs angezeigt, wie in der folgenden Abbildung dargestellt. Wir haben sieben Trainings- und sechs interaktive Jobs und simulieren dabei vier Data-Science-Teams, die jeweils über eigene Modelle im Einsatz oder in der Entwicklung verfügen. Bei interaktiven Jobs verwenden einzelne Entwickler Jupyter Notebooks, um ihren Code zu schreiben oder zu debuggen. Dadurch eignet es sich, GPU-Fraktionen ohne zu viele Cluster-Ressourcen bereitzustellen.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">Die Ergebnisse dieses Testszenarios zeigen Folgendes:</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">Der Cluster sollte voll sein: Es werden 16/16 GPUs verwendet.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">Hohe Cluster-Auslastung.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">Mehr Experimente als GPUs aufgrund der fraktionalen Zuweisung:</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text"><block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix="" category="inline-code"></block> Nutzt nicht die gesamte Quote; daher<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Da die Experimente mit zusätzlichen GPUs durchgeführt werden können, werden Innovationen schneller beschleunigt.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">Weiter: Grundlegende Ressourcenzuweisung Fairness</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834: NetApp und Iguazio für MLRun Pipeline</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">In diesem Dokument werden die Details der MLRun-Pipeline unter Verwendung von NetApp ONTAP AI, der NetApp AI Control Plane, der NetApp Cloud Volumes Software und der Iguazio Data Science Platform behandelt. Wir verwendeten Nuclio serverlose Funktion, Kubernetes Persistent Volumes, NetApp Cloud Volumes, NetApp Snapshot Kopien, Grafana Dashboard, Und andere Dienste auf der Iguazio-Plattform, um eine End-to-End-Daten-Pipeline für die Simulation von Netzwerkausfall Erkennung zu bauen. Die Technologien von Iguazio und NetApp wurden integriert, um schnelle Modellbereitstellung, Datenreplizierung und Produktionsüberwachungsfunktionen vor Ort und in der Cloud zu ermöglichen.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">Der Fokus der Arbeit eines Datenwissenschaftlers sollte auf das Training und Tuning von ml- (Machine Learning) und künstlicher Intelligenz (KI)-Modellen liegen. Allerdings verbringen Data Scientists nach Untersuchungen von Google ~80 % ihrer Zeit damit, herauszufinden, wie ihre Modelle mit Enterprise-Applikationen funktionieren und im Maßstab laufen lassen können, wie in der folgenden Abbildung dargestellt, die Modellentwicklung im AI/ML-Workflow.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">Für das Management von End-to-End-KI/ML-Projekten ist ein umfassenderes Verständnis von Unternehmenskomponenten erforderlich. Obwohl DevOps die Definition, Integration und Implementierung dieser Typen von Komponenten übernommen hat, zielen Machine-Learning-Vorgänge auf einen ähnlichen Flow ab, der KI/ML-Projekte umfasst. Eine Vorstellung der Merkmale einer End-to-End-KI/ML-Pipeline im Unternehmen erhalten Sie in der folgenden Liste der erforderlichen Komponenten:</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="list-text">Storage</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">Datenbanken</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">File-Systeme</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="list-text">Container</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">CI/CD-Pipeline (Continuous Integration und Continuous Deployment</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">Integrierte Entwicklungsumgebung (IDE)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">Sicherheit</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">Datenzugriffsrichtlinien</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="list-text">Einheitliche</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">Toolsets und Bibliotheken für Data Science</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">In diesem Whitepaper zeigen wir, wie die Partnerschaft zwischen NetApp und Iguazio die Entwicklung einer End-to-End-KI/ML-Pipeline deutlich vereinfacht. Dadurch wird die Markteinführungszeit für alle Ihre KI/ML-Applikationen verkürzt.</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">Zielgruppe</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">Die Welt der Datenwissenschaft berührt mehrere Disziplinen in der Informationstechnologie und im Business.</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Der Data Scientist benötigt die Flexibilität, ihre Tools und Bibliotheken einzusetzen.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">Der Data Engineer muss wissen, wie die Daten fließen und wo sie sich befinden.</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps-Engineers benötigen die Tools, um neue KI/ML-Applikationen in ihre CI/CD-Pipelines zu integrieren.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">Geschäftsanwender möchten auf KI-/ML-Applikationen zugreifen können. Wir beschreiben, wie NetApp und Iguazio jede dieser Rollen unterstützen, mit unseren Plattformen einen Mehrwert für das Unternehmen zu schaffen.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">Diese Lösung folgt dem Lebenszyklus einer KI/ML-Applikation. Zunächst legen wir die Arbeit der Datenanalysten fest, welche Schritte für die Datenvorbereitung und das Training und die Implementierung der Modelle erforderlich sind. Wir befolgen die erforderlichen Arbeiten, um eine vollständige Pipeline zu erstellen mit der Möglichkeit, Artefakte zu verfolgen, mit der Durchführung zu experimentieren und sich nach Kubeflow zu implementieren. Um den gesamten Zyklus abzuschließen, integrieren wir die Pipeline mit NetApp Cloud Volumes, um die Datenversionierung zu ermöglichen, wie im folgenden Bild zu sehen ist.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">Weiter: Technologischer Überblick</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">Run:AI Dashboards und Ansichten</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Nach der Installation von Run:AI auf dem Kubernetes-Cluster und der korrekten Konfiguration der Container werden die folgenden Dashboards und Ansichten auf angezeigt<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> Im Browser, wie in der folgenden Abbildung dargestellt.</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">Es gibt insgesamt 16 GPUs im Cluster, die von zwei DGX-1-Nodes bereitgestellt werden. Sie sehen die Anzahl der Nodes, die insgesamt verfügbaren GPUs, die zugewiesenen GPUs, die Workloads zugewiesen werden, die Gesamtzahl der ausgeführten Jobs, ausstehende Jobs und inaktive GPUs. Rechts im Balkendiagramm werden GPUs pro Projekt angezeigt, die die Verwendung der Cluster-Ressource durch die verschiedenen Teams zusammenfassen. In der Mitte befindet sich die Liste der aktuell ausgeführten Jobs mit Jobdetails, einschließlich Jobname, Projekt, Benutzer, Jobtyp, Der Node, auf dem jeder Job ausgeführt wird, die Anzahl der für diesen Job zugewiesenen GPU(s), die aktuelle Laufzeit des Jobs, der Job-Fortschritt in Prozent und die GPU-Auslastung für diesen Job. Beachten Sie, dass das Cluster nicht ausgelastet ist (GPU-Auslastung bei 23 %), da nur drei laufende Jobs von einem einzigen Team eingereicht werden <block ref="9320270de4ff6824ae7a21f729fb7d44" prefix="(" category="inline-code"></block>).</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">Im folgenden Abschnitt zeigen wir, wie auf der Registerkarte „Projekte“ mehrere Teams erstellt und jedem Team GPUs zugewiesen werden können, um die Cluster-Auslastung zu maximieren und Ressourcen zu managen, wenn pro Cluster mehrere Benutzer vorhanden sind. Die Testszenarien nachahmen Enterprise-Umgebungen, in denen Speicher- und GPU-Ressourcen unter Training, Inferenz und interaktiven Workloads gemeinsam genutzt werden.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">Weiter: Projekte für Data Science Teams erstellen und GPUs zuweisen</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">Dieser Abschnitt enthält Details zum Einrichten der Plattform für die Durchführung von Distributed Training zur Lane-Erkennung mit dem RUN AI Orchestrator.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">Lane-Erkennung – verteiltes Training mit RUN:AI</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">Dieser Abschnitt enthält Details zum Einrichten der Plattform für die Durchführung von Distributed Training zur Lane-Erkennung mithilfe des RUN: AI Orchestrator. Wir sprechen über die Installation aller Lösungselemente und die Durchführung der verteilten Schulungen auf der besagten Plattform. DIE ML-Versionierung erfolgt über NetApp Snapshot, die mit RUN verbunden ist: KI-Experimente zur Erzielung von Daten und Modellreproduzierbarkeit. DIE ML-Versionierung spielt eine entscheidende Rolle bei Tracking-Modellen, bei der gemeinsamen Arbeit zwischen Teammitgliedern, bei der Reproduzierbarkeit der Ergebnisse, bei der Einführung neuer Modellversionen in die Produktion und bei der Datenerzeugung. NetApp ML Version Control (Snapshot) erfasst zeitpunktgenaue Versionen der Daten, geschulte Modelle und Protokolle für jedes Experiment. Die umfassende API-Unterstützung erleichtert die Integration IN DIE RUN: KI Plattform. Aufgrund des Trainingsstatus muss ein Ereignis nur ausgelöst werden. Man muss auch den Status des gesamten Experiments erfassen, ohne im Code oder in den Containern, die auf Kubernetes (K8s) laufen, etwas zu ändern.</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">Abschließend wird in diesem technischen Bericht die Performance-Bewertung auf mehreren GPU-fähigen Knoten in AKS durchgeführt.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">Verteiltes Training für Lane-Erkennung Anwendungsfall mit dem TuSimple-Datensatz</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">In diesem technischen Bericht werden verteilte Schulungen auf dem TuSimple-Datensatz zur Fahrspurerkennung durchgeführt. Horovod wird im Trainingscode für das verteilte Daten-Training auf mehreren GPU-Nodes gleichzeitig im Kubernetes Cluster über AKS verwendet. Code wird als Container-Images für TuSimple-Daten-Download und -Verarbeitung verpackt. Verarbeitete Daten werden auf persistenten Volumes gespeichert, die durch das NetApp Trident Plug-in zugewiesen werden. Für das Training wird ein weiteres Container-Image erstellt und die Daten, die in persistenten Volumes gespeichert sind, werden beim Herunterladen der Daten verwendet.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">Um den Daten- und Schulungsauftrag zu übermitteln, verwenden SIE RUN: KI zur Koordinierung von Ressourcenzuweisung und -Management. RUN: AI ermöglicht die Durchführung von MPI-Operationen (Message Passing Interface), die für Horovod benötigt werden. Mit diesem Layout können mehrere GPU-Knoten miteinander kommunizieren, um die Trainingsgewichte nach jedem Training-Mini-Batch zu aktualisieren. Zudem ermöglicht es das Monitoring des Trainings über die Benutzeroberfläche und die CLI, sodass der Fortschritt der Experimente einfach überwacht werden kann.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot ist in den Trainingscode integriert und erfasst den Status der Daten und das trainierte Modell für jedes Experiment. Damit können Sie die Version und den verwendeten Code sowie das damit verbundene trainierte Modell nachverfolgen.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AKS-Einrichtung und Installation</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">Erstellen Sie einen AKS-Cluster</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">Zur Einrichtung und Installation des AKS-Clusters gehen Sie zu<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. Führen Sie dann die folgenden Schritte aus:</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">Wählen Sie bei der Auswahl des Node-Typs (unabhängig davon, ob es sich um System- (CPU) oder „worker“-Nodes (GPU) handelt, Folgendes aus:</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">Fügen Sie den primären System-Node mit dem Namen hinzu<block ref="917718fb2e3dcf94043ea14d44580bc2" prefix=" " category="inline-code"></block> Am<block ref="2ec023527b0bfb6c720d8dd19493ad0d" prefix=" " category="inline-code"></block> Größe. Verwenden Sie die drei Standard-Nodes.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Fügen Sie den Node Worker hinzu<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block> Mit<block ref="801b9db365bdc8cd72301ec3fd4ed2ff" prefix=" " category="inline-code"></block> Pool-Größe. Verwenden Sie mindestens drei Nodes für GPU-Nodes.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">Implementierung dauert 5 bis 10 Minuten.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">Tools Installieren</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">Klicken Sie nach Abschluss der Bereitstellung auf mit Cluster verbinden. Um eine Verbindung mit dem neu erstellten AKS-Cluster herzustellen, installieren Sie das Kubernetes-Befehlszeilen-Tool aus Ihrer lokalen Umgebung (Laptop/PC). Besuchen Sie<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> So installieren Sie es nach Ihrem Betriebssystem.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">Installieren Sie die Azure CLI in Ihrer lokalen Umgebung</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">Um über das Terminal auf den AKS-Cluster zuzugreifen, geben Sie zuerst ein<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> Und geben Sie die Zugangsdaten ein.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">Führen Sie die folgenden beiden Befehle aus:</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Geben Sie diesen Befehl in die Azure CLI ein:</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">Wenn alle sechs Knoten wie hier dargestellt betriebsbereit sind, ist Ihr AKS-Cluster bereit und mit Ihrer lokalen Umgebung verbunden.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Gehen Sie wie folgt vor, um ein delegiertes Subnetz für Azure NetApp Files zu erstellen:</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Navigieren Sie im Azure-Portal zu virtuellen Netzwerken. Suchen Sie Ihr neu erstelltes virtuelles Netzwerk. Es sollte ein Präfix wie Aaks-vnet haben, wie hier zu sehen. Klicken Sie auf den Namen des virtuellen Netzwerks.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">Klicken Sie auf Subnetze, und wählen Sie in der oberen Symbolleiste +Subnetz aus.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">Geben Sie dem Subnetz einen Namen an, z. B.<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Wählen Sie unter der Überschrift Subnet Delegation die Option Microsoft.NetApp/volumes aus. Ändern Sie nichts anderes. Klicken Sie auf OK.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files Volumes werden dem Applikations-Cluster zugewiesen und als persistente Volume-Forderungen (PVCs) in Kubernetes genutzt. Diese Zuweisung wiederum bietet uns die Flexibilität, Volumes verschiedenen Services zuzuordnen, sei es bei Jupyter Notebooks, serverlosen Funktionen usw.</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">Benutzer von Services können Storage auf unterschiedliche Weise von der Plattform aus nutzen. Azure NetApp Files bietet folgende Hauptvorteile:</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">Bietet Benutzern die Möglichkeit, Snapshots zu verwenden.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Ermöglicht Benutzern die Speicherung großer Datenmengen auf Azure NetApp Files Volumes.</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Beziehen Sie sich die Performance-Vorteile von Azure NetApp Files Volumes durch Ausführung ihrer Modelle auf große Dateimengen.</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Einrichtung von Azure NetApp Files</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">QuickStart: Azure NetApp Files einrichten und ein NFS-Volume erstellen</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Um die Einrichtung von Azure NetApp Files abzuschließen, müssen Sie sie zuerst wie in beschrieben konfigurieren<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">Sie können jedoch die Schritte zur Erstellung eines NFS Volumes für Azure NetApp Files weglassen, wie Sie Volumes über Trident erstellen. Bevor Sie fortfahren, sollten Sie Folgendes beachten:</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Registriert für Azure NetApp Files und NetApp Resource Provider (über den Azure Cloud Shell)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">In Azure NetApp Files wurde ein Konto erstellt</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">Richten Sie einen Kapazitäts-Pool ein</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (Mindestens 4 tib Standard oder Premium, je nach Ihren Anforderungen)</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">Peering von virtuellem AKS-Netzwerk und virtuellem Azure NetApp Files-Netzwerk</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">Führen Sie als Nächstes die folgenden Schritte aus, um das virtuelle AKS-Netzwerk (vnet) mit dem Azure NetApp Files vnet in Verbindung zu setzen:</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Geben Sie in das Suchfeld oben im Azure-Portal virtuelle Netzwerke ein.</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">Klicken Sie auf vnet aks- vnet-Name, und geben Sie dann Peerings in das Suchfeld ein.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">Klicken Sie auf + Hinzufügen, und geben Sie die Informationen in der folgenden Tabelle ein:</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">Feld</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Wert oder Beschreibung</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">Linkname des Peering-Links</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">aks-vnet-Name_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">SubskriptionID</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">Abonnement des Azure NetApp Files vnet, zu dem Sie spähen</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">Vnet Peering-Partner</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files vnet</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">Lassen Sie alle nicht-Sternchen-Abschnitte standardmäßig unverändert</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">Klicken Sie AUF HINZUFÜGEN oder OK, um das Peering zum virtuellen Netzwerk hinzuzufügen.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">Virtuelles Netzwerk-Peering erstellen, ändern oder löschen</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">Weitere Informationen finden Sie unter<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident ist ein Open-Source-Projekt von NetApp für persistenten Storage für Applikations-Container. Trident wird als externer Controller für die bereitstellung implementiert, der selbst als Pod ausgeführt wird. Mit ihm werden Volumes überwacht und der Bereitstellungsprozess vollständig automatisiert.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident ermöglicht eine reibungslose Integration in K8s, indem persistente Volumes zum Speichern von Trainingsdatensätzen und trainierten Modellen erstellt und angehängt werden. So können Data Scientists und Data Engineers K8s einfacher verwenden – ohne die manuelle Speicherung und das manuelle Management von Datensätzen. Mit Trident müssen Data Scientists zudem keine Erfahrung mehr mit dem Management neuer Datenplattformen machen, da die Datenmanagement-Aufgaben durch die Integration der logischen API integriert werden.</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">So installieren Sie die Trident Software:</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">Zuerst Helm einbauen</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Laden Sie das Trident 21.01.1-Installationsprogramm herunter und extrahieren Sie es.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">Kopieren<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> In ein Verzeichnis im System<block ref="86657e3985b8aeae39f3d9136b5f3e58" prefix=" " category="inline-code"></block></block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Installation von Trident auf K8s Cluster mit Helm:</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">Verzeichnis in Steuerverzeichnis ändern.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Überprüfen Sie den Status von Trident Pods die übliche K8s Art und Weise:</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">Wenn alle Pods in Betrieb sind, ist Trident installiert und Sie können gut aufgestellt werden.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Richten Sie das Azure NetApp Files Back-End und die Storage-Klasse ein</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Gehen Sie wie folgt vor, um das Azure NetApp Files Back-End und die Storage-Klasse einzurichten:</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">Wechseln Sie zurück zum Home-Verzeichnis.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">Projekt-Repository</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">Klonen Sie die<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block><block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">Wechseln Sie zum<block ref="fb4dc0399a722eface234e077d9b496c" prefix=" " category="inline-code"></block> Verzeichnis.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Erstellung eines Azure-Serviceprinzips (das Service-Prinzip besteht darin, wie Trident mit Azure kommuniziert, um auf Ihre Azure NetApp Files-Ressourcen zuzugreifen).</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Erstellen Sie das Trident<block ref="27bac05160742a70c80c3e1db9b39988" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">Füllen Sie mithilfe Ihres bevorzugten Texteditors die folgenden Felder aus der Tabelle unten im aus<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Wert</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">SubskriptionID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Ihre Azure-Abonnement-ID</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">TenantID</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Ihre Azure Mandanten-ID (aus der Ausgabe von az ad sp im vorherigen Schritt)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">Client-ID</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">Ihre appID (aus der Ausgabe von az ad sp im vorherigen Schritt)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">ClientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">Ihr Kennwort (aus der Ausgabe von az ad sp im vorherigen Schritt)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">Die Datei sollte wie das folgende Beispiel aussehen:</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">Weisen Sie Trident an, das Azure NetApp Files-Back-End im zu erstellen<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> Namespace verwenden<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> Die Konfigurationsdatei ist wie folgt:</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">Speicherklasse erstellen:</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">K8 Benutzer stellen Volumes mithilfe von PVCs bereit, die eine Storage-Klasse nach Namen angeben. Weisen Sie K8s an, eine Speicherklasse zu erstellen<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Diese Referenz wird auf das im vorherigen Schritt erstellte Azure NetApp Files Back-End verweisen:</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">Überprüfen Sie, ob Storage-Klassen mit folgendem Befehl erstellt werden:</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">Bereitstellen und Einrichten von Volume Snapshot-Komponenten auf AKS</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">Wenn Ihr Cluster nicht mit den korrekten Volume-Snapshot-Komponenten vorinstalliert wird, können Sie diese Komponenten manuell installieren, indem Sie die folgenden Schritte ausführen:</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14 verfügt nicht über einen vorinstallierten Snapshot-Controller.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">Installieren Sie Snapshot Beta-CRDs unter Verwendung der folgenden Befehle:</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">Installieren Sie Snapshot Controller mithilfe der folgenden Dokumente von GitHub:</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">Volume Snapshot-Klasse</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">K8s einrichten<block ref="9431613e59ff5cc956e408e7f55906ef" prefix=" " category="inline-code"></block>: Vor der Erstellung eines Volume-Snapshot, a<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> Muss eingerichtet werden. Erstellen Sie einen Volume-Snapshot für Azure NetApp Files, und erstellen Sie mit dieser Technologie eine ML-Versionierung. Erstellen<block ref="0c1b563c97a31c710fb1be0e355b42e2" prefix=" " category="inline-code"></block> Und stellen Sie ihn als Standard `volumesnapshotclass `wie folgt ein:</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">Überprüfen Sie, ob die Klasse der Volume Snapshot Kopien mithilfe des folgenden Befehls erstellt wurde:</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">RUN:AI Installation</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">So installieren SIE RUN:AI:</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Installieren SIE RUN:AI Cluster auf AKS</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">Gehen Sie zu app.runai.ai, klicken Sie auf Neues Projekt erstellen und benennen Sie es Lane-Detection. Es wird einen Namespace auf einem K8s-Cluster erstellen, der mit beginnt<block ref="26ea39e1cbc12bc8c37993198043ec7c" prefix=" " category="inline-code"></block>- Gefolgt vom Projektnamen. In diesem Fall wäre der erstellte Namespace Runai-Lane-Erkennung.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">INSTALLIEREN SIE RUN:AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">Stellen Sie auf Ihrem Terminal standardmäßig die Lane-Detection ein: AI-Projekt mit folgendem Befehl:</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">ClusterRole und ClusterRoleBinding für den Projekt-Namespace erstellen (z. B.<block ref="ff4072c643ff862f118d673b2655bd00" prefix=" " category="inline-code"></block> Also das Standard-Servicekonto, das zu gehört<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> Namespace hat die Berechtigung zum Ausführen<block ref="2bbdf0e0d9e8bddf5f3f89a53a8e524f" prefix=" " category="inline-code"></block> Operationen während der Jobausführung:</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">Listen Sie Namespaces auf, um das zu überprüfen<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> Existiert durch Verwendung dieses Befehls:</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">Die Ausgabe sollte wie im folgenden Beispiel erscheinen:</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">ClusterCole erstellen<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> Und ClusterRoleBending<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> Verwenden der folgenden Befehle:</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">Den TuSimple-Datensatz als RUN:AI-Job herunterladen und verarbeiten</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">Der Prozess zum Herunterladen und Verarbeiten des TuSimple-Datensatzes als RUN: AI-Job ist optional. Sie umfasst folgende Schritte:</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Erstellen und Drücken Sie das Docker-Bild, oder lassen Sie diesen Schritt aus, wenn Sie ein vorhandenes Docker-Bild verwenden möchten (z. B.<block ref="c545ab6370eda2ad54aefbe9cf39084c" prefix=" " category="inline-code"></block></block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">Zum Home-Verzeichnis wechseln:</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">Gehen Sie zum Datenverzeichnis des Projekts<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>:</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">Ändern<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> Shell-Skript und ändern Docker-Repository zu Ihrem. Beispiel: Ersetzen<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> Mit dem Namen des Docker-Repositorys. Sie können auch den Namen und DAS TAG des Docker-Images ändern (z. B.<block ref="d9ff85f787933e1dd61935daa84a1bdf" prefix=" " category="inline-code"></block> Und<block ref="e4c2e8edac362acab7123654b9e73432" prefix=" " category="inline-code"></block>):</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">Führen Sie das Skript aus, um das Docker-Image zu erstellen und es mithilfe folgender Befehle in das Docker-Repository zu verschieben:</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Senden Sie DEN RUN: AI Job zum Herunterladen, Extrahieren, Vorverarbeiten und Speichern der TuSimple Lane Detection Dataset in a<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>, Das von NetApp Trident dynamisch erstellt wird:</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">Übermitteln Sie den JOB „RUN: AI“ mithilfe der folgenden Befehle:</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">Geben Sie die Informationen aus der Tabelle unten ein, um den JOB RUN:AI einzureichen:</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-Name</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">Name des Jobs</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-pvc</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">PVC des Formats [StorageClassName]:Größe:ContainerMountPath in der oben genannten Jobeinreichung erstellen Sie ein PVC-basiertes On-Demand mit Trident mit Speicherklasse azurenetappfiles. Persistente Volumen Kapazität hier ist 100Gi und es ist an Pfad /mnt montiert.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">-Image</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">Das Docker-Image sollte beim Erstellen des Containers für diesen Job verwendet werden</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">Listen Sie die eingereichten RUN:AI-Jobs auf.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">Überprüfen Sie die eingereichten Jobprotokolle.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">Listen Sie die auf<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> Erstellt. Verwenden Sie diese Option<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> Befehl für Training im nächsten Schritt.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">Prüfen Sie DEN Job ausgeführt: KI-UI (oder<block ref="a008ed925fe48e20407afaf702b23152" prefix=" " category="inline-code"></block>).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Führen Sie mithilfe von Horovod eine Schulung zur Erkennung verteilter Fahrspuren durch</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">Das Training zur Distributed Lane Detection mit Horovod ist ein optionaler Prozess. Hier sind jedoch die Schritte zu beachten:</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Erstellen und Drücken Sie das Docker-Bild, oder überspringen Sie diesen Schritt, wenn Sie das vorhandene Docker-Bild verwenden möchten (z. B.<block ref="ff48b891d5ff0bac7c6319fafb5cd296" prefix=" " category="inline-code"></block></block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">Wechseln Sie zum Home Directory.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">Rufen Sie das Projektverzeichnis auf<block ref="3154c35109c9015233233f77dfc31bc7" prefix=" " category="inline-code"></block></block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">Ändern Sie die<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> Shell-Skript und ändern Docker-Repository zu Ihrem (z. B. Ersetzen<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> Mit dem Namen des Docker-Repository). Sie können auch den Namen und DAS TAG des Dockers ändern <block ref="40797c3457645b9820c9a3f42dbea93b" prefix="(" category="inline-code"></block> Und<block ref="dfddb1ffc29acf8914bca9a640b6362a" prefix=" " category="inline-code"></block>.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">Führen Sie das Skript aus, um das Docker-Image zu erstellen, und drücken Sie zum Docker-Repository.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">RUN: AI Job zur Durchführung von Distributed Training (MPI):</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">Verwendung von Run: AI zur automatischen Erstellung von PVC im vorherigen Schritt (zum Herunterladen von Daten) ermöglicht nur RWO-Zugriff, sodass nicht mehrere Pods oder Knoten zum verteilten Training auf dasselbe PVC zugreifen können. Aktualisieren Sie den Zugriffsmodus auf ReadWriteManche und verwenden Sie dazu den Kubernetes-Patch.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">Erhalten Sie zunächst den Volume-Namen des PVC durch Ausführen des folgenden Befehls:</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">Patchen des Volume und Aktualisieren des Zugriffsmodus auf ReadWriteManche (ersetzen Sie den Datenträgernamen durch Ihren im folgenden Befehl):</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">Senden Sie DEN JOB RUN: AI MPI zur Ausführung des Jobs für verteilte Schulungen` mithilfe von Informationen aus der folgenden Tabelle:</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">Name</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">Name des Distributed Training Job</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">Großer shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">Ein großes /dev/shm-Gerät mounten Es ist ein auf RAM montiertes Shared-Dateisystem und bietet genügend gemeinsamen Speicher für mehrere CPU-Mitarbeiter, um Batches in CPU-RAM zu verarbeiten und zu laden.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">Prozessen</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">Anzahl der verteilten Trainingsprozesse</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">gpu</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">Anzahl der GPUs/Prozesse, die für die Aufgabe in diesem Job zugewiesen werden sollen, es gibt drei GPU-Worker-Prozesse (--processes=3), die jeweils über eine einzelne GPU (--gpu 1) zugewiesen sind.</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">pvc</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">Verwenden Sie das vorhandene persistente Volume (pvc-download-tusimple-Data-0), das von einem vorherigen Job erstellt wurde (download-tusimple-Data), und es wird in Pfad /mnt bereitgestellt</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">Bild</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">Definieren Sie Umgebungsvariablen, die im Container festgelegt werden sollen</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">VERWENDEN VON MITARBEITERN</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">Wenn Sie das Argument auf true setzen, wird das Laden von mehreren Prozessdaten aktiviert</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">NUM_WORKERS</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">Anzahl der Data Loader Worker Prozesse</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">BATCH_SIZE</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">Batch-Größe für Training</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">NUTZUNG_VAL</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">Wenn Sie das Argument auf true setzen, kann die Validierung aktiviert werden</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">VAL_BATCH_SIZE</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">Batch-Größe der Validierung</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">AKTIVIEREN_SNAPSHOT</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">Wenn Sie das Argument auf true setzen, können Sie Daten und trainierte Modellschnappschüsse für ML-Versionierung erstellen</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">PVC-NAME</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">Name des pvc, von dem ein Snapshot erstellt werden soll. In der oben genannten Jobsendung erstellen Sie eine Momentaufnahme von pvc-Download-Tusimple-Data-0, bestehend aus Datensatz und trainierten Modellen</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">Fehler: Grafikbild fehlt</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">Geben Sie den eingereichten Job an.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">Eingereichte Jobprotokolle:</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">Prüfen Sie den Trainingsjob IN AUSFÜHRUNG: AI GUI (oder app.runai.ai): RUN: AI Dashboard, wie in den Abbildungen unten zu sehen. Die erste Abbildung zeigt drei GPUs, die für den verteilten Trainingsjob auf drei Knoten auf AKS verteilt sind, und den zweiten DURCHLAUF:KI-Jobs:</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">Prüfen Sie nach Abschluss des Trainings die NetApp Snapshot Kopie, die erstellt wurde und mit RUN: KI-Job verknüpft ist.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">Wiederherstellung von Daten aus der NetApp Snapshot Kopie</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">Um Daten aus der NetApp Snapshot Kopie wiederherzustellen, gehen Sie wie folgt vor:</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">Rufen Sie das Projektverzeichnis auf<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">Ändern<block ref="a5fe5fd907cdc55a6a74bfd705214476" prefix=" " category="inline-code"></block> Und Aktualisierung<block ref="d9d448f70687a1aa1f12b2f5ddaa4977" prefix=" " category="inline-code"></block><block ref="b068931cc450442b63f5b3d276ea4297" prefix=" " category="inline-code"></block> Feld zur Snapshot Kopie, aus der Sie Daten wiederherstellen möchten. Sie können auch den PVC-Namen ändern, in dem die Daten wiederhergestellt werden, in diesem Beispiel ist<block ref="1fcd0a4cb780ecfc14fadd89d5ad8fd2" prefix=" " category="inline-code"></block>.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">Erstellen Sie mithilfe von ein neues PVC<block ref="c6c5b510d872174c3b4e59ca4c66fd6e" prefix=" " category="inline-code"></block>.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">Wenn Sie die gerade wiederhergestellten Daten für die Schulung verwenden möchten, bleibt die Bewerbung gleich wie zuvor; ersetzen Sie nur die<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> Mit dem wiederhergestellten<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> Beim Einreichen des Schulungsjobs, wie in den folgenden Befehlen zu sehen:</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">Performance-Bewertung</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">Um die lineare Skalierbarkeit der Lösung zu zeigen, wurden Performance-Tests für zwei Szenarien durchgeführt: Eine GPU und drei GPUs. GPU-Zuweisung, GPU- und Arbeitsspeicherauslastung sowie verschiedene Single- und drei-Node-Metriken wurden während des Trainings im TuSimple Lane-Erkennungsdatensatz erfasst. Die Datenmenge wird um das fünf- fache erhöht, nur um die Ressourcenauslastung während der Trainingsprozesse zu analysieren.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files Service-Level</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">Die Lösung ermöglicht es Kunden, mit einem kleinen Datensatz und einigen GPUs zu beginnen. Wenn die Datenmenge und der Bedarf der GPUs steigen, können Kunden die Terabyte im Standard-Tier dynamisch horizontal skalieren und schnell auf die Premium-Tier skalieren. So wird der vierfache Durchsatz pro Terabyte erzielt, ohne Daten zu verschieben. Dieser Prozess wird im Abschnitt weiter erläutert. <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">Die Verarbeitungszeit auf einer GPU betrug 12 Stunden und 45 Minuten. Die Verarbeitungszeit von drei GPUs auf drei Nodes betrug etwa 4 Stunden und 30 Minuten.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">Die im verbleibenden Teil dieses Dokuments veranschaulichen Beispiele für Performance und Skalierbarkeit basierend auf den individuellen Geschäftsanforderungen.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">Die Abbildung unten zeigt 1 GPU-Zuweisung und Arbeitsspeicherauslastung.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">Die Abbildung unten zeigt die GPU-Auslastung mit einem Node.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">Die Abbildung unten zeigt die Größe des Single-Node-Speichers (16 GB).</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">Die Abbildung unten zeigt die GPU-Anzahl einzelner Nodes (1).</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">Die Abbildung unten zeigt die GPU-Zuweisung eines einzelnen Node (%).</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">Die Abbildung unten zeigt drei GPUs in drei Nodes: GPU-Zuweisung und Arbeitsspeicher.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">Die Abbildung unten zeigt drei GPUs für eine Auslastung von drei Nodes (%).</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">Die Abbildung unten zeigt drei GPUs über die Speicherauslastung mit drei Nodes (%).</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">Service-Level</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">Sie können den Service-Level eines vorhandenen Volumes ändern, indem Sie das Volume in einen anderen Kapazitätspool verschieben, der den verwendet<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> Sie wollen für das Volume. Bei dieser bestehenden Service-Level-Änderung für das Volume müssen Sie keine Daten migrieren. Er hat auch keinen Einfluss auf den Zugriff auf das Volume.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">Profitieren Sie von einer dynamischen Änderung des Service-Levels eines Volumes</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">Um den Service-Level eines Volumes zu ändern, gehen Sie wie folgt vor:</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">Klicken Sie auf der Seite Volumes mit der rechten Maustaste auf das Volume, dessen Service-Level Sie ändern möchten. Wählen Sie Pool Ändern.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">Wählen Sie im Fenster Pool ändern den Kapazitätspool aus, in den Sie das Volume verschieben möchten. Klicken Sie anschließend auf OK.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">Automatisieren Sie Service Level Change</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">Die dynamische Änderung des Service-Levels befindet sich derzeit noch in der öffentlichen Vorschau, ist aber standardmäßig nicht aktiviert. Um diese Funktion auf dem Azure-Abonnement zu aktivieren, folgen Sie diesen Schritten im Dokument “<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>.“</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">az netappfiles-Volume: Managt Azure NetApp Files (ANF) Volume-Ressourcen</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Für Azure können Sie auch die folgenden Befehle verwenden: CLI. Weitere Informationen zum Ändern der Pool-Größe von Azure NetApp Files finden Sie unter<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Ändern Sie den Pool für ein Azure NetApp Files-Volume</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">Der<block ref="2de1988ae552a465bf4f3a270c8403a4" prefix=" " category="inline-code"></block> Cmdlet, das hier angezeigt wird, kann den Pool eines Azure NetApp Files Volume ändern. Weitere Informationen zum Ändern der Volume-Pool-Größe und Azure PowerShell finden Sie unter<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Beispiel Kubeflow Operations und Tasks</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">Dieser Abschnitt enthält Beispiele für verschiedene Vorgänge und Aufgaben, die Sie mit Kubeflow ausführen möchten.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">Als Nächstes: Stellen Sie einen Jupyter Notebook Workspace für Data Scientist oder Developer zur Verfügung.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Zur Bewertung der Performance der vorgeschlagenen Architektur wurden zahlreiche Tests durchgeführt. Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Speech-to-Text, Und natürliche Sprachverarbeitung [NLP]), die Sie in drei verschiedenen Szenarien ausführen können - offline, Single Stream und Multistream.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Testergebnisse</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">Zurück: Testverfahren.</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">Testergebnisse für AFF</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">Zur Bewertung der Performance der vorgeschlagenen Architektur wurden zahlreiche Tests durchgeführt. Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Speech-to-Text, Und natürliche Sprachverarbeitung [NLP]), die Sie in drei verschiedenen Szenarien ausführen können: Offline, Single Stream und Multistream.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">Das letzte Szenario wird nur für die Bildklassifizierung und Objekterkennung implementiert.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Dies ergibt 15 mögliche Workloads, die alle unter drei verschiedenen Setups getestet wurden:</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Einzelner Server/lokaler Storage</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Einzelner Server/Netzwerk-Storage</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Multi-Server-/Netzwerk-Storage</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Die Ergebnisse werden in den folgenden Abschnitten beschrieben.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">KI-Inferenz für AFF im Offline-Szenario</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">In diesem Szenario waren alle Daten dem Server zur Verfügung und die Zeit, die für die Verarbeitung aller Proben erforderlich war, wurde gemessen. Als Ergebnisse der Tests berichten wir Bandbreiten in Proben pro Sekunde. Wenn mehr als ein Server verwendet wurde, berichten wir über die gesamte Bandbreite, die über alle Server zusammengefasst wurde. Die Ergebnisse für alle drei Anwendungsfälle sind in der folgenden Abbildung dargestellt. Für den Fall mit zwei Servern wird die kombinierte Bandbreite von beiden Servern angegeben.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Die Ergebnisse zeigen, dass Netzwerkspeicher sich nicht negativ auf die Performance auswirken – die Änderung ist minimal und bei einigen Aufgaben wird keine gefunden. Beim Hinzufügen des zweiten Servers wird die Gesamtbandbreite entweder genau verdoppelt oder im schlimmsten Fall ist die Änderung weniger als 1 %.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">KI-Inferenz in einem einzelnen Stream-Szenario für AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Dieser Benchmark misst die Latenz. Für den Fall mehrerer Computing-Server wird die durchschnittliche Latenz angegeben. Die Ergebnisse für die Aufgabensuite finden Sie in der folgenden Abbildung. Bei zwei Servern wird die durchschnittliche Latenz von beiden Servern angegeben.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Die Ergebnisse zeigen auch hier, dass der Netzwerkspeicher ausreichend ist, um die Aufgaben zu bewältigen. Der Unterschied zwischen lokalem und Netzwerk-Speicher in einem Server-Fall ist minimal oder nicht. Gleiches gilt, wenn zwei Server denselben Storage nutzen – die Latenz auf beiden Servern bleibt bei sehr geringen Änderungen gleich.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">KI-Inferenz in Multistream-Szenario für AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">In diesem Fall führt das System zu der Anzahl der Streams, die das System verarbeiten kann, und erfüllt gleichzeitig die QoS-Einschränkung. Das Ergebnis ist also immer eine ganze Zahl. Für mehrere Server wird die Gesamtanzahl der Streams, die über alle Server zusammengefasst wurden, angegeben. Nicht alle Workloads unterstützen dieses Szenario, aber wir haben sie auch ausgeführt. Die Ergebnisse unserer Tests sind in der folgenden Abbildung zusammengefasst. Im Fall von zwei Servern wird die kombinierte Anzahl von Streams beider Server angegeben.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Die Ergebnisse zeigen die perfekte Performance der Einrichtung: Lokaler Speicher und Netzwerk-Storage liefern die gleichen Ergebnisse, und mit dem zweiten Server verdoppelt sich die Anzahl der Streams, die durch das vorgeschlagene Setup bewältigt werden können.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Testergebnisse für EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Zur Bewertung der Performance der vorgeschlagenen Architektur wurden zahlreiche Tests durchgeführt. Es gibt sechs verschiedene Workloads (Bildklassifizierung, Objekterkennung [klein], Objekterkennung [groß], medizinische Bildgebung, Speech-to-Text, Und natürliche Sprachverarbeitung [NLP]), die in zwei verschiedenen Szenarien ausgeführt wurden: Offline und Single Stream. Die Ergebnisse werden in den folgenden Abschnitten beschrieben.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">KI-Inferenz im Offline-Szenario für EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">In diesem Szenario waren alle Daten dem Server zur Verfügung und die Zeit, die für die Verarbeitung aller Proben erforderlich war, wurde gemessen. Als Ergebnisse der Tests berichten wir Bandbreiten in Proben pro Sekunde. Für Einzelknoten-Ausführung berichten wir über den Durchschnitt beider Server, während für zwei Server-Ausführung die gesamte Bandbreite über alle Server zusammengefasst angegeben wird. Die Ergebnisse für Anwendungsfälle sind in der Abbildung unten dargestellt.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">KI-Inferenz in einem einzelnen Stream-Szenario für die EF-Series</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Dieser Benchmark misst die Latenz. In allen Fällen wird die durchschnittliche Latenz über alle Server angegeben, die in den Ausführung involviert sind. Die Ergebnisse für die Aufgabensuite sind gegeben.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Die Ergebnisse zeigen wieder, dass der Netzwerkspeicher zur Bewältigung der Aufgaben ausreicht. Der Unterschied zwischen dem lokalen Speicher und dem Netzwerk-Speicher in einem Server-Fall ist minimal oder gar nicht. Gleiches gilt, wenn zwei Server denselben Storage nutzen – die Latenz auf beiden Servern bleibt bei sehr geringen Änderungen gleich.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">Als Nächstes: Optionen zur Dimensionierung der Architektur.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">Die Autoren bedanken sich herzlich für die Beiträge, die zu diesem White Paper von unseren geschätzten Kollegen von NVIDIA gemacht wurden: Davide Onofrio, Alex Qi, Sicong Ji, Marty Jain und Robert Sohigian. Bedanken möchten sie sich auch für die Beiträge der zentralen NetApp Teammitglieder Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare, Erik Mulder und Mike McNamara.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">Unsere aufrichtige Wertschätzung und unser Dank richten sich an jeden Einzelnen, der mit seinen Einblicken und seinem Know-how einen wichtigen Beitrag zu diesem Dokument geleistet hat.</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">Weiter: Weitere Informationen</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">In diesem Abschnitt wird die Implementierung des virtuellen Einzelhandels-Assistenten ausführlich beschrieben.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">Weiter: Jarvis Deployment</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">Diese Lösung folgt dem Lebenszyklus einer KI/ML-Applikation. Wir beginnen mit der Arbeit von Data Scientists, um die verschiedenen Schritte zu definieren, die für die Vorbereitung von Daten und das Training von Modellen erforderlich sind. Durch die Nutzung VON RAPIDS on DASK führen wir Distributed Training für den Azure Kubernetes Service (AKS) Cluster durch, um die Trainingszeit im Vergleich zum herkömmlichen Python-Scikit-Learn-Ansatz deutlich zu reduzieren. Um den gesamten Zyklus abzuschließen, haben wir die Pipeline mit Azure NetApp Files integriert.</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904: Distributed Training in Azure - Click-Through Rate Prediction</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">Der Fokus der Arbeit eines Datenwissenschaftlers sollte auf das Training und Tuning von ml- (Machine Learning) und künstlicher Intelligenz (KI)-Modellen liegen. Laut einer Untersuchung von Google verbringen Data Scientists jedoch etwa 80 Prozent ihrer Zeit damit, herauszufinden, wie ihre Modelle mit Enterprise-Applikationen funktionieren und im großen Maßstab laufen lassen können.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">Für das Management von End-to-End-KI/ML-Projekten ist ein umfassenderes Verständnis von Unternehmenskomponenten erforderlich. Obwohl DevOps die Definition, Integration und Implementierung übernommen hat, zielen diese Komponententypen IM ML-Betrieb auf einen ähnlichen Flow ab, der auch KI-/ML-Projekte umfasst. Eine Vorstellung der Merkmale einer End-to-End-KI/ML-Pipeline im Unternehmen erhalten Sie in der folgenden Liste der erforderlichen Komponenten:</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">Integrierte Entwicklungsumgebung (IDE)</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">Die Welt der Datenwissenschaft berührt mehrere Disziplinen in IT und Business:</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">Cloud-Administratoren und -Architekten müssen in der Lage sein, Azure-Ressourcen einzurichten und zu managen.</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">Geschäftsanwender möchten auf KI-/ML-Applikationen zugreifen können.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">In diesem technischen Bericht beschreiben wir, wie Azure NetApp Files, RAPIDS KI, DASK und Azure jede dieser Rollen unterstützen, ihren geschäftlichen Nutzen zu steigern.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="section-title">Lösungsüberblick</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files bietet verschiedene Performance-Tiers. Kunden können mit einer Standardebene beginnen und unterbrechungsfrei auf eine hochperformante Tier skalieren, ohne Daten verschieben zu müssen. Auf diese Weise können Data Scientists Modelle nach Maß ohne Performance-Probleme trainieren und dabei Datensilos im gesamten Cluster vermeiden, wie in der Abbildung unten gezeigt.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp und Run:KI haben in diesem technischen Bericht gemeinsam die einzigartigen Funktionen der NetApp ONTAP AI Lösung zusammen mit der Run:KI Plattform zur Vereinfachung der Orchestrierung von KI-Workloads demonstriert. Die obigen Schritte führen zu einer Referenzarchitektur, um den Prozess von Daten-Pipelines und Workload-Orchestrierung für Deep Learning zu optimieren. Kunden, die diese Lösungen implementieren möchten, können sich gern bei NetApp wenden und mit Run:AI weitere Informationen erhalten.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">Weiter: Testdetails für Abschnitt 4.8</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">Anwendungsfälle</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">Auch wenn heute kein KI-gestützter Einsatz ist, entwickelt sich das Unternehmen zunehmend mit neuen Funktionen, die Kunden auf die immensen Vorteile der KI zugreifen können. Für die Einführung von KI benötigen Applikationen eine Infrastruktur, die ihnen die Ressourcen bietet, die sie für einen optimalen Betrieb und die Weiterentwicklung benötigen.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">Bei KI-gestützten Applikationen fungieren Edge-Standorte als Hauptquelle für Daten. Verfügbare Daten können für Schulungen genutzt werden, wenn sie über einen Zeitraum von mehreren Edge-Standorten erfasst werden, um einen Trainingdatensatz zu bilden. Das trainierte Modell kann dann zurück an den Edge-Standorten implementiert werden, an denen die Daten erfasst wurden. So lassen sich Inferenz schneller durchführen, ohne dass wiederholt Produktionsdaten auf eine dedizierte Inferenzplattform übertragen werden müssen.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">Die NetApp HCI AI Inferenzlösung mit NetApp H615c Computing-Nodes mit NVIDIA T4-GPUs und Cloud-vernetzten NetApp Storage-Systemen wurde von NetApp und NVIDIA entwickelt und verifiziert. NetApp HCI vereinfacht die Implementierung von KI-Inferenzlösungen im Edge-Datacenter, indem es Ambiguität beseitigt und damit die Komplexität des Designs und das Ende von Unsicherheiten beseitigt. Mit dieser Lösung erhalten IT-Abteilungen eine präskriptive Architektur, die folgende Vorteile bietet:</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">Ermöglicht KI-Inferenz im Edge-Datacenter</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">Optimiert die Nutzung von GPU-Ressourcen</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Bietet eine Kubernetes-basierte Plattform zur Inferenz für Flexibilität und Skalierbarkeit</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">Edge-Datacenter managen und verarbeiten Daten an Standorten, die sich sehr nahe am Erzeugungspunkt befinden. Diese Nähe erhöht die Effizienz und verringert die beim Umgang mit Daten involvierte Latenz. In vielen vertikalen Märkten wurden die Vorteile eines Edge Datacenters erkannt und dieser verteilte Ansatz für die Datenverarbeitung wird stark umgesetzt.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">In der folgenden Tabelle sind die Edge-Branchen und -Applikationen aufgeführt.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">Vertikale Märkte</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">Applikationen Unterstützt</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">Medizinisch</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">Computergestützte Diagnostik unterstützt medizinisches Personal bei der Früherkennung von Krankheiten</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">Öl und Gas</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">Autonome Inspektion von Remote-Produktionsstätten, Video- und Bildanalysen</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">Luftverkehr</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">Unterstützung bei der Flugsicherung und Videofeed-Analysen in Echtzeit</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">Media und Entertainment</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">Audio-/Video-Content-Filterung für familienfreundliche Inhalte</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">Geschäftsanalysen</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">Markenbekanntheit zur Analyse des Markenauftritts in Live-Stream-Fernsehveranstaltungen</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">E-Commerce</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">Intelligente Bündelung von Lieferanten Angebote, um ideale Händler-und Lager-Kombinationen zu finden</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">Einzelhandel</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">Automatisierte Kasse, um Artikel zu erkennen, die ein Kunde in den Warenkorb gelegt hat, und die digitale Zahlung zu erleichtern</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">Smart City</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">Verbesserung des Verkehrsflusses, Optimierung des Parkplatzes und Verbesserung der Fußgänger- und Radfahrersicherheit</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">Fertigung</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">Qualitätskontrolle, Montage-Leitungsüberwachung und Fehlererkennung</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">Kundendienst</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">Automatisierung des Kundenservice zur Analyse und Bewertung von Anfragen (Telefon, E-Mail und Social Media)</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">Landwirtschaft</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">Intelligente Farm-Betrieb und Aktivitätenplanung, um Dünger- und Herbizidanwendung zu optimieren</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">Die Zielgruppe für die Lösung umfasst die folgenden Gruppen:</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">Data Scientists</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT-Architekten</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">Field Consultants</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">Professional Services</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT Manager zu erreichen</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">Andere Unternehmen benötigen eine Infrastruktur, die IT-Innovationen und stabile Daten- und Applikations-Services am Edge-Standort bietet</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">Als Nächstes: Architektur</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise with NetApp and VMware – Initial Setup</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Ersteinrichtung</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">Früher: Architektur.</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">In diesem Abschnitt werden die anfänglichen Einrichtungsaufgaben beschrieben, die durchgeführt werden müssen, um NVIDIA AI Enterprise mit NetApp und VMware zu nutzen.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise Product Support Matrix</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Dokumentation der Lösungen von NetApp und VMware</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte durchführen, gehen wir davon aus, dass Sie VMware vSphere und NetApp ONTAP bereits implementiert haben. Siehe <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> Weitere Informationen zu unterstützten vSphere Versionen finden Sie unter. Siehe <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> Finden Sie Einzelheiten zur Implementierung von VMware vSphere mit NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">NVIDIA AI Enterprise Host Software installieren</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise Quick Start Guide</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Befolgen Sie zum Installieren der NVIDIA AI Enterprise Host-Software die Anweisungen in Abschnitt 1-4 in <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">Als Nächstes: NVIDIA NGC Software verwenden</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="208683138843b8d3d5e2d587c3c7655b" category="doc">TR-4815: NetApp AFF A800 und Fujitsu Server PRIMERGY GX2570 M5 für Trainings-Workloads im KI- und ML-Modell</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette, NetApp Takashi Oishi, Fujitsu</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">Der Schwerpunkt dieser Lösung liegt auf einer Scale-out-Architektur zur Implementierung künstlicher Intelligenz-Systeme mit NetApp Storage-Systemen und Fujitsu Servern. Die Lösung wurde mit MLperf v0.6 Modell-Trainings-Benchmarks unter Verwendung von Fujitsu GX2570 Servern und einem NetApp AFF A800 Storage-System validiert.</block>
  <block id="b7c37fdfd029affe5cf4c25d73b9084d" category="inline-link-macro"><block ref="b7c37fdfd029affe5cf4c25d73b9084d" category="inline-link-rx"></block></block>
  <block id="dc4386f7ba9f47c00c36d26452de1559" category="paragraph"><block ref="dc4386f7ba9f47c00c36d26452de1559" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">Klicken Sie sich durch die Verarbeitung der Tarifprognosen und das Modelltraining</block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">Zurück: Schlussfolgerung.</block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">Interaktive 3D-Demos</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">Direkter Austausch mit einem NetApp KI-Experten</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">NVDIA Base Command Platform mit NetApp – Lösungsüberblick</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">Infografik: NetApp for AI 10 gute Gründe</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">AI im Gesundheitswesen: Deep Learning zur Identifizierung von COVID-19 Läsionen in Lungen-CT-Scans Whitepaper</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">KI im Gesundheitswesen: Whitepaper zur Überwachung der Gesichtsmaske in Einstellungen für das Gesundheitswesen</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">KI im Gesundheitswesen: Technischer Bericht zur diagnostischen Bildgebung</block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">AI für den Einzelhandel: NetApp Convertional AI mit NVIDIA RIVA</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI – Lösungsüberblick</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps Toolkit – Lösungsüberblick</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">NetApp AI Control Plane – Lösungsüberblick</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">Wie Sie ganze Branchen mithilfe von KI-eBook „Daten verändern“</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF-Series KI – Lösungsüberblick</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">Lösungsüberblick: NetApp AI und Lenovo ThinkSystem für KI-Inferenz</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">NetApp AI und Lenovo ThinkSystem für Enterprise-KI und -ML – Lösungsüberblick</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp und NVIDIA – Definieren Sie, was möglich ist, mit KI-Video</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">Diese Seite vergleicht die Modelltrainings-Zeit mit konventionellem Pandas im Vergleich zu Dask. Bei Pandas haben wir eine kleinere Menge an Daten geladen, weil die Verarbeitungszeit langsamer ist, um Speicherüberlauf zu vermeiden. Daher haben wir die Ergebnisse interpoliert, um einen fairen Vergleich zu bieten.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">Vergleich der Schulungszeit</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">Früher: Überwachen Sie DASK mit nativen Task Streams Dashboard.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">Dieser Abschnitt vergleicht die Modelltrainings-Zeit mit konventionellem Pandas im Vergleich zu Dask. Bei Pandas haben wir eine kleinere Menge an Daten geladen, weil die Verarbeitungszeit langsamer ist, um Speicherüberlauf zu vermeiden. Daher haben wir die Ergebnisse interpoliert, um einen fairen Vergleich zu bieten.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">Die folgende Tabelle zeigt den Vergleich der Rohtrainings-Zeiten, wenn für das Modell der zufälligen Wälder von Pandas deutlich weniger Daten benötigt werden (50 Millionen Zeilen von 20 Milliarden pro Tag 15 des Datensatzes). Diese Stichprobe benötigt nur weniger als 0.25 % aller verfügbaren Daten. Während wir für Dask-cuML das Zufallswaldmodell auf allen 20 Milliarden verfügbaren Reihen trainiert haben. Die beiden Ansätze ergaben eine vergleichbare Trainingszeit.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">Vorgehensweise</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">Schulungszeit</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-Learn: Verwendung von nur 50M Reihen im Tag15 als Trainingsdaten</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 Minuten und 21 Sekunden</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-DASK: Alle 20B-Reihen täglich an15 als Trainingsdaten nutzen</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 Stunde, 12 Minuten und 11 Sekunden</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">Wenn wir die Ergebnisse der Trainingszeit linear interpolieren, wie in der folgenden Tabelle dargestellt, bietet sich ein bedeutender Vorteil für die Verwendung verteilter Schulungen mit Dask. Es würde 13 Tage dauern, bis der konventionelle Pandas scikit-Lernansatz 45GB Daten für einen einzigen Tag mit Klick-Protokollen verarbeitet und trainiert, während der RAPIDS-DASK-Ansatz die gleiche Datenmenge 262.39-mal schneller verarbeitet.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-Learn: Alle 20B-Reihen im Tag15 als Trainingsdaten verwenden</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 Tage, 3 Stunden, 40 Minuten und 11 Sekunden</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">In der vorherigen Tabelle ist zu sehen, dass durch die Verwendung VON RAPIDS mit DASK die Datenverarbeitung und das Modelltraining über mehrere GPU-Instanzen hinweg deutlich kürzer ist als bei der konventionellen Pandas DataFrame-Verarbeitung mit scikit-Learn Modelltrainings. Dieses Framework ermöglicht sowohl vertikale als auch horizontale Skalierung in der Cloud als auch On-Premises in einem Multi-Node-Cluster mit mehreren GPUs.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">Nächster: Monitor Dask and RAPIDS mit Prometheus und Grafana.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI und KI Control Plane</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">Die NetApp ONTAP KI-Architektur mit NVIDIA DGX-Systemen und Cloud-vernetzten NetApp Storage-Systemen. Diese Referenzarchitektur bietet IT-Abteilungen folgende Vorteile:</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">Computing und Storage können unabhängig voneinander skaliert werden</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">Bietet eine Reihe von Storage-Optionen für diverse Performance- und KostenpunkteNetApp ONTAP AI integriert DGX-Systeme und NetApp AFF A800 Storage-Systeme nahtlos in hochmoderne Netzwerke. Mithilfe von NetApp ONTAP AI und DGX-Systemen können Komplexität und Unsicherheiten bei der Systemaufsetzung beseitigt werden, was den Einsatz von KI-Projekten vereinfacht. Kunden können mit einer kleinen Installation starten und ihre Systeme unterbrechungsfrei erweitern. Gleichzeitig erhalten sie intelligente Datenmanagement-Funktionen, mit denen sich Daten zwischen Datenaufnahme, zentraler Datenplattform und Cloud frei verschieben lassen.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp AI Control Plane ist eine Daten- und Experimentmanagementlösung für Data Scientists und Data Engineers, eine Full-Stack-KI, ML und Deep Learning (DL). Beim zunehmenden Einsatz von KI sehen sich Unternehmen vielen Herausforderungen gegenüber, darunter Workload-Skalierbarkeit und Datenverfügbarkeit. NetApp AI Control Plane begegnet diesen Herausforderungen mit Funktionalitäten, beispielsweise dem schnellen Klonen eines Daten-Namespace wie bei einer Git-Reversion. KI-Trainings-Workflows definieren und implementieren, bei denen die nahezu sofortige Erstellung von Daten- und Modellbasiden für die Rückverfolgbarkeit und Versionierung integriert ist. Mit der NetApp AI Control Plane können Sie Daten nahtlos über Standorte und Regionen hinweg replizieren und rasch Jupyter Notebook-Workspaces mit Zugriff auf riesige Datensätze bereitstellen.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">Next: KI-Plattform für KI-Workload-Orchestrierung</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Beispiel Für Apache Airflow Workflows</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Das NetApp Data Science Toolkit für Kubernetes</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">Der<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kann in Verbindung mit Airflow verwendet werden. Mit dem NetApp Data Science Toolkit in Airflow können Sie NetApp Datenmanagement-Operationen in automatisierte Workflows einbinden, die mit Airflow orchestriert sind.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Beispiele Für Luftströmungen</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">Siehe<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> Im Abschnitt zum NetApp Data Science Toolkit GitHub Repository finden Sie weitere Informationen zur Verwendung des Toolkit mit Airflow.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">Weiter: Beispiel Trident Operations.</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">Dieser Abschnitt enthält Links zu zwei Jupyter-Notizbüchern, die für diesen technischen Bericht relevant sind.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter-Notebooks als Referenz</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">Früher: Dataset and Model Versioning Using NetApp DataOps Toolkit.</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">Diesem technischen Bericht sind zwei Jupyter Notebooks zugeordnet:</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR-PandasRF-collated.ipynb.*</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> Dieses Notebook lädt Tag 15 aus dem Criteo Terabyte Click Protokolldatensatz, verarbeitet und formatiert Daten in einen Pandas DataFrame, trainiert ein Scikit-Learn Zufallswaldmodell, führt Vorhersage aus und berechnet Genauigkeit.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">*criteo_dask_RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> Dieses Notebook lädt Tag 15 aus dem Criteo Terabyte Click Log Datensatz, verarbeitet und formatiert Daten in einen Damast CuDF, trainiert ein Dusk CuML Zufallswaldmodell, führt Vorhersage aus und berechnet Genauigkeit. Durch die Nutzung von mehreren Worker-Nodes mit GPUs ist dieser verteilte Daten- und Modellverarbeitungs- und Trainingsansatz äußerst effizient. Je mehr Daten Sie verarbeiten, desto größer ist die Zeitersparnis im Vergleich zu einem herkömmlichen ML-Ansatz. Dieses Notebook lässt sich in der Cloud, vor Ort oder in einer hybriden Umgebung bereitstellen, in der Ihr Kubernetes-Cluster Computing und Storage an verschiedenen Standorten enthält, sofern Ihr Netzwerk-Setup Daten und die Modellverteilung frei ermöglicht.</block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">Implementierung von cnvrg.io</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Cnvrg-KERN mit Helm implementieren</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm ist der einfachste Weg, cnvrg schnell über beliebige Cluster, On-Premises, Minikube oder in einem beliebigen Cloud-Cluster (wie AKS, EKS und GKE) zu implementieren. In diesem Abschnitt wird beschrieben, wie cnvrg auf einer On-Premises-Instanz (DGX-1) mit installiertem Kubernetes installiert wurde.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">Bevor Sie die Installation abschließen können, müssen Sie die folgenden Abhängigkeiten auf Ihrem lokalen Computer installieren und vorbereiten:</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes-Cluster ab 1.15</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Implementierung Mit Helm</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">Um die aktuellsten cnvrg Steuerdiagramme herunterzuladen, führen Sie den folgenden Befehl aus:</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">Bevor Sie cnvrg implementieren, benötigen Sie die externe IP-Adresse des Clusters und den Namen des Node, auf dem Sie cnvrg bereitstellen. Führen Sie den folgenden Befehl aus, um cnvrg auf einem lokalen Kubernetes-Cluster zu implementieren:</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">Führen Sie die aus<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> Befehl. Alle Services und Systeme werden automatisch in Ihrem Cluster installiert. Dieser Vorgang kann bis zu 15 Minuten dauern.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">Der<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> Der Befehl kann bis zu 10 Minuten dauern. Nach Abschluss der Bereitstellung rufen Sie die URL Ihrer neu implementierten cnvrg auf oder fügen Sie den neuen Cluster als Ressource innerhalb Ihres Unternehmens hinzu. Der<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> Der Befehl informiert Sie über die richtige URL.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">Wenn der Status aller Container ausgeführt oder abgeschlossen ist, wurde cnvrg erfolgreich bereitgestellt. Es sollte ähnlich wie bei der folgenden Beispielausgabe aussehen:</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">Computer Vision Model Training mit ResNet50 und dem Thorax-Röntgendatensatz</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH Download-Site</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">Cnvrg.io AI OS wurde in einem Kubernetes Setup auf einer NetApp ONTAP KI-Architektur auf Basis des NVIDIA DGX-Systems implementiert. Zur Validierung haben wir den NIH Chest Röntgendatensatz verwendet, der aus entidentifizierten Bildern von Thoraxröntgenbildern besteht. Die Bilder waren im PNG-Format. Die Daten wurden vom NIH Clinical Center bereitgestellt und sind über den verfügbar<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. Wir verwendeten eine 250-GB-Datenprobe mit 627, 615 Bildern aus 15 Klassen.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">Der Datensatz wurde auf die cnvrg Plattform hochgeladen und auf einem NFS-Export aus dem NetApp AFF A800 Speichersystem zwischengespeichert.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">Richten Sie die Computing-Ressourcen ein</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">Die cnvrg Architektur und die Meta-Scheduling-Funktion ermöglichen es Ingenieuren und IT-Experten, verschiedene Computing-Ressourcen zu einer einzelnen Plattform anzubinden. In unserem Setup haben wir denselben Cluster cnvrg verwendet, der für die Ausführung der Deep-Learning-Workloads implementiert wurde. Wenn Sie weitere Cluster hinzufügen müssen, verwenden Sie die GUI, wie im folgenden Screenshot gezeigt.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">Daten Laden</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">Zum Hochladen von Daten auf die cnvrg Plattform können Sie die GUI oder den cnvrg CLI verwenden. Für große Datensätze empfiehlt NetApp die Verwendung der CLI, da es sich um ein starkes, skalierbares und zuverlässiges Tool handelt, das eine große Anzahl von Dateien verarbeiten kann.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">Gehen Sie wie folgt vor, um Daten hochzuladen:</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">Cnvrg CLI</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">Laden Sie die herunter<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">Navigieren Sie zum Röntgenverzeichnis.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">Initialisieren Sie den Datensatz in der Plattform mit dem<block ref="93683f43f0985082ca58f41ff93ff85f" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">Alle Inhalte des Verzeichnisses mit dem in den zentralen Data Lake hochladen<block ref="3e18d74143663f7fae3446eb44229f0f" prefix=" " category="inline-code"></block> Befehl.Nachdem die Daten in den zentralen Objektspeicher hochgeladen wurden (StorageGRID, S3 oder andere), können Sie mit der GUI navigieren. Die folgende Abbildung zeigt eine geladene PNG-Datei mit Röntgenfibrose im Brustbild. Darüber hinaus versioniere cnvrg die Daten, so dass jedes Modell, das Sie erstellen, auf die Datenversion reproduziert werden kann.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Cach-Daten</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">Damit das Training schneller durchgeführt wird und mehr als 600.000 Dateien für jedes Modelltraining und jedes Experiment nicht heruntergeladen werden können, haben wir die Daten-Caching-Funktion verwendet, nachdem die Daten ursprünglich in den zentralen Data-Lake-Objektspeicher hochgeladen wurden.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">Nachdem Benutzer auf Cache geklickt haben, lädt cnvrg die Daten in seinem spezifischen Commit aus dem Remote-Objektspeicher herunter und speichert sie auf dem ONTAP NFS Volume ab. Nach Abschluss der Schulung stehen die Daten für ein sofortiges Training zur Verfügung. Wenn die Daten zudem für einige Tage nicht verwendet werden (z. B. für Modelltraining oder Exploration), löscht cnvrg automatisch den Cache.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">AUFBAU einer ML-Pipeline mit zwischengespeicherten Daten</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">Cnvrg-Ströme ermöglichen es Ihnen, problemlos Produktions-ML-Pipelines aufzubauen. Flows sind flexibel, können für jede Art VON ML-Anwendungsfall und über die GUI oder den Code erstellt werden. Jede Komponente in einem Flow kann auf unterschiedlichen Computing-Ressourcen mit einem anderen Docker-Image ausgeführt werden. So lässt sich Hybrid-Cloud- und ml-Pipelines erstellen.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">Erstellen des Thoraxröntgendurchflusses: Einstellen der Daten</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">Wir haben unseren Datensatz zu einem neu erstellten Flow hinzugefügt. Beim Hinzufügen des Datensatzes können Sie die bestimmte Version (Commit) auswählen und angeben, ob die zwischengespeicherte Version verwendet werden soll. In diesem Beispiel haben wir den Cache-Commit ausgewählt.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">Erstellen des Thorax-Röntgenflusses: Einstellen Trainingsmodell: ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">In der Pipeline können Sie jede Art von benutzerdefiniertem Code hinzufügen. In cnvrg gibt es auch die AI-Bibliothek, eine wiederverwendbare ML-Komponenten-Sammlung. In der KI-Bibliothek gibt es Algorithmen, Skripte, Datenquellen und andere Lösungen, die in jedem ML- oder Deep-Learning-Flow verwendet werden können. In diesem Beispiel haben wir das vordefinierte ResNet50-Modul ausgewählt. Wir haben Standardparameter wie Batch_size:128, Epochs:10 und mehr verwendet. Diese Parameter können in der Dokumentation der KI-Bibliothek angezeigt werden. Der folgende Screenshot zeigt den neuen Flow, in dem der Röntgendatensatz an ResNet50 angeschlossen ist.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">Definieren Sie die Compute-Ressource für ResNet50</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">Jeder Algorithmus oder jede Komponente in cnvrg-Flows kann auf einer anderen Computing-Instanz mit einem anderen Docker-Image ausgeführt werden. In unserem Setup wollten wir den Trainingsalgorithmus auf den NVIDIA DGX Systemen mit der NetApp ONTAP AI Architektur ausführen. In der folgenden Abbildung haben wir ausgewählt<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block>, Eine Computing-Vorlage und -Spezifikation für unseren On-Premises-Cluster. Wir haben auch eine Warteschlange mit Vorlagen erstellt und mehrere Vorlagen ausgewählt. Auf diese Weise, wenn der<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block> Die Ressource kann nicht zugewiesen werden (wenn beispielsweise andere Data Scientists sie nutzen), dann können Sie automatisches Cloud-Bursting durch Hinzufügen einer Cloud-Provider-Vorlage aktivieren. Der folgende Screenshot zeigt die Verwendung von gpu-Real als Compute-Node für ResNet50.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">Nachverfolgung und Überwachung der Ergebnisse</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">Nachdem ein Flow ausgeführt wurde, löst cnvrg die Tracking- und Monitoring-Engine aus. Jeder Flow-Durchlauf wird automatisch dokumentiert und in Echtzeit aktualisiert. Hyperparameter, Metriken, Ressourcenauslastung (GPU-Auslastung und mehr), Codeversion, Artefakte, Protokolle Und so weiter sind im Abschnitt Experimente automatisch verfügbar, wie in den folgenden beiden Screenshots gezeigt.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">In dieser Architektur liegt der Schwerpunkt auf dem rechenintensivsten Teil des verteilten Trainingsprozesses von Lane-Erkennung durch KI oder Machine Learning (ML).</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">In dieser Architektur liegt der Schwerpunkt auf dem rechenintensivsten Teil des verteilten Trainingsprozesses von Lane-Erkennung durch KI oder Machine Learning (ML). Fahrspurerkennung ist eine der wichtigsten Aufgaben im autonomen Fahren, die hilft, Fahrzeuge durch Lokalisierung der Fahrspurmarkierungen zu führen. Statische Bauteile wie Fahrspurmarkierungen führen das Fahrzeug dazu, interaktiv und sicher auf der Autobahn zu fahren.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">Convolutional Neural Network (CNN)-basierte Ansätze haben das Verständnis und die Segmentierung von Szenen auf eine neue Ebene verschoben. Auch wenn es nicht gut funktioniert für Objekte mit langen Strukturen und Regionen, die verdeckt werden könnten (z. B. Pole, Schatten auf der Spur, und so weiter). Das Spatial Convolutional Neural Network (SNN) verallgemeinert die CNN auf eine reiche räumliche Ebene. Es ermöglicht die Informationsverbreitung zwischen Neuronen in der gleichen Schicht, was es am besten für strukturierte Objekte wie Lanes, Pole oder LKW mit Oktazionen geeignet macht. Diese Kompatibilität ist, weil die räumliche Information verstärkt werden kann, und es bewahrt Glätte und Kontinuität.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">Tausende von Szenenbildern müssen im System injiziert werden, damit das Modell die verschiedenen Komponenten im Datensatz erlernen und unterscheiden kann. Diese Bilder umfassen Wetter, tagsüber oder nachts, Mehrspurstraßen und andere Verkehrsbedingungen.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">Aus dem Training werden gute Qualität und Quantität der Daten benötigt. Eine einzelne GPU oder mehrere GPUs können Tage bis Wochen dauern, bis das Training abgeschlossen ist. Das Training mit verteilten Daten kann den Prozess mithilfe von GPUs mit mehreren Nodes beschleunigen. Horovod ist ein solches Framework, das verteiltes Training gewährt, aber das Lesen von Daten über GPUs Cluster hinweg kann als Hindernis fungieren. Azure NetApp Files bietet einen extrem hohen Durchsatz und kontinuierlich niedrige Latenz, um Funktionen für die horizontale und vertikale Skalierung bereitzustellen, sodass GPUs optimal auf die Computing-Kapazität eingesetzt werden. Unsere Experimente bestätigten, dass alle GPUs im Cluster durchschnittlich mehr als 96 % beim Training der Lane-Erkennung mit SNN verwendet werden.</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">Data Science beinhaltet mehrere Disziplinen in IT und Business, weshalb mehrere Personas Teil unserer Zielgruppe sind:</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">Die Data Scientists benötigen die Flexibilität, die Tools und Bibliotheken ihrer Wahl einzusetzen.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">Data Engineers müssen wissen, wie die Daten fließen und wo sie sich befinden.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">Autonomes Fahren – Fallexperten.</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">Cloud-Administratoren und -Architekten, um Cloud-Ressourcen (Azure) einzurichten und zu managen</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">DevOps-Engineers benötigen die Tools, um neue KI/ML-Applikationen in ihre Continuous Integration und Continuous Deployment (CI/CD)-Pipelines zu integrieren.</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">In diesem Dokument beschreiben wir, wie Azure NetApp Files, RUN: AI und Microsoft Azure jeder dieser Rollen einen Mehrwert für das Unternehmen bieten können.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">Lösungstechnologie</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">In diesem Abschnitt werden die technologischen Anforderungen für die Lane-Erkennung erläutert. Hierzu wird eine verteilte Trainingslösung in großem Umfang implementiert, die in der Azure Cloud ausgeführt wird. Die Abbildung unten bietet einen Überblick über die Lösungsarchitektur.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">Folgende Elemente werden in dieser Lösung verwendet:</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes-Service (AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">Azure Computing SKUs mit NVIDIA GPUs</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Dateien</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">AUSFÜHREN: KI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">Links zu allen hier genannten Elementen sind im aufgeführt <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> Abschnitt.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">Cloud-Ressourcen und -Serviceanforderungen</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">In der folgenden Tabelle werden die Hardwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Je nach den Anforderungen des Kunden können die Cloud-Komponenten, die in einer beliebigen Implementierung dieser Lösung verwendet werden, variieren.</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">Mindestens drei System-Nodes und drei GPU-Worker-Nodes</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">VM (Virtual Machine) SKU-System-Nodes</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Drei Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM-SKU-GPU-Worker-Nodes</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">Drei Standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4 TB Standard Tier</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Softwareanforderungen</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">In der folgenden Tabelle werden die Softwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Je nach den Anforderungen des Kunden können die in einer beliebigen Implementierung dieser Lösung verwendeten Softwarekomponenten abweichen.</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">Version oder andere Informationen</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - Kubernetes-Version</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">AUSFÜHREN:AI-CLI</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">Version 2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">RUN:AI Orchestration Kubernetes Operator Version</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">Übersicht Über Die Fehlervorhersage Für Netzwerkgeräte: Anwendungsbeispiel</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">Dieser Anwendungsfall basiert auf einem Iguazio-Kunden im Telekommunikationsbereich in Asien. Da 100.000 Enterprise-Kunden und jedes Jahr 125 Netzwerkausfälle verursacht haben, war es entscheidend, dass sie proaktiv Maßnahmen ergreifen und verhindern müssen, dass Netzwerkausfälle die Kunden beeinträchtigen. Diese Lösung bot den Kunden folgende Vorteile:</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">Prädiktive Analysen bei Netzwerkausfällen</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">Integration in ein Ticketsystem</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">Proaktive Maßnahmen zur Verhinderung von Netzwerkfehlern infolge dieser Implementierung von Iguazio wurden 60 % der Ausfälle proaktiv verhindert.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">Weiter: Setup-Übersicht</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">Projekte für Data Science-Teams erstellen und GPUs zuweisen</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">Forscher können Workloads über Run:AI CLI, Kubeflow oder ähnliche Prozesse senden. Um die Ressourcenzuweisung zu optimieren und Priorisierungen zu erstellen, führt Run:AI das Projektkonzept ein. Projekte sind Quoteneinheiten, die einen Projektnamen mit GPU-Zuweisung und -Einstellungen verknüpfen. Mehrere Data-Science-Teams können auf einfache und bequeme Weise gemanagt werden.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">Ein Forscher, der einen Workload einreicht, muss ein Projekt mit einer Workload-Anforderung verknüpfen. Der Scheduler:AI vergleicht die Anforderung mit den aktuellen Zuweisungen und dem Projekt und bestimmt, ob der Workload Ressourcen zugewiesen werden kann oder ob er sich im ausstehenden Status befindet.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">Als Systemadministrator können Sie auf der Registerkarte Run:AI Projects die folgenden Parameter einstellen:</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">*Modellprojekte.* ein Projekt pro Benutzer festlegen, ein Projekt pro Benutzerteam festlegen und ein Projekt für ein echtes organisatorisches Projekt festlegen.</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">*Projektquoten.* jedes Projekt ist mit einer Quote von GPUs verknüpft, die für dieses Projekt gleichzeitig zugewiesen werden können. Dies ist eine garantierte Quote, da Forscher, die dieses Projekt nutzen, garantiert sind, diese Anzahl von GPUs zu erhalten, egal wie der Status im Cluster ist. In der Regel sollte die Summe der Projektzuweisung der Anzahl der GPUs im Cluster entsprechen. Darüber hinaus kann ein Benutzer dieses Projekts eine Überkontingente erhalten. Solange GPUs nicht verwendet werden, kann ein Forscher, der dieses Projekt verwendet, mehr GPUs erhalten. Wir führen Testszenarien mit Überquoten und fairer Erwägungen ein<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, und<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">Erstellen Sie ein neues Projekt, aktualisieren Sie ein vorhandenes Projekt und löschen Sie ein vorhandenes Projekt.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">Ausführen:KI-Dokumentation</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">*Anzahl der Aufträge, die auf bestimmten Knotengruppen ausgeführt werden sollen*. Sie können bestimmte Projekte nur auf bestimmten Knoten ausführen. Dies ist nützlich, wenn das Projektteam spezielle Hardware benötigt, zum Beispiel mit genügend Arbeitsspeicher. Alternativ kann ein Projektteam Eigentümer bestimmter Hardware sein, die mit einem speziellen Budget erworben wurde, oder wenn Unternehmen direkte Build- oder interaktive Workloads für die Arbeit an schwächerer Hardware und das direkte Training oder unbeaufsichtigte Arbeitslasten auf schnellere Nodes benötigen. Informationen zu Befehlen zum Gruppieren von Knoten und zum Festlegen der Affinität für ein bestimmtes Projekt finden Sie im <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">*Beschränken Sie die Dauer von interaktiven Jobs*. Forscher vergessen häufig, interaktive Jobs zu schließen. Dies könnte zu einer Verschwendung von Ressourcen führen. Einige Organisationen ziehen es vor, die Dauer von interaktiven Jobs zu begrenzen und automatisch zu schließen.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">Die folgende Abbildung zeigt die Ansicht „Projekte“ mit vier erstellten Teams. Jedem Team wird eine unterschiedliche Anzahl von GPUs zugewiesen, die verschiedenen Workloads Rechnung tragen. Die Gesamtzahl der GPUs entspricht der Gesamtzahl der verfügbaren GPUs in einem Cluster, der aus zwei DGX-1 besteht.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">Als Nächstes: Jobs in Run AI CLI senden</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise with NetApp and VMware - Architecture</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Der Netapp Architektur Sind</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">Zurück: Technologischer Überblick.</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Die Lösung baut auf einer bewährten, vertrauten Architektur auf, die NetApp, VMware und NVIDIA-zertifizierte Systeme umfasst. Einzelheiten hierzu finden Sie in der folgenden Tabelle.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">KI- und Data-Analytics-Software</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA AI Enterprise für VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Virtualisierungsplattform</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Computing-Plattform</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Von NVIDIA zertifizierte Systeme</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Datenmanagementplattform</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">Weiter: Ersteinrichtung.</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">Code von GitHub</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">Nachdem das NetApp Cloud Volume oder NetApp Trident Volume nun für den Iguazio Cluster und die Entwicklungsumgebung zur Verfügung steht, können Sie nun mit der Überprüfung der Applikation beginnen.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">Benutzer haben ihren eigenen Arbeitsbereich (Verzeichnis). Auf jedem Notebook befindet sich der Pfad zum Benutzerverzeichnis<block ref="60dfd72bb314eac7d0f73279723af059" prefix=" " category="inline-code"></block>. Die Iguazio-Plattform verwaltet das Verzeichnis. Wenn Sie die obigen Anweisungen befolgen, steht das NetApp Cloud Volume im zur Verfügung<block ref="61bc18ea7642b598a1fcfad2e953599b" prefix=" " category="inline-code"></block> Verzeichnis.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Holen Sie sich den Code von GitHub mit einem Jupyter Terminal.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Klont das Projekt in der Jupyter-Terminalaufforderung.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">Sie sollten jetzt sehen, die<block ref="fbeae7c8d4df4765206d2abb38069752" prefix=" " category="inline-code"></block> Ordner in der Dateistruktur im Jupyter-Arbeitsbereich.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">Als Nächstes: Arbeitsumgebung Konfigurieren</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Nutzen Sie die NVIDIA NGC Software – Beispiel Use Case - TensorFlow Training Job</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Beispiel: Anwendungsfall – TensorFlow Training Job</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">Zurück: Einrichtung.</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um einen TensorFlow-Trainingsjob in einer NVIDIA AI Enterprise-Umgebung auszuführen.</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="inline-link-macro">Einrichtung</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte durchführen, gehen wir davon aus, dass Sie bereits eine Gast-VM-Vorlage erstellt haben, und befolgen Sie die Anweisungen auf dem <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> Seite.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Gast-VM aus Vorlage erstellen</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Zunächst müssen Sie eine neue Gast-VM auf der Vorlage erstellen, die Sie im vorherigen Abschnitt erstellt haben. Um eine neue Gast-VM von Ihrer Vorlage zu erstellen, melden Sie sich bei VMware vSphere an, klicken Sie einfach auf den Vorlagennamen, wählen Sie „Neue VM aus dieser Vorlage...“ und folgen Sie dann dem Assistenten.</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Erstellen und Mounten des Daten-Volumes</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Als Nächstes müssen Sie ein neues Datenvolumen erstellen, auf dem Sie Ihren Trainingsdatensatz speichern können. Mit dem NetApp DataOps Toolkit können Sie schnell ein neues Datenvolumen erstellen. Der folgende Beispiel-Befehl zeigt die Erstellung eines Volumes mit dem Namen „imagenet“ mit einer Kapazität von 2 TB.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Bevor Sie Ihr Daten-Volume mit den Daten füllen können, müssen Sie es innerhalb der Gast-VM mounten. Mit dem NetApp DataOps Toolkit können Sie ein Datenvolumen schnell einbinden. Der folgende Beispielbefehl zeigt das Mounten des Volumes, das im vorherigen Schritt erstellt wurde.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Daten-Volume Füllen</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Nachdem das neue Volume bereitgestellt und angehängt wurde, kann der Trainingsdatensatz vom Quellspeicherort abgerufen und auf dem neuen Volume abgelegt werden. Dabei geht es in der Regel um das Abrufen der Daten von einem S3- oder Hadoop-Data Lake, was gelegentlich auch von einem Data Engineer ermöglicht wird.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Führen Sie TensorFlow Trainingsjob aus</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Sie sind jetzt bereit, Ihre TensorFlow-Schulungsaufgabe auszuführen. Führen Sie die folgenden Aufgaben aus, um Ihren TensorFlow-Schulungsjob auszuführen.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Rufen Sie das Image des NVIDIA NGC Enterprise TensorFlow Containers auf.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Starten Sie eine Instanz des NVIDIA NGC Enterprise TensorFlow Containers. Verwenden Sie die Option '-V', um Ihr Datenvolumen an den Container anzuhängen.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Führen Sie Ihr TensorFlow-Trainingsprogramm im Container aus. Der folgende Beispielbefehl zeigt die Ausführung eines Beispielprogramms ResNet-50, das im Container-Image enthalten ist.</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">Weiter: Weitere Informationen.</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">Das explosionsartige Wachstum der Daten und das exponentielle Wachstum von maschinellem Lernen (ML) und künstlicher Intelligenz (KI) haben sich konvergiert, um eine neue Wirtschaft mit einzigartigen Herausforderungen bei Entwicklung und Implementierung zu schaffen. In der Regel werden riesige Datenmengen in einem kostengünstigen Data Lake gespeichert, in dem hochperformante KI-Computing-Ressourcen wie GPUs nicht effizient darauf zugreifen können. In diesem Bericht stellen wir eine neuartige Lösung vor, in der Data Science-Fachleute ein Data Hub implementieren und mit nur einem Klick einen Cache von Datensätzen in Nähe ihrer Compute-Ressourcen erstellen – unabhängig von ihrem Standort. So können KI-Fachleute das High-Performance-Modelltraining durch optimierte Zusammenarbeit mit einem neuen Datensatz-Version-Hub einfacher durchführen.</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, Technical Marketing Engineer, NetApp</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">Santosh Rao, Senior Technical Director, NetApp</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="822b5b3ac9e0f170e124850176f6f5ad" category="doc">TR-4807: NetApp ONTAP AI Referenzarchitektur für Financial Services-Workloads – Solution Design</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam, Sung-Han Lin, NetApp Jacci Cenci, NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">Diese Referenzarchitektur bietet Richtlinien für Kunden, die eine künstliche Intelligenz mit NVIDIA DGX-1-Systemen und NetApp AFF Storage für Anwendungsfälle aus dem Finanzsektor aufbauen. Sie enthält Informationen zu den grundlegenden Workflows, die bei der Entwicklung von Deep-Learning-Modellen für Testfälle und Ergebnisse von Finanzdienstleistungen verwendet werden. Außerdem enthält sie Empfehlungen zur Dimensionierung für Kundenimplementierungen.</block>
  <block id="a6f98d09d0c8f042087143764a02630c" category="inline-link-macro"><block ref="a6f98d09d0c8f042087143764a02630c" category="inline-link-rx"></block></block>
  <block id="cc1efb0a1d820f8806a752002b5d9b4c" category="paragraph"><block ref="cc1efb0a1d820f8806a752002b5d9b4c" category="inline-link-macro-rx"></block></block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">August 2021</block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">Auf dieser Seite werden die Konfiguration von Cloud-Ressourcen für Azure NetApp Files beschrieben.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">Anforderungen an die Cloud-Ressourcen</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Früher: Software-Anforderungen.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Konfigurieren Sie Azure NetApp Files</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">QuickStart: Azure NetApp Files einrichten und ein NFS-Volume erstellen</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">Konfigurieren Sie Azure NetApp Files wie unter beschrieben<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">Sie können über den Abschnitt „Create NFS Volume for Azure NetApp Files“ hinaus fortfahren, weil Sie Volumes über Trident erstellen. Bevor Sie fortfahren, gehen Sie wie folgt vor:</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">Verlinken</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Registrieren Sie sich über die Azure Shell für Azure NetApp Files und NetApp Ressourcen-Provider (<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>).</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Erstellen Sie ein Konto in Azure NetApp Files (<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>).</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">Richten Sie einen Kapazitäts-Pool ein (mindestens 4 TB Standard oder Premium, je nach Bedarf) (<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>In der folgenden Tabelle sind die Anforderungen an die Netzwerkkonfiguration für die Einrichtung in der Cloud aufgeführt. Der DASK-Cluster und der Azure NetApp Files müssen sich im gleichen virtuellen Azure-Netzwerk (vnet) oder einem Peering vnet befinden.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">Ressourcen</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">Typ/Version</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">Agent-Knoten</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU-Node</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3x Standard_NC6s_v3</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">Standard-Kapazitäts-Pool</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">Kapazität in TB</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">Weiter: Click-through-Rate-Prognose use case summary.</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="455d43e3be683302c81c2b5626db170c" category="doc">TR-4851: NetApp StorageGRID Data Lake für Workloads für das autonome Fahren – Lösungsdesign</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 veranschaulicht die Verwendung von NetApp StorageGRID Objekt-Storage als Daten-Repository und Managementsystem für die Softwareentwicklung Machine Learning (ML) und Deep Learning (DL). In diesem Whitepaper werden der Datenfluss und die Anforderungen bei der Entwicklung der Software für autonome Fahrzeuge sowie die Funktionen von StorageGRID zur Optimierung des Daten-Lebenszyklus beschrieben. Diese Lösung gilt für alle mehrstufigen Daten-Pipeline-Workflows, die in DEN ML- und DL-Entwicklungsprozessen typisch sind.</block>
  <block id="5d5c58f2793c027dcda637fc95601825" category="inline-link-macro"><block ref="5d5c58f2793c027dcda637fc95601825" category="inline-link-rx"></block></block>
  <block id="17534f242f61128daf02fd0bde2ab66d" category="paragraph"><block ref="17534f242f61128daf02fd0bde2ab66d" category="inline-link-macro-rx"></block></block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">NetApp Einrichtung</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">Weiter:Übersicht</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">Konfigurieren Sie Die Arbeitsumgebung</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">Kopieren Sie die<block ref="3a4f8d88ea1eac117f98223609194cb9" prefix=" " category="inline-code"></block><block ref="4931c948234bb20e1915f851691b340a" prefix=" " category="inline-code"></block> Als<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Öffnen und bearbeiten<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Dieses Notizbuch legt Variablen für Anmeldeinformationen, Dateipositionen und Ausführungstreiber fest.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">Wenn Sie die obigen Anweisungen befolgen, sind die folgenden Schritte die einzigen Änderungen, die vorgenommen werden müssen:</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">Erhalten Sie diesen Wert über das Iguazio Services Dashboard:<block ref="bed2ad53cc10d1f92b477fc7c1476348" prefix=" " category="inline-code"></block></block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">Beispiel:<block ref="0ddf9a06edec7d150708463603b95f22" prefix=" " category="inline-code"></block></block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">Ändern<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block> An Ihren Iguazio-Benutzernamen:</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph"><block ref="0458c1c280a715ecb31b33b5269e101b" prefix="" category="inline-code"></block></block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">Nachstehend finden Sie Einzelheiten zur Systemverbindung mit ONTAP. Geben Sie den Volume-Namen an, der bei der Installation von Trident generiert wurde. Die folgende Einstellung gilt für ein ONTAP Cluster vor Ort:</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Die folgende Einstellung gilt für Cloud Volumes ONTAP:</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">Basis-Docker-Images Erstellen</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">Alles, was Sie zum Aufbau einer ML-Pipeline benötigen, ist in der Iguazio-Plattform enthalten. Der Entwickler kann die Spezifikationen der Docker-Images festlegen, die für die Ausführung der Pipeline erforderlich sind, und die Image-Erstellung aus Jupyter Notebook ausführen. Öffnen Sie das Notebook<block ref="61dfd8901a62e0f1e23dd2f5029d2639" prefix=" " category="inline-code"></block> Und alle Zellen ausführen.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">Dieses Notizbuch erstellt zwei Bilder, die wir in der Pipeline verwenden.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text"><block ref="b636b23a5b442c01733e45c199c11f56" prefix="" category="inline-code"></block> Zum behandeln VON ML-Aufgaben.</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text"><block ref="c59e60c5a3880eb8018ae68eaa70621c" prefix="" category="inline-code"></block>. Enthält Dienstprogramme zur Bearbeitung von NetApp Snapshot Kopien.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Überprüfen Sie Einzelne Jupyter Notebooks</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">In der folgenden Tabelle sind die Bibliotheken und Frameworks aufgeführt, mit denen wir diese Aufgabe erstellt haben. All diese Komponenten wurden vollständig in die rollenbasierten Zugriffs- und Sicherheitskontrollen von Iguazio integriert.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">Bibliotheken/Framework</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Ein von Iguazio verwaltet, um die Montage, Ausführung und Überwachung einer ML/AI-Pipeline zu ermöglichen.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nuclio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Ein serverloses Funktionsgerüst, das mit Iguazio integriert ist. Auch als Open-Source-Projekt von Iguazio verfügbar.</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">Kubernetes-basiertes Framework für die Implementierung der Pipeline Dies ist auch ein Open-Source-Projekt, zu dem Iguazio beiträgt. Es ist in Iguazio integriert für zusätzliche Sicherheit und Integration in den Rest der Infrastruktur.</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Eine Docker-Registry wird als Service in der Iguazio-Plattform ausgeführt. Sie können dies auch ändern, um eine Verbindung zu Ihrer Registrierung herzustellen.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volumes</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">Cloud Volumes auf AWS ermöglichen uns Zugriff auf große Datenmengen und die Möglichkeit, Snapshot Kopien mit den für das Training verwendeten Datensätzen zu erstellen.</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident ist ein Open-Source-Projekt, das von NetApp gemanagt wird. Sie vereinfacht die Integration in Storage- und Computing-Ressourcen in Kubernetes.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">Für die Erstellung der ML-Pipeline haben wir mehrere Notebooks verwendet. Jedes Notebook kann einzeln getestet werden, bevor es in die Pipeline gebracht wird. Wir decken jedes Notebook individuell nach dem Bereitstellungsablauf dieser Demonstrationsanwendung ab.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">Das gewünschte Ergebnis ist eine Pipeline, mit der ein Modell auf Basis einer Snapshot-Kopie der Daten trainiert und das Modell zur Inferenz implementiert wird. Im folgenden Bild ist ein Blockdiagramm einer abgeschlossenen MLRun-Pipeline dargestellt.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">Implementierung Der Funktion Zur Datengenerierung</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">In diesem Abschnitt wird beschrieben, wie wir Nuclio serverlose Funktionen zur Generierung von Netzwerkgerätedaten verwendet haben. Der Anwendungsfall wird von einem Iguazio-Client aus angepasst, der die Pipeline implementierte und Iguazio-Services zur Überwachung und Vorhersage von Fehlern bei Netzwerkgeräten verwendete.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nuclio Website</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">Wir haben Daten von Netzwerkgeräten simuliert. Ausführen des Jupyter-Notebooks<block ref="c2d07e7698686359c0371f481d2cc628" prefix=" " category="inline-code"></block> Erstellt eine serverlose Funktion, die alle 10 Minuten läuft und eine Parkett-Datei mit neuen Daten erzeugt. Um die Funktion bereitzustellen, führen Sie alle Zellen in diesem Notebook aus. Siehe<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> Um unbekannte Komponenten in diesem Notebook zu überprüfen.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">Beim Generieren der Funktion wird eine Zelle mit dem folgenden Kommentar ignoriert. Jede Zelle im Notebook wird als Teil der Funktion angenommen. Importieren Sie das Nuclio-Modul, um es zu aktivieren<block ref="85b0176bddfe93e918b8de4cb894780c" prefix=" " category="inline-code"></block>.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">In der Spezifikation für die Funktion definieren wir die Umgebung, in der die Funktion ausgeführt wird, wie sie ausgelöst wird und welche Ressourcen sie verbraucht.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">Der<block ref="b73982aa3ac6ac19ba867eb2f5819797" prefix=" " category="inline-code"></block> Die Funktion wird beim Initialisieren der Funktion vom Nuclio Framework aufgerufen.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">Jeder Code, der nicht in einer Funktion enthalten ist, wird aufgerufen, wenn die Funktion initialisiert wird. Wenn Sie ihn aufrufen, wird eine Handler-Funktion ausgeführt. Sie können den Namen des Handlers ändern und in der Funktionungsspezifikation angeben.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">Sie können die Funktion vor der Bereitstellung vom Notebook aus testen.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">Die Funktion kann über das Notebook bereitgestellt oder über eine CI/CD-Pipeline (Anpassung dieses Codes) bereitgestellt werden.</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">Pipeline-Notebooks</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">Diese Notizbücher sollen für dieses Setup nicht einzeln ausgeführt werden. Dies ist nur ein Bericht über jedes Notizbuch. Wir haben sie als Teil der Pipeline aufgerufen. Um sie einzeln auszuführen, lesen Sie die MLRun Dokumentation durch, um sie als Kubernetes Jobs auszuführen.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">Snap_cv.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">Dieses Notebook wickelt die Snapshot-Kopien des Cloud Volumes am Anfang der Pipeline ab. Er übergibt den Namen des Volumes an den Pipeline-Kontext. Dieses Notebook stößt ein Shell-Skript an, um die Snapshot Kopie zu bearbeiten. Während der Ausführung in der Pipeline enthält der Ausführungskontext Variablen, um alle Dateien zu finden, die für die Ausführung benötigt werden. Beim Schreiben dieses Codes muss sich der Entwickler nicht um den Speicherort der Datei im Container kümmern, der ihn ausführt. Wie später beschrieben, wird diese Applikation mit allen Abhängigkeiten implementiert und ist die Definition der Pipeline-Parameter, die den Kontext der Ausführung liefern.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">Der Speicherort der erstellten Snapshot-Kopie wird im MLRun-Kontext platziert, der von Schritten in der Pipeline verwendet werden soll.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">Die nächsten drei Notebooks werden parallel ausgeführt.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">Data-prep.ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">RAW-Metriken müssen in Funktionen für das Modelltraining umgewandelt werden. Dieses Notebook liest die RAW-Kennzahlen aus dem Snapshot Verzeichnis und schreibt die Funktionen für das Modelltraining auf das NetApp Volume.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">Bei Ausführung im Kontext der Pipeline ist der Input<block ref="6ca3f4659530db0c27f67623bd27b304" prefix=" " category="inline-code"></block> Enthält den Speicherort der Snapshot Kopie.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">Beschreiben.ipynb</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">Um die eingehenden Kennzahlen zu visualisieren, stellen wir einen Pipeline-Schritt bereit, der über die Kubeflow und MLRun UIs verfügbare Plots und Diagramme bereitstellt. Jede Ausführung hat eine eigene Version dieses Visualisierungstools.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">Deploy-Feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">Wir überwachen kontinuierlich die Metriken, die nach Anomalien suchen. Dieses Notizbuch erstellt eine serverlose Funktion, die die Funktionen generiert, die für die Vorhersage von eingehenden Metriken erforderlich sind. Dieses Notizbuch ruft die Erstellung der Funktion auf. Der Funktionscode befindet sich im Notebook<block ref="ddc05946399cb9a8e617080738240288" prefix=" " category="inline-code"></block>. Beachten Sie, dass wir für diesen Zweck dasselbe Notebook wie einen Schritt in der Pipeline verwenden.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">Training.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">Nachdem wir die Funktionen erstellt haben, lösen wir das Modelltraining aus. Das Ergebnis dieses Schritts ist das Modell, das zur Inferenz verwendet wird. Wir sammeln auch Statistiken, um jede Ausführung (Experiment) im Auge zu behalten.</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">Beispielsweise gibt der folgende Befehl die Genauigkeitbewertung in den Kontext des entsprechenden Experiments ein. Dieser Wert ist in Kubeflow und MLRun sichtbar.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">Bereitstellen-Inferenz-Funktion.ipynb</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">Der letzte Schritt in der Pipeline ist die Implementierung des Modells als serverlose Funktion für kontinuierliche Inferenz. Dieses Notebook ruft die Erstellung der serverlosen Funktion auf, die in definiert ist<block ref="8484275272e5c25a4b20c092eaed5ed3" prefix=" " category="inline-code"></block>.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">Pipeline prüfen und aufbauen</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">Die Kombination der Ausführung aller Notebooks in einer Pipeline ermöglicht es, kontinuierlich Experimente durchzuführen, um die Genauigkeit des Modells anhand neuer Metriken neu zu bewerten. Öffnen Sie zuerst das<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> Notebook. Wir erläutern Ihnen die Details, die zeigen, wie NetApp und Iguazio die Implementierung dieser ML-Pipeline vereinfachen.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">Wir verwenden MLRun, um jedem Schritt der Pipeline Kontext bereitzustellen und die Ressourcenzuordnung zu bearbeiten. Der MLRun API-Service wird auf der Iguazio-Plattform ausgeführt und dient als Interaktionsstelle mit Kubernetes-Ressourcen. Jeder Entwickler kann keine Ressourcen direkt anfordern. Die API verarbeitet die Anforderungen und ermöglicht Zugriffskontrollen.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">Diese Pipeline kann mit NetApp Cloud Volumes und On-Premises-Volumes eingesetzt werden. Wir haben diese Demo für die Verwendung von Cloud Volumes erstellt. Im Code sehen Sie jedoch die Option zur Ausführung vor Ort.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">Die erste Aktion, die erforderlich ist, um ein Jupyter-Notebook in einen Kubeflow-Schritt zu verwandeln, ist, den Code in eine Funktion zu verwandeln. Eine Funktion verfügt über alle Spezifikationen, die zum Ausführen dieses Notebooks erforderlich sind. Wenn Sie das Notebook nach unten scrollen, sehen Sie, dass wir für jeden Schritt in der Pipeline eine Funktion definieren.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">Teil des Notebooks</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;Code_to_Function&gt; (Teil des MLRun-Moduls)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">Name der Funktion: Projektname. Dient zur Organisation aller Projektartefakte. Dies ist in der MLRun UI sichtbar. Freundlich. In diesem Fall ist Kubernetes-Job. Dies könnte DASK, mpi, funkk8s und mehr sein. Weitere Informationen finden Sie in der MLRun-Dokumentation. Datei: Der Name des Notebooks. Dies kann auch ein Speicherort in Git (HTTP) sein.</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">Der Name des Docker Images, das wir für diesen Schritt verwenden. Das haben wir früher mit dem Notebook create-image.ipynb erstellt.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">Volume_Mounts und Volumes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">Einzelheiten zum Mounten des NetApp Cloud Volume zur Laufzeit.</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">Außerdem definieren wir Parameter für die Schritte.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">Nachdem Sie die Funktionsdefinition für alle Schritte erstellt haben, können Sie die Pipeline erstellen. Wir verwenden den<block ref="98dd4155c9c8287a5a8e1d92417d0a99" prefix=" " category="inline-code"></block> Modul, um diese Definition zu erstellen. Der Unterschied zwischen der Verwendung von MLRun und dem Selbstaufbau besteht in der Vereinfachung und Verkürzung der Codierung.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">Die von uns definierten Funktionen werden mit dem in Schrittkomponenten umgewandelt<block ref="6cebb60f71d9de65143ade7a8388e27a" prefix=" " category="inline-code"></block> Funktion von MLRun.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">Definition Von Snapshot-Schritten</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Initiieren einer Snapshot-Funktion, -Ausgabe und Mounten von v3io als Quelle:</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parameter</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">NewTask</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">NewTask ist die Definition der Funktion Run.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(MLRun-Modul)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">Handler. Name der zu aufrufe Python-Funktion. Wir haben den Namen Handler im Notebook verwendet, aber er ist nicht erforderlich. Param. Die Parameter, die wir an die Ausführung übergeben haben. Innerhalb unseres Codes verwenden wir context.get_param (‘PARAMETER’), um die Werte zu erhalten.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">As_Step</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">Name: Name des Kubeflow-Pipeline-Schritts. Ausgänge. Dies sind die Werte, die der Schritt dem Wörterbuch nach Abschluss hinzugefügt hat. Werfen Sie einen Blick auf das Snap_cv.ipynb Notebook. Mount_v3io(). Hiermit wird der Schritt zum Mounten von /Benutzer für den Benutzer konfiguriert, der die Pipeline ausführt.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">Eingänge</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">Sie können die Ausgänge eines vorherigen Schritts an einen Schritt übergeben. In diesem Fall ist Snap.Outputs ['snapVolumeDetails'] der Name der Snapshot Kopie, die wir im Snap Schritt erstellt haben.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">Out_PATH</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">Ein Speicherort für Artefakte, die mithilfe des MLRun-Moduls log_Artefakte erzeugt werden.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">Sie können laufen<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> Von oben nach unten. Anschließend können Sie im Iguazio-Dashboard zur Registerkarte Pipelines wechseln, um den Fortschritt zu überwachen, wie auf der Registerkarte Iguazio-Dashboard-Pipelines zu sehen ist.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">Da wir die Genauigkeit des Trainingsschritts in jedem Lauf protokolliert haben, haben wir für jedes Experiment eine Aufzeichnung der Genauigkeit, wie in der Aufzeichnung der Trainingsgenauigkeit zu sehen ist.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Wenn Sie den Schritt Snapshot auswählen, wird der Name der Snapshot Kopie angezeigt, die zur Ausführung dieses Experiments verwendet wurde.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">Der beschriebene Schritt hat visuelle Artefakte, um die von uns verwendeten Metriken zu untersuchen. Sie können erweitern, um die vollständige Darstellung wie im folgenden Bild zu sehen.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">Die MLRun API-Datenbank verfolgt auch Eingänge, Ausgänge und Artefakte für jeden nach Projekt organisierten Durchlauf. Ein Beispiel für Eingänge, Ausgänge und Artefakte für jeden Durchlauf ist im folgenden Bild zu sehen.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">Für jede Aufgabe werden zusätzliche Details gespeichert.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub-Website</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">Es gibt mehr Informationen über MLRun, als wir in diesem Dokument abdecken können. Al Artefakte, einschließlich der Definition der Schritte und Funktionen, können in der API-Datenbank gespeichert, versioniert und einzeln oder als volles Projekt aufgerufen werden. Projekte können auch gespeichert und zur späteren Verwendung an Git geschoben werden. Wir empfehlen Ihnen, weitere Informationen im zu erhalten<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">Als Nächstes: Deploy Grafana Dashboard</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">Auf dieser Seite wird die Einrichtung von „Dask with RAPIDS“-Einsatz auf AKS mit Helm beschrieben.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Einrichten von „Dask with RAPIDS Deployment“ auf AKS mit Helm</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">Früher: Trident Installieren.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Gehen Sie wie folgt vor, um die Implementierung von „Dask with RAPIDS“ auf AKS mit Helm einzurichten:</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Erstellen Sie einen Namespace für die Installation von DASK mit RAPIDS.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">Erstellen Sie ein PVC, um den Click-Through-Rate-Datensatz zu speichern:</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">Speichern Sie den folgenden YAML-Inhalt in einer Datei, um ein PVC zu erstellen.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Wenden Sie die YAML-Datei auf Ihr Kubernetes-Cluster an.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">Klonen Sie die<block ref="d126903117bcd329e601af7057853376" prefix=" " category="inline-code"></block> Repository (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>).</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">Ändern<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Und schließen Sie die PVC ein, die früher für Arbeiter und Jupyter-Workspace erstellt wurde.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">Wechseln Sie zum<block ref="47e38535ab0a13ca65c9bba04c686040" prefix=" " category="inline-code"></block> Verzeichnis des Repository.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Aktualisieren Sie die<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Datei und Mounten des Volumes mit PVC.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">Gehen Sie zum Home-Verzeichnis des Projektarchivs und stellen Sie Dask mit drei Worker-Knoten auf AKS mit Helm bereit.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">Weiter: Azure NetApp Files-Performance-Tiers.</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">Aktueller Stand der Technik, vortrainierte Modellierungs-Tools, die von NVIDIA, AWS, Google und anderen veröffentlicht werden, lässt sich nun eine End-to-End-Pipeline mit komplexen Modellen aufbauen und relativ einfach anpassen.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="doc">Anwendungsfälle</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">Früher: Support Center-Analysen.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">Aufgrund der Anzahl der Anrufe, die diese Support-Center bearbeiten, kann die Beurteilung der Anrufleistung bei manueller Durchführung viel Zeit in Anspruch nehmen. Traditionelle Methoden wie das Zählen von Bag-of-Words und andere Methoden können einige Automatisierung erreichen, aber diese Methoden erfassen nicht mehr differenzierte Aspekte und semantischen Kontext der dynamischen Sprache. Mithilfe von KI-Modellierungstechniken können einige dieser differenzierteren Analysen automatisiert durchgeführt werden. Angesichts des aktuellen Stand der Technik, von vortrainierten Modellierungs-Tools, die von NVIDIA, AWS, Google und anderen veröffentlicht werden, lässt sich zudem eine End-to-End-Pipeline mit komplexen Modellen aufbauen und relativ einfach anpassen.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">Eine End-to-End-Pipeline für die Sentimentanalyse des Support Centers speist Audiodateien in Echtzeit ein, während die Mitarbeiter mit Anrufern kommunizieren. Anschließend werden diese Audiodateien für die Verwendung in der sprach-zu-Text-Komponente verarbeitet, die sie in ein Textformat konvertiert. Jeder Satz im Gespräch erhält ein Etikett, das die Stimmung anzeigt (positiv, negativ oder neutral).</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">Die Sentimentanalyse kann einen wesentlichen Aspekt der Gespräche zur Beurteilung der Call-Performance liefern. Diese Gefühle verleihen den Interaktionen zwischen Mitarbeitern und Anrufern eine zusätzliche Tiefe. Das KI-gestützte Sentiment Dashboard bietet Führungskräften eine Echtzeit-Nachverfolgung der Stimmung innerhalb eines Gesprächs sowie eine rückblickende Analyse der vergangenen Anrufe des Mitarbeiters.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">Es gibt vordefinierte Tools, die auf leistungsstarke Weise kombiniert werden können, um schnell eine End-to-End-KI-Pipeline für die Lösung dieses Problems zu erstellen. In diesem Fall kann die NVIDIA RIVA-Bibliothek verwendet werden, um die beiden in-Serie-Aufgaben durchzuführen: Audio-Transkription und Sentiment-Analyse. Der erste ist ein überwachtes Lernsignal-Processing-Algorithmus und der zweite ist ein überwachtes Lernen-NLP-Klassifizierungsalgorithmus. Diese Out-of-the-Box-Algorithmen können über das NVIDIA TAO Toolkit für jeden relevanten Anwendungsfall mit geschäftlichen Daten optimiert werden. Die Folge sind präzisere und leistungsfähigere Lösungen, die nur zu einem Bruchteil der Kosten und der Ressourcen entwickelt werden. Kunden können die einbinden<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> Framework für GPU-beschleunigte Videokonferenzanwendungen in ihrem Support Center-Design.</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">Die folgenden Anwendungsfälle bilden den Kern dieser Lösung. Beide Anwendungsfälle verwenden das TAO Toolkit für die Modelloptimierung und RIVA für die Modellbereitstellung.</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="list-text">Sprache-zu-Text</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">Sentimentanalyse</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">Um die Interaktion zwischen Mitarbeitern und Kunden im Support Center zu analysieren, kann jedes Kundengespräch in Form von Audio-Anrufen über die Pipeline geführt werden, um Sentenebenen zu gewinnen. Diese Gefühle können dann von einem Menschen bestätigt werden, um die Gefühle zu rechtfertigen oder sie nach Bedarf anzupassen. Die markierten Daten werden dann an den Feinabstimmung-Schritt zur Verbesserung der Sentimentprognosen weitergeleitet. Falls bereits gekennzeichnete Stimmungsdaten vorliegen, kann eine Modelloptimierung beschleunigt werden. In beiden Fällen ist die Pipeline zu anderen Lösungen generierbar, die die Aufnahme von Audio und die Klassifizierung von Sätzen erfordern.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">Die Ausgaben für die KI-Einschätzung werden entweder in eine externe Cloud-Datenbank oder in ein vom Unternehmen gemanagtes Storage-System hochgeladen. Die Sentiment-Ergebnisse werden aus dieser größeren Datenbank in den lokalen Speicher übertragen, der zur Nutzung innerhalb des Dashboards zur Anzeige der Sentimentanalyse für Manager verwendet wird. Die primäre Funktionalität des Dashboards ist die Schnittstelle mit dem Kundendienstmitarbeiter in Echtzeit. Manager können die Mitarbeiter während ihrer Anrufe anhand von Live-Updates der Stimmung jedes Satzes bewerten und Feedback geben sowie eine historische Überprüfung der bisherigen Performance oder Kundenreaktionen des Mitarbeiters durchführen.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">Der <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Auch nach der RIVA Inferenzpipeline können die Storage-Systeme weiterhin gemanagt werden, um Sentiment-Labels zu generieren. Diese KI-Ergebnisse können auf ein Datenspeichersystem hochgeladen werden, das vom NetApp DataOps Toolkit verwaltet wird. Die Storage-Systeme müssen Hunderte von Inserts managen können und jede Minute auswählt. Das lokale Gerätelagersystem fragt den größeren Datenspeicher in Echtzeit zur Extraktion ab. Auch größere Storage-Instanzen können nach Archivdaten abgefragt werden, um das Dashboard noch effizienter zu gestalten. Das NetApp DataOps Toolkit fördert beide Nutzungszwecke durch schnelles Klonen von Daten und Verteilung über alle Konsolen, die die Daten nutzen.</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">Mitarbeitermanager</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">Data Engineers/Data Scientists</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT-Administratoren (lokal, in der Cloud oder Hybrid)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">Das Nachverfolgen von Empfindungen im Gespräch ist ein wertvolles Werkzeug zur Beurteilung der Mitarbeiterleistung. Über das KI-Dashboard können Manager sehen, wie Mitarbeiter und Anrufer ihre Gefühle in Echtzeit verändern und so Live-Bewertungen und Ratensitzungen ermöglichen. Darüber hinaus erhalten Unternehmen wertvolle Einblicke aus Kunden, die sich mit vokalen Gesprächen, Text-Chatbots und Videokonferenzen befassen. Bei derartigen Kundenanalysen kommen moderne, hochmoderne KI-Modelle und Workflows zum Einsatz, da die multimodale Verarbeitung nach Maß erfolgt.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">Auf der Datenseite wird täglich eine große Anzahl von Audiodateien vom Support Center verarbeitet. Das NetApp DataOps Toolkit erleichtert diese Datenhandhabung sowohl bei der regelmäßigen Optimierung der Modelle als auch bei den Dashboards für die Sentiment-Analyse.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT-Administratoren profitieren außerdem vom NetApp DataOps Toolkit, da es ihnen ermöglicht, Daten schnell zwischen Implementierungs- und Produktionsumgebungen zu verschieben. Außerdem müssen die NVIDIA-Umgebungen und -Server gemanagt und verteilt werden, um Echtzeitinformationen zu ermöglichen.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Cnvrg.io (<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>):</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">Cnvrg-KERN (kostenlose ML-Plattform)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Cnvrg Dokumentation</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1-Server:</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1-Server</block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor Core GPU</block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF Systeme:</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">NetApp FlashAdvantage für AFF</block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp Interoperabilitäts-Matrix:</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp Interoperabilitäts-Matrix-Tool</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP KI-Netzwerk:</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Switches der Cisco Nexus 3232C-Serie</block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Switches der Mellanox Spectrum 2000-Serie</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">DALI</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow: Ein Open-Source Machine Learning Framework für alle</block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod: Ubers Open-Source Distributed Deep Learning Framework for TensorFlow</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">NVIDIA-Blog: Enabling GPUs in the Container Runtime Ecosystem</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">Datensatz und Benchmarks:</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">Röntgendatensatz der NIH Thoraxröntgenaufnahme</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald Summers, ChestX-ray8: Thorax-Röntgendatenbank im Krankenhausmaßstab und Benchmarks auf schwach überwachte Klassifizierung und Lokalisierung allgemeiner Thorax-Erkrankungen, IEEE CVPR, S. 3462-3471, 2017TR-4841-0620</block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">Nutzen Sie nach der Implementierung alles Rückschlüsse auf neue Daten. Die Modelle prognostizieren, ob ein Benutzer basierend auf Browsing-Aktivitäten auf eine Anzeige klickt. Die Ergebnisse der Vorhersage werden in einem Damask cuDF gespeichert. Sie können die Ergebnisse mit Prometheus überwachen und in Grafana Dashboards visualisieren.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Überwachen Sie „Dask and RAPIDS“ mit Prometheus und Grafana</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">Früher: Vergleich der Trainingszeit.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS AI Medium Post</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">Weitere Informationen finden Sie unter<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">Als Nächstes: Datensatz- und Modellversionierung mithilfe des NetApp DataOps Toolkit.</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="03077b9327bcb8fdf3f360d27c4dd2a6" category="doc">NVA-1153-DEPLOY: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet Switches</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153-DEPLOY enthält Anleitungen zur Implementierung eines Storage-Systems für eine NetApp Verified Architecture für Machine Learning (ML) und KI-Workloads (künstliche Intelligenz) mit NetApp AFF A800 Storage-Systemen, NVIDIA DGX A100-Systemen und NVIDIA Mellanox Spectrum SN3700V 200-GB-Ethernet-Switches. Außerdem enthält es Anweisungen zur Ausführung von Validierungs-Benchmark-Tests nach Abschluss der Implementierung.</block>
  <block id="c24b711a1468d82d0ec120ccf0fe60e8" category="inline-link-macro"><block ref="c24b711a1468d82d0ec120ccf0fe60e8" category="inline-link-rx"></block></block>
  <block id="fa7cdfafd1276f51fd3285f61a6c4aec" category="paragraph"><block ref="fa7cdfafd1276f51fd3285f61a6c4aec" category="inline-link-macro-rx"></block></block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">Dieses Whitepaper bietet Richtlinien für Kunden, die konvergente künstliche Intelligenz (KI) mit dem NVIDIA Jarvis Framework und NetApp ONTAP AI und Cloud Sync für Einzelhändler und andere Anwendungsfälle erstellen. Sie enthält Informationen zu den grundlegenden Workflows, die bei der Entwicklung von NLP-Modellen (Natural Language Processing) für virtuelle Assistenten, validierte Testfälle und Ergebnisse verwendet werden.</block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">Auf dieser Seite sind die Softwareanforderungen aufgeführt, die für diese Lösung erforderlich sind.</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">In der folgenden Tabelle sind die Softwareanforderungen für diese Lösung aufgeführt.</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">Container-Image VON RAPIDS und Dask</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">Projektarchiv: "Rapidsai/rapidsai" Tag: 0.17-cuda11.0-Runtime-ubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">Der nächste: Anforderungen an die Cloud-Ressourcen.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">Dieser technische Bericht bietet Orientierungshilfen für Kunden, um eine Sentimentanalyse in einem globalen Support Center der Enterprise-Klasse durchzuführen. Dazu werden Datenmanagement-Technologien von NetApp mit einem NVIDIA Software-Framework genutzt, wobei Transfer-Learning und umgangssprachlich KI verwendet werden.</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910: Sentiment Analysis from Customer Communications with NetApp AI</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Sathish Thyagarajan und David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">Dieser technische Bericht bietet Orientierungshilfen für Kunden, um eine Sentimentanalyse in einem globalen Support Center der Enterprise-Klasse durchzuführen. Dazu werden Datenmanagement-Technologien von NetApp mit einem NVIDIA Software-Framework genutzt, wobei Transfer-Learning und umgangssprachlich KI verwendet werden. Diese Lösung ist für alle Branchen geeignet, die aus aufgezeichneten sprach- oder Textdateien, die Chat-Protokolle, E-Mails und andere Text- oder Audiokommunikation darstellen, Kundeneinblicke gewinnen möchten. Wir implementierten eine End-to-End-Pipeline, um die automatische Spracherkennung, Sentimentanalyse in Echtzeit und das Deep-Learning-Modell mit natürlicher Sprache zu demonstrieren – Umschulungsfunktionen auf einem GPU-beschleunigten Computing-Cluster mit NetApp All-Flash-Storage mit Cloud-Integration. Mit dem globalen Support Center können riesige, hochmoderne Sprachmodelle trainiert und optimiert werden, um Inferenz schnell durchzuführen. Das System bietet eine außergewöhnlich hohe Kundenzufriedenheit, und eine objektive, langfristige Beurteilung der Mitarbeiterleistung.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">Sentimentanalyse ist ein Studienfeld innerhalb der natürlichen Sprachverarbeitung (NLP), durch das positive, negative oder neutrale Gefühle aus dem Text extrahiert werden. Konvergente KI-Systeme sind auf eine nahezu globale Ebene der Integration angestiegen, da immer mehr Menschen mit ihnen interagieren. Sentiment-Analyse hat eine Vielzahl von Anwendungsbeispielen: Von der Ermittlung der Mitarbeiterleistung im Support-Center in Gesprächen mit Anrufern und der Bereitstellung geeigneter automatischer Chatbot-Antworten bis zur Prognose des Aktienpreises eines Unternehmens auf der Grundlage der Wechselwirkungen zwischen den Vertretern des Unternehmens und den Zuschauern bei vierteljährlichen Ergebnisgesprächen. Darüber hinaus kann die Sentiment-Analyse verwendet werden, um die Meinung des Kunden über die Produkte, Dienstleistungen oder Unterstützung der Marke zu bestimmen.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">Diese End-to-End-Lösung verwendet NLP-Modelle, um eine hochrangige Sentimentanalyse durchzuführen, die analytische Frameworks für Support-Center ermöglicht. Audioaufzeichnungen werden in geschriebenen Text verarbeitet, und die Stimmung wird aus jedem Satz im Gespräch extrahiert. Ergebnisse, die in einem Dashboard zusammengefasst werden, können so erstellt werden, dass Gesprächsgefühlen sowohl historisch als auch in Echtzeit analysiert werden können. Diese Lösung kann mit anderen Lösungen mit ähnlichen Datenmodalitäten und Ausgabeanforderungen verallgemeinert werden. Mit den entsprechenden Daten können andere Anwendungsfälle durchgeführt werden. So können beispielsweise die Ergebnisaufrufe des Unternehmens anhand derselben End-to-End-Pipeline auf die Stimmung analysiert werden. Auch andere Formen von NLP-Analysen, wie zum Beispiel Topic Modeling und Named Entity Recognition (NER), sind aufgrund der flexiblen Natur der Pipeline möglich.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">Diese KI-Implementierungen wurden von NVIDIA RIVA, dem NVIDIA TAO Toolkit und dem gemeinsam arbeiteten NetApp DataOps Toolkit ermöglicht. Die NVIDIA Tools werden verwendet, um hoch performante KI-Lösungen mithilfe von vordefinierten Modellen und Pipelines schnell zu implementieren. Das NetApp DataOps Toolkit vereinfacht verschiedene Datenmanagement-Aufgaben und beschleunigt so die Entwicklung.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">Mehrwert für den Kunden</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">Unternehmen sehen den Nutzen einer Mitarbeiterbewertung und eines Tools zur Reaktion auf Kundenverhalten bei Text-, Audio- und Videogesprächen für die Sentimentanalyse. Manager profitieren von den Informationen, die in der Konsole dargestellt werden, und können so auf beiden Seiten des Gesprächs eine Bewertung der Mitarbeiter und die Kundenzufriedenheit durchführen.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">Darüber hinaus managt das NetApp DataOps Toolkit die Versionierung und Zuweisung von Daten innerhalb der Infrastruktur des Kunden. Dies führt zu häufigen Updates der im Dashboard verfügbaren Analysen, ohne dass dabei unhandliche Storage-Kosten entstehen.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">Weiter: Anwendungsfälle.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Dieses Dokument beschreibt eine Computing- und Storage-Architektur, um GPU-basierte Inferenz (KI) auf NetApp Storage-Controllern und Lenovo ThinkSystem Servern in einer Edge-Umgebung zu implementieren, die auf neue Applikationsszenarien zugeschnitten ist.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: KI-Inferenzierung am Edge - NetApp mit Lenovo ThinkSystem - Solution Design</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Einführung</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">Unternehmen generieren immer mehr riesige Datenmengen am Netzwerkrand. Um Smart-Sensoren und IoT-Daten optimal zu nutzen, suchen Unternehmen eine Echtzeit-Ereignis-Streaming-Lösung, die Edge-Computing ermöglicht. Rechenanspruchsvolle Jobs werden daher zunehmend außerhalb des Datacenters am Edge ausgeführt. KI-Inferenz ist einer der Faktoren für diesen Trend. Edge-Server liefern für diese Workloads genügend Rechenleistung, insbesondere wenn Beschleuniger zum Einsatz kommen. Doch häufig stellt begrenzter Storage ein Problem dar, insbesondere in Umgebungen mit mehreren Servern. In diesem Dokument zeigen wir, wie ein Shared-Storage-System in der Edge-Umgebung implementiert werden kann und wie es von KI-Inferenz-Workloads profitiert, ohne dass sich die Performance beeinträchtigt.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">In diesem Dokument wird eine Referenzarchitektur für KI-Inferenz im Edge-Bereich beschrieben. Es kombiniert mehrere Lenovo ThinkSystem Edge Server mit einem NetApp Storage-System zu einer Lösung, die einfach zu implementieren und zu managen ist. Es soll als Basishandbuch für den praktischen Einsatz in verschiedenen Situationen dienen, wie zum Beispiel der Fabrikhalle mit mehreren Kameras und industriellen Sensoren, Point-of-Sale-Systeme (POS) im Einzelhandel oder Full Self-Driving (FSD)-Systeme, die visuelle Anomalien in autonomen Fahrzeugen identifizieren.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Dieses Dokument behandelt Tests und Validierungen einer Computing- und Storage-Konfiguration, die aus Lenovo ThinkSystem SE350 Edge Server sowie einem Storage-System der Einstiegsklasse von NetApp AFF und EF-Series besteht. Die Referenzarchitekturen sind eine effiziente und kostengünstige Lösung für KI-Implementierungen. Gleichzeitig bieten sie umfassende Datenservices, integrierte Datensicherung, nahtlose Skalierbarkeit und Cloud-vernetzten Storage mit NetApp ONTAP und der Datenmanagement-Software NetApp SANtricity.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Dieses Dokument richtet sich an folgende Zielgruppen:</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Führungskräfte und Enterprise-Architekten, die KI im Edge-Bereich productieren möchten</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Data Scientists, Data Engineers, KI/Machine Learning-Forscher (ML) und Entwickler von KI-Systemen.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Enterprise-Architekten, die Lösungen für die Entwicklung von KI/ML-Modellen und -Applikationen entwickeln</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Data Scientists und KI-Ingenieure, die nach effizienten Möglichkeiten suchen, Deep-Learning- (DL) und ML-Modelle zu implementieren.</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Dieser Lenovo ThinkSystem Server und die NetApp ONTAP oder NetApp SANtricity Storage-Lösung wurden entwickelt, um KI-Inferenz auf großen Datensätzen zu verarbeiten. Dabei wird die Verarbeitungsleistung von GPUs neben herkömmlichen CPUs verwendet. Diese Validierung belegt eine hohe Performance und ein optimales Datenmanagement mit einer Architektur, die entweder einzelne oder mehrere Lenovo SR350 Edge-Server verwendet, die mit einem einzelnen NetApp AFF-Storage-System verbunden sind, wie in den folgenden beiden Abbildungen dargestellt.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">Die logische Architekturübersicht in der folgenden Abbildung zeigt die Rollen der Computing- und Storage-Elemente in dieser Architektur. Sie zeigt im Detail Folgendes:</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Edge-Computing-Geräte führen Inferenz für die Daten durch, die von Kameras, Sensoren usw. empfangen werden.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Ein Shared-Storage-Element, das mehrere Zwecke erfüllt:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Ermöglicht den Inferenz-Modelle und andere Daten, die zu Vorgänge erforderlich sind. Compute-Server greifen direkt auf den Storage zu und nutzen Inferenzmodelle im gesamten Netzwerk, ohne dass diese lokal kopiert werden müssen.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Aktualisierte Modelle werden hier geschoben.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archivierung von Eingabedaten, die Edge-Server für eine spätere Analyse erhalten Wenn beispielsweise die Edge-Geräte an Kameras angeschlossen sind, speichert das Speicherelement die von den Kameras erfassten Videos.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">Rot</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">Blau</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo Computing-System</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF Storage-System</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Edge-Geräte, die Inferenz auf Eingänge von Kameras, Sensoren usw. durchführen.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Inferenzmodelle und Daten von Edge-Geräten für Shared Storage werden zur späteren Analyse gespeichert.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Diese Lösung von NetApp und Lenovo bietet folgende wichtige Vorteile:</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">GPU-beschleunigtes Computing im Edge-Bereich.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Implementierung mehrerer Edge-Server, unterstützt und über einen Shared Storage gemanagt</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Robuste Datensicherung zur Einhaltung niedriger Recovery-Zeitpunkte (RPOs) und Recovery-Zeiten (RTOs) ohne Datenverluste</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Optimiertes Datenmanagement mit NetApp Snapshot Kopien und Klonen zur Optimierung von Entwicklungs-Workflows</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Wie diese Architektur zu nutzen</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Dieses Dokument validiert das Design und die Performance der vorgeschlagenen Architektur. Bestimmte Software-Level-Komponenten wie Container-, Workload- oder Modellmanagement und Datensynchronisation mit On-Premises-Cloud- oder Datacentern haben wir jedoch noch nicht getestet, da sie für ein Implementierungsszenario spezifisch sind. Hier gibt es mehrere Möglichkeiten.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">Auf der Ebene der Containerverwaltung ist die Kubernetes-Containerverwaltung eine gute Wahl und wird sowohl in einer vollwertigen Version (Canonical) als auch in einer modifizierten Version unterstützt, die für Enterprise-Bereitstellungen (Red hat) geeignet ist. Der <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> Welches NetApp Trident und die neu hinzugefügte nutzt<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> Bietet integrierte Rückverfolgbarkeit, Datenmanagementfunktionen, Schnittstellen und Tools für Data Scientists und Data Engineers zur Integration in NetApp Storage. Kubeflow, das ML-Toolkit für Kubernetes, bietet zusätzliche KI-Funktionen sowie Unterstützung für Modellversionierung und KFServing auf mehreren Plattformen wie TensorFlow Serving oder NVIDIA Triton Inferenz Server. Eine weitere Option ist die NVIDIA EGX Plattform, die Workload-Management zusammen mit Zugriff auf einen Katalog von GPU-fähigen KI-Inferenz-Containern ermöglicht. Für diese Optionen ist jedoch unter Umständen ein erheblicher Aufwand und große Fachkenntnisse für die Produktion erforderlich, wobei unter Umständen die Unterstützung eines unabhängigen Softwareanbieters (ISV) oder eines Beraters durch Drittanbieter erforderlich ist.</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Der Hauptvorteil von KI-Inferenz und Edge-Computing ist die Möglichkeit von Geräten, Daten zu berechnen, zu verarbeiten und zu analysieren – ohne Latenz. Es gibt viel zu viele Beispiele für Edge-Computing-Anwendungsfälle, die in diesem Dokument beschrieben werden. Es gibt jedoch einige prominente Beispiele:</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobile: Autonome Fahrzeuge</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">Die klassische Edge Computing-Abbildung zeigt sich in den fortschrittlichen Fahrerassistenzsystemen (ADAS) in autonomen Fahrzeugen (AV). Die KI in selbstfahrenden Autos muss schnell viele Daten von Kameras und Sensoren verarbeiten, um ein erfolgreicher und sicherer Treiber zu sein. Es dauert zu lange, zwischen einem Objekt und einem Menschen zu interpretieren, kann Leben oder Tod bedeuten, daher ist es entscheidend, dass Daten so nah wie möglich am Fahrzeug verarbeitet werden können. In diesem Fall übernimmt ein oder mehrere Edge-Computing-Server die Eingaben von Kameras, RADAR, LiDAR und anderen Sensoren, während Shared Storage Inferenzmodelle enthält und die Eingangsdaten von Sensoren speichert.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Gesundheitswesen: Patientenüberwachung</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">Einer der größten Auswirkungen von KI und Edge-Computing ist die Fähigkeit, die kontinuierliche Überwachung von Patienten auf chronische Krankheiten zu verbessern, und zwar sowohl in der häuslichen Pflege als auch in Intensivstationen. Daten von Edge-Geräten, die Insulinspiegel, Atmung, neurologische Aktivität, Herzrhythmus und gastrointestinale Funktionen überwachen, erfordern eine sofortige Analyse von Daten, die sofort gehandelt werden müssen, weil es begrenzte Zeit zum Handeln gibt, um das Leben eines Menschen zu retten.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Einzelhandel: Kassierer-lose Zahlung</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">Edge-Computing unterstützt KI und ML und hilft Einzelhändlern dabei, die Kasse zu verkürzen und den Platzbedarf zu steigern. Kassierer-lose Systeme unterstützen verschiedene Komponenten, wie z. B.:</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Und -Zugriff. Verbinden des physischen Käuferkontos mit einem validierten Konto und Zulassen des Zugangs zu den Einzelhandelsflächen.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Bestandsüberwachung: Mithilfe von Sensoren, RFID-Tags und Computer-Vision-Systemen können Sie die Auswahl oder das Abwählen von Artikeln durch Kunden bestätigen.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Hier sind alle Edge-Server für jeden Kassenzähler zuständig, und das gemeinsam genutzte Speichersystem dient als zentraler Synchronisationspunkt.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Finanzdienstleistungen: Menschliche Sicherheit an Kiosken und Betrugsprävention</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Bankwesen setzen KI und Edge-Computing ein, um Innovationen voranzutreiben und ein personalisiertes Banking zu ermöglichen. Mithilfe von interaktiven Kiosks, die Datenanalysen in Echtzeit und KI-Inferenz ermöglichen, sind Geldautomaten nun nicht nur in der Lage, Geld zu ziehen, sondern überwachen Kiosksysteme proaktiv über die von Kameras erfassten Bilder, um Risiken für die menschliche Sicherheit oder das betrügerische Verhalten zu erkennen. In diesem Szenario sind Edge-Computing-Server und Shared-Storage-Systeme mit interaktiven Kiosken und Kameras verbunden. So können Banken Daten mit KI-Inferenzmodellen erfassen und verarbeiten.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Fertigung: Industrie 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">Die vierte industrielle Revolution (Industrie 4.0) hat begonnen, zusammen mit neuen Trends wie Smart Factory und 3D-Druck. Für die Vorbereitung auf eine datengesteuerte Zukunft werden umfassende Kommunikation zwischen Machine und Machine (M2M) und IoT integriert, um die Automatisierung zu steigern, ohne menschliches Eingreifen erforderlich zu sein. Die Fertigung ist bereits hochautomatisiert und das Hinzufügen von KI-Funktionen stellt eine natürliche Fortsetzung des langfristigen Trends dar. KI ermöglicht automatische Vorgänge, die mit Hilfe der Computervision und anderer KI-Funktionen automatisiert werden können. Sie können die Qualitätskontrolle oder Aufgaben automatisieren, die auf menschliche Vision oder Entscheidungsfindung beruhen, um schnellere Analysen von Materialien auf Montagelinien in Fabrikböden durchzuführen, um Fertigungsstätten dabei zu unterstützen, die geforderten ISO-Standards des Sicherheits- und Qualitätsmanagements zu erfüllen. Jeder Compute-Edge-Server ist hier mit einer Reihe von Sensoren verbunden, die den Fertigungsprozess überwachen und nach Bedarf aktualisierte Inferenzmodelle in den Shared Storage verschieben.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Telekommunikation: Rosterkennung, Turmüberwachung und Netzwerkoptimierung</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">Die Telekommunikationsbranche nutzt Computer Vision und KI-Techniken, um Bilder zu verarbeiten, die automatisch Rost erkennen und Zelltürme identifizieren, die Korrosion enthalten, und daher weitere Inspektionen erfordern. Die Verwendung von Drohnenbildern und KI-Modellen zur Identifizierung verschiedener Bereiche eines Turms zur Analyse von Rost, Oberflächenrissen und Korrosion hat in den letzten Jahren zugenommen. Die Nachfrage nach KI-Technologien wächst weiter, mit denen Telekommunikationsinfrastruktur und Zelltürme effizient untersucht, regelmäßig auf Abbaumaßnahmen bewertet und bei Bedarf zeitnah repariert werden können.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">Ein weiterer neuer Anwendungsfall in der Telekommunikation ist der Einsatz von KI- und ML-Algorithmen zur Vorhersage von Datenverkehrsmustern, zum Erkennen von 5G-fähigen Geräten sowie zur Automatisierung und Erweiterung des Energiemanagements bei mehreren Eingängen und Mehrfachausgängen (MIMO). MIMO-Hardware wird in Funktürmen verwendet, um die Netzwerkkapazität zu erhöhen; dies ist jedoch mit zusätzlichen Energiekosten verbunden. ML-Modelle für den „MIMO-Schlafmodus“, der an Zellstandorten eingesetzt wird, können die effiziente Nutzung von Funkgeräten vorhersagen und dazu beitragen, die Energiekosten für Mobilfunknetzbetreiber (MNOs) zu senken. Mithilfe von KI-Inferenz- und Edge-Computing-Lösungen können MNOs die Menge der zu Datacentern übertragenen Daten reduzieren, ihre TCO senken, den Netzwerkbetrieb optimieren und die allgemeine Performance für Endbenutzer verbessern.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841: Hybrides Cloud-KI-Betriebssystem mit Daten-Caching</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">Das explosionsartige Datenwachstum und das exponentielle Wachstum VON ML und KI haben sich konvergiert, um eine Zettabyte-Wirtschaft mit einzigartigen Herausforderungen bei Entwicklung und Implementierung zu schaffen.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">Es ist zwar allgemein bekannt, dass ML-Modelle datenintensiv sind und in Bezug auf Computing-Ressourcen hochperformanten Storage benötigen. In der Praxis ist es jedoch nicht ganz einfach, dieses Modell zu implementieren, insbesondere bei Hybrid Cloud- und elastischen Computing-Instanzen. In der Regel werden enorme Datenmengen in kostengünstigen Data Lakes gespeichert, auf denen hochperformante KI-Computing-Ressourcen wie GPUs nicht effizient zugreifen können. In einer Hybrid-Cloud-Infrastruktur, in der einige Workloads in der Cloud ausgeführt werden und einige sich vor Ort oder in einer anderen HPC-Umgebung vollständig befinden, wird dieses Problem verschärft.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">In diesem Dokument stellen wir eine neue Lösung vor, mit der IT-Experten und Data Engineers eine echte Hybrid-Cloud-KI-Plattform erstellen können. Diese Plattform bietet einen Topologiefähigen Daten-Hub, mit dem Datenanalysten sofort und automatisch einen Cache ihrer Datensätze in der Nähe ihrer Computing-Ressourcen erstellen können. Wo immer sie sich befinden. Somit kann nicht nur das Training eines hochperformanten Modells durchgeführt werden, sondern es werden auch zusätzliche Vorteile erzielt, etwa die Zusammenarbeit mehrerer KI-Fachleute, die innerhalb eines Dataset-Version-Hubs sofortigen Zugriff auf Datensatz-Caches, -Versionen und -Lineages haben.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">Weiter: Übersicht über Anwendungsfälle und Problembeschreibung</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">Die in diesem technischen Bericht vorgeschlagene Lösung wurde demonstriert, um die Bereitstellung eines so herausragenden Kundenerlebens zu unterstützen. Nun besteht die Herausforderung darin, dass Unternehmen Maßnahmen ergreifen, um ihre KI-Infrastruktur und -Workflows zu modernisieren.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Früher: Videos und Demos.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">Da die Kundenerfahrung immer mehr als ein wichtiger umkämpften Markt gilt, wird ein globales Support-Center mit KI-Unterstützung zu einem entscheidenden Faktor, den Unternehmen aus fast allen Branchen nicht vernachlässigen können. Die in diesem technischen Bericht vorgeschlagene Lösung wurde demonstriert, um die Bereitstellung eines so herausragenden Kundenerlebens zu unterstützen. Nun besteht die Herausforderung darin, dass Unternehmen Maßnahmen ergreifen, um ihre KI-Infrastruktur und -Workflows zu modernisieren.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">Die besten Implementierungen von KI im Kundenservice sollen menschliche Agenten nicht ersetzen. Stattdessen kann KI sie in die Lage versetzt werden, außergewöhnliche Kundenerlebnisse durch Stimmungsanalysen in Echtzeit, Streitschlichtung und multimodales affektives Computing zu schaffen, um verbale, nonverbale und gesichtsreiche Hinweise zu erkennen, mit denen umfassende KI-Modelle im großen Maßstab Empfehlungen abgeben und die fehlenden menschlichen Agenten ergänzen können. KI kann auch einen besseren Abgleich zwischen einem bestimmten Kunden mit den aktuell verfügbaren Agenten ermöglichen. Mithilfe von KI können Unternehmen wertvolle Kundenstimmung in Bezug auf ihre Gedanken und Eindrücke von den Produkten, Services und dem Markenimage des Anbieters gewinnen.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">Die Lösung kann auch verwendet werden, um Zeitreihendaten für Support-Agenten zu erstellen, um eine objektive Leistungsbewertung zu bieten. In herkömmlichen Umfragen zur Kundenzufriedenheit fehlt es oft an ausreichenden Antworten. Durch das Sammeln von langfristigen Empfindung von Mitarbeitern und Kunden können Arbeitgeber informierte Entscheidungen über die Leistung von Supportmitarbeitern treffen.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">Die Kombination aus NetApp, SFL Scientific, opensource-Orchestrierungs-Frameworks und NVIDIA vereint die neuesten Technologien als Managed Services mit hoher Flexibilität und ermöglicht so eine schnellere Technologieeinführung und eine schnellere Markteinführung neuer KI/ML-Applikationen. Diese erweiterten Services werden vor Ort bereitgestellt, die problemlos in Cloud-native Umgebungen und in hybriden Architekturen portiert werden können.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">Auf dieser Seite finden Sie Hintergrundinformationen darüber, wie NetApp KI-Projekte vorantreiben kann, einschließlich Informationen zu Containern, Kubernetes, NetApp Trident und mehr.</block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">Konzepte und Komponenten</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">Künstliche Intelligenz</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">KI ist eine Informatik-Disziplin, in der Computer trainiert werden, um kognitive Funktionen des menschlichen Verstandes nachzuahmen. KI-Entwickler Schulen Computer, um Probleme so zu lernen oder zu lösen, dass sie dem Menschen ähneln oder sogar überlegen sind. Deep Learning und Machine Learning sind Unterfelder der KI. Unternehmen setzen zunehmend auf KI, ML und DL, um ihre kritischen Geschäftsanforderungen zu unterstützen. Dies sind einige Beispiele:</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analyse großer Datenmengen für bislang unbekannte geschäftliche Einblicke</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Direkte Interaktion mit Kunden über natürliche Sprachverarbeitung</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatisierung verschiedener Geschäftsprozesse und Funktionen</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">Moderne KI-Trainings- und Inferenz-Workloads erfordern extrem hohe parallele Computing-Funktionen. Deshalb werden GPUs zunehmend zur Ausführung von KI-Operationen eingesetzt, da die Funktionen der parallelen Verarbeitung von GPUs denen allgemeiner CPUs überlegen sind.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Container sind isolierte Instanzen von Benutzerspeicherplatz, die auf einem Kernel des Shared-Host-Betriebssystems laufen. Die Einführung von Containern nimmt immer schneller zu. Container bieten viele der gleichen Vorteile von Applikationen im Sandbox-Bereich, die Virtual Machines (VMs) bieten. Da jedoch der Hypervisor und das Gastbetriebssystem die Anzahl der VMs beseitigen, sind die Container viel schlanker. Die folgende Abbildung zeigt eine Visualisierung von Virtual Machines gegenüber Containern.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker-Website</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">Container erlauben außerdem die effiziente Bündelung von Applikationsabhängigkeiten, Laufzeiten usw. und damit direkt mit einer Applikation. Das am häufigsten verwendete Format für Containerverpackungen ist der Docker Container. Eine Applikation, die im Docker-Container-Format gesichert wurde, kann auf jeder Maschine ausgeführt werden, die Docker Container ausführen kann. Dies gilt auch dann, wenn die Abhängigkeiten der Anwendung nicht auf der Maschine vorhanden sind, weil alle Abhängigkeiten im Container selbst verpackt sind. Weitere Informationen finden Sie auf der<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes-Website</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes ist eine ursprünglich von Google entwickelte Open-Source-Plattform zur Container-Orchestrierung, die jetzt von der Cloud Native Computing Foundation (CNCF) verwaltet wird. Kubernetes ermöglicht die Automatisierung von Implementierungs-, Management- und Skalierungsfunktionen für Container-Applikationen. In den letzten Jahren hat sich Kubernetes zur führenden Plattform für die Container-Orchestrierung entwickelt. Obwohl andere Container-Verpackungsformate und Laufzeiten unterstützt werden, wird Kubernetes am häufigsten als Orchestrierungssystem für Docker Container verwendet. Weitere Informationen finden Sie auf der<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident Website</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident ist ein Open-Source-Storage-Orchestrator, der von NetApp entwickelt und gewartet wird. Damit wird die Erstellung, das Management und die Nutzung von persistentem Storage für Kubernetes-Workloads erheblich vereinfacht. Trident, selbst eine native Kubernetes-Applikation, wird direkt in einem Kubernetes Cluster ausgeführt. Mit Trident können Kubernetes-Benutzer (Entwickler, Data Scientists, Kubernetes Administratoren usw.) persistente Storage-Volumes im gewohnten Kubernetes-Standardformat erstellen, managen und interagieren. Gleichzeitig können sie von den erweiterten Datenmanagement-Funktionen von NetApp und der Data Fabric Strategie von NetApp profitieren. Trident abstrahiert die Komplexität von persistentem Storage und vereinfacht die Nutzung. Weitere Informationen finden Sie auf der<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps-Website</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps ist ein Open-Source-Projekt von NVIDIA, das mithilfe von Ansible die Implementierung von GPU-Server-Clustern gemäß Best Practices automatisiert. DeepOps ist modular aufgebaut und kann für verschiedene Implementierungsaufgaben verwendet werden. DeepOps wird in diesem Dokument und der hier beschriebene Validierungsübung verwendet, um ein Kubernetes-Cluster zu implementieren, der aus GPU-Server-Worker-Nodes besteht. Weitere Informationen finden Sie auf der<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow-Website</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow ist ein Open Source AI und ML Toolkit für Kubernetes und wurde ursprünglich von Google entwickelt. Das Kubeflow-Projekt macht Implementierungen von KI- und ML-Workflows auf Kubernetes einfach, tragbar und skalierbar. Kubeflow abstrahiert die Besonderheiten von Kubernetes und ermöglicht Data Scientists, sich auf das zu konzentrieren, was sie am besten kennen―Datenwissenschaft. Eine Visualisierung finden Sie in der folgenden Abbildung. Kubeflow hat seine Bedeutung gewonnen, da DIE IT-Abteilungen in Unternehmen zunehmend auf Kubernetes standardisiert haben. Weitere Informationen finden Sie auf der<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow-Pipelines</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow Pipelines sind ein Schlüsselbestandteil von Kubeflow. Kubeflow Pipelines sind eine Plattform und ein Standard für die Definition und Implementierung portabler und skalierbarer KI- und ML-Workflows. Weitere Informationen finden Sie im<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter-Website</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Ein Jupyter Notebook Server ist eine Open Source Web-Anwendung, mit der Data Scientists Wiki-ähnliche Dokumente erstellen können, genannt Jupyter Notebooks, die sowohl Live-Code als auch einen beschreibenden Test enthalten. Jupyter Notebooks werden in der KI- und ML-Community häufig eingesetzt, um KI- und ML-Projekte zu dokumentieren, zu speichern und gemeinsam zu nutzen. Kubeflow vereinfacht die Bereitstellung und Bereitstellung von Jupyter Notebook-Servern auf Kubernetes. Weitere Informationen zu Jupyter Notebooks finden Sie auf der<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Weitere Informationen zu Jupyter Notebooks im Kontext von Kubeflow finden Sie im<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>.</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Apache Airflow</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow ist eine Open-Source-Workflow-Managementplattform, die programmatisches Authoring, Scheduling und Monitoring für komplexe Unternehmens-Workflows ermöglicht. Sie wird häufig zur Automatisierung von ETL- und Daten-Pipeline-Workflows verwendet, beschränkt sich jedoch nicht auf diese Arten von Workflows. Das Airflow-Projekt wurde von Airbnb gestartet, ist aber inzwischen sehr populär in der Branche und fällt nun unter die Schirmherrschaft der Apache Software Foundation. Der Luftstrom wird in Python geschrieben, Airflow-Workflows werden über Python-Skripte erstellt und Airflow wird nach dem Prinzip „Configuration as Code“ entworfen. Viele Benutzer von Airflow setzen nun Airflow auf Kubernetes aus.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Gesteuerte Acyclic-Grafiken (DAGs)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">In Airflow werden Workflows als gesteuerte Acyclic Grafs (DAGs) bezeichnet. DAGs bestehen aus Aufgaben, die je nach DAG-Definition nacheinander, parallel oder kombiniert ausgeführt werden. Der Airflow Scheduler führt individuelle Aufgaben auf einem Array von Mitarbeitern aus und erfüllt dabei die in der DAG-Definition festgelegten Abhängigkeiten auf Aufgabenebene. DAGs werden über Python Skripte definiert und erstellt.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 ist die neueste Generation der Storage-Managementsoftware von NetApp. Mit ihr können Unternehmen wie Ihres ihre Infrastruktur modernisieren und auf ein Cloud-fähiges Datacenter umstellen. Dank der erstklassigen Datenmanagementfunktionen lassen sich mit ONTAP Ihre Daten mit einem einzigen Toolset managen und schützen, ganz gleich, wo sich diese Daten befinden. Zudem können Sie die Daten problemlos dorthin verschieben, wo Sie sie benötigen: Zwischen Edge, Core und Cloud. ONTAP 9 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, geschäftskritische Daten beschleunigen und schützen und die Infrastruktur über Hybrid-Cloud-Architekturen hinweg zukunftssicher machen.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">Datenmanagement Vereinfachen</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">Für Ihren Enterprise-IT-Betrieb spielt Datenmanagement eine zentrale Rolle, da es die richtigen Ressourcen für Ihre Applikationen und Datensätze verwenden kann. ONTAP umfasst die folgenden Funktionen, um den Betrieb zu optimieren und zu vereinfachen und damit die Gesamtbetriebskosten zu senken:</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">*Inline-Data-Compaction und erweiterte Deduplizierung.* Data-Compaction reduziert den ungenutzten Speicherplatz in Storage-Blöcken, während Deduplizierung die effektive Kapazität deutlich steigert.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Minimum, Maximum und anpassungsfähige Quality of Service (QoS)* durch granulare QoS-Kontrollen können geschäftskritische Applikationen auch in hochgemeinsam genutzten Umgebungen weiterhin Performance-Level aufrechterhalten.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">*ONTAP FabricPool.* Diese Funktion bietet automatisches Tiering von „kalten“ Daten in Private- und Public-Cloud-Storage-Optionen, einschließlich Amazon Web Services (AWS), Azure und objektbasiertem NetApp StorageGRID Storage.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">Daten beschleunigen und sichern</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP bietet überdurchschnittliche Performance und Datensicherung, erweitert durch folgende Funktionen:</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">*Hohe Performance und niedrige Latenz.* ONTAP bietet den höchstmöglichen Durchsatz bei geringstmöglicher Latenz.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">*NetApp ONTAP FlexGroup-Technologie.* Ein FlexGroup Volume ist ein hochperformanter Daten-Container, der sich linear auf bis zu 20 PB und 400 Milliarden Dateien skalieren lässt und über einen Single Namespace das Datenmanagement vereinfacht.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">*NetApp Volume Encryption.* ONTAP bietet native Verschlüsselung auf Volume-Ebene mit integriertem und externem Verschlüsselungsmanagement.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">Zukunftssichere Infrastruktur</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 hilft Unternehmen dabei, flexibel auf ständig wechselnde Geschäftsanforderungen zu reagieren:</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">*Nahtlose Skalierung und unterbrechungsfreier Betrieb.* ONTAP unterstützt das unterbrechungsfreie Hinzufügen von Kapazitäten zu bestehenden Controllern sowie das Scale-out von Clustern. Damit lassen sich Upgrades auf die neuesten Technologien wie NVMe und 32 GB FC ohne teure Datenmigrationen oder Ausfälle durchführen.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">*Cloud Connection.* ONTAP ist eine der Storage-Managementsoftware mit der umfassendsten Cloud-Integration und bietet Optionen für softwaredefinierten Storage (ONTAP Select) und Cloud-native Instanzen (NetApp Cloud Volumes Service) in allen Public Clouds.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">*Integration in moderne Applikationen.* durch den Einsatz derselben Infrastruktur, die bereits vorhandene Enterprise-Applikationen unterstützt, bietet ONTAP Datenservices der Enterprise-Klasse für Plattformen und Applikationen der neuesten Generation, wie OpenStack, Hadoop und MongoDB.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot Kopien</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Eine NetApp Snapshot Kopie ist ein schreibgeschütztes, zeitpunktgenaues Image eines Volumes. Das Image verbraucht nur minimalen Speicherplatz und beeinträchtigt den Performance-Overhead, da nur Änderungen an Dateien aufgezeichnet werden, die seit der letzten Snapshot Kopie erstellt wurden, wie in der folgenden Abbildung dargestellt.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot Kopien sind der zentralen ONTAP Storage-Virtualisierungstechnologie, dem Write Anywhere File Layout (WAFL), verdanken sie ihre Effizienz. Wie eine Datenbank verwendet WAFL Metadaten, um auf die tatsächlichen Datenblöcke auf der Festplatte zu verweisen. Im Gegensatz zu einer Datenbank überschreiben WAFL jedoch keine vorhandenen Blöcke. Aktualisierte Daten werden in einen neuen Block geschrieben und die Metadaten geändert. Der Grund dafür ist, dass ONTAP bei der Erstellung einer Snapshot Kopie Metadaten referenziert, statt Datenblöcke zu kopieren. Somit sind die Snapshot Kopien so effizient. So entfallen die Suchzeit, die andere Systeme beim Auffinden der zu kopierenden Blöcke sowie die Kosten für die Erstellung der Kopie selbst tragen.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Sie können eine Snapshot Kopie verwenden, um einzelne Dateien oder LUNs wiederherzustellen oder den gesamten Inhalt eines Volume wiederherzustellen. ONTAP vergleicht Zeigerinformationen in der Snapshot-Kopie mit Daten auf der Festplatte, um das fehlende oder beschädigte Objekt ohne Ausfallzeiten und hohe Performance-Kosten zu rekonstruieren.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone Technologie</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">Die NetApp FlexClone Technologie referenziert Snapshot Metadaten, um beschreibbare, zeitpunktgenaue Kopien eines Volumes zu erstellen. Kopien verwenden Datenblöcke gemeinsam mit ihren Eltern und verbrauchen somit keinen Storage, außer was für Metadaten erforderlich ist, bis Änderungen in die Kopie geschrieben werden, wie in der folgenden Abbildung dargestellt. Bei der Erstellung herkömmlicher Kopien dauert die Erstellung von Minuten oder gar Stunden, mit FlexClone können Sie selbst die größten Datensätze nahezu sofort kopieren. Daher eignet sie sich besonders für Situationen, in denen mehrere Kopien identischer Datensätze (z. B. ein Entwicklungs-Workspace) oder temporäre Kopien eines Datensatzes benötigt werden (d. h. eine Applikation gegen einen Produktionsdatensatz testen).</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror Datenreplizierung</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror ist eine kostengünstige, benutzerfreundliche und einheitliche Replizierungslösung für die gesamte Data-Fabric-Strategie. Sie repliziert Daten mit hoher Geschwindigkeit über LAN oder WAN. Sie bietet hohe Datenverfügbarkeit und schnelle Datenreplizierung für alle Arten von Applikationen, einschließlich geschäftskritischer Applikationen in virtuellen und herkömmlichen Umgebungen. Durch das Replizieren und ständige Aktualisieren der sekundären Daten auf einem Storage-System von NetApp sind die Daten immer aktuell und verfügbar. Es sind keine externen Replizierungsserver erforderlich. In der folgenden Abbildung finden Sie ein Beispiel für eine Architektur, die die SnapMirror Technologie nutzt.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror Software nutzt NetApp ONTAP Storage-Effizienzfunktionen, indem nur geänderte Datenblöcke im Netzwerk verschoben werden. Außerdem verwendet SnapMirror Software eine integrierte Netzwerkkomprimierung, um die Datenübertragung zu beschleunigen und die Auslastung der Netzwerkbandbreite um bis zu 70 % zu reduzieren. Mit der SnapMirror Technologie lässt sich ein Thin-Replication-Datenstrom erstellen, um ein einzelnes Repository zu erstellen, das sowohl den aktiven Spiegel als auch die zeitpunktgenau Kopien enthält. Auf diese Weise verringert sich der Datenverkehr im Netzwerk um bis zu 50 %.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync ist ein NetApp Service für schnelle und sichere Datensynchronisierung. Unabhängig davon, ob Sie Dateien zwischen On-Premises-NFS oder SMB-Dateifreigaben übertragen müssen: NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob Google Cloud Storage oder IBM Cloud Object Storage – Cloud Sync verschiebt Dateien schnell und sicher dorthin, wo sie benötigt werden.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">Nach der Übertragung stehen die Daten an der Quelle und am Ziel vollständig zur Verfügung. Cloud Sync kann Daten nach Bedarf synchronisieren, wenn ein Update ausgelöst wird oder kontinuierlich Daten gemäß einem vordefinierten Zeitplan synchronisiert werden. Unabhängig davon werden bei Cloud Sync nur die Deltawerte verschoben. Daher werden Zeit und Kosten für die Datenreplizierung minimiert.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync ist ein Software-as-a-Service-Tool (SaaS), das extrem einfach einzurichten und zu verwenden ist. Von Cloud Sync ausgelöste Datentransfers werden durch Data Makler durchgeführt. Cloud Sync-Datenvermittler können in AWS, Azure, Google Cloud Platform oder On-Premises implementiert werden.</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">Der Client-basierte NetApp XCP Software ermöglicht Datenmigrationen zwischen beliebigen Systemen von NetApp und NetApp zu NetApp sowie Einblicke in das Filesystem. XCP ist für Skalierung ausgelegt und erreicht maximale Performance, indem alle verfügbaren Systemressourcen für umfangreiche Datensätze und hochperformante Migrationen genutzt werden. Mit XCP erhalten Sie eine vollständige Übersicht über das Dateisystem und können Berichte generieren.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP ist in einem einzigen Paket erhältlich, das NFS- und SMB-Protokolle unterstützt. XCP enthält eine Linux-Binärdatei für NFS-Datensätze und ein Windows Executable für SMB-Datensätze.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">Die hostbasierte Software NetApp XCP File Analytics erkennt Dateifreigaben, führt Scans im Filesystem aus und bietet ein Dashboard für Dateianalysen. XCP File Analytics ist sowohl mit Systemen von NetApp als auch mit Systemen anderer Hersteller kompatibel und wird auf Linux- oder Windows-Hosts ausgeführt, um Analysen für NFS- und SMB-exportierte Filesysteme zu ermöglichen.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup Volumes</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Ein Trainingsdatensatz kann eine Sammlung von möglicherweise Milliarden von Dateien sein. Dateien können Text, Audio, Video und andere Formen unstrukturierter Daten enthalten, die gespeichert und verarbeitet werden müssen, damit sie gleichzeitig gelesen werden können. Das Storage-System muss eine große Anzahl an kleinen Dateien speichern und diese parallel für sequenzielle und zufällige I/O lesen</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Ein FlexGroup Volume ist ein einziger Namespace, der aus mehreren zusammengehörigen Member Volumes besteht, wie in der folgenden Abbildung dargestellt. Aus Sicht eines Storage-Administrators wird ein FlexGroup Volume wie ein NetApp FlexVol Volume gemanagt und verhält sich so wie ein NetApp Volume. Dateien in einem FlexGroup Volume werden Volumes einzelner Mitglieder zugewiesen und nicht über Volumes oder Nodes verteilt. Sie bieten folgende Möglichkeiten:</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup Volumes bieten eine Kapazität im Petabyte-Bereich und eine planbare niedrige Latenz für Workloads mit vielen Metadaten.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Sie unterstützen bis zu 400 Milliarden Dateien im selben Namespace</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Sowie parallelisierte Vorgänge bei NAS-Workloads über CPUs, Nodes, Aggregate und zusammengehörige FlexVol Volumes hinweg.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">Nächste: Hardware- und Software-Anforderungen.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise with NetApp and VMware – Weitere Informationen</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">Früher: Beispiel Anwendungsfall – TensorFlow Training Job.</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP Datenmanagement-Software – ONTAP Informationsbibliothek</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise with VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Sr Manager, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, Systemadministrator bei NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Technical Marketing Engineer, NetApp</block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">Sie können den Service-Level eines vorhandenen Volumes ändern, indem Sie das Volume in einen anderen Kapazitäts-Pool verschieben und dabei das gewünschte Service-Level für das Volume nutzen. Mithilfe dieser Lösung können Kunden mit einem kleinen Datensatz und einer kleinen Anzahl GPUs in der Standard-Ebene beginnen und bei zunehmender Datenmenge und GPUs horizontal oder vertikal auf Premium-Tier skalieren.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files-Performance-Tiers</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">Früher: Einrichten von „Dask with RAPIDS Deployment“ auf AKS mit Helm.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">Sie können den Service-Level eines vorhandenen Volumes ändern, indem Sie das Volume in einen anderen Kapazitäts-Pool verschieben und dabei das gewünschte Service-Level für das Volume nutzen. Mithilfe dieser Lösung können Kunden mit einem kleinen Datensatz und einer kleinen Anzahl GPUs in der Standard-Ebene beginnen und bei zunehmender Datenmenge und GPUs horizontal oder vertikal auf Premium-Tier skalieren. Die Premium-Ebene bietet als Standardebene einen viermal so hohen Durchsatz pro Terabyte. Die vertikale Skalierung erfolgt ohne dass Daten verschoben werden müssen, um den Service Level eines Volumes zu ändern.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">Um den Service-Level eines Volumes dynamisch zu ändern, gehen Sie wie folgt vor:</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">Wählen Sie im Fenster Pool ändern den Kapazitätspool aus, in den Sie das Volume verschieben möchten.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Klicken Sie auf OK.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">Automatisieren Sie Änderungen in Performance-Tiers</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">Zur Automatisierung von Änderungen in der Performance-Ebene stehen folgende Optionen zur Verfügung:</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">Die dynamische Änderung des Service-Levels befindet sich derzeit noch in der öffentlichen Vorschau und ist standardmäßig nicht aktiviert. Um diese Funktion im Azure-Abonnement zu aktivieren, lesen Sie in dieser Dokumentation nach, wie Sie diese Funktion aktivieren können<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">Dokumentation der Änderungen am Volume Pool</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">In werden Änderungsbefehle für den Azure CLI-Volume-Pool bereitgestellt<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> Und im folgenden Beispiel:</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Cmdlet "AzNetAppFilesVolumePool</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell: Das<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Ändert den Pool eines Azure NetApp Files Volume und wird im folgenden Beispiel dargestellt:</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">Weiter: Bibliotheken für die Datenverarbeitung und Modellschulung.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">Die Architektur dieser Support Center-Lösung dreht sich um die vorgefertigten Tools von NVIDIA und das NetApp DataOps Toolkit. Die NVIDIA Tools werden verwendet, um schnell hochperformante KI-Lösungen unter Verwendung vordefinierter Modelle und Pipelines zu implementieren. Das NetApp DataOps Toolkit vereinfacht verschiedene Datenmanagement-Aufgaben und beschleunigt so die Entwicklung.</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">Zurück – Anwendungsfälle.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> Ist ein GPU-beschleunigtes SDK für die Erstellung von multimodalen, umgangssprachlichen KI-Anwendungen, die Performance bei GPUs in Echtzeit liefern. Das NVIDIA Train, Adapt, and Optimize (TAO) Toolkit bietet eine schnellere und einfachere Möglichkeit, Trainings zu beschleunigen und schnell hochgenaue und performante, domänenspezifische KI-Modelle zu erstellen.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">Das NetApp DataOps Toolkit ist eine Python Library, die Entwickler, Data Scientists, DevOps Engineers und Data Engineers zur Ausführung verschiedener Datenmanagementaufgaben vereinfacht. Dies umfasst die nahezu sofortige Bereitstellung eines neuen Daten-Volumes oder einer JupyterLab-Umgebung, das nahezu sofortige Klonen eines Daten-Volumes oder einer JupyterLab-Umgebung sowie das nahezu sofortige Snapshotten eines Daten-Volumes oder JupyterLab Workspace für die Rückverfolgbarkeit und Baseline.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">Architekturdiagramm</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">Das folgende Diagramm zeigt die Lösungsarchitektur. Es gibt drei Hauptkategorien: Die Cloud, der Core und der Edge. Jede der Kategorien kann geografisch verteilt sein. Die Cloud enthält z. B. Objektspeicher mit Audiodateien in Buckets aus verschiedenen Regionen, während der Core Datacenter enthalten kann, die über ein Hochgeschwindigkeits-Netzwerk oder NetApp Cloud Sync verbunden sind. Die Randknoten bezeichnen die täglichen Arbeitsplattformen des einzelnen menschlichen Agenten, auf denen interaktive Dashboard-Tools und Mikrofone zur Visualisierung der Stimmung und zur Erfassung von Audiodaten aus Gesprächen mit Kunden zur Verfügung stehen.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">Storage-Design</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">RIVA</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao Toolkit</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">Bei GPU-beschleunigten Datacentern können Unternehmen das NVIDIA verwenden<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> Framework zum Erstellen dialogbasierter KI-Applikationen, mit denen das erstellt werden kann<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Verbindungen für Modellabbildung und Umschulung mithilfe von Transfer L-Learning-Techniken. Computing-Applikationen und Workflows werden von dem bereitgestellt<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Bereitstellung der besten Datenmanagement-Funktionen, die ONTAP zu bieten hat. Mit dem Toolkit können Datenteams schnell Prototypen ihrer Modelle mit strukturierten und unstrukturierten Daten erstellen. Diese lassen sich über Snapshots und Klone für Rückverfolgbarkeit, Versionierung, A/B-Tests einsetzen und bieten so Sicherheit, Governance, Und Einhaltung gesetzlicher Vorschriften. Siehe Abschnitt <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> Entnehmen.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">Diese Lösung zeigt die Verarbeitung von Audiodateien, das NLP-Modelltraining, das Transfer Learning und die Detailschritte zum Datenmanagement. Die daraus resultierende End-to-End-Pipeline erzeugt eine Sentimentzusammenfassung, die in Echtzeit auf den Dashboards von Mitarbeitern des menschlichen Supports angezeigt wird.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Hardwareanforderungen</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">In der folgenden Tabelle werden die Hardwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Je nach den Anforderungen des Kunden können die tatsächlich in einer konkreten Implementierung dieser Lösung eingesetzten Hardwarekomponenten abweichen.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">Tests mit Verzögerungen der Reaktionszeit</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">Zeit (Millisekunden)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">Datenverarbeitung</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">Inferenz</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">Diese Tests zur Reaktionszeit wurden auf mehr als 50,000 Audiodateien in 560 Gesprächen ausgeführt. Jede Audiodatei war ~100KB groß als MP3 und ~1 MB, wenn sie in WAV konvertiert wurde. Der Schritt der Datenverarbeitung wandelt MP3s in WAV-Dateien um. Die Inferenzschritte wandeln die Audiodateien in Text um und extrahieren eine Stimmung aus dem Text. Diese Schritte sind alle unabhängig voneinander und können parallel ausgeführt werden, um den Prozess zu beschleunigen.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">Unter Berücksichtigung der Latenz, die beim Übertragen von Daten zwischen Geschäften entsteht, sollten Manager innerhalb einer Sekunde nach dem Ende des Satzes Aktualisierungen zur Echtzeitanalyse der Sentimentalität sehen können.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA RIVA-Hardware</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">Anforderungen</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">BETRIEBSSYSTEM</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU-Speicher (ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">Streaming-Modelle: ~5600 MB nicht-Streaming-Modelle: ~3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU-Speicher (NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">~500 MB pro BERT-Modell</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO Toolkit-Hardware</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">System-RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU-RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 Kerne</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA (A100, V100 und RTX 30x0)</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100 GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">Flash Storage-System</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ONTAP 9.9, die jüngste Generation der Storage-Managementsoftware von NetApp, ermöglicht Unternehmen eine Modernisierung der Infrastruktur und den Übergang zu einem Cloud-fähigen Datacenter. Dank der erstklassigen Datenmanagementfunktionen lassen sich mit ONTAP sämtliche Daten mit einem einzigen Toolset managen und schützen, ganz gleich, wo sich diese Daten befinden. Zudem können Sie die Daten problemlos dorthin verschieben, wo sie benötigt werden: Zwischen Edge, Core und Cloud. ONTAP 9.9 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, geschäftskritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation über Hybrid-Cloud-Architekturen hinweg ermöglichen.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Ist ein NetApp Service für schnelle und sichere Datensynchronisierung, ermöglicht die Übertragung von Dateien zwischen lokalen NFS- oder SMB-Dateifreigaben an eines der folgenden Ziele:</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="list-text">NetApp StorageGRID</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service (Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System (Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google Cloud Storage</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM Cloud Objekt-Storage</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync verschiebt Dateien schnell und sicher dorthin, wo sie benötigt werden. Nach der Übertragung stehen die Daten sowohl auf dem Quell- als auch auf dem Zielsystem uneingeschränkt zur Verfügung. Cloud Sync synchronisiert kontinuierlich die Daten, die basierend auf Ihrem vordefinierten Zeitplan basieren, um nur die Deltas zu verschieben – und so den Zeit- und Kostenaufwand für die Datenreplizierung zu minimieren. Cloud Sync ist ein Software-als-Service-Tool (SaaS), das einfach einzurichten und zu verwenden ist. Von Cloud Sync ausgelöste Datentransfers werden durch Data Makler durchgeführt. Cloud Sync-Datenmanager können in AWS, Azure, Google Cloud Platform oder vor Ort implementiert werden.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">Die softwaredefinierte Objekt-Storage Suite von StorageGRID unterstützt eine Vielzahl von Anwendungsfällen für nahtlose Public-, Private- und Hybrid-Multi-Cloud-Umgebungen. Branchenführende Innovationen sorgen dafür, dass NetApp StorageGRID unstrukturierte Daten für eine heterogene Nutzung speichert, sichert, sichert und schützt. Dazu gehört auch automatisiertes Lifecycle Management über längere Zeit. Weitere Informationen finden Sie im<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> Standort.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">In der folgenden Tabelle werden die Softwarekomponenten aufgeführt, die für die Implementierung dieser Lösung erforderlich sind. Je nach den Anforderungen des Kunden können die in einer konkreten Implementierung dieser Lösung verwendeten Softwarekomponenten abweichen.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">Host-Rechner</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">RIVA (ehemals JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">TAO Toolkit (früher Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX-BETRIEBSSYSTEM</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DOTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA RIVA Software</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02 (mit installiertem nvidia-Docker)&gt;=19.03, wenn nicht mit DGX</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA-Treiber</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01+ 418.40, 440.33+, 450.51+, 460.27+ für Data Center GPUs</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">Container-OS</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">CUBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">CuDNN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton Inferenz Server</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO Toolkit-Software</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;=3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">docker-ce</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">&gt;19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">docker-API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">nvidia-Container-Toolkit</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-Container-Runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">nvidia-Treiber</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-Pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">Neueste Version</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">Einzelheiten zum Anwendungsfall</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Diese Lösung trifft auf folgende Anwendungsfälle zu:</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">Der Anwendungsfall Speech-to-Text beginnt mit der Aufnahme von Audiodateien für die Support Center. Dieses Audio wird dann an die von RIVA benötigte Struktur angepasst. Wenn die Audiodateien nicht bereits in ihre Analyseneinheiten aufgeteilt wurden, muss dies vor der Übergabe an RIVA erfolgen. Nach der Verarbeitung der Audiodatei wird sie als API-Aufruf an DEN RIVA-Server übergeben. Der Server verwendet eines der vielen Modelle, die er hostet, und gibt eine Antwort aus. Dieser Text (Teil der automatischen Spracherkennung) liefert eine Textdarstellung des Audiosignals. Von dort aus wechselt die Pipeline in den Bereich der Sentiment-Analyse.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">Zur Sentimentanalyse dient die Textausgabe der automatischen Spracherkennung als Eingabe zur Textklassifizierung. Textklassifizierung ist die NVIDIA-Komponente zum Klassifizieren von Text in eine beliebige Anzahl von Kategorien. Die Sentiment-Kategorien reichen von positiv bis negativ für die Gespräche im Support Center. Die Leistung der Modelle kann mit einem Holdout-Satz bewertet werden, um den Erfolg des Feintuning-Schritts zu bestimmen.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC-Katalog</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">Eine ähnliche Pipeline wird sowohl für die sprach-zu-Text- als auch für die Sentimentanalyse im TAO Toolkit verwendet. Der große Unterschied ist die Verwendung von Etiketten, die für die Feinabstimmung der Modelle erforderlich sind. Die TAO Toolkit-Pipeline beginnt mit der Verarbeitung der Datendateien. Dann die vortrainierten Modelle (aus dem<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>) Sind mit den Support-Center-Daten fein abgestimmt. Die fein abgestimmten Modelle werden anhand ihrer entsprechenden Leistungskennzahlen bewertet und, wenn sie performanter sind als die vortrainierten Modelle, auf DEM RIVA-Server eingesetzt.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">Als Nächstes: Design-Überlegungen.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">Unternehmen und Unternehmen aller Größen und Branchen setzen zunehmend auf künstliche Intelligenz (KI), Machine Learning (ML) und Deep Learning (DL), um Probleme aus der Praxis zu lösen, innovative Produkte und Services zu entwickeln und sich in einem immer härter umkämpften Markt einen Schritt voraus zu sein. Beim verstärkten Einsatz von KI, ML und DL müssen Unternehmen mit vielen Herausforderungen konfrontiert werden, darunter Workload-Skalierbarkeit und Datenverfügbarkeit. Diese Herausforderungen können durch den Einsatz der NetApp AI Control Plane Lösung bewältigt werden.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">Mit dieser Lösung können Sie einen Daten-Namespace schnell klonen. Darüber hinaus können Kunden AI-, ML- und DL-Training-Workflows definieren und implementieren, die die nahezu sofortige Erstellung von Daten und Modellbasiden für Rückverfolgbarkeit und Versionierung enthalten. Mit dieser Lösung können Sie hinter jedem einzelnen Modell-Training zurück zu den genauen Datensätzen führen, mit denen das Modell geschult und/oder validiert wurde. Und schließlich können Sie mit dieser Lösung schnell Jupyter Notebook-Workspaces mit Zugriff auf riesige Datensätze bereitstellen.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">Da diese Lösung auf Data Scientists und Data Engineers ausgerichtet ist, sind minimale Fachkenntnisse von NetApp oder NetApp ONTAP erforderlich. Bei dieser Lösung lassen sich Datenmanagementfunktionen mit einfachen und vertrauten Tools und Schnittstellen ausführen. Darüber hinaus nutzt diese Lösung vollständig Open-Source- und freie Komponenten. Wenn Sie also bereits NetApp Storage in Ihrer Umgebung haben, können Sie diese Lösung heute implementieren. Wenn Sie diese Lösung testen möchten, aber noch nicht bereits über NetApp Storage verfügen, besuchen Sie<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>, Und Sie sind innerhalb kürzester Zeit mit einer Cloud-basierten NetApp Storage-Lösung einsatzbereit.</block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">Details zur Lösungsimplementierung und -Validierung</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">In den folgenden Abschnitten werden die Einzelheiten zur Implementierung und Validierung der Lösung beschrieben.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">Dann: ONTAP AI Deployment</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes Deployment</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">Um Ihren Kubernetes-Cluster mit NVIDIA DeepOps zu implementieren und zu konfigurieren, führen Sie die folgenden Aufgaben über einen Bereitstellungs-Jump-Host aus:</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">Erste Schritte</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">Laden Sie NVIDIA DeepOps herunter, indem Sie den Anweisungen auf der folgen<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Kubernetes Deployment Guide</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">Implementieren Sie Kubernetes in Ihrem Cluster, indem Sie die Anweisungen auf dem befolgen<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">Damit die Implementierung von DeepOps Kubernetes funktioniert, muss auf allen Kubernetes Master- und Worker-Nodes derselbe Benutzer vorhanden sein.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">Wenn die Bereitstellung fehlschlägt, ändern Sie den Wert von<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> Mit FALSE innen<block ref="399db550c3eadd49b7f0681bf65049a0" prefix=" " category="inline-code"></block> Und wiederholen Sie Schritt 2. Der<block ref="3d9043b4bfb5ecceda4eaf60e73c2655" prefix=" " category="inline-code"></block> Aufgabe, die nur dann ausgeführt wird, wenn der Wert von<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> Stimmt. Es basiert auf dem fetch Ansible-Modul, das bekannte Probleme bei der Speichernutzung hat. Diese Probleme mit der Speichernutzung können manchmal dazu führen, dass die Aufgabe nicht ausgeführt wird. Wenn die Aufgabe aufgrund eines Speicherproblems ausfällt, wird der restliche Bereitstellungsvorgang nicht erfolgreich abgeschlossen.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">Wenn die Bereitstellung erfolgreich abgeschlossen wurde, nachdem Sie den Wert von geändert haben<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> Bis<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block>, Dann müssen Sie die manuell kopieren<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> Von einem Kubernetes-Master-Node zu dem Bereitstellungs-Jump-Host Sie finden den Standort des<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> Auf einem bestimmten Master-Knoten, indem Sie den ausführen<block ref="c768a64827ad16455d7c655ea5ae91ff" prefix=" " category="inline-code"></block> Befehl direkt auf diesem Node.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">Weiter: Implementierung von Cnvrg.io</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Um einen synchronen AI- und ML-Job mit mehreren Nodes in Ihrem Kubernetes-Cluster auszuführen, führen Sie die auf dieser Seite aufgeführten Aufgaben auf dem Jump-Host der Implementierung aus. Mit diesem Prozess können Sie auf einem NetApp Volume gespeicherte Daten nutzen und mehr GPUs verwenden, als ein einzelner Worker-Node bieten kann.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Ausführung eines synchronen, verteilten KI-Workloads</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Um einen synchronen AI- und ML-Job mit mehreren Nodes in Ihrem Kubernetes-Cluster auszuführen, führen Sie die folgenden Aufgaben auf dem Jump-Host der Implementierung durch. Mit diesem Prozess können Sie auf einem NetApp Volume gespeicherte Daten nutzen und mehr GPUs verwenden, als ein einzelner Worker-Node bieten kann. Die folgende Abbildung zeigt einen synchronen, verteilten KI-Job.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Synchrone, verteilte Jobs können dazu beitragen, die Performance und die Trainingsgenauigkeit im Vergleich zu asynchronen, verteilten Jobs zu steigern. Eine Diskussion über die vor- und Nachteile von synchronen Jobs gegenüber asynchronen Jobs geht nicht in dieses Dokument über.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">Die folgenden Beispielbefehle zeigen die Erstellung eines Workers, der an der synchronen, verteilten Ausführung desselben TensorFlow Benchmark-Jobs beteiligt ist, der auf einem einzelnen Node im Beispiel im Abschnitt ausgeführt wurde <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. In diesem speziellen Beispiel wird nur ein einziger Worker bereitgestellt, da der Job über zwei Worker-Nodes ausgeführt wird.</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Dieses Beispiel für die Implementierung eines Mitarbeiters fordert acht GPUs an und kann so auf einem einzelnen GPU-Worker-Node mit acht oder mehr GPUs ausgeführt werden. Wenn Ihre GPU-Worker-Nodes mehr als acht GPUs aufweisen, um die Performance zu maximieren, könnte die Anzahl dieser GPUs erhöht werden, die der Funktion der Worker-Nodes entsprechen. Weitere Informationen über Kubernetes-Implementierungen finden Sie im<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">In diesem Beispiel wird eine Kubernetes-Implementierung erstellt, da dieser spezifische Container-Worker niemals eigenständig abgeschlossen sein würde. Daher macht es keinen Sinn, es durch die Verwendung des Kubernetes Job-Konstrukts zu implementieren. Wenn Ihr Mitarbeiter für sich selbst konzipiert oder geschrieben wurde, ist es möglicherweise sinnvoll, das Job-Konstrukt für die Bereitstellung Ihres Mitarbeiters zu verwenden.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">Dem POD, der in diesem Beispiel der Implementierungsspezifikation angegeben ist, wird eine zugewiesen<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Der Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Dieser Wert bedeutet, dass der Pod den Netzwerk-Stack des Host-Mitarbeiters-Nodes anstelle des virtuellen Netzwerk-Stacks verwendet, den Kubernetes normalerweise für jeden Pod erstellt. Diese Annotation wird in diesem Fall verwendet, da der spezifische Workload auf Open MPI, NCCL und Horovod angewiesen ist, um den Workload in einer synchronen, verteilten Art und Weise auszuführen. Daher ist für diese Lösung der Zugriff auf den Host-Netzwerk-Stack erforderlich. Eine Diskussion über Open MPI, NCCL und Horovod geht nicht in dieses Dokument über. Ob oder nicht<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> Eine Anmerkung ist erforderlich, abhängig von den Anforderungen des spezifischen Workloads, die Sie ausführen. Weitere Informationen zum<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Feld, siehe<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Bestätigen Sie, dass die in Schritt 1 erstellte Workers-Bereitstellung erfolgreich gestartet wurde. Die folgenden Beispielbefehle bestätigen, dass ein Pod für einzelne Mitarbeiter für die Implementierung erstellt wurde, wie in der Implementierungsdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Worker-Nodes ausgeführt wird.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">Kubernetes-Job für einen Master erstellen, der zu Beginn startet, an dem er teilnimmt und die Ausführung des synchronen Jobs mit mehreren Nodes verfolgt. Die folgenden Beispielbefehle erzeugen einen Master, der abstartet, an dem teilnimmt und die synchrone, verteilte Ausführung desselben TensorFlow-Benchmark-Jobs verfolgt, der auf einem einzelnen Node im Beispiel im Abschnitt ausgeführt wurde <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Dieses Beispiel-Master-Job fordert acht GPUs an, wodurch auf einem einzelnen GPU-Worker-Node mit acht oder mehr GPUs ausgeführt werden kann. Wenn Ihre GPU-Worker-Nodes mehr als acht GPUs aufweisen, um die Performance zu maximieren, könnte die Anzahl dieser GPUs erhöht werden, die der Funktion der Worker-Nodes entsprechen.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Der Master-Pod, der in dieser Beispiel-Jobdefinition angegeben wird, wird A zugewiesen<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Der Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>, So wie der Arbeiter POD wurde ein<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> Der Wert von<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> In Schritt 1. Weitere Informationen dazu, warum dieser Wert notwendig ist, finden Sie in Schritt 1.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Vergewissern Sie sich, dass der in Schritt 3 erstellte Master-Job korrekt ausgeführt wird. Der folgende Beispielbefehl bestätigt, dass für den Job ein einzelner Master-Pod erstellt wurde, wie in der Jobdefinition angegeben, und dass dieser Pod derzeit auf einem der GPU-Worker-Nodes ausgeführt wird. Sie sollten auch sehen, dass der Worker Pod, den Sie ursprünglich in Schritt 1 gesehen haben, noch läuft und dass die Master- und Worker-Pods auf unterschiedlichen Nodes ausgeführt werden.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Vergewissern Sie sich, dass der in Schritt 3 erstellte Masterjob erfolgreich abgeschlossen wurde. Mit den folgenden Beispielbefehlen wird bestätigt, dass der Job erfolgreich abgeschlossen wurde.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Löschen Sie die Mitarbeiterbereitstellung, wenn Sie sie nicht mehr benötigen. Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 1 erstellten Workers Deployment-Objekts.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Wenn Sie das Bereitstellungsobjekt für Mitarbeiter löschen, löscht Kubernetes automatisch alle zugehörigen „Worker“-Pods.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Optional:* Säubern Sie die Master Job Artefakte. Die folgenden Beispielbefehle zeigen das Löschen des in Schritt 3 erstellten Master-Jobobjekts.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Wenn Sie das Master-Job-Objekt löschen, löscht Kubernetes automatisch alle zugehörigen Master-Pods.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">Als Nächstes: Performance-Tests.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">Auf dieser Seite werden die Aufgaben beschrieben, die zur Implementierung eines Kubernetes-Clusters erforderlich sind, damit die NetApp AI Control Plane Lösung implementiert werden kann. Wenn Sie bereits einen Kubernetes Cluster besitzen, können Sie diesen Abschnitt überspringen, solange Sie eine von Kubeflow und NetApp Trident unterstützte Version von Kubernetes ausführen.</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die zur Implementierung eines Kubernetes-Clusters erforderlich sind, in dem die NetApp AI Control Plane Lösung implementiert werden kann. Wenn Sie bereits einen Kubernetes Cluster besitzen, können Sie diesen Abschnitt überspringen, solange Sie eine von Kubeflow und NetApp Trident unterstützte Version von Kubernetes ausführen. Eine Liste der von Kubeflow unterstützten Kubernetes-Versionen finden Sie im<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Eine Liste der von Trident unterstützten Kubernetes-Versionen finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">Für lokale Kubernetes-Implementierungen, die Bare-Metal-Nodes mit NVIDIA-GPU(s) einbinden, empfiehlt NetApp die Verwendung des NVIDIA DeepOps Kubernetes-Implementierungstools. In diesem Abschnitt wird die Bereitstellung eines Kubernetes-Clusters mit DeepOps beschrieben.</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">Sie haben bereits alle Bare-Metal-Kubernetes-Nodes (z. B. ein NVIDIA DGX-System, das Teil eines ONTAP AI Pods ist) gemäß den Standardkonfigurationsanweisungen konfiguriert.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub-Website</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">Sie haben ein unterstütztes Betriebssystem auf allen Kubernetes Master- und Worker-Nodes und auf einem Deployment Jump-Host installiert. Eine Liste der von DeepOps unterstützten Betriebssysteme finden Sie im<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">Verwenden Sie NVIDIA DeepOps zum Installieren und Konfigurieren von Kubernetes</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">Laden Sie NVIDIA DeepOps herunter, indem Sie den Anweisungen auf der folgen<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Seite „Kubernetes Deployment Guide“</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">Implementieren Sie Kubernetes in Ihrem Cluster, indem Sie die Anweisungen auf dem befolgen<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> Auf der NVIDIA DeepOps GitHub Website.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">Weiter: Überblick über die Implementierung und Konfiguration von NetApp Trident</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785: KI Deployment with NetApp E-Series and BeeGFS</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju, Daniel Landes, Nathan Swartz, Amine Bennani, NetApp</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">Applikationen für künstliche Intelligenz (KI), Machine Learning (ML) und Deep Learning (DL) umfassen große Datensätze und hohe Berechnungen. Um diese Workloads erfolgreich auszuführen, benötigen Sie eine flexible Infrastruktur, die sowohl die Storage- als auch die Compute-Nodes nahtlos horizontal skalieren kann. Dieser Bericht enthält die Schritte zur Ausführung eines KI-Trainingsmodells in einem verteilten Modus, das eine nahtlose horizontale Skalierung von Computing- und Storage-Nodes ermöglicht. Außerdem enthält der Bericht verschiedene Performance-Kennzahlen, um zu zeigen, wie eine Lösung, die NetApp E-Series Storage mit dem parallelen Filesystem BeeGFS kombiniert, eine flexible, kostengünstige und einfache Lösung für KI-Workloads bietet.</block>
  <block id="ee8f67cac9ef02f83e05d3b531bbaa8f" category="inline-link-macro"><block ref="ee8f67cac9ef02f83e05d3b531bbaa8f" category="inline-link-rx"></block></block>
  <block id="f23e849942acdc76ad2147cc16d1c207" category="paragraph"><block ref="f23e849942acdc76ad2147cc16d1c207" category="inline-link-macro-rx"></block></block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Kubernetes-Cluster Konfigurieren</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">Dieser Abschnitt ist in zwei Teile für die Cloud und lokale Implementierung unterteilt.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Konfiguration Von Cloud Deployment Kubernetes</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">Über NetApp Cloud Manager können Sie die Verbindung zum Iguazio Kubernetes Cluster definieren. Für Trident ist Zugriff auf mehrere Ressourcen im Cluster erforderlich, damit das Volume verfügbar wird.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">Um den Zugriff zu aktivieren, rufen Sie die Kubernetes-Konfigurationsdatei von einem der Iguazio-Knoten ab. Die Datei befindet sich unter<block ref="c94d2475115399d9803ef7d9f1fc7b59" prefix=" " category="inline-code"></block> Laden Sie diese Datei auf Ihren Desktop herunter.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">Gehen Sie zu Discover Cluster, um zu konfigurieren.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Laden Sie die Kubernetes-Konfigurationsdatei hoch. Siehe folgendes Bild.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Trident implementieren und ein Volume dem Cluster zuweisen. Sehen Sie das folgende Bild zum Definieren und Zuweisen eines Persistent Volumes zum Iguazio-Cluster.dieser Prozess erstellt ein Persistent Volume (PV) im Iguazio-Cluster. Bevor Sie ihn verwenden können, müssen Sie einen Persistent Volume Claim (PVC) definieren.</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">On-Premises-Implementierung Der Kubernetes-Konfiguration</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">Eine lokale Installation von NetApp Trident finden Sie unter<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Entsprechende Details. Nach der Konfiguration des Kubernetes-Clusters und der Installation von NetApp Trident können Sie Trident mit dem Iguazio Cluster verbinden, um NetApp Datenmanagementfunktionen zu aktivieren, wie beispielsweise die Erstellung von Snapshot Kopien Ihrer Daten und Modelle.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Als Nächstes Definieren Sie Persistent Volume Claim</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="5c6463fd6d00a2574dfb072c48e8de49" category="doc">TR-4859: Deploying IBM Spectrum Scale with NetApp E-Series Storage – Installation and Validation</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859 beschreibt den Prozess der Bereitstellung einer vollständigen parallelen Dateisystem-Lösung auf der Grundlage von IBM Spectrum Scale Software Stack. Der TR-4859 enthält Details zur Installation von Spectrum Scale, zur Validierung der Infrastruktur und zum Management der Konfiguration.</block>
  <block id="c9bcc5e8e66d05c764fccb9ece380847" category="inline-link-macro"><block ref="c9bcc5e8e66d05c764fccb9ece380847" category="inline-link-rx"></block></block>
  <block id="22c1cefecec00093f0b70a70b2680dcf" category="paragraph"><block ref="22c1cefecec00093f0b70a70b2680dcf" category="inline-link-macro-rx"></block></block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">Implementierung von VMware Virtual Infrastructure auf NetApp HCI mit nde (automatisierte Implementierung)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">Voraussetzungen für die nde Implementierung</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">Checkliste für Voraussetzungen für NetApp HCI</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">Konsultieren Sie die<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> Vor der Implementierung müssen die Anforderungen und Empfehlungen für NetApp HCI angezeigt werden.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">Anforderungen und Konfiguration von Netzwerk und Switches</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">Erforderliche VLAN-IDs vorbereiten</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">Switch-Konfiguration</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">IP-Adresse für NetApp HCI und VMware</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS und Anforderungen für die Zeitabhaltung</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">Abschließende Vorbereitungen</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">Ausführung der nde</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">Bevor Sie die nde ausführen, müssen Sie das Rack und den Stack aller Komponenten, die Konfiguration der Netzwerk-Switches und die Überprüfung aller Voraussetzungen abschließen. Nde lassen sich durch Verbindung mit der Managementadresse eines einzelnen Storage-Nodes ausführen, wenn nde plant, alle Adressen automatisch zu konfigurieren.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">Nde führt die folgenden Aufgaben aus, um ein HCI-System online zu schalten:</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">Installiert den Storage-Node (NetApp Element Software) auf mindestens zwei Storage-Nodes</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">Installiert den VMware Hypervisor auf mindestens zwei Computing-Nodes</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">Installiert VMware vCenter zum Management des gesamten NetApp HCI Stacks</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">Installiert und konfiguriert den NetApp Storage Management-Node (mNode) und den NetApp Monitoring Agent.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">Bei dieser Validierung werden alle Adressen automatisch mit nde konfiguriert. Sie können zudem in Ihrer Umgebung DHCP einrichten oder jedem Storage Node und jedem Computing Node manuell IP-Adressen zuweisen. Diese Schritte werden in diesem Leitfaden nicht erläutert.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">Wie bereits erwähnt, verwendet diese Validierung eine 2-Kabel-Konfiguration für Computing-Nodes.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">Detaillierte Schritte für die nde werden in diesem Dokument nicht behandelt.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">Implementierungsleitfaden</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">Eine Schritt-für-Schritt-Anleitung zum Abschließen der Bereitstellung der NetApp HCI Basis-Plattform finden Sie im<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">Melden Sie sich nach Abschluss von nde im vCenter an und erstellen Sie eine verteilte Portgruppe<block ref="b792ce2538db0b838bb1f2cd727d3417" prefix=" " category="inline-code"></block> Soll das NFS-Netzwerk von ONTAP Select und der Applikation verwendet werden.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">Als Nächstes konfigurieren Sie NetApp H615c (manuelle Implementierung)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SE350-Server und Details zur Storage-Bereitstellung beschrieben.</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">Zurück: Testplan</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">Die folgende Abbildung zeigt die Testkonfiguration. Wir verwendeten das NetApp AFF C190 Storage-System und zwei Lenovo ThinkSystem SE350 Server (jeweils mit einem NVIDIA T4 Accelerator). Diese Komponenten sind über einen 10-GbE-Netzwerk-Switch verbunden. Der Netzwerk-Storage enthält Validierungs-/Testdatensätze und vortrainierte Modelle. Die Server liefern Berechnungsfunktion, und auf den Storage wird über das NFS-Protokoll zugegriffen.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">In diesem Abschnitt werden die getesteten Konfigurationen, die Netzwerkinfrastruktur, der SE350-Server und Details zur Storage-Bereitstellung beschrieben. In der folgenden Tabelle werden die Basiskomponenten für die Lösungsarchitektur aufgeführt.</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 SE350-Server mit jeweils einer NVIDIA T4-GPU-Karte</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Jeder Server enthält eine Intel Xeon D-2123IT CPU mit vier physischen Kernen mit 2,20 GHz und 128 GB RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">NetApp AFF Storage-System der Einstiegsklasse (HA-Paar)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 Software</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24 x 960-GB-SSDs</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Eine Schnittstellengruppe pro Controller, mit vier logischen IP-Adressen für Mount-Punkte</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">In der folgenden Tabelle ist die Storage-Konfiguration aufgeführt: AFF C190 mit 2RU, 24 Laufwerksschächten.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Controller</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregat</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup Volume</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Aggregatesize</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumize</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Systemeinhängungspunkt ausführen</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Kontroller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr. 1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/Netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8,42 tib</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr. 2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">Der Ordner /netappLenovo_AI_fg enthält die Datensätze, die für die Modellvalidierung verwendet werden.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">Die Abbildung unten zeigt die Testkonfiguration. Wir verwendeten das NetApp EF280 Storage-System und zwei Lenovo ThinkSystem SE350 Server (jeweils mit einem NVIDIA T4 Accelerator). Diese Komponenten sind über einen 10-GbE-Netzwerk-Switch verbunden. Der Netzwerk-Storage enthält Validierungs-/Testdatensätze und vortrainierte Modelle. Die Server liefern Berechnungsfunktion, und auf den Storage wird über das NFS-Protokoll zugegriffen.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">In der folgenden Tabelle wird die Storage-Konfiguration für EF280 aufgeführt.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Volume-Gruppe</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Datenmenge</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Verbindungsmethode</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Band 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 auf iSCSI-LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Lautstärke 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 auf iSCSI-LUN 1</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="0ae928f6b14175d27f45a4e5ad647657" category="doc">NVA-1151-DEPLOY: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-DEPLOY enthält Anleitungen zur Implementierung von Storage-Systemen für eine NetApp Verified Architecture (NVA) für Machine Learning (ML) und KI-Workloads (künstliche Intelligenz) mit NetApp AFF A800 Storage-Systemen, NVIDIA DGX A100-Systemen und NVIDIA Mellanox Netzwerk-Switches. Außerdem enthält er Anweisungen zum Ausführen von Validierungs-Benchmark-Tests nach Abschluss der Implementierung.</block>
  <block id="213372f55b01b1d34de9624d7447ce72" category="inline-link-macro"><block ref="213372f55b01b1d34de9624d7447ce72" category="inline-link-rx"></block></block>
  <block id="f66a35643d6d6ce9bd6be71845a54cf8" category="paragraph"><block ref="f66a35643d6d6ce9bd6be71845a54cf8" category="inline-link-macro-rx"></block></block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915: Datenverschiebung mit E-Series und BeeGFS für KI- und Analyse-Workflows</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">Cody Harryman und Ryan Rodine, NetApp</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">TR-4915 beschreibt, wie Daten aus einem beliebigen Daten-Repository in ein BeeGFS Filesystem verschoben werden, das durch SAN-Storage der NetApp E-Series unterstützt wird. Bei Applikationen für künstliche Intelligenz (KI) und Machine Learning (ML) müssen Kunden daher möglicherweise routinemäßig große Datensätze von mehr als vielen Petabyte an Daten in ihre BeeGFS Cluster verschieben, um Modelle zu entwickeln. In diesem Dokument wird erläutert, wie Sie dies mithilfe von NetApp XCP und NetApp Cloud Sync Tools erreichen.</block>
  <block id="69735c95d12121c6a49bf7078822f1a5" category="inline-link-macro"><block ref="69735c95d12121c6a49bf7078822f1a5" category="inline-link-rx"></block></block>
  <block id="85f5a6a68a78eee054d216895dfe53a9" category="paragraph"><block ref="85f5a6a68a78eee054d216895dfe53a9" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">Auf dieser Seite sind die Vorteile von Azure NetApp Files bei Schulungen mit verteilter oder großer Schulungseinheiten zusammengefasst.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">Anwendungsbeispiel für die Click-Through-Rate-Prognose</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Früher: Anforderungen an Cloud-Ressourcen.</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">Terabyte Auf Protokolle Klicken</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo AI Lab</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">Dieser Anwendungsfall basiert auf dem öffentlich zugänglichen<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> Datensatz von<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. Aufgrund der jüngsten Fortschritte BEI ML-Plattformen und -Applikationen wird jetzt viel Aufmerksamkeit auf das Lernen in großen Umgebungen gerichtet. Die Klickrate (Klickrate, CTR) ist definiert als die durchschnittliche Anzahl der Klickrate pro hundert Online-Werbeeindrücke (ausgedrückt als Prozentsatz). Es wird in verschiedenen Branchen und Anwendungsfällen, darunter digitales Marketing, Einzelhandel, E-Commerce und Service-Provider, häufig als wichtige Metrik eingeführt. Beispiele für die Verwendung von CTR als wichtige Kennzahl für potenziellen Kundenverkehr sind:</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google Analytics</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">Anzeigeneinstufung</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">*Digital Marketing:* in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR kann verwendet werden, um zu messen, wie gut ein Werbetreibender oder Kaufmann die Keywords, Anzeigen und kostenlose Angebote durchführen. Ein hoher CTR ist ein guter Hinweis darauf, dass Benutzer Ihre Anzeigen und Inserate hilfreich und relevant finden. CTR trägt auch zu Ihrem Keyword erwartet CTR, die eine Komponente von ist<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">*E-Commerce:* Neben der Nutzung<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>, Es gibt mindestens einige Besucherstatistiken in einem E-Commerce-Backend. Obwohl diese Statistiken auf den ersten Blick nicht nützlich erscheinen, sind sie in der Regel leicht zu lesen und können genauer als andere Informationen sein. Datensätze von Erstanbietern, die sich aus diesen Statistiken zusammensetzt, sind vertraulich und daher am wichtigsten für E-Commerce-Verkäufer, Käufer und Plattformen. Diese Datensätze können zur Festlegung von Benchmarks verwendet und mit dem Ergebnis vom letzten Jahr und von gestern verglichen werden, indem eine Zeitreihe zur weiteren Analyse erstellt wird.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">*Einzelhandel:* stationäre Einzelhändler können die Anzahl der Besucher und die Anzahl der Kunden mit dem CTR korrelieren. Die Anzahl der Kunden kann aus ihrer Verkaufsgeschichte ersichtlich werden. Die CTR von den Webseiten des Einzelhändlers oder Werbeverkehr kann zu den oben genannten Verkäufen führen. Treueprogramme sind ein weiterer Anwendungsfall, weil Kunden von Online-Anzeigen oder anderen Websites umgeleitet werden könnten, um Belohnungen zu verdienen. Einzelhändler können Kunden über Treueprogramme gewinnen und Verhaltensweisen aus Verkaufsprogrammen aufzeichnen, um ein Empfehlungssystem zu entwickeln, das nicht nur das Kaufverhalten der Verbraucher in verschiedenen Kategorien prognostiziert, sondern auch Coupons personalisiert und Abgänge verringert.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">*Service-Provider:* Telekommunikationsunternehmen und Internet-Service-Provider haben eine Fülle an Telemetriedaten von Erstbenutzern für aufschlussreiche KI-, ML- und Analytics-Anwendungsfälle. So kann ein Telekommunikationsanbieter beispielsweise täglich die Protokolle der Top-Level-Domain-Historie seiner mobilen Abonnenten nutzen, um vorhandene Modelle zu optimieren, um eine aktuelle Segmentierung der Zielgruppe zu erstellen, das Kundenverhalten vorherzusagen und mit Werbetreibenden zusammenzuarbeiten, um Anzeigen in Echtzeit zu platzieren, um ein besseres Online-Erlebnis zu ermöglichen. In einem solchen datengesteuerten Marketing-Workflow ist CTR eine wichtige Kennzahl, um Konvertierungen widerzuspiegeln.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Criteo Terabyte Klicken Sie Auf Protokolle</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">Im Rahmen des digitalen Marketings<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> Sind jetzt der Referenzdatensatz zur Bewertung der Skalierbarkeit VON ML-Plattformen und -Algorithmen. Mit der Prognose der Klickrate kann ein Werbetreibender die Besucher auswählen, die am ehesten auf die Werbeanzeigen antworten, seinen Browserverlauf analysieren und die relevantesten Werbeanzeigen basierend auf den Interessen des Benutzers anzeigen.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">Die in diesem technischen Bericht bereitgestellte Lösung hebt die folgenden Vorteile hervor:</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Vorteile von Azure NetApp Files bei verteilten oder umfassenden Schulungen</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RAPIDS CUDA-fähige Datenverarbeitung (cuDF, cuPy usw.) und ML-Algorithmen (cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">Das Parallel Computing Framework für verteilte Schulungen</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Ein umfassender Workflow auf Basis VON RAPIDS AI und Azure NetApp Files zeigt eine drastische Verbesserung des Trainings für zufällige Waldmodelle im zwei Größenordnungen. Diese Verbesserung ist im Vergleich zum herkömmlichen Pandas-Ansatz signifikant, wenn es um real-world click Logs mit 45GB strukturierter tabellarischer Daten (im Durchschnitt) jeden Tag geht. Dies entspricht einem DataFrame mit etwa zwanzig Milliarden Zeilen. In diesem technischen Bericht werden die Einrichtung einer Cluster-Umgebung, die Installation eines Framework und einer Bibliothek, das Laden und die Verarbeitung von Daten, das konventionelle oder verteilte Training, die Visualisierung und das Monitoring demonstriert und die kritischen Ergebnisse der End-to-End-Laufzeit verglichen.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">Als nächstes: Installieren und einrichten Sie das aks Cluster.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">Testdetails für Abschnitt 4.10</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">Dieser Abschnitt enthält Testdetails für den Abschnitt <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">Senden von Jobs in der folgenden Reihenfolge für<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>:</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 Workload in Warteschlange</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 Workloads in Warteschlange</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">Zwei Workloads erfordern GPUs (je zwei)</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">Zwei Workloads erfordern jeweils zwei GPUs</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">Löschen Sie dann alle Workloads für<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block>:</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">Siehe Abschnitt <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, Für Diskussionen über das Fortsetzen des Testszenarios.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="8ada98332d4bde2905136eacd122ca17" category="doc">NVA-1150-DESIGN: Quantum StorNext with NetApp E-Series Systems Design Guide</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Dieses Dokument enthält genaue Informationen zur Entwicklung einer StorNext parallelen File-System-Lösung mit NetApp E-Series Storage-Systemen. Diese Lösung umfasst das NetApp EF280 All-Flash-Array, das NetApp EF300 All-Flash-NVMe-Array, das EF600 All-Flash-NVMe-Array und das NetApp E5760 Hybrid-System. Es bietet Leistungscharakterisierungen auf Basis von Frametest Benchmarking, einem Tool, das für Tests in der Medien- und Unterhaltungsbranche weit verbreitet ist.</block>
  <block id="8d34cd86db3dd46b4c83d32098f9f458" category="inline-link-macro"><block ref="8d34cd86db3dd46b4c83d32098f9f458" category="inline-link-rx"></block></block>
  <block id="580fb8819de48faa426f431251c8b4db" category="paragraph"><block ref="580fb8819de48faa426f431251c8b4db" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Für diese Validierung haben wir mithilfe eines Satzes an RAW-Bildern Inferenz für einen Anwendungsfall der Bilderkennung durchgeführt. Dann führten wir dieselbe Inferenzaufgabe auf demselben Bildersatz durch, wobei vor der Inferenz die Protopia-Obfuskation hinzugefügt wurde. Wir haben die Aufgabe mit unterschiedlichen Werten VON ALPHA für die Komponente Protopia obfuscation wiederholt.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Vergleich der Inferenzgenauigkeit</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Für diese Validierung haben wir mithilfe eines Satzes an RAW-Bildern Inferenz für einen Anwendungsfall der Bilderkennung durchgeführt. Dann führten wir dieselbe Inferenzaufgabe auf demselben Bildersatz durch, wobei vor der Inferenz die Protopia-Obfuskation hinzugefügt wurde. Wir haben die Aufgabe mit unterschiedlichen Werten VON ALPHA für die Komponente Protopia obfuscation wiederholt. Im Zusammenhang mit der Protopia-Obfuskation stellt der ALPHA-Wert die Menge der aufgetragenen Obfuskation dar, wobei ein höherer ALPHA-Wert ein höheres Maß an Obfuskation darstellt. Dann haben wir die Genauigkeit der Inferenz in diesen verschiedenen Durchläufen verglichen.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Die folgenden beiden Tabellen enthalten Details zu unserem Anwendungsfall und geben die Ergebnisse an.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia arbeitet direkt mit den Kunden zusammen, um den passenden ALPHA-Wert für einen bestimmten Anwendungsfall zu ermitteln.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes (PyTorch) -</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Datensatz</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB-Datensatz</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Protopia obfuscation</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALPHA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Genauigkeit</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Nein</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">K. A.</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Ja.</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">Weiter: Obfuskationsgeschwindigkeit.</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">Betrieb und Performance dieses Systems haben wir mithilfe von Benchmark-Tools TensorFlow Benchmarks der Branche validiert. Der ImageNet-Datensatz wurde für das Training von ResNet-50 verwendet, einem berühmten Convolutional Neural Network (CNN) DL-Modell für die Bildklassifizierung. ResNet-50 erzielt ein präzises Trainingsergebnis mit einer schnelleren Verarbeitungszeit, was uns ermöglicht, einen ausreichenden Bedarf an Storage zu steigern.</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">In diesem Abschnitt wird beschrieben, wie Sie das AKS-Vnet mit dem Azure NetApp Files-vnet in Kontakt setzen.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">Peer AKS vnet und Azure NetApp Files vnet</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">Zurück: Erstellen Sie ein delegiertes Subnetz für Azure NetApp Files.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">Gehen Sie wie folgt vor, um das AKS-Vnet an das Azure NetApp Files-Netz anzugleichen:</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">Geben Sie im Suchfeld virtuelle Netzwerke ein.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">Wählen Sie<block ref="c5d2d918f55de1b8309376bc0310c265" prefix=" " category="inline-code"></block> Klicken Sie darauf und geben Sie im Suchfeld Peerings ein.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">Klicken Sie Auf + Hinzufügen.</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">Geben Sie die folgenden Deskriptoren ein:</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">Der Peering-Linkname ist<block ref="5d43607a5a0ebb50f3ea9348485daa15" prefix=" " category="inline-code"></block>.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">SubscriptionID und Azure NetApp Files vnet als vnet Peering-Partner.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">Lassen Sie alle nicht-Sternchen-Abschnitte mit den Standardwerten zurück.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Klicken Sie Auf Hinzufügen.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">Weitere Informationen finden Sie unter<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">Als Nächstes: Trident Installieren.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">Stellen Sie eine Verbindung zu APIs von Drittanbietern als Fulfillment Engine her</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">Wir haben die folgenden Drittanbieter-APIs als Fulfillment Engine verbunden, um Fragen zu beantworten:</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: Gibt das Wetter, die Temperatur, den Niederschlag und den Schnee an einem bestimmten Ort zurück.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion-API</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: Gibt die nächstgelegenen Informationen an einem bestimmten Ort zurück.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">EBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: Gibt den Preis eines bestimmten Artikels zurück.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">Weiter: Demonstration des NetApp Retail Assistant</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">Senden von Jobs in Run:AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">Dieser Abschnitt enthält die Details zum grundlegenden Befehl „Run:AI“, mit denen Sie jeden Kubernetes-Job ausführen können. Je nach Workload-Typ in drei Teile unterteilt: KI/ML/DL-Workloads können in zwei generische Typen unterteilt werden:</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">*Nicht besuchte Schulungen*. Bei diesen Workloads bereitet der Data Scientist einen selbstständigen Workload auf und sendet ihn zur Ausführung. Während der Durchführung kann der Kunde die Ergebnisse untersuchen. Dieser Workload wird häufig in der Produktion verwendet oder wenn sich die Modellentwicklung zu einer Phase befindet, in der kein menschliches Eingreifen erforderlich ist.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">*Interaktive Build-Sitzungen*. Bei diesen Workloads öffnet der Data Scientist eine interaktive Sitzung mit Bash, Jupyter Notebook, Remote PyCharm oder ähnlichen IDEs und greift direkt auf GPU-Ressourcen zu. Wir fügen ein drittes Szenario für die Ausführung interaktiver Workloads mit angeschlossenen Ports ein, um dem Container-Benutzer einen internen Port zu zeigen.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">Unbeaufsichtigte Trainings-Workloads</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">Nachdem Sie Projekte eingerichtet und GPU(s) zugewiesen haben, können Sie jeden beliebigen Kubernetes-Workload mit dem folgenden Befehl an der Befehlszeile ausführen:</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">Mit diesem Befehl wird ein unbeaufsichtigter Schulungsauftrag für Team A mit einer Zuweisung einer einzelnen GPU gestartet. Der Job basiert auf einem Beispielbild für Docker.<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block>. Wir haben die Aufgabe genannt<block ref="b10f762d9445989813486accc082c6f1" prefix=" " category="inline-code"></block>. Sie können dann den Fortschritt des Jobs überwachen, indem Sie folgenden Befehl ausführen:</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">Die folgende Abbildung zeigt das Ergebnis des<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> Befehl. Folgende typische Status werden möglicherweise angezeigt:</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text"><block ref="8627ca3ad23f4fb9adc6ba05047004c6" prefix="" category="inline-code"></block>. Der Docker-Container wird aus dem Cloud-Repository heruntergeladen.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text"><block ref="2d13df6f8b5e4c5af9f87e0dc39df69d" prefix="" category="inline-code"></block>. Der Job wartet auf die Planung.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text"><block ref="5bda814c4aedb126839228f1a3d92f09" prefix="" category="inline-code"></block>. Der Job wird ausgeführt.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">Führen Sie den folgenden Befehl aus, um einen zusätzlichen Status für Ihren Job zu erhalten:</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">Um die Protokolle des Jobs anzuzeigen, führen Sie den aus<block ref="13be9f2fcfc2532531562b1e0c6dd431" prefix=" " category="inline-code"></block> Befehl:</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">In diesem Beispiel sollten Sie das Protokoll einer laufenden DL-Sitzung sehen, einschließlich der aktuellen Trainingszeit, ETA, Wert der Verlustfunktion, Genauigkeit und Zeit, die für jeden Schritt verstrichen ist.</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">Der Cluster-Status kann in der Benutzeroberfläche „Run:AI“ von angezeigt werden<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. Unter Dashboards &gt; Übersicht können Sie die GPU-Auslastung überwachen.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">Um diesen Workload zu beenden, führen Sie den folgenden Befehl aus:</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">Unbeaufsichtigte Trainings-Workloads starten</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">Dieser Befehl stoppt den Trainings-Workload. Sie können diese Aktion überprüfen, indem Sie ausführen<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> Ein weiteres Jahr in der Weitere Informationen finden Sie unter<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">Interaktive Build-Workloads</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">Nach dem Einrichten von Projekten und der Zuweisung von GPU(s) können Sie einen interaktiven Build-Workload mit dem folgenden Befehl in der Befehlszeile ausführen:</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">Der Job basiert auf einer Beispieldatei-Bildpython. Wir nannten den Job build1.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">Der<block ref="1f21ac5e64afff9d56d5047ace21ffd8" prefix=" " category="inline-code"></block> Flag bedeutet, dass der Job kein Start oder Ende hat Es liegt in der Verantwortung des Forschers, den Job zu schließen. Der Administrator kann ein Zeitlimit für interaktive Jobs festlegen, nach denen sie vom System beendet werden.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">Der<block ref="41edd6984c1a14599f6d54cd297a423e" prefix=" " category="inline-code"></block> Flag weist diesem Job eine einzelne GPU zu. Der Befehl und das angegebene Argument lautet<block ref="f18e9c054b4fccbc27cd764cb472a213" prefix=" " category="inline-code"></block>. Sie müssen einen Befehl angeben, oder der Container startet und wird sofort beendet.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">Die folgenden Befehle funktionieren ähnlich wie die in beschriebenen Befehle <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text"><block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix="" category="inline-code"></block>: Zeigt den Namen, Status, Alter, Knoten, Bild, Projekt, Benutzer und GPUs für Jobs.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text"><block ref="1051ced5efff9d2868a1edd38f951e6e" prefix="" category="inline-code"></block>: Zeigt zusätzlichen Status im Job build1 an.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text"><block ref="624c1f4b1937b32c12cfa1346cb037f9" prefix="" category="inline-code"></block>: Stoppt die interaktive Arbeitslast build1.um eine Bash-Shell in den Container zu bekommen, den folgenden Befehl:</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">Dadurch wird eine direkte Shell in den Computer integriert. Data Scientists können dann ihre Modelle innerhalb des Containers entwickeln oder feinfinden.</block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">Starten und Verwenden interaktiver Build-Workloads</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">Der Cluster-Status kann in der Benutzeroberfläche „Run:AI“ von angezeigt werden<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. Weitere Informationen finden Sie unter<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">Interaktive Workloads mit verbundenen Ports</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">Eindringen</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Als Erweiterung von interaktiven Build-Workloads können Sie dem Container-Benutzer interne Ports beim Starten eines Containers mit der Run:AI-CLI offenbaren. Dies ist nützlich für Cloud-Umgebungen, die Arbeit mit Jupyter Notebooks oder die Verbindung zu anderen Microservices.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Zugriff auf Kubernetes-Services von außerhalb des Kubernetes-Clusters aus. Sie können den Zugriff konfigurieren, indem Sie eine Sammlung von Regeln erstellen, die definieren, welche eingehenden Verbindungen welche Dienste erreichen.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">Für eine bessere Verwaltung des externen Zugriffs auf die Services in einem Cluster empfehlen wir, Cluster-Administratoren zu installieren<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Und konfigurieren den Load Balancer.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">Um Ingress als Servicetyp zu verwenden, führen Sie den folgenden Befehl aus, um den Methodentyp und die Ports beim Senden des Workloads festzulegen:</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">Nachdem der Container erfolgreich gestartet wurde, führen Sie die Ausführung aus<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> Um den anzuzeigen<block ref="8d6518907bf83f7ae243a42bc2d2daba" prefix=" " category="inline-code"></block> Mit dem auf das Jupyter Notebook zugegriffen werden kann. Die URL setzt sich aus dem Ingress-Endpunkt, dem Job-Namen und dem Port zusammen. Siehe zum Beispiel<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">Starten eines interaktiven Build-Workloads mit verbundenen Ports</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">Weitere Informationen finden Sie unter<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">Next: Erreichen Einer Hohen Cluster-Auslastung</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">Dieser Abschnitt beschreibt die detaillierten Schritte, die zur Implementierung dieser Lösung erforderlich sind.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">Bereitstellung der Sentimentanalyse des Support Centers</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">Früher: Designüberlegungen.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">Zum Einsatz der Lösung gehören die folgenden Komponenten:</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC-Konfiguration</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA RIVA Server</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO Toolkit</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">Exportieren Sie TAO-Modelle nach RIVA</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">Um eine Implementierung durchzuführen, gehen Sie wie folgt vor:</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps Toolkit: Die Stimmungsanalyse im Support Center</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">Um die zu verwenden<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Vervollständigen Sie die folgenden Schritte:</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP installieren Sie das Toolkit.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">Konfigurieren des Datenmanagements</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC-Konfiguration: Support Center-Sentiment-Analyse</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">Zur Einrichtung<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>, Vervollständigen Sie die folgenden Schritte:</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">NGC herunterladen</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">Fügen Sie Ihr aktuelles Verzeichnis zum Pfad hinzu.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">Sie müssen NGC-CLI für Ihren Gebrauch konfigurieren, damit Sie die Befehle ausführen können. Geben Sie bei der entsprechenden Aufforderung den folgenden Befehl ein, einschließlich Ihres API-Schlüssels.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">Hier</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Für nicht Linux-basierte Betriebssysteme finden Sie unter<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA RIVA Server: Support Center Sentiment Analyse</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">Zur Einrichtung<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>, Vervollständigen Sie die folgenden Schritte:</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">Laden Sie DIE RIVA-Dateien von NGC herunter.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">RIVA-Setup initialisieren <block ref="b57bfc797452f0a8f165771280704dc4" prefix="(" category="inline-code"></block>).</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Starten Sie DEN RIVA-Server <block ref="9578e0f1e91365703f275dd0aa9dd913" prefix="(" category="inline-code"></block>).</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Starten Sie DEN RIVA-Client <block ref="98e192e15ed3b76551ab5ef8d11ef1e8" prefix="(" category="inline-code"></block>).</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFMPEG</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Installieren Sie im RIVA-Client die Audio-Processing-Library (<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">Starten Sie den<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> Server:</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Führen Sie das RIVA Inferenz Pipeline Notebook aus.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit: Sentimentanalyse im Supportcenter</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">Gehen Sie wie folgt vor, um das NVIDIA TAO Toolkit einzurichten:</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">Virtualisierten Umgebung von</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">Vorbereiten und Aktivieren eines<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> Für TAO Toolkit.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">Erforderliche Pakete</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">Installieren Sie den<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">Ziehen Sie das während des Trainings und der Feinabstimmung verwendete Bild manuell ab.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">Führen Sie das TAO Fine-Tuning Notebook aus.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">Export von TAO-Modellen nach RIVA: Sentimentanalyse im Supportzentrum</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">TAO Toolkit Modelle in RIVA</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">Zu verwenden<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>, Vervollständigen Sie die folgenden Schritte:</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">Speichern Sie Modelle im TAO Fine-Tuning Notebook.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">Kopieren Sie TAO-trainierte Modelle in das RIVA-Modellverzeichnis.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">Hürden auf dem Weg zur Implementierung</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">Bitte beachten Sie folgende Punkte bei der Entwicklung Ihrer eigenen Lösung:</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">Das NetApp DataOps Toolkit wird zuerst installiert, um sicherzustellen, dass das Storage-System optimal läuft.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC muss vor allem installiert sein, weil es das Herunterladen von Bildern und Modellen authentifiziert.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">RIVA muss vor dem TAO Toolkit installiert werden. Die RIVA-Installation konfiguriert den Docker-Daemon so, dass Bilder nach Bedarf abgerufen werden.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX und Docker müssen über Internetzugang verfügen, um die Modelle herunterladen zu können.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">Weiter: Validierungsergebnisse.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="32940041bf5093eb48af6ffae914f8cc" category="doc">NVA-1156-DESIGN: NetApp EF-Series AI mit NVIDIA DGX A100 Systems und BeeGFS</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick und David Arnette, NetApp</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">NVA-1156-DESIGN beschreibt eine NetApp Verified Architecture für Machine-Learning- (ML) und AI-Workloads (künstliche Intelligenz) mit NetApp EF600 NVMe-Storage-Systemen, dem BeeGFS Parallel Filesystem, NVIDIA DGX A100-Systemen und NVIDIA Mellanox Quantum QM8700 200 Gbps IB-Switches. Dieses Design verfügt über 200 Gbit/s InfiniBand (IB) für die Storage- und Compute-Cluster Interconnect-Fabric und bietet damit eine vollständig auf IB basierende Architektur für hochperformante Workloads. Dieses Dokument enthält außerdem Benchmark-Testergebnisse für die implementierte Architektur.</block>
  <block id="aca17de13a4a5756ad91fcaa1eac2f32" category="inline-link-macro"><block ref="aca17de13a4a5756ad91fcaa1eac2f32" category="inline-link-rx"></block></block>
  <block id="62d0bf89b3e7ccd1a8242fc23544a5a4" category="paragraph"><block ref="62d0bf89b3e7ccd1a8242fc23544a5a4" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">Diese Seite beschreibt, wie wir Pandas und DataFrames zum Laden von Click Logs Daten aus dem Criteo Terabyte Datensatz verwendet haben. Der Anwendungsfall ist in der digitalen Werbung relevant, damit Anzeigenaustausch Nutzer-Profile bauen kann, indem er vorhersagt, ob Werbeanzeigen angeklickt werden oder wenn der Austausch kein genaues Modell in einer automatisierten Pipeline verwendet.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Criteo Click Logs Tag 15 in Pandas laden und ein scikit-Learn Zufallswaldmodell trainieren</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Früher: Bibliotheken für die Datenverarbeitung und Modellschulung.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">In diesem Abschnitt wird beschrieben, wie wir Pandas und DataFrames zum Laden von Click Logs-Daten aus dem Criteo Terabyte-Datensatz verwendet haben. Der Anwendungsfall ist in der digitalen Werbung relevant, damit Anzeigenaustausch Nutzer-Profile bauen kann, indem er vorhersagt, ob Werbeanzeigen angeklickt werden oder wenn der Austausch kein genaues Modell in einer automatisierten Pipeline verwendet.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Wir haben Tag 15 Daten aus dem Click Logs Datensatz geladen, insgesamt 45GB. Ausführen der folgenden Zelle im Jupyter-Notebook<block ref="687d69c323eb8500d21df9bfb49c3b55" prefix=" " category="inline-code"></block> Erstellt einen Pandas DataFrame, der die ersten 50 Millionen Zeilen enthält und ein scikit-Learn Zufallswaldmodell erzeugt.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">Offizielle Scikit-Learn-Dokumentation</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">Führen Sie den folgenden Abschnitt in diesem Notizbuch aus, um eine Vorhersage mit einem trainierten zufälligen Waldmodell durchzuführen. Wir haben die letzten 1 Million Zeilen ab Tag 15 als Testsatz genommen, um mögliche Duplikate zu vermeiden. Die Zelle berechnet auch die Genauigkeit der Vorhersage, definiert als Prozentsatz der Vorkommen das Modell sagt genau aus, ob ein Benutzer auf eine Anzeige klickt oder nicht. Informationen zu unbekannten Komponenten in diesem Notebook finden Sie im<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">Nächster: Lade Tag 15 in Damsk und trainiere ein Dusk CuML Zufallswaldmodell.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Dieses Dokument folgt dem Code MLPerf Inferenz v0.7, dem MLPerf-Inferenz v1.1-Code und den Regeln. Die Benchmarks für den Inferenz am Edge wurden ausgeführt, wie in den in diesem Abschnitt dargestellten Tabellen definiert.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Testplan</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">Regeln</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Dieses Dokument folgt MLPerf Inferenz v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, MLPerf Inferenz v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, und<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. Wir führten MLPerf-Benchmarks aus, die für die Inferenz am Rand entwickelt wurden, wie in der folgenden Tabelle definiert.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">Werden</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Aufgabe</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL-Größe</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualität</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">Einschränkung der Latenz bei mehreren Streams</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Vision</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Bildklassifizierung</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet (24 x 224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99 % des FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Objekterkennung (groß)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD - Wiedereinsetzen Net34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200 x 1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Objekterkennung (klein)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD- MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentierung von medizinischem Bildmaterial</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D-UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">Briats 2019 (22x24 x 2160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99 % und 99.9 % des FP32</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">k. A.</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Sprache</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Sprache-zu-Text</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Sprache</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Sprachverarbeitung</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">BERT</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Kader v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">In der folgenden Tabelle sind Edge Benchmark-Szenarien aufgeführt.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Szenarien</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Bildklassifizierung</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Single Stream, offline, Multistream</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Single Stream offline</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Diese Benchmarks wurden mithilfe der im Rahmen dieser Validierung entwickelten Netzwerk-Storage-Architektur durchgeführt und mit denen von lokalen Ausführung auf den Edge-Servern verglichen, die zuvor MLPerf vorgelegt wurden. Der Vergleich soll ermitteln, welche Auswirkungen der Shared Storage auf die Inferenz-Performance hat.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX-Systeme</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1-System<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor Core GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">Run:KI-Container-Orchestrierungslösung</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">Run:KI: Produktvorstellung<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">Run:AI Installationsdokumentation<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Senden von Jobs in Run:AI CLI<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">Zuordnen von GPU-Fraktionen in Run:AI-CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">Technischer Bericht<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">Kurzform-Demo<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub Repository<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A-Series – Datenblatt<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">NetApp Flash Advantage für All Flash FAS<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 Informationsbibliothek<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">Technischer Bericht zu NetApp ONTAP FlexGroup Volumes<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Cisco Networking<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">ONTAP AI mit DGX-1 und Cisco Networking Deployment Guide<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-1 und Mellanox Networking<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">Design-Leitfaden: ONTAP AI mit DGX-2<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">Die von NetApp und NVIDIA entwickelte und verifizierte NetApp ONTAP KI Architektur basiert auf NVIDIA DGX Systemen und Cloud-vernetzten NetApp Storage-Systemen. Diese Referenzarchitektur bietet IT-Abteilungen folgende Vorteile:</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Zahlreiche Storage-Optionen für diverse Performance- und Kostenpunkte werden angeboten</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI integriert DGX-Systeme und NetApp AFF A800 Storage-Systeme nahtlos in hochmoderne Netzwerke. Mithilfe von NetApp ONTAP AI und DGX-Systemen können Komplexität und Unsicherheiten bei der Systemaufsetzung beseitigt werden, was den Einsatz von KI-Projekten vereinfacht. Kunden können mit einer kleinen Installation starten und ihre Systeme unterbrechungsfrei erweitern. Gleichzeitig erhalten sie intelligente Datenmanagement-Funktionen, mit denen sich Daten zwischen Datenaufnahme, zentraler Datenplattform und Cloud frei verschieben lassen.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp AI Control Plane ist eine Daten- und Experimentmanagementlösung für Data Scientists und Data Engineers, eine Full-Stack-KI, ML und Deep Learning (DL). Beim zunehmenden Einsatz von KI sehen sich Unternehmen vielen Herausforderungen gegenüber, darunter Workload-Skalierbarkeit und Datenverfügbarkeit. NetApp AI Control Plane bewältigt diese Herausforderungen mithilfe von Funktionalitäten, z. B. dem schnellen Klonen eines Daten-Namespace wie bei einer Git-Revo, und dem Definieren und Implementieren von KI-Trainings-Workflows, die die nahezu sofortige Erstellung von Daten- und Modellbasiden für die Rückverfolgbarkeit und Versionierung umfassen. Mit der NetApp AI Control Plane können Sie Daten nahtlos über Standorte und Regionen hinweg replizieren und rasch Jupyter Notebook-Workspaces mit Zugriff auf riesige Datensätze bereitstellen.</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">Run:AI hat die weltweit erste Orchestrierungs- und Virtualisierungsplattform für KI-Infrastrukturen entwickelt. Durch Abstrahieren von Workloads von der zugrunde liegenden Hardware erzeugt Run:AI einen gemeinsamen Pool von GPU-Ressourcen, der dynamisch bereitgestellt werden kann. So wird eine effiziente Orchestrierung von KI-Workloads und eine optimierte Verwendung von GPUs ermöglicht. Data Scientists können reibungslos große Mengen von GPU-Leistung verbrauchen, um ihre Forschung zu verbessern und zu beschleunigen. Gleichzeitig behalten IT-Teams die zentrale, standortübergreifende Kontrolle und die Echtzeittransparenz bei der Ressourcenbereitstellung, Warteschlangen und Auslastung. Die Run:AI Plattform baut auf Kubernetes auf und ermöglicht dadurch eine einfache Integration in vorhandene IT- und Data-Science-Workflows.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Die Plattform Run:AI bietet folgende Vorteile:</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">*Schnellere Innovationszeit.* durch den Einsatz von Run:AI Ressourcen-Pooling, Warteschlangen und Priorisierungsmechanismen in Kombination mit einem NetApp Storage-System fallen Forscher weg vom Infrastrukturmanagement und können sich ausschließlich auf Data Science konzentrieren. Run:KI und NetApp Kunden steigern die Produktivität, indem sie genau so viele Workloads ohne Engpässe bei Computing oder Daten-Pipeline ausführen.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">*Höhere Teamproduktivität.* Run:AI Fairness Algorithmen garantieren, dass alle Nutzer und Teams ihren gerechten Anteil an Ressourcen erhalten. Richtlinien für vorrangige Projekte können voreingestellt werden, und die Plattform ermöglicht die dynamische Zuweisung von Ressourcen von einem Benutzer oder Team zu einem anderen, so dass Benutzer rechtzeitig auf begehrte GPU-Ressourcen zugreifen können.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">*Verbesserte GPU-Auslastung.* der Run:AI Scheduler ermöglicht Benutzern die einfache Verwendung von fraktionalen GPUs, ganzzahligen GPUs und mehreren GPUs für Distributed-Training auf Kubernetes. Auf diese Weise werden KI-Workloads basierend auf Ihren Anforderungen ausgeführt, nicht auf der Kapazität. Data-Science-Teams können mehr KI-Experimente in der gleichen Infrastruktur ausführen.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">Run:AI Installation</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">So installieren Sie Run:AI:</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">Installieren Sie den Kubernetes-Cluster mit DeepOps und konfigurieren Sie die NetApp Standard-Storage-Klasse.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">GPU-Nodes vorbereiten:</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">Vergewissern Sie sich, dass NVIDIA-Treiber auf GPU-Nodes installiert sind.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">Verifizieren Sie das<block ref="03550f513b5eb839088628d4a360b865" prefix=" " category="inline-code"></block> Ist als Standard-Docker-Laufzeit installiert und konfiguriert.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">Install-Run:KI:</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">Ausführung:KI-Admin-UI</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">Melden Sie sich bei an<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> Um den Cluster zu erstellen.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">Laden Sie das erstellte herunter<block ref="6b351eac623bdfae151b8db2b05a8131" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Wenden Sie die Bedienerkonfiguration auf das Kubernetes-Cluster an.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">Überprüfen Sie die Installation:</block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">Gehen Sie zu<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">Wechseln Sie zum Dashboard „Übersicht“.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Installieren von Run:AI in einem lokalen Kubernetes-Cluster</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Installieren der Run:AI-CLI</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">Überprüfen Sie, ob die Anzahl der GPUs oben rechts die erwartete Anzahl von GPUs und die GPU-Nodes alle in der Liste der Server vorhanden sind.Weitere Informationen zu Run:KI-Implementierung finden Sie unter<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> Und<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">Als Nächstes: Führen Sie AI-Dashboards und -Ansichten aus</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">In diesem Abschnitt werden die Design-Überlegungen für die verschiedenen Komponenten dieser Lösung beschrieben.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">Designüberlegungen</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">Design von Netzwerk und Computing</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">Je nach den Einschränkungen der Datensicherheit müssen alle Daten innerhalb der Infrastruktur des Kunden oder einer sicheren Umgebung verbleiben.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">Storage-Design</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">Das NetApp DataOps Toolkit dient als primärer Service für das Management von Storage-Systemen. Das DataOps Toolkit ist eine Python Library, mit der Entwickler, Data Scientists, DevOps Engineers und Data Engineers verschiedene Datenmanagement-Aufgaben ausführen können, zum Beispiel die nahezu sofortige Bereitstellung eines neuen Daten-Volumes oder einer JupyterLab Workspace, das nahezu sofortiges Klonen eines Daten-Volumes oder einer JupyterLab Workspace. Und nahezu sofortiges Snapshots eines Daten-Volumes oder einer JupyterLab Arbeitsumgebung für Rückverfolgbarkeit oder Baselining. Diese Python-Bibliothek kann entweder als Befehlszeilen-Utility oder als Bibliothek mit Funktionen verwendet werden, die in jedes Python-Programm oder Jupyter Notebook importiert werden können.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">RIVA Best Practices</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">Best Practices für Daten</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA bietet einige allgemeine Funktionen<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Zur Verwendung VON RIVA:</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">*Verwenden Sie möglichst verlustfreie Audioformate.* die Verwendung verlustbehafteten Codecs wie MP3 kann die Qualität verringern.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">*Erweitern Sie Trainingsdaten.* das Hinzufügen von Hintergrundgeräuschen zu Audio-Trainingsdaten kann zunächst die Genauigkeit verringern und gleichzeitig die Robustheit steigern.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">*Limit Vokabular Größe bei Verwendung von Scraped Text.* viele Online-Quellen enthalten Tippfehler oder Nebenpronomen und unübliche Wörter. Durch das Entfernen dieser Optionen kann das Sprachmodell verbessert werden.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">*Verwenden Sie möglichst eine minimale Abtastrate von 16 kHz.* Versuchen Sie es jedoch nicht erneut zu verteilen, da dadurch die Audioqualität verringert wird.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">Zusätzlich zu diesen Best Practices müssen Kunden Prioritäten beim Sammeln eines repräsentativen Beispieldatensatzes mit genauen Angaben zu jedem Schritt der Pipeline setzen. Anders ausgedrückt: Der Beispieldatensatz sollte proportional zu den angegebenen Eigenschaften entsprechen, die in einem Zieldatensatz beispielhaft genannt werden. Gleichermaßen sind es die Datensatzanschriften dafür verantwortlich, die Genauigkeit und die Schnelligkeit der Kennzeichnung auszugleichen, um die Qualität und Quantität der Daten zu maximieren. Beispielsweise sind für diese Supportcenter-Lösung Audiodateien, beschriftete Texte und Sentiment-Labels erforderlich. Die sequenzielle Natur dieser Lösung bedeutet, dass Fehler vom Anfang der Pipeline bis zum Ende weiterverbreitet werden Wenn die Audiodateien von schlechter Qualität sind, werden auch die Text-Transkriptionen und Sentiment-Labels sein.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">Diese Fehlerweitergabe gilt ähnlich für die Modelle, die auf diesen Daten geschult wurden. Wenn die Sentimentprognosen zu 100 % genau sind, aber das sprach-zu-Text-Modell schlecht funktioniert, dann wird die endgültige Pipeline durch die anfängliche Audio- zu-Text-Transkription begrenzt. Es ist wichtig, dass Entwickler die Leistung jedes Modells einzeln und als Bestandteil einer größeren Pipeline betrachten. In diesem speziellen Fall ist das Ziel, eine Pipeline zu entwickeln, die die Stimmung präzise vorhersagen kann. Daher ist die Gesamtmetrik, auf der die Pipeline beurteilt werden soll, die Genauigkeit der Gefühle, die die Sprache-zu-Text-Transkription direkt beeinflusst.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">Das NetApp DataOps Toolkit ergänzt die Pipeline für die Datenqualitätsüberprüfung durch den Einsatz seiner nahezu sofortigen Datenklontechnologie. Jede markierte Datei muss bewertet und mit den vorhandenen beschrifteten Dateien verglichen werden. Durch die Verteilung dieser Qualitätskontrollen auf verschiedene Datenspeichersysteme wird sichergestellt, dass diese Prüfungen schnell und effizient durchgeführt werden.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">Als Nächstes: Bereitstellung von Sentimentanalysen im Support-Center.</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">Bei der Erstellung eigener KI/ML-Pipelines ist die Konfiguration der Integration, Verwaltung, Sicherheit und Zugänglichkeit der Komponenten einer Architektur eine schwierige Aufgabe. Der Zugriff auf und die Kontrolle über ihre Umgebung für Entwickler stellt eine weitere Herausforderung dar.</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">Die Kombination aus NetApp und Iguazio vereint diese Technologien als Managed Services, um die Technologieeinführung zu beschleunigen und die Markteinführungszeit für neue KI/ML-Applikationen zu verkürzen.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Beispiel für Jupyter Notebooks und Kubeflow Pipelines</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">Beispiel für Notebooks und Pipelines</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">Der<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kann in Verbindung mit Kubeflow verwendet werden. Die Verwendung des NetApp Data Science Toolkit und Kubeflow bietet folgende Vorteile:</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">Data Scientists können erweiterte NetApp Datenmanagement-Vorgänge direkt über ein Jupyter Notebook ausführen.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Erweiterte Datenmanagement-Vorgänge von NetApp können mithilfe des Kubeflow Pipelines in automatisierte Workflows integriert werden.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow Beispiele</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">Siehe<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Im Abschnitt zum NetApp Data Science Toolkit GitHub Repository finden Sie weitere Informationen zur Verwendung des Toolkit mit Kubeflow.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">Weiter: Apache Airflow Deployment.</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="1cfaf5b4fb65d4736720e0bc9565006f" category="doc">NVA-1150-DEPLOY: Quantum StorNext with NetApp E-Series Systems Design Guide</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">Dieses Dokument enthält Details zur Implementierung einer StorNext parallelen File-System-Lösung mit NetApp E-Series Storage-Systemen. Diese Lösung umfasst das NetApp EF280 All-Flash-Array, das NetApp EF300 All-Flash-NVMe-Array, das NetApp EF600 All-Flash-NVMe-Array und das NetApp E5760 Hybrid-System. Es bietet Leistungscharakterisierungen auf Basis von Frametest Benchmarking, einem Tool, das für Tests in der Medien- und Unterhaltungsbranche weit verbreitet ist.</block>
  <block id="60e713e183b7355809395b78af237e3d" category="inline-link-macro"><block ref="60e713e183b7355809395b78af237e3d" category="inline-link-rx"></block></block>
  <block id="3da570d632857f468742bb9e82bb15bc" category="paragraph"><block ref="3da570d632857f468742bb9e82bb15bc" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Speichern von Daten in einem mit Trident bereitgestellten PersistenzVolume</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident ist ein vollständig unterstütztes Open-Source-Projekt, damit Sie die anspruchsvollen Persistenzanforderungen Ihrer Container-Applikationen erfüllen können. Daten können in ein mit Trident bereitgestelltes Kubernetes PersistentVolume (PV) gelesen und geschrieben werden. Hinzu kommen Daten-Tiering, Verschlüsselung, NetApp Snapshot Technologie, Compliance und hohe Performance der Datenmanagement-Software NetApp ONTAP.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">Verwendung von PVCs in einem vorhandenen Namespace</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident Dokumentation</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">Bei größeren KI-Projekten könnte es effizienter sein, dass unterschiedliche Container Daten in dasselbe Kubernetes PV lesen und schreiben. Zur Wiederverwendung einer Kubernetes Persistent Volume Claim (PVC) muss der Anwender bereits eine PVC erstellt haben. Siehe<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> Für Details zur Erstellung eines PVC. Hier ein Beispiel für die Wiederverwendung einer vorhandenen PVC:</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">Führen Sie den folgenden Befehl aus, um den Status des Jobs anzuzeigen<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block> Für Projekt<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>:</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">Sie sollten die PV /tmp/pvc1Mount auf sehen<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Job<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block>. Auf diese Weise können mehrere Container aus demselben Volume gelesen werden. Das ist hilfreich, wenn es mehrere konkurrierende Modelle in der Entwicklung oder in der Produktion gibt. Data Scientists können ein Modellensemble aufbauen und dann Vorhersageergebnisse durch Mehrheitsvotum oder andere Techniken kombinieren.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">Verwenden Sie Folgendes für den Zugriff auf die Container-Shell:</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">Anschließend können Sie das gemountete Volume prüfen und auf Ihre Daten innerhalb des Containers zugreifen.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">Diese Funktion zur Wiederverwendung von VES funktioniert mit NetApp FlexVol Volumes und NetApp ONTAP FlexGroup Volumes. Damit können Data Engineers flexiblere und robustere Datenmanagement-Optionen nutzen, um die NetApp Data Fabric nutzen zu können.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">In diesem Abschnitt werden die Jupyter Notebooks und andere für diese Lösung nützliche Ressourcen aufgeführt.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">Videos und Demos</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Zurück: Validierungsergebnisse.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">„Support-Center-Sentiment-Analysis-Pipeline.ipynb“</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">„Support-Center-Model-Transfer-Learning-and-Fine-Tuning.ipynb“</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">Es gibt zwei Notizbücher, die die Pipeline für die Sentiment-Analyse enthalten:<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> Und <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. Zusammen zeigen diese Notebooks, wie eine Pipeline entwickelt werden kann, um Support Center-Daten aufzunehmen und Gefühle aus jedem Satz zu extrahieren. Dabei verwenden sie hochmoderne Deep-Learning-Modelle, die auf die Daten des Benutzers abgestimmt sind.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">Support Center - Sentiment Analysis Pipeline.ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">Dieses Notizbuch enthält die Inferenz RIVA-Pipeline zum Einnehmen von Audio, Konvertieren in Text und Extrahieren von Gefühlen für die Verwendung in einem externen Dashboard. Datensatz wird automatisch heruntergeladen und verarbeitet, wenn dies noch nicht geschehen ist. Der erste Abschnitt im Notizbuch ist der Speech-to-Text, der die Konvertierung von Audiodateien in Text verarbeitet. Anschließend folgt der Abschnitt Sentiment Analysis, der für jeden Textsatz Einstellungen extrahiert und diese Ergebnisse in einem Format wie das vorgeschlagene Dashboard anzeigt.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">Dieses Notebook muss vor dem Modelltraining und der Feinabstimmung ausgeführt werden, da der MP3-Datensatz heruntergeladen und in das richtige Format umgewandelt werden muss.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Support Center - Modellschulung und Feinabstimmungs.ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">Die virtuelle TAO Toolkit-Umgebung muss vor Ausführung des Notebooks eingerichtet werden (Installationsanweisungen finden Sie im Abschnitt TAO Toolkit in der Befehlsübersicht).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">Dieses Notebook setzt auf das TAO Toolkit, um Deep-Learning-Modelle auf die Kundendaten abzustimmen. Wie beim vorherigen Notizbuch wird dieses in zwei Abschnitte für die Komponenten Speech-to-Text und Sentiment Analysis unterteilt. Jeder Abschnitt durchläuft die Datenverarbeitung, das Modelltraining und die Feinabstimmung, die Auswertung der Ergebnisse und den Modellexport. Schließlich gibt es einen Abschnitt für die Bereitstellung Ihrer beiden fein abgestimmten Modelle für die Verwendung in RIVA.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">In diesem Abschnitt erweitern wir das Szenario, in dem mehrere Teams Workloads einreichen und ihre Kontingente übertreffen. Auf diese Weise zeigen wir, wie Run:AI Fairness-Algorithmus Clusterressourcen entsprechend dem Verhältnis voreingestellter Quoten zuweist.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">Ziele für dieses Testszenario:</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">Warteschlangenmechanismus anzeigen, wenn mehrere Teams GPUs über ihre Kontingente anfordern</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">Zeigen Sie, wie das System einen fairen Anteil des Clusters zwischen mehreren Teams verteilt, die entsprechend dem Verhältnis zwischen ihren Quoten über ihrem Kontingent liegen, so dass das Team mit dem höheren Kontingent einen größeren Anteil der freien Kapazität erhält.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">Am Ende von <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, Es gibt zwei Workloads in die Warteschlange: Einen für<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und eins für<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>. In diesem Abschnitt werden zusätzliche Workloads Warteschlange gestellt.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">Testdetails für Abschnitt 4.10</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">Details wie Stellenausschreibungen, verwendete Container-Images und ausgeführte Befehlssequenzen finden Sie unter <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">Wenn alle Jobs gemäß Abschnitt gesendet werden <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>, Das System-Dashboard zeigt das an<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Alle haben mehr GPUs als ihre voreingestellten Quoten.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Belegt vier mehr GPUs als die voreingestellte Soft Quota (vier), wohingegen<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Jeder besetzen zwei mehr GPUs als ihre Soft-Quota (zwei). Das Verhältnis der zugewiesenen GPUs zu viel Kontingent entspricht dem ihrer voreingestellten Quote. Das liegt daran, dass das System das voreingestellte Kontingent als Referenz der Priorität verwendet und entsprechend bereitgestellt hat, wenn mehrere Teams mehr GPUs anfordern und ihre Quoten übertreffen. Ein solcher automatischer Lastausgleich ist Fairness und Priorisierung, wenn Datenwissenschaftler im Unternehmen aktiv an der Entwicklung und Produktion von KI-Modellen arbeiten.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">Das System beginnt, die Workloads anderer Teams in die Warteschlange zu stellen.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">Die Reihenfolge der Abwarteschlangen wird nach Fairness-Algorithmen festgelegt, so dass<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Erhalten Sie die gleiche Menge von Over-Quota GPUs (da sie eine ähnliche Quote haben), und<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Erhält eine doppelte Menge von GPUs, da ihre Quote doppelt so hoch ist wie die Quote von<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> Und<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">Die gesamte Zuweisung erfolgt automatisch.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">Daher sollte sich das System in folgenden Staaten stabilisieren:</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPUs zugewiesen</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">Vier GPUs über die Quote. Leere Warteschlange.</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">Zwei GPUs über dem Kontingent. Ein Workload in Warteschlange.</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">GPU verwendet überhaupt nicht; keine Workloads in der Warteschlange.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">Die folgende Abbildung zeigt die GPU-Zuweisung pro Projekt im Dashboard „Run:AI Analytics“ für die Abschnitte <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, und <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. Die einzelnen Zeilen in der Abbildung geben die Anzahl der GPUs an, die jederzeit für ein Data-Science-Team bereitgestellt werden. Wie wir sehen, weist das System GPUs dynamisch entsprechend den eingereichten Workloads zu. So können Teams im Cluster GPUs zur Verfügung stehen und Jobs entsprechend der Fairness vorbeugen, bevor sie endlich einen stabilen Zustand für alle vier Teams erreichen.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">Nächste Schritte: Speichern von Daten in einem mit Trident bereitgestellten PersistenzVolume</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Nutzen Sie NVIDIA NGC Software – Setup</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">Zuvor: NVIDIA NGC Software verwenden</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">In diesem Abschnitt werden die anfänglichen Einrichtungsaufgaben beschrieben, die durchgeführt werden müssen, um NVIDIA NGC Enterprise-Software in einer NVIDIA KI Enterprise-Umgebung zu nutzen.</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">Bevor Sie die in diesem Abschnitt beschriebenen Schritte ausführen, gehen wir davon aus, dass Sie die NVIDIA AI Enterprise Host-Software bereits implementiert haben. Befolgen Sie dazu die Anweisungen auf der <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> Seite.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Erstellen einer Ubuntu Gast-VM mit vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI Enterprise Deployment Guide</block>
  <block id="1d7d5c692ef1d70e3217e93bb16af99e" category="paragraph">Zunächst müssen Sie eine Ubuntu 20.04 Gast-VM mit vGPU erstellen. Um eine Ubuntu 20.04 Gast-VM mit vGPU zu erstellen, befolgen Sie die Anweisungen in der <block ref="f5168fb76d8813fb2707289c4637d2ea" category="inline-link-macro-rx"></block>.</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Laden Sie die NVIDIA Gast-Software herunter und installieren Sie sie</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Als Nächstes müssen Sie die erforderliche NVIDIA-Gastsoftware auf der Gast-VM installieren, die Sie im vorherigen Schritt erstellt haben. Befolgen Sie zum Herunterladen und Installieren der erforderlichen NVIDIA-Gastsoftware auf der Gast-VM die Anweisungen in den Abschnitten 5.1-5.4 in <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Wenn Sie die in Abschnitt 5.4 beschriebenen Verifizierungsaufgaben durchführen, müssen Sie möglicherweise ein anderes CUDA Container Image Version-Tag verwenden, da das CUDA Container-Image seit dem Schreiben des Handbuchs aktualisiert wurde. In unserer Validierung haben wir 'nvidia/cuda:11.0.3-base-ubuntu20.04' verwendet.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">KI-/Analytics-Framework-Container herunterladen</block>
  <block id="12a93794571377dc80b4be8c2f22349c" category="paragraph">Als Nächstes müssen Sie benötigte KI- oder Analyse-Framework-Container-Images von NVIDIA NGC herunterladen, damit diese in Ihrer Gast-VM verfügbar sein können. Befolgen Sie zum Herunterladen von Framework-Containern innerhalb der Gast-VM die Anweisungen im <block ref="26bd3715eff2817a0154bee58d883e27" category="inline-link-macro-rx"></block>.</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installation und Konfiguration des NetApp DataOps Toolkit</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Als Nächstes müssen Sie das NetApp DataOps Toolkit für herkömmliche Umgebungen innerhalb der Gast-VM installieren. Das NetApp DataOps Toolkit kann zur Verwaltung von horizontal skalierbaren Daten-Volumes auf Ihrem ONTAP System direkt aus dem Terminal innerhalb der Gast-VM verwendet werden. Führen Sie die folgenden Aufgaben aus, um das NetApp DataOps Toolkit in der Gast-VM zu installieren.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installieren Sie pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Melden Sie sich vom Gast-VM-Terminal ab und melden Sie sich dann erneut an.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Konfigurieren Sie das NetApp DataOps Toolkit. Um diesen Schritt abzuschließen, benötigen Sie API-Zugriffsdetails für Ihr ONTAP-System. Möglicherweise müssen Sie diese Informationen von Ihrem Storage-Administrator beziehen.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Erstellen einer Gast-VM-Vorlage</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Und schließlich müssen Sie eine VM-Vorlage auf der Grundlage Ihrer Gast-VM erstellen. Sie können diese Vorlage verwenden, um schnell Gast-VMs zur Nutzung der NVIDIA NGC Software zu erstellen.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Um eine VM-Vorlage auf der Grundlage Ihrer Gast-VM zu erstellen, melden Sie sich bei VMware vSphere an, klicken Sie einfach auf den Namen der Gast-VM, wählen Sie „Klonen“, wählen Sie „Vorlage klonen...“ und folgen Sie dann dem Assistenten.</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">Weiter: Beispiel Anwendungsfall – TensorFlow Training Job.</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">In diesem Abschnitt werden Konzepte und Komponenten für das Daten-Caching in einem ML-Workflow behandelt.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">Maschinelles Lernen</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML werden in vielen Unternehmen und Unternehmen auf der ganzen Welt schnell zum entscheidenden Faktor. IT- und DevOps-Teams stehen daher vor der Herausforderung, ML-Workloads zu standardisieren und Cloud-, On-Premises- und Hybrid-Computing-Ressourcen bereitzustellen, die die dynamischen und intensiven Workflows unterstützen, die ML-Jobs und Pipelines benötigen.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">Container-basiertes Machine Learning und Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">Container sind isolierte Instanzen von Benutzerspeicherplatz, die auf einem Kernel des Shared-Host-Betriebssystems laufen. Die Einführung von Containern nimmt rasant zu. Container bieten viele der gleichen Vorteile von Applikationen im Sandbox-Bereich, die Virtual Machines (VMs) bieten. Da jedoch der Hypervisor und das Gastbetriebssystem die Anzahl der VMs beseitigen, sind die Container viel schlanker.</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">Container erlauben außerdem die effiziente Bündelung von Applikationsabhängigkeiten, Laufzeiten usw. und zwar direkt mit einer Applikation. Das am häufigsten verwendete Format für Containerverpackungen ist der Docker Container. Eine Applikation, die im Docker-Container-Format gesichert wurde, kann auf jeder Maschine ausgeführt werden, die Docker Container ausführen kann. Dies gilt auch dann, wenn die Abhängigkeiten der Anwendung nicht auf der Maschine vorhanden sind, weil alle Abhängigkeiten im Container selbst verpackt sind. Weitere Informationen finden Sie auf der<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">Kubernetes, der beliebte Container-Orchestrator, ermöglicht Datenanalysten die Einführung flexibler, containerbasierter Jobs und Pipelines. Darüber hinaus sind Infrastrukturteams in der Lage, ML-Workloads in einer einzigen gemanagten und Cloud-nativen Umgebung zu managen und zu überwachen. Weitere Informationen finden Sie auf der<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">Cnvrg.io ist ein KI-Betriebssystem, das Unternehmen einen Wandel beim Management, der Skalierung und der Beschleunigung der KI- und Datenwissenschaft in der Forschung und Produktion ermöglicht. Die Code-First-Plattform wurde von Data Scientists für Data Scientists entwickelt und bietet Flexibilität für die Ausführung vor Ort oder in der Cloud. Mit Modellmanagement, MLOps und kontinuierlichen ML-Lösungen vereint cnvrg.io den Datenwissenschaftler Top-Technologien, mit denen sie sich weniger Zeit für DevOps und sich auf reale Algorithmen konzentrieren können. Seit dem Einsatz von cnvrg.io haben Teams aus allen Branchen immer mehr Modelle in die Produktion aufgenommen und damit einen höheren geschäftlichen Nutzen erzielt.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">Cnvrg.io Meta-Scheduler</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">Cnvrg. io verfügt über eine einzigartige Architektur, die IT und Ingenieuren die Möglichkeit ermöglicht, unterschiedliche Computing-Ressourcen auf derselben Kontrollebene zu verbinden. Cnvrg.io ermöglicht das Management VON ML-Jobs auf allen Ressourcen. Das bedeutet, DASS DIE IT diverse lokale Kubernetes-Cluster, VM-Server und Cloud-Konten anbinden und ML-Workloads auf allen Ressourcen ausführen kann, wie in der folgenden Abbildung dargestellt.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">Cnvrg.io Daten-Caching</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">Cnvrg.io ermöglicht Data Scientists die Definition von Versionen mit oft benötigten Datensätzen und liefert Daten-Caching-Technologie. Datensätze werden standardmäßig in einer zentralen Objekt-Storage-Datenbank gespeichert. Data Scientists können dann eine bestimmte Datenversion auf der ausgewählten Computing-Ressource zwischenspeichern, um Zeit beim Download zu sparen und damit die ML-Entwicklung und -Produktivität zu steigern. Datensätze, die gecachte und für einige Tage nicht in Verwendung sind, werden automatisch aus dem ausgewählten NFS gelöscht. Das Caching und Löschen des Cache erfolgt mit einem einzigen Klick. Es ist kein Coding, ER ODER DevOps Work erforderlich.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">Cnvrg.io fließt und ML-Pipelines</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">Cnvrg.io Flows ist ein Werkzeug für den Bau von ml-Pipelines für die Produktion. Jede Komponente in einem Flow ist ein Skript/Code, das auf einem ausgewählten Rechner mit einem Basis-Docker-Image ausgeführt wird. Data Scientists und Engineers können auf diesem Design eine einzige Pipeline aufbauen, die sowohl On-Premises als auch in der Cloud ausgeführt werden kann. Cnvrg.io sorgt dafür, dass Daten, Parameter und Artefakte zwischen den verschiedenen Komponenten verschoben werden. Darüber hinaus wird jeder Flow überwacht und für 100% reproduzierbare Datenwissenschaft nachverfolgt.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">KERN cnvrg.io</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">Cnvrg.io CORE ist eine kostenlose Plattform für die Data-Science-Community, mit der sich Data Scientists auf Data Science konzentrieren können, statt sich auf DevOps zu konzentrieren. DIE flexible Infrastruktur DES KERNS ermöglicht Data Scientists die Kontrolle über die Verwendung beliebiger Sprache, KI-Frameworks oder Computing-Umgebungen – vor Ort oder in der Cloud –, um das Beste aus ihnen zu machen – Algorithmen zu entwickeln. Cnvrg.io CORE kann mit einem einzigen Befehl auf einem beliebigen Kubernetes Cluster ganz einfach installiert werden.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI ist eine Datacenter-Referenzarchitektur für ML- und Deep-Learning-Workloads (DL), die NetApp AFF Storage-Systeme und NVIDIA DGX-Systeme mit Tesla V100 GPUs verwenden. ONTAP AI basiert auf dem branchenüblichen NFS-Dateiprotokoll über 100 GB Ethernet. Dadurch verfügen Kunden über eine hochperformante ML/DL-Infrastruktur, die mithilfe standardisierter Datacenter-Technologien den Implementierungs- und Administrations-Overhead reduziert. Mithilfe standardisierter Netzwerke und Protokolle kann ONTAP AI in Hybrid-Cloud-Umgebungen integriert werden, während gleichzeitig die betriebliche Konsistenz und Benutzerfreundlichkeit erhalten bleiben. Als vorab validierte Infrastrukturlösung senkt ONTAP AI die Implementierungszeit und -Risiken und reduziert den Administrations-Overhead erheblich, sodass Kunden eine schnellere Amortisierung erreichen können.</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident ist ein Open-Source-Storage-Orchestrator, der von NetApp entwickelt und gewartet wird. Damit wird die Erstellung, das Management und die Nutzung von persistentem Storage für Kubernetes-Workloads erheblich vereinfacht. Trident selbst ist eine native Kubernetes-Applikation, die direkt in einem Kubernetes Cluster ausgeführt werden kann. Mit Trident können Kubernetes-Benutzer (Entwickler, Data Scientists, Kubernetes Administratoren usw.) persistente Storage-Volumes im gewohnten Kubernetes-Standardformat erstellen, managen und interagieren. Gleichzeitig können sie von den erweiterten Datenmanagement-Funktionen von NetApp und der Data Fabric Strategie von NetApp profitieren. Trident abstrahiert die Komplexität von persistentem Storage und vereinfacht die Nutzung. Weitere Informationen finden Sie auf der<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID ist eine softwaredefinierte Objekt-Storage-Plattform, die diese Anforderungen erfüllt. Sie bietet einfachen Cloud-ähnlichen Storage, auf den Benutzer über das S3-Protokoll zugreifen können. StorageGRID ist ein Scale-out-System, das diverse Nodes unabhängig von der Entfernung über Internet-verbundene Standorte unterstützt. Mithilfe der intelligenten Richtlinien-Engine von StorageGRID können Benutzer Objekte zur Einhaltung von Datenkonsistenz (Erasure Coding) über Standorte hinweg auswählen und so für Ausfallsicherheit bei geografisch verteilten Standorten oder Objektreplizierung zwischen Remote Standorten sorgen, um die WAN-Zugriffslatenz zu minimieren. StorageGRID bietet in dieser Lösung einen hervorragenden primären Objekt-Storage-See in der Private Cloud.</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">Die NetApp Cloud Volumes ONTAP Datenmanagement-Software bietet Kontrolle, Schutz und Effizienz für Benutzerdaten. Gleichzeitig bietet sie die Flexibilität von Public Cloud-Providern, einschließlich AWS, Google Cloud Platform und Microsoft Azure. Cloud Volumes ONTAP ist eine Cloud-native Datenmanagement-Software auf Basis der Storage-Software NetApp ONTAP. Sie bietet Benutzern eine erstklassige universelle Storage-Plattform, die ihre Datenanforderungen in der Cloud erfüllt. Mit derselben Storage-Software in der Cloud und on-Premises profitieren Benutzer von allen Vorteilen der Data-Fabric-Strategie, ohne DASS DAS IT-Personal komplett neue Methoden zum Datenmanagement erlernen muss.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">Kunden, die sich für Hybrid-Cloud-Implementierungsmodelle interessieren, können Cloud Volumes ONTAP in den meisten Public Clouds dieselben Funktionen und erstklassige Performance bieten. Damit profitieren sie in jeder Umgebung von einer konsistenten und nahtlosen Benutzererfahrung.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">Nächste: Hardware- und Software-Anforderungen</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">Validierungsergebnisse</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">Gehen Sie wie folgt vor, um eine Probe-Inferenzanforderung auszuführen:</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">Holen Sie eine Shell zum Client-Container/POD.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">Führen Sie eine Beispielanfrage für Inferenz aus.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">Diese Inferenzanforderung nennt den<block ref="e8121e2c92eb0c17d4d331407502d266" prefix=" " category="inline-code"></block> Modell, das für die Bilderkennung verwendet wird. Andere Clients können Inferenzanfragen gleichzeitig senden, indem sie einen ähnlichen Ansatz verfolgen und das entsprechende Modell aufrufen.</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="955b9fb8bb717f45a2531f62ebef906d" category="doc">NVA-1151-DESIGN: Design Guide für NetApp ONTAP AI mit NVIDIA DGX A100 Systems</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151-DESIGN beschreibt eine NetApp Verifizierte Architektur für Machine-Learning- und künstliche Intelligenz-Workloads mit NetApp AFF A800 Storage-Systemen, NVIDIA DGX A100-Systemen und NVIDIA Mellanox Netzwerk-Switches. Es enthält außerdem Benchmark-Testergebnisse für die Architektur, wie sie implementiert wurde.</block>
  <block id="20821bbf55dddb9fb677efca1bfcf4d1" category="inline-link-macro"><block ref="20821bbf55dddb9fb677efca1bfcf4d1" category="inline-link-rx"></block></block>
  <block id="7d7e004acd6ddcaf6ddbea36835d3a1e" category="paragraph"><block ref="7d7e004acd6ddcaf6ddbea36835d3a1e" category="inline-link-macro-rx"></block></block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">Wo finden Sie zusätzliche Informationen, Bestätigungen und Versionsverlauf</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">NetApp Persistent Storage für Container – NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI – vertrauliche Inferenz</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton Inference Server Documentation</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">FaceBoxes in PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, Principal Product Manager, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, Technical Marketing Engineer, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Chief Technology Officer und Professor, Protopia AI</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">Versionsverlauf Des Dokuments</block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">Mai 2022</block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NVIDIA AI Enterprise mit NetApp und VMware – Nutzen Sie NVIDIA NGC Software</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">NVIDIA NGC Software</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">Zurück: Initial Setup.</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">In diesem Abschnitt werden die Aufgaben beschrieben, die ausgeführt werden müssen, um NVIDIA NGC Enterprise-Software in einer NVIDIA KI Enterprise-Umgebung zu verwenden.</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">Weiter: Einrichtung.</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">Bei der Erstellung dieser Lösung haben wir einen einfachen Performance-Vergleich durchgeführt. Wir haben mithilfe von Kubernetes mehrere standardmäßige NetApp Benchmark-Aufgaben durchgeführt. Die Benchmark-Ergebnisse wurden mit den Ausführung von Exekutionen verglichen, die über einen einfachen Docker Run-Befehl ausgeführt wurden.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">Performance-Tests</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">Bei der Erstellung dieser Lösung haben wir einen einfachen Performance-Vergleich durchgeführt. Wir haben mithilfe von Kubernetes mehrere standardmäßige NetApp KI-Benchmark-Jobs ausgeführt. Die Benchmark-Ergebnisse wurden mit Ausführungsvorgängen verglichen, die über einen einfachen Docker Run-Befehl ausgeführt wurden. Wir haben keine spürbaren Unterschiede in der Performance gesehen. Daher kamen wir zu dem Schluss, dass die Verwendung von Kubernetes zur Orchestrierung von Training-Jobs in Container-KI keine negative Auswirkung auf die Performance hat. Die Ergebnisse unseres Performance-Vergleichs finden Sie in der folgenden Tabelle.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">Benchmark</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker Run (Images/Sek.)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes (Bilder/Sek.)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">TensorFlow mit einem Node</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">Synthetische Daten</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">Synchrones verteiltes TensorFlow mit zwei Knoten</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858: NetApp Orchestrierungslösung mit Run:AI</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-Han Lin, NetApp Yaron Goldberg, Run:AI</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF Storage-Systeme bieten extrem hohe Performance und branchenführende Funktionen für das Hybrid-Cloud-Datenmanagement. NetApp und Run:KI haben gemeinsam die einzigartigen Funktionen der NetApp ONTAP KI Lösung für künstliche Intelligenz (KI) und ml-Workloads (Machine Learning) vorgestellt, die Performance, Zuverlässigkeit und Support der Enterprise-Klasse bieten. Ausführung:die KI-Orchestrierung von KI-Workloads bietet eine Kubernetes-basierte Plattform für Planung und Ressourcenauslastung, die Forscher beim Management und bei der Optimierung der GPU-Auslastung unterstützt. Zusammen mit NVIDIA DGX-Systemen bieten die kombinierte Lösung von NetApp, NVIDIA und Run:AI einen Infrastruktur-Stack, der speziell für KI-Enterprise-Workloads entwickelt wurde. Dieser technische Bericht gibt Kunden eine Orientierungshilfe beim Aufbau konversationaler KI-Systeme zur Unterstützung verschiedener Anwendungsfälle und Branchen. Er enthält Informationen zur Implementierung von Run:AI und einem NetApp AFF A800 Storage-System. Er dient als Referenzarchitektur, um KI-Initiativen so schnell und erfolgreich zu implementieren.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">Enterprise-Architekten, die Lösungen für die Entwicklung von KI-Modellen und -Software für Kubernetes-basierte Anwendungsfälle wie containerisierte Microservices entwerfen</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">Data Scientists, die nach effizienten Möglichkeiten suchen, Modelle in einer Cluster-Umgebung mit mehreren Teams und Projekten effizient zu entwickeln</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">Data Engineers, die für die Wartung und den Betrieb von Produktionsmodellen verantwortlich sind</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">Führungskräfte und IT-Entscheidungsträger, die die optimale Auslastung von Kubernetes-Cluster-Ressourcen schaffen und mit KI-Initiativen die kürzeste Markteinführungszeit erreichen möchten</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328: NetApp Convergentional AI mit NVIDIA Jarvis</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-Han Lin, NetApp Davide Onofrio, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">Die NVIDIA DGX-Systemfamilie besteht aus den weltweit ersten integrierten Systemen für künstliche Intelligenz (KI), die speziell für Enterprise-KI entwickelt wurden. NetApp AFF Storage-Systeme bieten extrem hohe Performance und branchenführende Funktionen für das Hybrid-Cloud-Datenmanagement. NetApp und NVIDIA haben gemeinsam die NetApp ONTAP AI Referenzarchitektur entwickelt, eine sofort einsatzbereite Lösung für KI- und ML-Workloads (Machine Learning) mit Performance, Zuverlässigkeit und Support der Enterprise-Klasse.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">Dieses Whitepaper gibt Kunden eine Orientierungshilfe beim Aufbau konversationaler KI-Systeme zur Unterstützung verschiedener Anwendungsfälle in verschiedenen Branchen. Es enthält Informationen über die Bereitstellung des Systems mit NVIDIA Jarvis. Die Tests wurden mit einer NVIDIA DGX Station und einem NetApp AFF A220 Storage-System durchgeführt.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">Enterprise-Architekten, die Lösungen für die Entwicklung von KI-Modellen und -Software für umgangssprachlich KI-Anwendungsfälle wie einen virtuellen Einzelhandelsassistent entwerfen</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">Data Scientists, die nach effizienten Möglichkeiten suchen, Ziele bei der Sprachmodellierung zu erreichen</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">Dateningenieure, die für die Pflege und Verarbeitung von Textdaten wie Kundenfragen und Dialogtranskripte verantwortlich sind</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">Führungskräfte und IT-Entscheidungsträger, die daran interessiert sind, die konvergente KI-Erfahrung zu verändern und mit KI-Initiativen die kürzeste Markteinführungszeit zu erreichen</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Lösungsseite zur Architektur für Azure NetApp Files</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">Persistenter Trident Storage für Container:</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files und Trident zu überzeugen</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask und RAPIDS:</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Fragen Sie Nach</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Installieren Sie Die Dask</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">DASK-API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Maschinelles Lernen Absprechen</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Distributed Diagnostics Abfragen</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="doc">Passen Sie die Staaten und Abläufe für den Einzelhandel an</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">Sie können die Zustände und Abläufe des Dialog-Managers für Ihre spezifischen Anwendungsfälle anpassen. In unserem Einzelhandelbeispiel haben wir die folgenden vier yaml-Dateien, um das Gespräch nach verschiedenen Absichten zu lenken.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">SE die folgende Liste mit Dateinamen und Beschreibung jeder Datei:</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text"><block ref="ef7c28f5093b59a07761555c8914df26" prefix="" category="inline-code"></block>: Definiert die wichtigsten Gesprächsflüsse und -Zustände und leitet den Fluss zu den anderen drei yaml-Dateien, wenn nötig.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text"><block ref="dfc9a806326d590aa4ccf49aa6909cda" prefix="" category="inline-code"></block>: Enthält Staaten im Zusammenhang mit Einzelhandels- oder Interessenfragen. Das System liefert entweder die Informationen zum nächstgelegenen Geschäft oder den Preis eines bestimmten Artikels.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text"><block ref="6e08d9d65c68d5f447f4fd239052c12e" prefix="" category="inline-code"></block>: Enthält Staaten im Zusammenhang mit Wetterfragen. Wenn der Standort nicht ermittelt werden kann, fragt das System eine weitere Frage zur Klärung.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text"><block ref="b7dc1d2ced2caa9352158983c5ffeda1" prefix="" category="inline-code"></block>: Behandelt Fälle, in denen Benutzer Intents nicht in die oben genannten drei yaml-Dateien fallen. Nach dem Anzeigen einer Fehlermeldung wird das System erneut auf Benutzerfragen zurückleitet.die folgenden Abschnitte enthalten die detaillierten Definitionen für diese yaml-Dateien.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">Main_Flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">Retail_Flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">Wetter_Flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">Error_Flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">Weiter: Als Fulfillment Engine mit APIs von Drittanbietern verbinden</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP AI und Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">Die NetApp ONTAP KI-Architektur mit NVIDIA DGX -Systemen und Cloud-vernetzten NetApp Storage-Systemen wurde von NetApp und NVIDIA entwickelt und verifiziert. Diese Referenzarchitektur bietet IT-Abteilungen folgende Vorteile:</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">Bietet eine Reihe von Storage-Optionen für verschiedene Performance- und KostenpunkteNetApp ONTAP AI integriert DGX-Systeme und NetApp AFF A220 Storage-Systeme nahtlos in hochmoderne Netzwerke. Mithilfe von NetApp ONTAP AI und DGX-Systemen können Komplexität und Unsicherheiten bei der Systemaufsetzung beseitigt werden, was den Einsatz von KI-Projekten vereinfacht. Kunden können mit einer kleinen Installation starten und ihre Systeme unterbrechungsfrei erweitern. Gleichzeitig erhalten sie intelligente Datenmanagement-Funktionen, mit denen sich Daten zwischen Datenaufnahme, zentraler Datenplattform und Cloud frei verschieben lassen.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">Mit NetApp Cloud Sync lassen sich Daten einfach über verschiedene Protokolle verschieben, ob zwischen zwei NFS-Freigaben, zwischen zwei CIFS-Freigaben oder zwischen einer Dateifreigabe und Amazon S3, Amazon Elastic File System (EFS) oder Azure Blob Storage. Durch die aktiv/aktiv-Vorgänge ist gleichzeitiges Arbeiten an Daten am Quell- und am Zielort möglich, während die Datenänderungen bei Bedarf inkrementell synchronisiert werden. Da sich Daten zwischen lokalen und Cloud-basierten Quell- und Zielsystem verschieben und inkrementell synchronisieren lassen, bietet Cloud Sync zahlreiche neue Möglichkeiten für die Nutzung der Daten. Das Migrieren von Daten zwischen On-Premises-Systemen, Cloud-On-Boarding und Cloud-Migration oder Collaboration und Datenanalysen ist leicht möglich. Die Abbildung unten zeigt die verfügbaren Quellen und Ziele.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">Bei konvergenten KI-Systemen können Entwickler mithilfe von Cloud Sync Gesprächsverlauf von der Cloud zu Datacentern archivieren und so das Offline-Training von NLP-Modellen (Natural Language Processing) ermöglichen. Durch Training von Modellen, um mehr Absichten zu erkennen, wird das Conversational KI-System besser gerüstet sein, um komplexere Fragen von den Endbenutzern zu managen.</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> Ist ein durchgängiges Framework für die Erstellung umgangssprachlicher KI-Services. Es umfasst die folgenden GPU-optimierten Services:</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">Automatische Spracherkennung (ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">Verständnis natürlicher Sprachen (NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">Integration in domänenspezifische Fulfillment Services</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">Text-to-Speech (TTS)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">Computer Vision (CV)Jarvis-basierte Services nutzen moderne Deep-Learning-Modelle, um der komplexen und anspruchsvollen Aufgabe von Echtzeit-konvergierter KI gerecht zu werden. Um natürliche Echtzeit-Interaktionen mit einem Endbenutzer zu ermöglichen, müssen die Modelle die Berechnungen in weniger als 300 Millisekunden durchführen. Natürliche Interaktionen sind anspruchsvoll und erfordern eine multimodale sensorische Integration. Modell-Pipelines sind auch komplex und erfordern Koordination über die oben genannten Services.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis ist ein vollständig beschleunigtes Applikations-Framework für die Erstellung multimodaler, umgangssprachlicher KI-Services, die eine End-to-End-Deep-Learning-Pipeline nutzen. Das Jarvis-Framework umfasst vortrainierte konvergente KI-Modelle, Tools und optimierte End-to-End-Services für sprach-, Vision- und NLU-Aufgaben. Neben den KI-Services ermöglicht Jarvis die gleichzeitige Sicherung von Bild-, Audio- und anderen Sensoreingängen, um Funktionen wie Multi-User-, Multi-Context-Gespräche in Anwendungen wie virtuellen Assistenten, Multi-User-Diarization und Callcenter-Assistenten bereitzustellen.</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> Es ist ein Open-Source-Python-Toolkit für die Erstellung, das Training und die Feinabstimmung von GPU-beschleunigten, hochmodernen KI-Modellen mit benutzerfreundlichen APIs (Application Programming Interfaces). Nemo arbeitet mit Tensor Cores in NVIDIA GPUs und kann bis auf mehrere GPUs skaliert werden, um die höchstmögliche Trainings-Performance zu erzielen. Nemo wird zur Erstellung von Modellen für ASR-, NLP- und TTS-Anwendungen in Echtzeit verwendet, wie z. B. Videoanrufe-Transkriptionen, intelligente Videoassistenten und automatisierte Unterstützung von Callcenter in verschiedenen Branchen, einschließlich Gesundheitswesen, Finanzen, Einzelhandel und Telekommunikation.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Mit Nemo trainierte man Modelle, die komplexe Absichten aus Benutzerfragen in der Vergangenheit archivierter Gespräche erkennen. Diese Schulung erweitert die Fähigkeiten des virtuellen Einzelhandels-Assistenten über das hinaus, was Jarvis als bereitgestellt unterstützt.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">Anwendungsbeispiel Im Einzelhandel – Zusammenfassung</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">Mithilfe von NVIDIA Jarvis haben wir einen virtuellen Retail-Assistenten entwickelt, der sprach- oder Texteingaben akzeptiert und Fragen zu Wetter, Points of Interest und Bestandspreisen beantwortet. Das Conversational AI-System kann sich an den Gesprächsablauf erinnern, beispielsweise eine weitere Frage stellen, wenn der Benutzer nicht den Standort für Wetter oder Points of Interest angeben kann. Das System erkennt auch komplexe Einheiten wie „Thai Food“ oder „Laptop-Speicher“. Es versteht natürliche Sprachfragen wie „regnet es nächste Woche in Los Angeles?“ Eine Demonstration des virtuellen Assistenten für den Einzelhandel finden Sie in<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">Diese Seite bietet einen Überblick über die in dieser Lösung verwendete Technologie.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft und NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">Seit Mai 2019 bietet Microsoft einen nativen Portal-Service auf Basis von Azure, dem First-Party-Anbieter für NFS- und SMB-Fileservices der Enterprise-Klasse, die auf der NetApp ONTAP Technologie basieren. Ziel dieser Entwicklung ist eine strategische Partnerschaft zwischen Microsoft und NetApp, mit der auch die Ausweitung der Reichweite erstklassiger ONTAP-Datenservices auf Azure möglich ist.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Der Azure NetApp Files Service ist ein hochperformanter File Storage-Service der Enterprise-Klasse mit Messung. Azure NetApp Files unterstützt jeden Workload-Typ und ist standardmäßig hochverfügbar. Sie können Service- und Performance-Level auswählen und Snapshot-Kopien über den Service einrichten. Azure NetApp Files ist ein Azure-Erstanbieter-Service zur Migration und Ausführung der anspruchsvollsten Enterprise-Datei-Workloads in der Cloud, einschließlich Datenbanken, SAP und High-Performance-Computing-Applikationen ohne Codeänderungen.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">Diese Referenzarchitektur bietet IT-Abteilungen folgende Vorteile:</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">Bietet eine Reihe von Storage-Tiers für diverse Performance- und Kostenpunkte</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask und NVIDIA RAPIDS: Überblick</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">DASK ist ein Open-Source-Tool für paralleles Computing, das Python Bibliotheken auf mehreren Maschinen skaliert und eine schnellere Verarbeitung großer Datenmengen ermöglicht. Es stellt eine API zur Verfügung, die herkömmlichen Python-Bibliotheken mit einem Thread wie Pandas, Numpy und scikit-Learn ähnelt. Daher sind native Python-Benutzer nicht gezwungen, viel am vorhandenen Code zu ändern, um Ressourcen auf dem Cluster zu nutzen.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS ist eine Suite aus Open-Source-Bibliotheken, mit denen es möglich ist, vollständig auf GPUs ausgeführte ML- und Data-Analytics-Workflows auszuführen. Zusammen mit DASK können Sie mühelos von der GPU-Workstation (vertikal skalierbar) auf Multi-Node-Cluster mit mehreren GPUs skalieren (horizontal skalierbar).</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">Für die Implementierung von DASK auf einem Cluster könnte Kubernetes zur Ressourcenorchestrierung verwendet werden. Sie können die Worker-Nodes auch entsprechend den Prozessanforderungen vertikal oder horizontal skalieren und so den Cluster-Ressourcenverbrauch optimieren, wie in der folgenden Abbildung dargestellt.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">Als Nächstes: Softwareanforderungen</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">Dieser Abschnitt beschreibt die Beladung von Criteo Click Logs Tag 15 in Pandas und Training eines scikit-Learn Zufallswaldmodells. In diesem Beispiel haben wir DataFrame-Beladung mit Dask cuDF durchgeführt und ein zufälliges Waldmodell in Dask cuML trainiert.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Laden Sie Tag 15 in Damast und trainieren Sie ein Damast CuML zufälligen Wald Modell</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">Früher: Laden Criteo Click Logs Tag 15 in Pandas und trainieren ein scikit-lernen zufälligen Wald Modell.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">„Zeitvergleich Training“.</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">Ähnlich wie im vorherigen Abschnitt, laden Criteo Click Logs Tag 15 in Pandas und trainieren ein scikit-Learn Zufallswaldmodell. In diesem Beispiel haben wir DataFrame-Beladung mit Dask cuDF durchgeführt und ein zufälliges Waldmodell in Dask cuML trainiert. Im Abschnitt wurden die Unterschiede in Trainingszeit und Umfang verglichen <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dask_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">Dieses Notizbuch importiert<block ref="2ea9510c37f7f89e4941ff75f62f21cb" prefix=" " category="inline-code"></block>,<block ref="7bdff0c624ecc34cd492f58859b5a599" prefix=" " category="inline-code"></block>, Und das nötige<block ref="b2015e522a418c3350d3af1da8790aeb" prefix=" " category="inline-code"></block> Bibliotheken, wie im folgenden Beispiel gezeigt:</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Dask Client() Initiieren.</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">Wenn das Cluster ordnungsgemäß konfiguriert ist, können Sie den Status von „Worker“-Nodes anzeigen.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">In unserem AKS-Cluster wird folgender Status angezeigt:</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Beachten Sie, dass Dask das faule Ausführungsmodell verwendet: Anstatt den Verarbeitungscode sofort auszuführen, erstellt Dask stattdessen ein gesteuertes Acyclic Graph (DAG) der Ausführung. DAG umfasst eine Reihe von Aufgaben und ihre Interaktionen, die jeder Mitarbeiter ausführen muss. Dieses Layout bedeutet, dass die Tasks nicht ausgeführt werden, bis der Benutzer DASK anweist, sie auf die eine oder andere Weise auszuführen. Mit DASK haben Sie drei Hauptoptionen:</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">*Aufruf Compute() auf einem DataFrame.* dieser Aufruf verarbeitet alle Partitionen und gibt die Ergebnisse dann in den Scheduler für die abschließende Aggregation und Konvertierung in cuDF DataFrame zurück. Diese Option sollte sparsam und nur bei stark reduzierten Ergebnissen verwendet werden, es sei denn, Ihr Scheduler-Node verfügt über keinen Arbeitsspeicher.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">*Call persist() auf einem DataFrame.* dieser Aufruf führt die Grafik aus, aber anstatt die Ergebnisse an den Scheduler-Knoten zurückzugeben, wird sie über den Cluster im Speicher verwaltet, sodass der Benutzer diese Zwischenergebnisse in der Pipeline wiederverwenden kann, ohne dass eine erneute Verarbeitung erforderlich ist.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">*Call Head() auf einem DataFrame.* wie bei cuDF gibt dieser Aufruf 10 Datensätze zurück zum Scheduler-Knoten. Mit dieser Option können Sie schnell überprüfen, ob Ihr DataFrame das gewünschte Ausgabeformat enthält oder ob die Datensätze selbst in Abhängigkeit von Ihrer Verarbeitung und Berechnung sinnvoll sind.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">Wenn der Benutzer eine dieser Aktionen nicht anruft, warten die Arbeiter daher nicht, bis der Planer die Verarbeitung initiiert hat. Dieses faul Ausführungsparadigma ist häufig in modernen Parallel- und Distributed Computing Frameworks wie Apache Spark zu finden.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">Im folgenden Abschnitt wird ein Zufallswaldmodell mit Hilfe von Dask cuML für verteiltes GPU-beschleunigtes Computing trainiert und die Genauigkeit der Modellvorhersage berechnet.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">Nächster: Überwachung des DASK mit dem Dashboard für native Task Streams.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Dieser Abschnitt bietet einen Überblick über die verschiedenen technischen Komponenten, die zum Abschließen dieser Lösung erforderlich sind.</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">Früher waren es Lösungsbereiche.</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI bietet heute eine unauffällige, rein softwarebasierte Lösung für vertrauliche Inferenz auf dem Markt. Die Protopia Lösung bietet unübertroffenen Schutz für Inferenz-Services, da die Gefahr von sensiblen Daten minimiert wird. Die KI ist nur aus den Informationen des Datensatzes gespeist, die für eine wirklich wichtige Aufgabe und nicht mehr zur Hand sind. Bei den meisten Inferenzaufgaben werden nicht alle in jedem Datensatz vorhandenen Informationen verwendet. Unabhängig davon, ob Ihre KI Bild-, sprach-, Video- oder sogar strukturierte tabellarische Daten verbraucht, steht Protopia nur bereit, was der Inferenz-Service benötigt. Die patentierte Kerntechnologie nutzt mathematisch kuratiertes Rauschen, um die Daten stochvoll zu transformieren und die Informationen zu erhalten, die von einem bestimmten ML-Service nicht benötigt werden. Diese Lösung maskiert die Daten nicht, sondern ändert die Datendarstellung durch kuratierte Zufallsgeräusche.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Die Protopia-Lösung formuliert das Problem der Änderung der Darstellung als gradienten-basierte Perturbationsmaximierungsmethode, die die relevanten Informationen im Eingabefeature-Raum hinsichtlich der Funktionalität des Modells behält. Dieser Erkennungsvorgang wird als Pass für die Feinabstimmung am Ende des Trainings DES ML-Modells ausgeführt. Nach dem Pass werden automatisch eine Reihe von Wahrscheinlichkeitsverteilungen generiert, bei der mit geringem Overhead Datenumwandlung werden Rauschproben aus diesen Distributionen an die Daten angewendet und vor dem Übergang zum Modell für die Inferenz verschleiert.</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">Die NetApp ONTAP AI Referenzarchitektur mit DGX A100-Systemen und Cloud-vernetzten NetApp Storage-Systemen wurde von NetApp und NVIDIA entwickelt und verifiziert. Sie bietet IT-Abteilungen eine Architektur mit folgenden Vorteilen:</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI integriert DGX A100-Systeme und NetApp AFF A800 Storage-Systeme nahtlos in hochmoderne Netzwerke. Mithilfe von ONTAP AI können Komplexität und Unsicherheiten bei der Systemaufsetzung beseitigt werden, was den Einsatz von KI-Vorhaben vereinfacht. Kunden können mit einer kleinen Installation starten und unterbrechungsfrei wachsen. Gleichzeitig erhalten sie intelligente Datenmanagement-Funktionen, mit denen sich Daten zwischen Datenaufnahme, zentraler Datenplattform und Cloud frei verschieben lassen.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">Die folgende Abbildung zeigt verschiedene Varianten der ONTAP AI Lösungsfamilie mit DGX A100-Systemen. Die Performance des AFF A800 Systems wurde mit bis zu acht DGX A100-Systemen verifiziert. Durch Hinzufügen von Storage-Controller-Paaren zum ONTAP Cluster kann die Architektur auf mehrere Racks skaliert werden, um viele DGX A100-Systeme und Petabyte an Storage-Kapazität mit linearer Performance zu unterstützen. Dieser Ansatz bietet die Möglichkeit, das Computing-zu-Storage-Verhältnis unabhängig voneinander anzupassen, je nach Größe der verwendeten DL-Modelle und der erforderlichen Performance-Kennzahlen.</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Weitere Informationen zu ONTAP KI finden Sie unter<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, die jüngste Generation der Storage-Managementsoftware von NetApp, ermöglicht Unternehmen eine Modernisierung der Infrastruktur und den Übergang zu einem Cloud-fähigen Datacenter. Dank der erstklassigen Datenmanagementfunktionen lassen sich mit ONTAP sämtliche Daten mit einem einzigen Toolset managen und schützen, ganz gleich, wo sich diese Daten befinden. Zudem können Sie die Daten problemlos dorthin verschieben, wo sie benötigt werden: Zwischen Edge, Core und Cloud. ONTAP 9.11 umfasst zahlreiche Funktionen, die das Datenmanagement vereinfachen, geschäftskritische Daten beschleunigen und schützen und Infrastrukturfunktionen der nächsten Generation über Hybrid-Cloud-Architekturen hinweg ermöglichen.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit ist eine Python Library, mit der Entwickler, Data Scientists, DevOps Engineers und Data Engineers verschiedene Datenmanagement-Aufgaben ausführen können, zum Beispiel die nahezu sofortige Bereitstellung eines neuen Daten-Volumes oder einer JupyterLab Workspace, das nahezu sofortiges Klonen eines Daten-Volumes oder einer JupyterLab Workspace. Und nahezu sofortige Snapshots von Daten-Volumes oder JupyterLab Workspace für Rückverfolgbarkeit oder Baselining. Diese Python-Bibliothek kann entweder als Befehlszeilen-Dienstprogramm oder als Bibliothek mit Funktionen verwendet werden, die Sie in jedes Python-Programm oder Jupyter-Notebook importieren können.</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton Inferenz Server ist eine Open-Source-Software für Inferenz-Server. Sie unterstützt die Standardisierung der Implementierung und Ausführung von Modellen, um schnelle und skalierbare KI in der Produktion zu ermöglichen. Triton Inference Server optimiert die KI-Inferenz, indem Teams trainierte KI-Modelle von jedem Framework auf jeder GPU- oder CPU-basierten Infrastruktur implementieren, ausführen und skalieren können. Der Triton Inference Server unterstützt alle wichtigen Frameworks wie TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO und so weiter. Die Lösung lässt sich in Kubernetes integrieren und ermöglicht so die Orchestrierung und Skalierung, die Sie in allen wichtigen KI- und Kubernetes-Plattformen nutzen können. Es ist auch in viele MLOps Software-Lösungen integriert.</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> Ist ein Open-Source-ML-Framework. Es ist eine optimierte Tensor-Bibliothek für Deep Learning, die GPUs und CPUs verwendet. Das PyTorch-Paket enthält Datenstrukturen für multidimensionale Tensor, die viele Dienstprogramme zur effizienten Serialisierung von Tensors unter anderen nützlichen Dienstprogrammen liefern. Es hat auch ein CUDA Pendant, mit dem Sie Ihre Tensor Berechnungen auf einer NVIDIA GPU mit Compute-Fähigkeit ausführen können. In dieser Validierung verwenden wir die OpenCV-Python (cv2) Bibliothek, um unser Modell zu validieren und dabei die intuitivsten Computer-Vision-Konzepte von Python zu nutzen.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra Control Service</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">Die NetApp Astra Produktfamilie bietet Storage und applikationsgerechte Datenmanagement-Services für Kubernetes-Applikationen On-Premises und in der Public Cloud auf der Basis von NetApp Storage- und Datenmanagement-Technologien. Sie ermöglicht einfaches Backup von Kubernetes-Applikationen, Migration von Daten in andere Cluster und die sofortige Erstellung von Klonen funktionierter Applikationen. Wenn Sie Kubernetes-Applikationen managen müssen, die in einer Public Cloud ausgeführt werden, finden Sie in der Dokumentation für<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>. Astra Control Service ist ein von NetApp gemanagter Service, der applikationsgerechtes Datenmanagement für Kubernetes-Cluster in Google Kubernetes Engine (GKE) und Azure Kubernetes Service (AKS) ermöglicht.</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="section-title">NetApp Astra Trident</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp ist ein Open-Source-Orchestrator für den dynamischen Storage von Docker und Kubernetes, das die Erstellung, das Management und die Nutzung von persistentem Storage vereinfacht. Trident, eine native Kubernetes-Applikation, wird direkt in einem Kubernetes Cluster ausgeführt. Trident ermöglicht Kunden die nahtlose Implementierung von DL-Container-Images auf NetApp Storage und bietet eine Erfahrung der Enterprise-Klasse für den Einsatz von KI-Containern. Kubernetes-Benutzer (ML-Entwickler, Data Scientists usw.) können die Orchestrierung und das Klonen erstellen, managen und automatisieren und so von erweiterten Datenmanagement-Funktionen der NetApp Technologie profitieren.</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Ist ein NetApp Service für schnelle und sichere Datensynchronisierung. Unabhängig davon, ob Sie Dateien zwischen On-Premises-NFS oder SMB-Dateifreigaben übertragen müssen: NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon Simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage Oder IBM Cloud Object Storage: Cloud Sync verschiebt Dateien schnell und sicher dorthin, wo sie benötigt werden. Nach der Übertragung stehen die Daten an der Quelle und am Ziel vollständig zur Verfügung. Cloud Sync synchronisiert kontinuierlich die Daten basierend auf Ihrem vorab definierten Zeitplan – so werden nur die Deltawerte verschoben – so wird der Zeitaufwand und die Kosten für die Datenreplizierung minimiert. Cloud Sync ist ein SaaS-Tool (Software-as-a-Service), das extrem einfach einzurichten und zu verwenden ist. Von Cloud Sync ausgelöste Datentransfers werden durch Data Makler durchgeführt. Cloud Sync-Datenmanager können in AWS, Azure, Google Cloud Platform oder vor Ort implementiert werden.</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">NetApp Cloud Data Sense –</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">Unterstützt durch leistungsstarke KI-Algorithmen <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> Automatisierte Kontrollmechanismen und Daten-Governance für den gesamten Datenbestand Hier können Sie mühelos Kosteneinsparungen ermitteln, Bedenken hinsichtlich Compliance und Datenschutz identifizieren und Möglichkeiten zur Optimierung finden. Das Cloud Data Sense Dashboard bietet Einblicke, um doppelte Daten zu identifizieren, um Redundanz zu beseitigen, persönliche, nicht persönliche und sensible Daten zuzuordnen und Alarme für sensible Daten und Anomalien zu aktivieren.</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">Als Nächstes: Test- und Validierungsplan.</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow ist in der Lage, neue Jupyter Notebook-Server schnell als Data Scientist-Workspaces bereitzustellen. Um einen neuen Jupyter Notebook-Server mit Kubeflow bereitzustellen, führen Sie die auf dieser Seite aufgeführten Aufgaben aus.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Bereitstellen eines Jupyter Notebook Workspace für Data Scientist oder Entwickler</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow ist in der Lage, neue Jupyter Notebook-Server schnell als Data Scientist-Workspaces bereitzustellen. Um einen neuen Jupyter Notebook-Server mit Kubeflow bereitzustellen, führen Sie die folgenden Aufgaben aus. Weitere Informationen zu Jupyter Notebooks im Kubeflow-Kontext finden Sie im<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Klicken Sie im zentralen Kubeflow Dashboard im Hauptmenü auf Notebook-Server, um zur Jupyter Notebook-Serververwaltungsseite zu navigieren.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">Klicken Sie auf Neuer Server, um einen neuen Jupyter Notebook-Server bereitzustellen.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">Geben Sie Ihrem neuen Server einen Namen, wählen Sie das Docker-Image aus, auf dem Ihr Server basieren soll, und geben Sie die CPU- und RAM-Größe an, die von Ihrem Server reserviert werden soll. Wenn das Namespace-Feld leer ist, wählen Sie über das Menü Namespace auswählen in der Seitenüberschrift einen Namespace aus. Das Namespace-Feld wird dann automatisch mit dem ausgewählten Namespace gefüllt.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">Im folgenden Beispiel wird der verwendet<block ref="aec502449511a35e8b040af72693bf5c" prefix=" " category="inline-code"></block> Namespace ausgewählt. Darüber hinaus werden die Standardwerte für das Docker Image, die CPU und den RAM akzeptiert.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">Geben Sie die Einzelheiten zum Workspace-Volumen an. Wenn Sie ein neues Volume erstellen möchten, wird dieses Volume oder PVC mithilfe der Standard-StorageClass bereitgestellt. Da ein StorageClass mit Trident als Standard-StorageClass in diesem Abschnitt festgelegt wurde <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, Das Volume oder die PVC wird mit Trident bereitgestellt. Dieses Volume wird automatisch als Standardarbeitsbereich im Jupyter Notebook Server-Container bereitgestellt. Alle Notebooks, die ein Benutzer auf dem Server erstellt, die nicht in einem separaten Datenvolumen gespeichert werden, werden automatisch in diesem Workspace-Volume gespeichert. Daher bleiben die Notebooks auch bei Neustarts erhalten.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">Hinzufügen von Daten-Volumes Im folgenden Beispiel wird ein vorhandenes PVC mit dem Namen „pb-fg-all“ angegeben und der Standard-Bereitstellungspunkt akzeptiert.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">*Optional:* Anfrage, dass die gewünschte Anzahl von GPUs Ihrem Notebook-Server zugewiesen wird. Im folgenden Beispiel wird eine GPU angefordert.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">Klicken Sie auf Starten, um Ihren neuen Notebook-Server bereitzustellen.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">Warten Sie, bis Ihr Notebook-Server vollständig bereitgestellt ist. Dies kann einige Minuten dauern, wenn Sie noch keinen Server mit dem von Ihnen angegebenen Docker-Image bereitgestellt haben, da das Image heruntergeladen werden muss. Wenn Ihr Server vollständig bereitgestellt wurde, wird in der Spalte Status auf der Seite Jupyter Notebook Server Administration ein grünes Häkchen angezeigt.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">Klicken Sie auf Verbinden, um eine Verbindung mit der neuen Server-Webschnittstelle herzustellen.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">Vergewissern Sie sich, dass das in Schritt 6 angegebene Datensatz-Volume auf dem Server installiert ist. Beachten Sie, dass dieses Volume standardmäßig im Standardarbeitsbereich bereitgestellt wird. Aus der Perspektive des Benutzers ist dies nur ein weiterer Ordner im Arbeitsbereich. Der Anwender, der wahrscheinlich ein Data Scientist ist und nicht ein Infrastruktur-Experte ist, muss nicht über Storage-Fachkenntnisse verfügen, um dieses Volumen zu nutzen.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">Öffnen Sie ein Terminal und, vorausgesetzt, dass ein neues Volume in Schritt 5 angefordert wurde, führen Sie aus<block ref="109faa0d3af468439c8966d496020840" prefix=" " category="inline-code"></block> So bestätigen Sie, dass ein neues persistentes Volume mit Trident-Bereitstellung als Standardarbeitsbereich gemountet wird.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">Das Standard-Workspace-Verzeichnis ist das Basisverzeichnis, mit dem Sie angezeigt werden, wenn Sie zum ersten Mal auf die Web-Schnittstelle des Servers zugreifen. Auf diesem persistenten Volume durch Trident werden daher alle mit der Web-Schnittstelle erstellten Artefakte gespeichert.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">Führen Sie mit dem Terminal aus<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Um zu bestätigen, dass dem Notebook-Server die korrekte Anzahl an GPUs zugewiesen wurde. Im folgenden Beispiel wurde dem Notebook-Server eine GPU zugewiesen, wie in Schritt 7 angefordert.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">Weiter: Beispiel Notebooks und Pipelines.</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">Auf dieser Seite werden die Schritte beschrieben, die zur Einrichtung des AKS-Clusters erforderlich sind.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">Installieren und Einrichten des AKS-Clusters</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">Zurück: Click-through-Rate Vorhersage use case summary.</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">Informationen zum Installieren und Einrichten des AKS-Clusters finden Sie auf der Webseite<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> Und führen Sie dann folgende Schritte aus:</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">Wählen Sie bei Auswahl des Node-Typs (System [CPU] oder Worker [GPU] Nodes) Folgendes aus:</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">Die Knoten des primären Systems sollten Standard DS2v2 sein <block ref="917718fb2e3dcf94043ea14d44580bc2" prefix="(" category="inline-code"></block> Standard: Drei Nodes).</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">Fügen Sie dann den Worker-Node Standard_NC6s_v3-Pool (mindestens drei Nodes) für die Benutzergruppe (für GPU-Nodes) mit dem Namen hinzu<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block>.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">Die Implementierung dauert 5 bis 10 Minuten. Klicken Sie nach Abschluss des Service auf Verbinden mit dem Cluster.</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">Um eine Verbindung zum neu erstellten AKS-Cluster herzustellen, installieren Sie Folgendes aus Ihrer lokalen Umgebung (Laptop/pc):</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">Anweisungen für Ihr spezifisches Betriebssystem</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">Das Kubernetes-Befehlszeilen-Tool mithilfe des<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Installieren Sie die Azure CLI</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">Der Azure-CLI, wie im Dokument beschrieben,<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">Um über das Terminal auf den AKS-Cluster zuzugreifen, geben Sie ein<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> Und geben Sie die Anmeldeinformationen ein.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Eingabe<block ref="33ba05f3df928c75694839078d97b2e4" prefix=" " category="inline-code"></block>.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">Wenn alle sechs Knoten betriebsbereit sind, wie im folgenden Beispiel dargestellt, ist Ihr AKS-Cluster bereit und mit Ihrer lokalen Umgebung verbunden</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">Als Nächstes: Erstellen Sie ein delegiertes Subnetz für Azure NetApp Files.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Die Daten sind in drei Bundesstaaten unterwegs: Im Ruhezustand, während der Übertragung und im Computing. Ein wichtiger Bestandteil jedes KI-Inferenz-Services sollte der Schutz der Daten vor Bedrohungen während des gesamten Prozesses sein. Der Schutz von Daten während der Inferenz ist von großer Bedeutung, da der Prozess private Informationen über externe Kunden und das Unternehmen, das den Inferenzservice bereitstellt, offenlegen kann.</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">Zurück: Obfuskationsgeschwindigkeit.</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">Die Daten sind in drei Bundesstaaten unterwegs: Im Ruhezustand, während der Übertragung und im Computing. Ein wichtiger Bestandteil jedes KI-Inferenz-Services sollte der Schutz der Daten vor Bedrohungen während des gesamten Prozesses sein. Der Schutz von Daten während der Inferenz ist von großer Bedeutung, da der Prozess private Informationen über externe Kunden und das Unternehmen, das den Inferenzservice bereitstellt, offenlegen kann. Protopia AI ist eine nicht aufdringliche rein softwarebasierte Lösung für vertrauliche KI-Inferenz auf dem heutigen Markt. Mit Protopia werden KI nur die transformierten Informationen in den Datensätzen gespeist, die für die Durchführung der KI/ML-Aufgabe am wichtigsten sind – und nicht mehr. Diese stochastische Transformation ist keine Form der Maskierung und basiert auf mathematisch veränderten Darstellung der Daten durch die Verwendung kuratierter Geräusche.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">NetApp Storage-Systeme mit ONTAP-Funktionen bieten dieselbe oder bessere Performance wie lokaler SSD-Storage und bieten in Kombination mit dem NetApp DataOps Toolkit Data Scientists, Data Engineers, KI/ML-Entwickler und Entscheidungsträger in Unternehmen oder IT die folgenden Vorteile:</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Datensicherung und Data Governance der Enterprise-Klasse für Disaster Recovery, Business Continuity und gesetzliche Vorschriften.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Vereinfachtes Aufrufen von Datenmanagement-Prozessen; schnelle Erstellung von Snapshot Kopien von Arbeitsbereichen für Data Scientists zur Sicherung und Rückverfolgbarkeit über das NetApp DataOps Toolkit in Jupyter Notebooks.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">Die Lösung von NetApp und Protopia bietet eine flexible Scale-out-Architektur, die sich ideal für KI-Inferenz-Implementierungen der Enterprise-Klasse eignet. Sie ermöglicht Datensicherung und Datenschutz für sensible Informationen, bei denen vertrauliche KI-Inferenz-Anforderungen mit verantwortlichen AI-Praktiken sowohl in On-Premises- als auch in Hybrid-Cloud-Implementierungen erfüllt werden können.</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">Weiter: Wo finden Sie zusätzliche Informationen, Danksagungen und Versionsverlauf.</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Implementierung Von Grafana Dashboard</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">Wenn alles bereitgestellt ist, kommen wir Rückschlüsse auf neue Daten. Die Modelle prognostizieren den Ausfall der Netzwerkgeräte. Die Ergebnisse der Vorhersage werden in einer Iguazio-Timeseries-Tabelle gespeichert. Sie können die Ergebnisse mit Grafana in der in die Sicherheits- und Datenzugriffsrichtlinie von Iguazio integrierten Plattform visualisieren.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">Sie können das Dashboard bereitstellen, indem Sie die bereitgestellte JSON-Datei in die Grafana-Schnittstellen im Cluster importieren.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Um zu überprüfen, ob der Grafana-Service ausgeführt wird, suchen Sie unter Services.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">Wenn diese nicht vorhanden ist, stellen Sie eine Instanz im Abschnitt „Services“ bereit:</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">Klicken Sie Auf Neuer Dienst.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">Wählen Sie Grafana aus der Liste aus.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">Akzeptieren Sie die Standardeinstellungen.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">Klicken Sie Auf Weiter.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">Geben Sie Ihre Benutzer-ID ein.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">Klicken Sie Auf Dienst Speichern.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">Klicken Sie oben auf Änderungen übernehmen.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">Laden Sie die Datei herunter, um das Dashboard bereitzustellen<block ref="5399022d93458a73556ae80388186793" prefix=" " category="inline-code"></block> Über die Jupyter-Schnittstelle.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Öffnen Sie Grafana im Abschnitt Services, und importieren Sie das Dashboard.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Klicken Sie Auf Hochladen<block ref="b31ec5f19793e2b7103acd7336754a1c" prefix=" " category="inline-code"></block> Datei und wählen Sie die Datei aus, die Sie zuvor heruntergeladen haben <block ref="5399022d93458a73556ae80388186793" prefix="(" category="inline-code"></block>). Das Dashboard wird nach Abschluss des Uploads angezeigt.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">Funktion „Bereinigen“ Bereitstellen</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">Wenn Sie eine Menge Daten generieren, ist es wichtig, die Dinge sauber und organisiert zu halten. Stellen Sie dazu die Bereinigungsfunktion mit dem bereit<block ref="11652556f686b20fd51b96992986630e" prefix=" " category="inline-code"></block> Notebook.</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">Vorteile</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp und Iguazio beschleunigen und vereinfachen die Implementierung von KI- und ML-Applikationen. Dazu bauen sie in wichtigen Frameworks wie Kubeflow, Apache Spark und TensorFlow sowie Orchestrierungs-Tools wie Docker und Kubernetes auf. Durch die Vereinheitlichung der End-to-End-Datenpipeline reduzieren NetApp und Iguazio die Latenz und Komplexität moderner Computing-Workloads, wodurch die Lücke zwischen Entwicklung und Betrieb geschlossen wird. Data Scientists können Abfragen zu großen Datensätzen durchführen und Daten und algorithmische Modelle während der Trainingsphase sicher mit autorisierten Benutzern teilen. Sobald die Container-Modelle für die Produktion bereit sind, können Sie sie ganz einfach von Entwicklungsumgebungen in betriebliche Umgebungen verschieben.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NetApp EF-Series AI mit NVIDIA</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">Übersicht über die konvergenten EF-Series KI-Infrastrukturlösungen von NetApp und NVIDIA</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="section-title">EF-Series AI mit NVIDIA DGX A100 Systems und BeeGFS</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">Design-Leitfaden</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">Implementierungsleitfaden</block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS Deployment Guide</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">Dieser Bericht zeigt Ihnen, wie Sie einen Daten-Namespace schnell klonen können. Es zeigt, wie KI-Trainings-Workflows definiert und implementiert werden, die eine nahezu sofortige Erstellung von Daten und Modellbasiden für Rückverfolgbarkeit und Versionierung enthalten. Es zeigt außerdem, wie Daten nahtlos über Standorte und Regionen hinweg repliziert werden können und wie schnell Jupyter Notebook-Workspaces mit Zugriff auf riesige Datensätze bereitgestellt werden.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798: NetApp AI Control Plane</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">Unternehmen aller Größen und Branchen setzen zunehmend auf künstliche Intelligenz (KI), maschinelles Lernen (ML) und Deep Learning (DL), um Probleme aus der Praxis zu lösen, innovative Produkte und Services bereitzustellen und sich in einem immer härter umkämpften Markt einen Schritt voraus zu sein. Beim verstärkten Einsatz von KI, ML und DL müssen Unternehmen mit vielen Herausforderungen konfrontiert werden, darunter Workload-Skalierbarkeit und Datenverfügbarkeit. In diesem Dokument wird veranschaulicht, wie Sie diese Herausforderungen mit der NetApp AI Control Plane bewältigen können. Diese Lösung vereint die Datenmanagement-Funktionen von NetApp mit gängigen Open-Source-Tools und -Frameworks.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">Dieser Bericht zeigt Ihnen, wie Sie einen Daten-Namespace schnell klonen können. Außerdem zeigt sie, wie Daten nahtlos über Standorte und Regionen hinweg repliziert werden, um eine zusammenhängende und einheitliche KI/ML/DL-Datenpipeline zu erstellen. Darüber hinaus werden die Trainings-Workflows für AI, ML und DL definiert und implementiert, die die nahezu sofortige Erstellung von Daten und Modellbasiden für Rückverfolgbarkeit und Versionierung enthalten. Mit dieser Lösung können Sie verfolgen, welches Modell-Training zurück zu dem genauen Datensatz führt, der zum Training und/oder zur Validierung des Modells verwendet wurde. Abschließend erfahren Sie in diesem Dokument, wie Sie Jupyter Notebook-Workspaces mit Zugriff auf riesige Datensätze schnell bereitstellen können.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">Die vollständig unterstützte parallele NetApp Lösung BeeGFS von NetApp</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">Hinweis: Für verteilte Schulungen im HPC-Stil mit einer großen Anzahl von GPU-Servern, die einen gemeinsamen Zugriff auf denselben Datensatz benötigen oder wenn Sie ein paralleles Dateisystem benötigen/bevorzugen, schauen Sie sich das hier an <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. In diesem technischen Bericht wird die Vorgehensweise erläutert <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> Teil der NetApp KI-Kontrollebene. Diese Lösung wurde entwickelt, um von einer Handvoll NVIDIA DGX A100-Systemen bis zu einem voll aufgeblasen SuperPOD mit 140 Nodes skalieren zu können.</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">Die NetApp AI Control Plane ist auf Data Scientists und Data Engineers ausgerichtet und benötigt daher nur eine minimale NetApp oder NetApp ONTAP® Expertise. Bei dieser Lösung lassen sich Datenmanagementfunktionen mit einfachen und vertrauten Tools und Schnittstellen ausführen. Wenn Sie bereits NetApp Storage in Ihrer Umgebung haben, können Sie noch heute die NetApp AI Control Plane testen. Wenn Sie die Lösung testen möchten, aber noch nicht bereits über NetApp Storage verfügen, besuchen Sie<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>, Und Sie sind innerhalb von Minuten mit einer Cloud-basierten NetApp Storage-Lösung einsatzbereit. Die folgende Abbildung bietet eine Visualisierung der Lösung.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">Weiter: Konzepte und Komponenten.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files, RAPIDS und DASK beschleunigen und vereinfachen die Implementierung umfangreicher ML-Verarbeitung und -Trainings. Dazu gehören Orchestrierungs-Tools wie Docker und Kubernetes. Durch die Vereinheitlichung der End-to-End-Datenpipeline verringert diese Lösung die Latenz und Komplexität vieler moderner Computing-Workloads und schließt damit die Lücke zwischen Entwicklung und Betrieb.</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS und Dask beschleunigen und vereinfachen die Implementierung umfangreicher ML-Verarbeitung und -Trainings durch die Integration mit Orchestrierungs-Tools wie Docker und Kubernetes. Durch die Vereinheitlichung der End-to-End-Datenpipeline verringert diese Lösung die Latenz und Komplexität vieler moderner Computing-Workloads und schließt damit die Lücke zwischen Entwicklung und Betrieb. Data Scientists können Abfragen zu großen Datensätzen durchführen und Daten und algorithmische Modelle während der Trainingsphase sicher mit anderen Benutzern teilen.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">Durch die Entwicklung eines End-to-End-Trainingsmodells und einer verteilten Datenpipeline in der Cloud haben wir gegenüber einem herkömmlichen Open-Source-Ansatz zwei Möglichkeiten zur Verbesserung der gesamten Workflow-Vervollständigung aufgezeigt, der die GPU-beschleunigte Datenverarbeitung und Computing Frameworks nicht ausübte.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">Die Kombination aus NetApp, Microsoft, opensource-Orchestrierungs-Frameworks und NVIDIA vereint die neuesten Technologien als Managed Services mit hoher Flexibilität und ermöglicht so eine beschleunigte Technologieeinführung und eine kürzere Markteinführungszeit für neue KI/ML-Applikationen. Diese erweiterten Services werden in einer Cloud-nativen Umgebung bereitgestellt, die sowohl für On-Premises- als auch für hybride Architekturen problemlos portiert werden kann.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Für diese Validierung haben wir die Protopia-Obfuskation fünfmal auf ein 1920 x 1080 Pixel-Bild angewendet und die Zeit gemessen, die für den obfuscation-Schritt erforderlich war, um jedes Mal abzuschließen.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Obfuskationsgeschwindigkeit</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">Zurück: Vergleich der Inferenzgenauigkeit.</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">Für diese Validierung haben wir die Protopia-Obfuskation fünfmal auf ein 1920 x 1080 Pixel-Bild angewendet und die Zeit gemessen, die für den obfuscation-Schritt erforderlich war, um jedes Mal abzuschließen. Wir verwendeten PyTorch, der auf einer einzelnen NVIDIA V100 GPU ausgeführt wurde, um den Verschleierung anzuwenden, und wir löchten den GPU-Cache zwischen den Durchläufen. Der obfuscation-Schritt dauerte 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms bzw. 4,84 ms, um in den fünf Durchläufen abzuschließen. Die durchschnittliche Geschwindigkeit betrug 5,072 ms.</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NetApp ONTAP AI mit NVIDIA</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">Überblick über die konvergenten ONTAP KI-Infrastrukturlösungen von NetApp und NVIDIA</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NetApp ONTAP AI mit NVIDIA DGX A100 Systemen</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches</block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">Auf dieser Seite wird beschrieben, wie Sie DASK mit dem systemeigenen Task-Stream-Dashboard überwachen.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">Überwachung des DASK mit dem systemeigenen Task-Streams-Dashboard</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">Früher: Laden Sie Tag 15 in Damast und trainieren Sie ein Damast CuML zufälligen Wald Modell.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Distributed Scheduler abfragen</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">Der<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> Live-Feedback in zwei Formen:</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">Ein interaktives Dashboard mit vielen Darstellungen und Tabellen mit Live-Informationen</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">Eine Fortschrittsleiste, die für den interaktiven Einsatz in Konsolen oder Notebooks geeignet ist</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">In unserem Fall zeigt die folgende Abbildung, wie Sie den Fortschritt der Aufgabe überwachen können, einschließlich gespeicherter Bytes, den Task-Stream mit einer detaillierten Aufschlüsselung der Anzahl von Streams und den Fortschritt nach Aufgabennamen mit den ausgeführten Funktionen. In unserem Fall, weil wir drei Arbeiter-Knoten haben, gibt es drei Hauptblöcke des Streams und die Farbcodes bezeichnen verschiedene Aufgaben innerhalb jedes Streams.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">Sie haben die Möglichkeit, einzelne Aufgaben zu analysieren und die Ausführungszeit in Millisekunden zu untersuchen oder Hindernisse oder Hindernisse zu identifizieren. Die folgende Abbildung zeigt beispielsweise die Aufgabenströme für die Zufallsphase des Waldmodells. Es werden wesentlich mehr Funktionen ausgeführt, darunter ein einzigartiger Chunk für die DataFrame-Verarbeitung, _construct_rf für die Anpassung der zufälligen Gesamtstruktur usw. Die meiste Zeit wurde auf DataFrame-Operationen aufgrund der großen Größe (45 GB) von einem Tag Daten aus den Criteo Click Logs verwendet.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">Als Nächstes: Vergleich der Trainingszeit.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">Setup-Übersicht</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Iguazio-Installation</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio kann lokal oder bei einem Cloud-Provider installiert werden. Die Bereitstellung kann als Service ausgeführt und von Iguazio oder vom Kunden gemanagt werden. In beiden Fällen bietet Iguazio eine Implementierungsapplikation (Provazio) für die Bereitstellung und das Management von Clustern.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">Auf dieser Seite</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">Informationen zur vor-Ort-Installation finden Sie unter<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> Für Computing-, Netzwerk- und Storage-Einrichtung. Der vor-Ort-Einsatz von Iguazio wird von Iguazio ohne zusätzliche Kosten für den Kunden bereitgestellt. Siehe<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> Für DNS- und SMTP-Serverkonfigurationen. Die Seite für die Installation von Provazio wird wie folgt angezeigt.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">Weiter: Kubernetes Cluster Konfigurieren</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">Die NetApp AI Control Plane Lösung ist nicht von dieser spezifischen Hardware abhängig.</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">Die NetApp AI Control Plane Lösung ist nicht von dieser spezifischen Hardware abhängig. Die Lösung ist mit jeder physischen NetApp Storage Appliance, jeder softwaredefinierten Instanz oder jedem Cloud-Service kompatibel, der von Trident unterstützt wird. Hierzu zählen beispielsweise ein NetApp AFF Storage-System, Azure NetApp Files, NetApp Cloud Volumes Service, eine softwaredefinierte Storage-Instanz von NetApp ONTAP Select oder eine NetApp Cloud Volumes ONTAP Instanz. Außerdem kann die Lösung auf jedem beliebigen Kubernetes Cluster implementiert werden, solange die verwendete Kubernetes-Version von Kubeflow und NetApp Trident unterstützt wird. Eine Liste der von Kubeflow unterstützten Kubernetes-Versionen finden Sie im<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Eine Liste der von Trident unterstützten Kubernetes-Versionen finden Sie im<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. In den folgenden Tabellen finden Sie Einzelheiten zur Umgebung, die zur Validierung der Lösung verwendet wurde.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">Infrastrukturkomponente</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">Betriebssystem</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">Bereitstellung Jump-Host</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes Master-Nodes</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes-Worker-Nodes</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes-GPU-Worker-Nodes</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 (Bare-Metal)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 (basierend auf Ubuntu 18.04.2 LTS)</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 HA-Paar</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Software-Komponente</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache Airflow Helm Chart</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">Trident-Implementierungsfunktionen von der Master-Zweigstelle bei der Übertragung <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>; Alle anderen Funktionen von Version 21.03</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Unterstützung</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">Kontakt zu NetApp</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp bietet keine Enterprise-Unterstützung für Apache Airflow, Docker, Kubeflow, Kubernetes oder NVIDIA DeepOps. Wenn Sie an einer vollständig unterstützten Lösung mit Funktionen interessiert sind, die ähnlich der NetApp KI Control Plane Lösung sind, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> Über vollständig unterstützte KI/ML-Lösungen, die NetApp gemeinsam mit Partnern anbietet.</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">Weiter: Kubernetes Deployment.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">Bereitstellen der Anwendung</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">In den folgenden Abschnitten wird die Installation und Bereitstellung der Anwendung beschrieben.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">Als Nächstes erhalten Sie Code von GitHub</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">In diesem Abschnitt werden die Aufgaben beschrieben, die zum Abschließen der Validierung erforderlich sind.</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Um die in diesem Abschnitt beschriebenen Aufgaben auszuführen, müssen Sie auf einen Linux- oder macOS-Host zugreifen können, auf dem die folgenden Tools installiert und konfiguriert sind:</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (für Zugriff auf ein vorhandenes Kubernetes-Cluster konfiguriert)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Anweisungen zur Installation und Konfiguration finden Sie<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>.</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Installationsanweisungen finden Sie<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>.</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Szenario 1 – On-Demand-Inferenz in JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Kubernetes-Namespace für KI/ML-Inferenz-Workloads erstellen</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um ein persistentes Volume für die Daten bereitzustellen, auf denen Sie die Inferenz ausführen.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um einen neuen JupyterLab Workspace zu erstellen. Mounten Sie das persistente Volume, das im vorherigen Schritt mit dem erstellt wurde<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> Option. Weisen Sie mit dem NVIDIA-GPUs dem Workspace nach Bedarf zu<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> Option.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Im folgenden Beispiel wird das persistente Volume beschrieben<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> Wird im JupyterLab-Workspace-Container unter installiert<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>. Bei der Verwendung von offiziellen Projekt-Jupyter-Container-Images,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> Wird als oberes Verzeichnis innerhalb der JupyterLab-Weboberfläche dargestellt.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Greifen Sie auf den JupyterLab-Arbeitsbereich über die URL zu, die in der Ausgabe des angegeben ist<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> Befehl. Das Datenverzeichnis stellt das persistente Volume dar, das in den Arbeitsbereich gemountet wurde.</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Öffnen Sie das<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> Verzeichnis erstellen und die Dateien hochladen, auf denen die Inferenz durchgeführt werden soll. Wenn Dateien in das Datenverzeichnis hochgeladen werden, werden sie automatisch auf dem persistenten Volume gespeichert, das in den Arbeitsbereich eingebunden wurde. Um Dateien hochzuladen, klicken Sie wie im folgenden Bild gezeigt auf das Symbol Dateien hochladen.</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Kehren Sie zum Verzeichnis der obersten Ebene zurück und erstellen Sie ein neues Notebook.</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Fügen Sie dem Notebook den Inferenzcode hinzu. Im folgenden Beispiel wird der Inferenzcode für einen Anwendungsfall der Bilderkennung gezeigt.</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Fügen Sie Protopia Obfuscation in Ihren Inferenzcode ein. Protopia arbeitet direkt mit Kunden zusammen, um eine anwendungsspezifische Dokumentation bereitzustellen und befindet sich außerhalb des Umfangs dieses technischen Berichts. Das folgende Beispiel zeigt den Inferenzcode für eine Bilderkennung, wobei Protopia obfuscation hinzugefügt wurde.</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Szenario 2 – Batch-Inferenz auf Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Füllen Sie das neue persistente Volume mit den Daten, auf denen Sie die Inferenz durchführen möchten.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Funktionen des NetApp DataOps Toolkit S3 Data Mover</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">Es gibt verschiedene Methoden zum Laden von Daten auf ein PVC. Wenn Ihre Daten aktuell in einer S3-kompatiblen Objekt-Storage-Plattform wie NetApp StorageGRID oder Amazon S3 gespeichert sind, können Sie verwenden<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>. Eine weitere einfache Methode ist es, einen JupyterLab-Arbeitsbereich zu erstellen und dann Dateien über die JupyterLab-Webschnittstelle hochzuladen, wie in den Schritten 3 bis 5 im Abschnitt “ beschrieben<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>.“</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Erstellen eines Kubernetes-Jobs für die Batch-Inferenz. Das folgende Beispiel zeigt einen Batch-Inferenzauftrag für einen Anwendungsfall zur Bilderkennung. Dieser Job führt die Inferenz auf jedem Bild in einem Satz von Bildern durch und schreibt Metriken zur Inferenzgenauigkeit.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Bestätigen Sie, dass der Inferenzauftrag erfolgreich abgeschlossen wurde.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Fügen Sie Protopia Obfuscation zu Ihren Inferenz Job. Die anwendungsspezifische Anleitung zum Hinzufügen von Protopia-Obfuskation kann direkt aus Protopia gefunden werden, die nicht im Rahmen dieses technischen Berichts liegt. Das folgende Beispiel zeigt einen Batch-Inferenzauftrag für eine Gesichtserkennung Anwendungsfall mit Protopia-Obfuscation, die durch die Verwendung eines ALPHAWERTS von 0.8 hinzugefügt wurde. Bei diesem Job wird die Protopia-Obfuskation vor der Durchführung der Inferenz für jedes Bild in einer Reihe von Bildern angewendet und dann Kenngrößen für die Inferenzgenauigkeit geschrieben.</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">„Vergleich der Genauigkeit bei der Inferenzierung“.</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">Wir haben diesen Schritt für ALPHA-Werte 0.05, 0.1, 0.2, 0.4, 0.6, wiederholt. 0.8, 0.9 und 0.95. Die Ergebnisse sehen Sie in <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Szenario 3 – NVIDIA Triton Inferenz Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um ein persistentes Volume bereitzustellen, das als Modell-Repository für den NVIDIA Triton Inference Server verwendet werden kann.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">Formatieren</block>
  <block id="97be18cb741b4fd763ebe22e034705fa" category="list-text">Sie können Ihr Modell auf dem neuen persistenten Volume in einem speichern<block ref="bfcdc35d352d3deff6efdd3b8b2ac7ac" category="inline-link-rx"></block> Das wird vom NVIDIA Triton Inferenz Server erkannt.</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">Es gibt verschiedene Methoden zum Laden von Daten auf ein PVC. Eine einfache Methode ist es, einen JupyterLab-Arbeitsbereich zu erstellen und dann Dateien über die JupyterLab-Webschnittstelle hochzuladen, wie in den Schritten 3 bis 5 in “ beschrieben<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. „</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Verwenden Sie das NetApp DataOps Toolkit, um eine neue NVIDIA Triton Inferenz Server-Instanz zu implementieren.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Verwenden Sie ein Triton Client SDK zur Durchführung einer Inferenz. Im folgenden Python-Code-Auszug wird das Triton Python-Client-SDK verwendet, um eine Inferenzaufgabe für einen Anwendungsfall zur Gesichtserkennung durchzuführen. Dieses Beispiel nennt die Triton API und führt ein Bild zur Inferenz durch. Der Triton Inference Server erhält dann die Anfrage, ruft das Modell auf und gibt die Inferenzausgabe als Teil der API-Ergebnisse zurück.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Fügen Sie Protopia Obfuscation in Ihren Inferenzcode ein. Die anwendungsspezifische Anleitung zum Hinzufügen von Protopia-Obfuskation kann direkt aus Protopia gefunden werden; dieser Vorgang liegt jedoch außerhalb des Geltungsbereichs dieses technischen Berichts. Das folgende Beispiel zeigt denselben Python-Code, der im vorhergehenden Schritt 5, jedoch mit Protopia Obfuscation hinzugefügt wird.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Beachten Sie, dass die Protopia-Obfuskation auf das Bild angewendet wird, bevor es an die Triton-API übergeben wird. So verlässt das nicht-verschleierte Bild nie die lokale Maschine. Nur das obfuscated Image wird über das Netzwerk übertragen. Dieser Workflow eignet sich für Anwendungsfälle, in denen Daten in einer vertrauenswürdigen Zone erfasst und dann zur Inferenz außerhalb der vertrauenswürdigen Zone weitergeleitet werden müssen. Ohne Protopia Obfuscation ist es nicht möglich, diesen Workflow ohne sensible Daten zu implementieren, die jemals die vertrauenswürdige Zone verlassen.</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">Weiter: Vergleich der Inferenzgenauigkeit.</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">Auf dieser Seite finden Sie Videos und Tutorials.</block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">Hybrid Cloud, Virtualisierung und Container Videos und Demos</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">Sehen Sie sich die folgenden Videos und Demos an, in denen die spezifischen Funktionen von Hybrid Cloud-, Virtualisierungs- und Container-Lösungen vorgestellt werden.</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">NetApp ONTAP Tools für VMware vSphere</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">ONTAP Tools für VMware - Übersicht</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">Bereitstellung von VMware iSCSI-Datenspeichern mit ONTAP</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">Bereitstellung von VMware NFS-Datenspeichern mit ONTAP</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">VMware Cloud auf AWS mit AWS FSX für NetApp ONTAP</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">Windows Guest Connected Storage mit FSX ONTAP über iSCSI</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">Linux Guest Connected Storage with FSX ONTAP Using NFS</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="example-title">VMware Cloud auf AWS TCO-Einsparungen mit Amazon FSX für NetApp ONTAP</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="example-title">VMware Cloud auf AWS zusätzlicher Datastore mit Amazon FSX für NetApp ONTAP</block>
  <block id="1709b8b454125c7d55fd44e302c8aee3" category="example-title">VMware Cloud auf AWS Migration mit FSxN, VMware HCX</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">Azure VMware-Services auf Azure mit Azure NetApp Files (ANF)</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="example-title">Übersicht über die Azure VMware Lösung zusätzlichen Datastore mit Azure NetApp Files</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="example-title">Azure VMware Lösung für DR mit Cloud Volumes ONTAP, SnapCenter und JetStream</block>
  <block id="875970986c8d6a0d19f47ed744bf33e1" category="example-title">Migration der Azure VMware Lösung mit ANF, VMware HCX</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="example-title">SnapCenter Plug-in für VMware vSphere</block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">Die NetApp SnapCenter Software ist eine unkomplizierte Enterprise-Plattform, die die Koordination und das Management der Datensicherung für alle Applikationen, Datenbanken und Filesysteme sicher gestaltet.</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">Das SnapCenter Plug-in für VMware vSphere ermöglicht Ihnen Backup-, Wiederherstellungs- und Anschlussvorgänge für VMs sowie Backup- und Mount-Vorgänge für Datastores, die bei SnapCenter direkt in VMware vCenter registriert sind.</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link-macro">Überblick über NetApp SnapCenter Plug-in für VMware vSphere</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">Weitere Informationen zum NetApp SnapCenter Plug-in für VMware vSphere finden Sie im <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>.</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">SnapCenter Plug-in für VMware vSphere – Voranforderungen für eine Lösung</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">SnapCenter Plug-in für VMware vSphere – Implementierung</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">SnapCenter Plug-in für VMware vSphere – Backup-Workflow</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">SnapCenter Plug-in für VMware vSphere – Workflow wiederherstellen</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - SQL Restore-Workflow</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="example-title">NetApp mit VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">Mit VMware Tanzu können Kunden ihre Kubernetes-Umgebung über vSphere oder VMware Cloud Foundation implementieren, managen und managen. Mit diesem VMware Portfolio können Kunden alle relevanten Kubernetes Cluster über eine einzige Kontrollebene managen. Dazu wählen sie die für sie am besten geeignete VMware Tanzu Edition.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu Overview</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">Weitere Informationen zu VMware Tanzu finden Sie im<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. Diese Überprüfung behandelt Anwendungsfälle, verfügbare Ergänzungen und mehr über VMware Tanzu.</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">Verwendung von VVols mit NetApp und VMware Tanzu Basic, Teil 1</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">Verwendung von VVols mit NetApp und VMware Tanzu Basic, Teil 2</block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">Verwendung von VVols mit NetApp und VMware Tanzu Basic, Teil 3</block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="example-title">NetApp mit Red hat OpenShift</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">Red hat OpenShift, eine Kubernetes-Plattform für Unternehmen, ermöglicht die Ausführung von Container-basierten Applikationen mit einer offenen Hybrid-Cloud-Strategie. Red hat OpenShift ist als Cloud-Service auf führenden Public Clouds oder als eigenständige Software verfügbar und bietet Kunden die Flexibilität, die sie beim Entwurf ihrer containerbasierten Lösung benötigen.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Übersicht über Red hat OpenShift</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Weitere Informationen zu Red hat OpenShift finden Sie hier<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. Weitere Informationen zu Red hat OpenShift finden Sie in der Produktdokumentation und den Bereitstellungsoptionen.</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">Workload-Migration – Red hat OpenShift mit NetApp</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="inline-link">Red hat OpenShift Deployment on RHV: Red hat OpenShift mit NetApp</block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">Schritte zur Implementierung eines NetApp ONTAP-NVMe/FC-Storage für VMFS-Datenspeichers in einer VMware vSphere-Umgebung</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">VSphere VMFS Datastore – NVMe/FC mit ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">Über diese Aufgabe</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">In diesem Abschnitt wird die Erstellung eines VMFS-Datenspeichers mit ONTAP-Storage mithilfe von NVMe/FC beschrieben.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">Verwenden Sie eines der folgenden Skripte für die automatisierte Bereitstellung: <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, Oder <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">Was Sie brauchen</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">Erforderliche Grundkenntnisse für das Management von vSphere Umgebungen und ONTAP</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">Grundkenntnisse von NVMe/FC</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">Ein ONTAP-Storage-System (FAS/AFF/CVO/ONTAP Select/ASA) mit {ontap_Version}</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP-Anmeldedaten (SVM-Name, Benutzer-ID und Passwort)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">ONTAP WWPN für Host-, Ziel- und SVMs- sowie LUN-Informationen</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">Ein ausgefülltes FC-Konfigurationsarbeitsblatt</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">VCenter Server</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">Informationen zu vSphere-Host(s) ({vsphere_Version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">Fabric Switch(e)</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">Mit ONTAP FC-Daten-Ports und vSphere-Hosts verbunden.</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">Bei aktivierter N_Port ID Virtualization (NPIV).</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">Erstellen einer Zielzone für einen einzelnen Initiator</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">Erstellen Sie für jeden Initiator eine Zone (einzelne Initiatorzone).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">Geben Sie für jede Zone ein Ziel an, das die logische ONTAP FC-Schnittstelle (WWPN) für die SVMs ist. Es sollten mindestens zwei logische Schnittstellen pro Node pro SVM vorhanden sein. Verwenden Sie den WWPN von physischen Ports nicht.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">Bereitstellung von VMFS-Datenspeichern</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Interoperabilitäts-Matrix-Tool (IMT)</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">Prüfen Sie die Kompatibilität mit dem<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">Vergewissern Sie sich, dass die NVMe/FC-Konfiguration unterstützt wird.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP Aufgaben</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">Überprüfen Sie die ONTAP Lizenz für FCP.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>Verwenden Sie die<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Befehl und Prüfung, ob NVMe_of aufgeführt ist. Nutzung<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> Um eine Lizenz hinzuzufügen.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">Vergewissern Sie sich, dass das NVMe-Protokoll auf der SVM aktiviert ist.</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">Konfigurieren Sie SVMs für NVMe.</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">Stellen Sie sicher, dass auf den SVMs logische NVMe/FC-Schnittstellen verfügbar sind.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">Nutzung<block ref="e38d07be71f760e81ec7c17103cd57db" prefix=" " category="inline-code"></block> Um den FCP-Adapter zu überprüfen.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">Wird mit der GUI eine SVM erstellt, gehören zu diesem Prozess logische Schnittstellen.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">Verwenden Sie zum Umbenennen der Netzwerkschnittstelle den Befehl<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">NVMe Namespace und Subsystem erstellen</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">Aufgaben für VMware vSphere</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">Informationen Zum Storage-Adapter</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">Vergewissern Sie sich, dass die HBA-Treiber installiert sind. Die von VMware unterstützten HBAs verfügen über die Out-of-the-Box-Treiber und sollten bei sichtbar sein <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">Führen Sie die Installation des vSphere Host-NVMe-Treibers und Validierungsaufgaben durch</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">Erstellen eines VMFS-Datenspeichers</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp bietet viele Best Practices und Lösungen für eine robuste Virtualisierungsumgebung sowohl vor Ort als auch in der Cloud.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">NetApp Lösungen für Virtualisierung</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">Auf dieser Seite finden Sie Schritte zur Bereitstellung eines NetApp ONTAP-Storage-FC-VMFS-Datenspeichers in einer VMware vSphere-Umgebung.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">VSphere VMFS Datastore – Fibre-Channel-Storage-Back-End mit ONTAP</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">In diesem Abschnitt wird die Erstellung eines VMFS-Datenspeichers mit ONTAP Fibre Channel (FC)-Storage behandelt.</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">Grundkenntnisse für das Management einer vSphere Umgebung und einer ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">ONTAP Storage-Systeme (FAS/AFF/CVO/ONTAP Select/ASA) mit {ontap_Version}</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">ONTAP WWPN von Host-, Ziel- und SVM- sowie LUN-Informationen</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">Das ausgefüllte FC-Konfigurationsarbeitsblatt</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">Anmeldedaten für vCenter Server</block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">Informationen zu vSphere Hosts</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vsphere_Version}</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">Mit verbundenen ONTAP FC-Daten-Ports und vSphere-Hosts</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">Bei aktivierter N_Port ID Virtualization (NPIV)</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">Erstellen Sie einen einzelnen Initiator-Zielbereich.</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">Geben Sie für jede Zone ein Ziel an, das die logische ONTAP FC-Schnittstelle (WWPN) für die SVMs ist. Es sollten mindestens zwei logische Schnittstellen pro Node pro SVM vorhanden sein. Verwenden Sie den WWPN der physischen Ports nicht.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">Ein ONTAP Tool für Implementierung, Konfiguration und Einsatzbereitschaft von VMware vSphere</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">Bereitstellung eines VMFS-Datenspeichers</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">Gehen Sie wie folgt vor, um einen VMFS-Datenspeicher bereitzustellen:</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">Prüfen Sie die Kompatibilität mit dem<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">FCP-Konfiguration wird unterstützt</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">Überprüfen Sie das <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">Vergewissern Sie sich, dass Sie eine ONTAP-Lizenz für FCP haben.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">Verwenden Sie die<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Befehl zum Überprüfen, ob FCP aufgeführt ist.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">Nutzung<block ref="79868b45624cf0644299a1019c0f9dc9" prefix=" " category="inline-code"></block> Um die Lizenz hinzuzufügen.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">Vergewissern Sie sich, dass das FCP-Protokoll auf der SVM aktiviert ist.</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">Überprüfen Sie das FCP auf einer vorhandenen SVM.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">Konfigurieren Sie das FCP für eine vorhandene SVM.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">Erstellen Sie mit dem FCP eine neue SVM.</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">Stellen Sie sicher, dass auf einer SVM logische FCP-Schnittstellen verfügbar sind.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">Wird mit der GUI eine SVM erstellt, gehören zu diesem Prozess logische Schnittstellen.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">Verwenden Sie zum Umbenennen von Netzwerkschnittstellen<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">Erstellen und Zuordnen einer LUN.</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> Überspringen Sie diesen Schritt, wenn Sie ONTAP-Tools für VMware vSphere verwenden.</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">Aufgaben für VMware vSphere</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">Die HBA-Treiber sind installiert. Von VMware unterstützte HBAs verfügen über Out-of-the-Box-Treiber, die im sichtbar sein sollten <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">Stellen Sie einen VMFS-Datenspeicher mit ONTAP Tools bereit</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Auf dieser Seite werden die Best Practices zur Implementierung einer NetApp ONTAP Storage-Lösung in einer VMware vSphere Umgebung beschrieben.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="doc">Best Practices in sich vereint</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">VSphere Datastore- und Protokollfunktionen</block>
  <block id="7a787d6880ccfe1032af2f4288ce3901" category="paragraph">Fünf Protokolle können für die Anbindung von VMware vSphere ESXi Hosts an ONTAP Systeme für Datastores genutzt werden:</block>
  <block id="6b8f0029ce30f9b4d5fe0def33875511" category="list-text">FC</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="list-text">NFS</block>
  <block id="cbc9a42283809f1edcb32b4a495813f9" category="paragraph">FC, FCoE, NVMe/FC und iSCSI sind Blockprotokolle. VMware Datastores werden über das vSphere Virtual Machine File System (VMFS) gespeichert, um VMs innerhalb von ONTAP LUNs oder Namespaces zu speichern, die in einem ONTAP Volume enthalten sind. Beachten Sie, dass VMware ab vSphere 7.0 keine Software FCoE mehr in Produktionsumgebungen unterstützt. NFS ist ein File-Protokoll. Hierbei werden die Datastores nicht zusätzlich mit VMFS formatiert. VMs laufen direkt auf dem ONTAP Volume. SMB, iSCSI oder NFS kann direkt aus einem Gastbetriebssystem von ONTAP genutzt werden.</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">VMware Konfigurationsmaxima</block>
  <block id="6a6d2374b838393f6805b58d97c2c490" category="paragraph">In der folgenden Tabelle werden die von vSphere unterstützten Funktionen herkömmlicher Datastores mit ONTAP vorgestellt. Diese Informationen gelten nicht für VVols Datastores, sie gelten jedoch im Allgemeinen für Versionen von vSphere 6.x und 7.x, in denen unterstützte ONTAP Versionen verwendet werden. Sie können sich auch beraten<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> Bestätigen Sie für bestimmte vSphere Versionen bestimmte Limits.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Funktion/Feature</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formatieren</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS oder Raw Device Mapping (RDM)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS oder RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Maximale Anzahl an Datastores oder LUNs</block>
  <block id="468abcddfc22ae5cb2288b9937b300fb" category="cell">256 Ziele/HBA</block>
  <block id="72097e262592a146da0e4e856068965b" category="cell">256 Ziele</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256-Mounts Standard-NFS MaxVolumes ist 8. Erhöhen Sie mit den ONTAP Tools für VMware vSphere auf 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Maximale Datastore-Größe</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB FlexVol Volume oder mehr mit FlexGroup Volume</block>
  <block id="a4b27c6cd629522064dc48306e2bf8bb" category="cell">Maximale Datastore-Dateigröße (für VMDKs mit vSphere Version 5.5 und VMFS 5 oder höher)</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="ddf38e51732c3f7da57dc13c31a5483b" category="cell">VSphere unterstützt maximal 16 TB bei 62 TB.</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Optimale „Queue depth“ pro LUN oder Filesystem</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">In der folgenden Tabelle sind die unterstützten Funktionen in Bezug auf VMware Storage aufgeführt.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Kapazität/Funktion</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Storage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Storage Distributed Resource Scheduler (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware vStorage APIs for Data Protection (VADP)-fähige Backup-Software</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) oder Failover Clustering in einer VM</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Ja*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Nicht unterstützt</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Fehlertoleranz</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Site Recovery Manager</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">VMs (virtuelle Festplatten) mit Thin Provisioning</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Ja Diese Einstellung ist der Standard für alle VMs im NFS, wenn nicht VAAI verwendet wird.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Natives VMware Multipathing</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Einrichtung für Windows Server Failover Clustering</block>
  <block id="547211ca8a6b93fee863925a03cd341b" category="paragraph">*NetApp empfiehlt für Microsoft Cluster die Verwendung von in-Guest iSCSI anstelle von Multiwriter-fähigen VMDKs in einem VMFS Datastore. Dieser Ansatz wird von Microsoft und VMware vollständig unterstützt. Er bietet mit ONTAP ein hohes Maß an Flexibilität (SnapMirror auf ONTAP Systeme vor Ort oder in der Cloud), lässt sich leicht konfigurieren und automatisieren und kann mit SnapCenter gesichert werden. In vSphere 7 wurde eine neue Clustered VMDK-Option hinzugefügt. Diese unterscheidet sich von VMDKs mit Multi-Writer-Unterstützung, erfordert aber einen Datenspeicher, der über das FC-Protokoll bereitgestellt wird, bei dem die Unterstützung für geclusterte VMDK aktiviert ist. Weitere Einschränkungen sind möglich. Siehe VMware's<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> Dokumentation für Konfigurationsrichtlinien.</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">In der folgenden Tabelle werden die unterstützten ONTAP Storage-Managementfunktionen aufgeführt.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Datendeduplizierung</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Einsparungen im Array</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Einsparungen im Datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Thin Provisioning</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datenspeicher oder RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datenspeicher</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Datenspeichergröße ändern</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Erweitern Sie nur</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Vergrößerung, Autogrow und Verkleinerung</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">SnapCenter Plug-ins für Windows, Linux Applikationen (in Gast-BS)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Monitoring und Host-Konfiguration mit ONTAP Tools für VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Bereitstellung mit ONTAP Tools für VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">In der folgenden Tabelle sind die unterstützten Backup-Funktionen aufgeführt.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">ONTAP Snapshot Kopien</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">Durch replizierte Backups unterstütztes SRM</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">Volume SnapMirror</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VDMK Image-Zugriff</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP fähige Backup-Software</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP fähige Backup-Software, vSphere Client und vSphere Web Client Datastore-Browser</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VDMK-Zugriff auf Dateiebene</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP fähige Backup-Software, nur Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP fähige Backup-Software und Applikationen von Drittanbietern</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP-Granularität</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore oder VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Auswahl eines Storage-Protokolls</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Systeme mit ONTAP Software unterstützen alle wichtigen Storage-Protokolle, sodass die Kunden das für ihre Umgebung am besten geeignete Protokoll auswählen können. Dies hängt von der vorhandenen und geplanten Netzwerkinfrastruktur und den Fähigkeiten der Mitarbeiter ab. Bei von NetApp durchgeführten Tests zeigten sich generell nur geringfügige Unterschiede zwischen Protokollen, die mit ähnlichen Übertragungsgeschwindigkeiten ausgeführt wurden. Daher empfiehlt es sich, den Schwerpunkt in erster Linie auf die Netzwerkinfrastruktur und die Fähigkeiten der Mitarbeiter und erst in zweiter Linie auf die ursprüngliche Protokoll-Performance zu legen.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Die folgenden Faktoren könnten bei Überlegungen zur Auswahl eines Protokolls hilfreich sein:</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">*Gegenwärtige Kundenumgebung.* Obwohl IT-Teams normalerweise erfahren sind, um Ethernet IP-Infrastrukturen zu managen, sind nicht alle erfahren im Management einer FC SAN Fabric. Jedoch, die Verwendung eines allgemeinen IP-Netzwerk, das nicht für Storage-Traffic entwickelt ist, könnte nicht gut funktionieren. Berücksichtigen Sie Ihre vorhandene Netzwerkinfrastruktur, alle geplanten Optimierungen sowie die Fähigkeiten und die Verfügbarkeit von Mitarbeitern, die diese managen.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Einfache Einrichtung.* über die Erstkonfiguration der FC-Fabric hinaus (zusätzliche Switches und Kabel, Zoning und die Verifizierung der Interoperabilität von HBA und Firmware) müssen Blockprotokolle auch LUNs erstellen und zuordnen sowie vom Gastbetriebssystem Erkennung und Formatierung vornehmen. Nach der Erstellung und dem Export der NFS-Volumes werden sie vom ESXi Host gemountet und sind dann betriebsbereit. Für NFS sind keine besonderen Hardwarequalifizierungen oder Firmware für das Management erforderlich.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Einfaches Management.* bei SAN-Protokollen sind bei Bedarf mehrere Schritte erforderlich, darunter das Vergrößern einer LUN, das erneute Erkennen der neuen Größe und das Anwachsen des Dateisystems). Obwohl eine LUN vergrößert werden kann, ist eine Reduzierung der Größe einer LUN nicht möglich. Auch das Recovery von ungenutztem Speicherplatz kann weiteren Aufwand bedeuten. NFS ermöglicht eine problemlose Größenanpassung, die durch das Storage-System automatisiert werden kann. SAN bietet über TRIM/UNMAP-Befehle des Gast-Betriebssystems eine Speicherplatzrückgewinnung, sodass Speicherplatz aus gelöschten Dateien an das Array zurückgegeben werden kann. Diese Art der Rückgewinnung von ungenutztem Speicherplatz ist bei NFS-Datenspeichern schwieriger.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Storage-Speicherplatztransparenz.* die Storage-Auslastung ist in NFS-Umgebungen in der Regel einfacher zu erkennen, da Thin Provisioning unmittelbare Einsparungen ermöglicht. In ähnlicher Form sind Einsparungen durch Deduplizierung und Klonen unmittelbar für andere VMs im selben Datastore oder für Storage-System-Volumes verfügbar. Die VM-Dichte ist typischerweise ebenfalls größer als in einem NFS-Datastore. Hierdurch können höhere Einsparungen bei der Deduplizierung sowie eine Senkung der Managementkosten erzielt werden, da weniger Datastores gemanagt werden müssen.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Datenspeicher-Layout</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link-macro">Empfohlene ESXi Host-Einstellungen und andere ONTAP Einstellungen</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">ONTAP Storage-Systeme bieten beim Erstellen von Datastores für VMs und virtuelle Festplatten ein hohes Maß an Flexibilität. Obwohl viele ONTAP Best Practices angewendet werden, wenn Datastores für vSphere mit VSC bereitgestellt werden (siehe Abschnitt) <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>), hier sind einige zusätzliche Richtlinien zu berücksichtigen:</block>
  <block id="73ab3808ccb313675f9b890edf67fd09" category="list-text">Der Einsatz von vSphere mit ONTAP-NFS-Datastores sorgt für eine hochperformante, einfach zu managende Implementierung mit VM/Datastore-Verhältnissen, die mit blockbasierten Storage-Protokollen nicht erreicht werden können. Diese Architektur kann zu einer Verzehnfachung der Datastore-Dichte und einer damit korrelierenden Verringerung der Datastore-Anzahl führen. Obwohl ein größerer Datastore die Storage-Effizienz begünstigen und betriebliche Vorteile bieten ONTAP kann, sollten Sie mindestens vier Datastores (FlexVol Volumes) verwenden. Durch die Verteilung der Datastores auf die Controller kann so die bestmögliche Ausnutzung der Hardware gewährleistet werden. Mit diesem Ansatz können Sie auch Datastores mit unterschiedlichen Recovery-Richtlinien erstellen. Einige können je nach den geschäftlichen Anforderungen häufiger gesichert oder repliziert werden als andere. Bei einer Skalierung des Designs sind keine mehreren Datastores für FlexGroup Volumes erforderlich.</block>
  <block id="68281e9d236ee27e21f68ce5838462f1" category="list-text">NetApp empfiehlt den Einsatz von FlexVol Volumes und beginnend mit ONTAP 9.8 FlexGroup Volumes, NFS-Datastores. Andere ONTAP Storage-Container wie qtrees werden im Allgemeinen nicht empfohlen, da diese derzeit nicht von ONTAP Tools für VMware vSphere unterstützt werden. In hoch automatisierten Umgebungen, die von Kontingenten auf Datastore-Ebene oder VM-Dateiklonen profitieren können, kann es hilfreich sein, Datastores als mehrere qtrees in einem einzelnen Volume zu implementieren.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Eine gute Größe für einen FlexVol Volume-Datastore liegt bei etwa 4 TB bis 8 TB. Diese Größe bildet einen guten Ausgleichspunkt im Hinblick auf Performance, einfaches Management und Datensicherung. Beginnen Sie mit einem kleinen Datastore (beispielsweise 4 TB) und vergrößern Sie diesen nach Bedarf (bis auf maximal 100 TB). Kleinere Datenspeicher lassen sich nach einem Backup oder nach einem Ausfall schneller wiederherstellen und können schnell im Cluster verschoben werden. Die automatische Größenanpassung von ONTAP kann sinnvoll sein, um das Volume bei wechselnder Speicherplatzbelegung automatisch zu vergrößern oder zu verkleinern. Der ONTAP Tools für die Bereitstellung von VMware vSphere Datastores verwendet Autosize standardmäßig für neue Datastores. Eine weitere Anpassung der Vergrößerungs- und Verkleinerungsschwellenwerte sowie der maximalen und minimalen Größe kann mit System Manager oder über die Befehlszeile erfolgen.</block>
  <block id="12346208f1923ebe162c32f3c4ccf23a" category="list-text">Alternativ können VMFS Datastores mit LUNs konfiguriert werden, auf die über FC, iSCSI oder FCoE zugegriffen wird. Bei VMFS können alle ESX Server in einem Cluster gleichzeitig auf herkömmliche LUNs zugreifen. VMFS Datastores können eine Größe von bis zu 64 TB haben und bestehen aus bis zu 32 2TB LUNs (VMFS 3) oder einer einzelnen 64-TB-LUN (VMFS 5). Die maximale LUN-Größe von ONTAP beträgt auf den meisten Systemen 16 TB und 128 TB auf All SAN Array-Systemen. Daher kann auf den meisten ONTAP Systemen ein VMFS 5 Datastore mit maximaler Größe aus vier 16-TB-LUNs erstellt werden. Für Workloads mit hohem I/O-Aufkommen und mehreren LUNs (bei High-End FAS oder AFF Systemen) können Performance-Vorteile zum Tragen kommen, allerdings werden diese durch das komplexere Management beim Erstellen, Managen und Sichern der Datastore-LUNs und ein erhöhtes Verfügbarkeitsrisiko ausgeglichen. NetApp empfiehlt im Allgemeinen, eine einzelne, große LUN für jeden Datastore zu verwenden. Und nur im Ausnahmefall, wenn größere Datastores mit über 16 TB gebraucht werden, mit Extends zu arbeiten. Analog zu dem NFS Ansatz, verteilen ONTAP Sie ebenfalls die Datastores über die Controller, um die bestmögliche Performance zu erzielen.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Ältere Gastbetriebssysteme (OS) mussten an das Storage-System angeglichen werden (Alignment), um die bestmögliche Performance und Storage-Effizienz zu erzielen. Bei modernen Betriebssystemen mit Anbieterunterstützung von Microsoft und Linux Distributoren wie Red hat sind jedoch keine Anpassungen mehr erforderlich, um die Filesystem-Partition mit den Blöcken des zugrunde liegenden Storage-Systems in einer virtuellen Umgebung zu alignen. Wenn Sie ein altes Betriebssystem verwenden, für das unter Umständen ein Alignment erforderlich ist, suchen Sie in der NetApp Support Knowledgebase nach Artikeln, in denen das Thema VM Alignment behandelt wird, oder fordern Sie bei einem NetApp Ansprechpartner für den Vertrieb oder für Partner ein Exemplar des technischen Berichts TR-3747 an.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">Vermeiden Sie die Verwendung von Defragmentierung innerhalb des Gastbetriebssystems, da dies keinen Performance-Vorteil bietet und die Storage-Effizienz sowie die Speicherplatznutzung von Snapshot-Kopien beeinträchtigt. Zudem sollten Sie die Suchindizierung im Gastbetriebssystem für virtuelle Desktops deaktivieren.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ist eines der branchenweit führenden Unternehmen mit innovativen Storage-Effizienzfunktionen, mit denen Sie Ihren nutzbaren Festplattenspeicherplatz maximal ausschöpfen können. AFF Systeme sind durch Inline-Deduplizierung und -Komprimierung sogar noch effizienter. Die Daten werden über alle Volumes hinweg in einem Aggregat dedupliziert. Daher müssen zur Maximierung der Einsparungen keine ähnlichen Betriebssysteme und ähnlichen Applikationen in einem einzelnen Datastore mehr gruppieren.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633: Oracle Databases on Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">In einigen Fällen benötigen Sie eventuell nicht einmal einen Datastore. Um die beste Performance und ein optimales Management zu erzielen, sollten Sie für Applikationen mit hohem I/O-Aufkommen – beispielsweise für Datenbanken und bestimmte Applikationen – keinen Datastore verwenden. Hier sind „inguest“-Ansätze via NFS oder iSCSI in Erwägung zu ziehen, die vom Gastbetriebssystem verwaltet werden oder via Raw Device Mapping (RDM). Eine Anleitung zu bestimmten Applikationen finden Sie in den technischen Berichten von NetApp für die jeweilige Applikation. Beispiel:<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> Ein Abschnitt zur Virtualisierung mit hilfreichen Details.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Festplatten der ersten Klasse (oder verbesserte virtuelle Festplatten) ermöglichen über vCenter gemanagte Festplatten unabhängig von einer VM mit vSphere 6.5 und höher. Sie werden zwar primär durch API gemanagt, sind aber auch mit VVols nützlich, insbesondere bei dem Management mit OpenStack oder Kubernetes-Tools. Sie werden von ONTAP unterstützt sowie ONTAP Tools für VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Datastore und VM-Migration</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Wenn Sie VMs aus einem bestehenden Datastore in einem anderen Storage-System zu ONTAP migrieren, sollten Sie die folgenden Praktiken berücksichtigen:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Verwenden Sie Storage vMotion, um den Großteil Ihrer Virtual Machines in ONTAP zu verschieben. Dieser Ansatz ermöglicht nicht nur einen unterbrechungsfreien Betrieb der VMs, sondern auch die Nutzung von ONTAP Storage-Effizienzfunktionen wie Inline-Deduplizierung und -Komprimierung zur Verarbeitung der Daten während der Migration. Es empfiehlt sich unter Umständen, mithilfe von vCenter Funktionen mehrere VMs aus der Bestandsliste auszuwählen und die Migration dann zu einem geeigneten Zeitpunkt zu planen (dazu klicken Sie mit gedrückter Strg-Taste auf „Actions“).</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">Sie können eine Migration auf geeignete Ziel-Datastores zwar genau planen, doch es ist oft einfacher, große Datenmengen zu migrieren und diese anschließend nach Bedarf zu organisieren. Falls Sie spezifische Datensicherungsanforderungen erfüllen müssen, beispielsweise unterschiedliche Snapshot Schedules, sollten Sie diesen Ansatz wählen, um die Migration in verschiedene Datastores zu steuern.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">Die meisten VMs und deren Storage können im Betrieb (eingeschalteter Zustand) migriert werden. Attached Storage (nicht im Datastore) – beispielsweise in Form von ISOs, LUNs oder NFS-Volumes – aus einem anderen Storage-System muss jedoch unter Umständen im ausgeschalteten Zustand migriert werden.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">Virtual Machines, bei denen eine präzisere Migration erforderlich ist, sind unter anderem Datenbanken und Applikationen mit Nutzung von Attached Storage. Im Allgemeinen sollten Sie die Verwendung der Tools der Anwendung in Betracht ziehen, um die Migration zu verwalten. Für Oracle empfiehlt sich zur Migration der Datenbankdateien die Nutzung von Oracle-Tools wie RMAN oder ASM. Siehe<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> Finden Sie weitere Informationen. Ganz ähnlich kommen für SQL Server entweder SQL Server Management Studio oder NetApp Tools wie SnapManager für SQL Server oder SnapCenter in Betracht.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">ONTAP Tools für VMware vSphere</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">Wenn Sie vSphere mit ONTAP verwenden, ist es eine Best Practice, die ONTAP Tools für VMware vSphere Plug-in (ehemals Virtual Storage Console) zu installieren und zu verwenden. Dieses vCenter Plug-in vereinfacht das Storage-Management, erhöht die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder bei NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert die ESXi Hosteinstellungen für Multipath- und HBA-Timeouts (diese sind in Anhang B beschrieben). Weil es ein vCenter-Plug-in ist, ist es für alle vSphere Web-Clients verfügbar, die sich mit dem vCenter-Server verbinden.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">Das Plug-in hilft Ihnen auch bei der Nutzung anderer ONTAP Tools in vSphere Umgebungen. Mit der Software können Sie das NFS-Plug-in für VMware VAAI installieren, das einen Copy-Offload zu ONTAP für VM-Klonvorgänge, eine Speicherplatzreservierung für Thick Virtual Disk Files und einen ONTAP Snapshot Copy Offload ermöglicht.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">Das Plug-in ist auch die Managementoberfläche für viele Funktionen von VASA Provider für ONTAP und unterstützt das richtlinienbasierte Storage-Management mit VVols. Nach der Registrierung von ONTAP Tools für VMware vSphere erstellen Sie damit Storage-Funktionsprofile, ordnen diesen Storage zu und stellen im Laufe der Zeit die Datastore-Compliance mit den Profilen sicher. Vasa Provider verfügt auch über eine Schnittstelle zum Erstellen und Managen von vVol Datastores.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">Im Allgemeinen empfiehlt NetApp zur Bereitstellung herkömmlicher und VVols Datastores die Verwendung der ONTAP Tools für die Schnittstelle VMware vSphere in vCenter, um die Einhaltung von Best Practices sicherzustellen.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Allgemeines Networking</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">Wenn Sie vSphere mit Systemen mit ONTAP Software verwenden, ist die Konfiguration von Netzwerkeinstellungen einfach und erfolgt ähnlich wie andere Netzwerkkonfigurationen. Folgende Punkte sind dabei zu berücksichtigen:</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">Separater Storage-Netzwerk-Traffic aus anderen Netzwerken. Ein separates Netzwerk kann mithilfe eines dedizierten VLANs oder separater Switches für Storage eingerichtet werden. Falls im Storage-Netzwerk physische Pfade wie Uplinks geteilt werden, sind eventuell QoS oder zusätzliche Uplink-Ports erforderlich, um eine ausreichende Bandbreite sicherzustellen. Verbinden Sie Hosts nicht direkt mit Storage; verwenden Sie Switches, um redundante Pfade zu haben und erlauben Sie VMware HA ohne Intervention zu arbeiten.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Jumbo Frames können genutzt werden, sofern dies gewünscht ist und von Ihrem Netzwerk unterstützt wird, insbesondere bei Verwendung von iSCSI. Vergewissern Sie sich bei ihrem Einsatz, dass sie auf allen Netzwerkgeräten, VLANs etc. Im Pfad zwischen Storage und dem ESXi Host gleich konfiguriert sind. Anderenfalls kann es zu Performance- oder Verbindungsproblemen kommen. Auf dem virtuellen ESXi Switch, dem VMkernel Port, sowie den physischen Ports oder den Interface Groups muss für jeden ONTAP Node auch jeweils dieselbe MTU festgelegt sein.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp empfiehlt eine Deaktivierung der Netzwerk- Flusssteuerung nur an den Cluster-Netzwerkports innerhalb eines ONTAP Clusters. Für die übrigen Netzwerkports, die für Daten-Traffic verwendet werden, gibt NetApp im Hinblick auf Best Practices keine weiteren Empfehlungen. Diese Ports sollten Sie nach Bedarf aktivieren oder deaktivieren. Siehe<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> Für mehr Hintergrund zur Flusssteuerung.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Wenn ESXi und ONTAP Storage-Arrays mit Ethernet-Storage-Netzwerken verbunden werden, empfiehlt NetApp, die Ethernet-Ports, mit denen diese Systeme verbunden werden, mit der Cisco PortFast Funktion oder als Rapid Spanning Tree Protocol (RSTP)-Edge-Ports zu konfigurieren. NetApp empfiehlt die Aktivierung der Spanning Tree PortFast Trunk-Funktion in Umgebungen mit Verwendung der Cisco PortFast Funktion und 802.1Q VLAN-Trunking entweder für den ESXi Server oder für die ONTAP Storage-Arrays.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">Für die Link-Aggregation empfiehlt NetApp die folgenden Best Practices:</block>
  <block id="102e4f88579e89519d8c614561d5e302" category="list-text">Verwenden Sie Switches, die die Link-Aggregation von Ports in zwei separaten Switch-Chassis durch einen Ansatz mit einer Multi-Chassis-Link-Aggregationsgruppe wie Virtual PortChannel (vPC) von Cisco unterstützen.</block>
  <block id="f331781b955fd46506835e783c953ed4" category="list-text">Deaktivieren Sie LACP für mit ESXi verbundene Switch Ports, sofern Sie nicht dvSwitches mit der Versionen 5.1 oder höher mit konfiguriertem LACP verwenden.</block>
  <block id="eb8cf3a79d16ed9f0e2c1de65c379bc5" category="list-text">Erstellen Sie mit LACP Link-Aggregate für ONTAP Storage-Systeme mit dynamischen Multimode-Schnittstellengruppen mit IP-Hash.</block>
  <block id="8ebcba6104088fb46f64395277d21edd" category="list-text">Verwenden Sie die IP-Hash-Teaming-Richtlinie für ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">Die folgende Tabelle enthält eine Zusammenfassung der Netzwerkkonfigurationselemente sowie Angaben dazu, wo die Einstellungen angewendet werden.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Element</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Switch</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Knoten</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP-Adresse</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">Nein**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Link-Aggregation</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Virtueller Switch</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">Nein*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel und VM-Portgruppen</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Flusskontrolle</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning Tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (für Jumbo Frames)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Virtueller Switch und VMkernel Port (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Ja (auf Maximalwert eingestellt)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Ja (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Failover-Gruppen</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Ja (erstellen)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Ja (auswählen)</block>
  <block id="93e04df6f821105fd0ab88e95eaee167" category="paragraph">*SVM-LIFs werden mit Ports, Schnittstellengruppen oder VLAN-Schnittstellen verbunden, die über VLAN-, MTU- und andere Einstellungen verfügen. Diese Einstellungen werden jedoch nicht auf SVM-Ebene gemanagt.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Diese Geräte haben eigene IP-Adressen für das Management, aber diese Adressen werden nicht im Zusammenhang mit ESXi Storage Networking verwendet.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">Mit vSphere gibt es drei Methoden, blockbasierten Speicher zu nutzen:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Mit VMFS Datastores</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Mit Raw Device Mapping (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">Auf diese LUN wird von einem Software-Initiator aus einem VM-Gastbetriebssystem zugegriffen und gesteuert</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS ist ein hochperformantes geclustertes Filesystem, das Datastores bereitstellt, bei denen es sich um Shared-Storage-Pools handelt. VMFS Datastores können mit LUNs konfiguriert werden, auf die über FC, iSCSI, FCoE oder NVMe Namespaces zugegriffen wird, auf die das NVMe/FC-Protokoll zugegriffen wird. Bei VMFS können alle ESX Server in einem Cluster gleichzeitig auf herkömmliche LUNs zugreifen. Die maximale LUN-Größe beträgt bei ONTAP im Allgemeinen 16 TB; daher wird ein VMFS 5 Datastore mit einer maximalen Größe von 64 TB (siehe erste Tabelle in diesem Abschnitt) aus vier 16-TB-LUNs erstellt (alle SAN-Array-Systeme unterstützen die maximale VMFS-LUN-Größe von 64 TB). Da die ONTAP LUN-Architektur keine kleinen individuellen „Queue Depths“ aufweist, sind VMFS Datastores in ONTAP relativ problemlos in einem höheren Maße skalierbar gegenüber herkömmlichen Array-Architekturen.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere umfasst integrierte Unterstützung für mehrere Pfade zu Storage-Geräten. Dieses Verfahren wird als natives Multipathing (NMP) bezeichnet. NMP kann den Storage-Typ für unterstützte Storage-Systeme erkennen und den NMP-Stack automatisch so konfigurieren, dass die Funktionen des verwendeten Storage-Systems unterstützt werden.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Sowohl NMP als auch NetApp ONTAP unterstützen Asymmetric Logical Unit Access (ALUA) zur Ermittlung optimierter und nicht optimierter Pfade. In ONTAP folgt ein ALUA-optimierter Pfad auf einen direkten Datenpfad. Dabei wird ein Zielport auf dem Node verwendet, der die LUN hostet, auf die zugegriffen wird. ALUA ist sowohl in vSphere als auch in ONTAP standardmäßig aktiviert. NMP erkennt das ONTAP Cluster als ALUA-fähig und verwendet ein ALUA Storage-Array-Plug-in <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) Und wählt das Plug-in zur Auswahl des Round-Robin-Pfads aus <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 unterstützt bis zu 256 LUNs und insgesamt bis zu 1,024 Pfade zu LUNs. Alle über diese Grenzen hinausgehenden LUNs oder Pfade werden von ESXi nicht erkannt. Ausgehend von dieser maximalen Anzahl an LUNs lässt das Pfadlimit vier Pfade pro LUN zu. In einem größeren ONTAP Cluster ist es möglich, dass das Pfadlimit vor dem LUN-Limit erreicht wird. Zur Beseitigung dieser Beschränkung unterstützt ONTAP ab Version 8.3 die selektive LUN-Zuordnung (Selective LUN Map, SLM).</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="a1319b3463fde689889152797a3cf966" category="paragraph">SLM beschränkt die Nodes, die Pfade an eine bestimmte LUN weitergeben. Eine Best Practice von NetApp sieht mindestens eine logische Schnittstelle (Logical Interface, LIF) pro Node pro SVM und die Verwendung von SLM vor, um die Pfade zu begrenzen, die an den Node weitergegeben werden, der die LUN und deren HA-Partner hostet. Obwohl es andere Pfade gibt, werden sie standardmäßig nicht beworben. Die weitergegebenen Pfade können mit den Node-Argumenten zum Hinzufügen oder Entfernen der Berichterstellung in SLM geändert werden. Beachten Sie, dass in Versionen vor 8.3 erstellte LUNs alle Pfade weitergeben. Sie müssen geändert werden, damit nur die Pfade zum Hosting-HA-Paar weitergegeben werden. Weitere Informationen zu SLM finden Sie im Abschnitt 5.9 von<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. Um die für eine LUN verfügbaren Pfade weiter zu reduzieren, kann auch die frühere Portsatzmethode verwendet werden. Portsätze tragen dazu bei, die Anzahl der sichtbaren Pfade zu verringern, durch die Initiatoren in einer Initiatorgruppe LUNs ausfindig machen können.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM ist standardmäßig aktiviert. Sofern Sie keine Portsätze verwenden, ist keine weitere Konfiguration erforderlich.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Für LUNs, die vor Data ONTAP 8.3 erstellt wurden, wenden Sie SLM manuell an, indem Sie die ausführen<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Befehl, um die LUN-Nodes für die Berichterstellung zu entfernen und den LUN-Zugriff auf den LUN-Eigentümer-Node und seinen HA-Partner zu beschränken.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Blockprotokolle (iSCSI, FC und FCoE) greifen mithilfe von LUN-IDs und Seriennummern sowie mit eindeutigen Namen auf LUNs zu. FC und FCoE verwenden weltweite Namen (WWNNs und WWPNs) und iSCSI verwendet qualifizierte iSCSI-Namen (IQNs). Der Pfad zu LUNs innerhalb des Storage hat für die Blockprotokolle keine Bedeutung und wird nirgendwo im Protokoll angegeben. Daher muss ein Volume, das nur LUNs enthält, nicht intern gemountet werden. Zudem ist für Volumes, die in Datastores verwendete LUNs enthalten, kein Verbindungspfad erforderlich. Das NVMe-Subsystem in ONTAP funktioniert ähnlich.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Weitere Best Practices, die berücksichtigt werden sollten:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Vergewissern Sie sich, dass für jede SVM auf jedem Node im ONTAP Cluster eine logische Schnittstelle (LIF) erstellt wird, um maximale Verfügbarkeit und Mobilität zu gewährleisten. Als Best Practice empfiehlt sich für ONTAP SANs die Verwendung von zwei physischen Ports und LIFs pro Node, einer für jede Fabric. Mit ALUA werden Pfade geparst und aktive optimierte (direkte) Pfade im Gegensatz zu aktiven nicht optimierten Pfaden identifiziert. ALUA wird für FC, FCoE und iSCSI verwendet.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Nutzen Sie für iSCSI-Netzwerke mehrere VMkernel Netzwerkschnittstellen für verschiedene Subnetze mit NIC-Teaming, wenn mehrere virtuelle Switches vorhanden sind. Darüber hinaus können Sie mehrere physische NICs nutzen, die mit mehreren physischen Switches verbunden sind, um Hochverfügbarkeit und einen höheren Durchsatz bereitzustellen. Die folgende Abbildung zeigt ein Beispiel für Multipath-Konnektivität. Konfigurieren Sie in ONTAP entweder eine Single-Mode-Schnittstellengruppe für Failover mit zwei oder mehr Links, die mit zwei oder mehreren Switches verbunden sind, oder nutzen Sie LACP oder eine andere Link-Aggregationstechnologie mit Multimode-Schnittstellengruppen, um Hochverfügbarkeit und die Vorteile der Link-Aggregation bereitzustellen.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Wenn das Challenge-Handshake Authentication Protocol (CHAP) in ESXi für die Zielauthentifizierung verwendet wird, muss es auch in ONTAP über die CLI konfiguriert werden <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) Oder mit System Manager (bearbeiten Sie die Initiatorsicherheit unter „Storage“ &gt; „SVMs“ &gt; „SVM-Einstellungen“ &gt; „Protocols“ &gt; „iSCSI“).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere, um LUNs und Initiatorgruppen zu erstellen und zu managen. Das Plug-in bestimmt automatisch die WWPNs von Servern und erstellt entsprechende Initiatorgruppen. Darüber hinaus konfiguriert er LUNs gemäß Best Practices und ordnet sie den richtigen Initiatorgruppen zu.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">Kompatibilitätsmodus für physischen und virtuellen Modus</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Setzen Sie RDMs mit Bedacht ein, da ihr Management schwieriger sein kann. Zudem verwenden sie auch Pfade, die, wie bereits beschrieben, beschränkt sind. ONTAP LUNs unterstützen beide<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDMs:</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">ONTAP NVMe/FC-Host-Konfigurationsleitfaden</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Weitere Informationen zur Verwendung von NVMe/FC mit vSphere 7.0 finden Sie im hier<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> Und<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>Die folgende Abbildung zeigt die Multipath-Konnektivität von einem vSphere Host zu einer ONTAP LUN.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">Bei vSphere können Kunden mithilfe von NFS-Arrays der Enterprise-Klasse gleichzeitigen Zugriff auf Datastores auf allen Nodes in einem ESXi Cluster ermöglichen. Wie im Abschnitt zu Datastores erwähnt, gibt es bei der Verwendung von NFS mit vSphere einige Vorteile im Hinblick auf Benutzerfreundlichkeit, Storage-Effizienz und Sichtbarkeit.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Für die Verwendung von ONTAP NFS mit vSphere werden folgende Best Practices empfohlen:</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">Verwenden einer einzelnen logischen Schnittstelle (LIF) für jede SVM auf jedem Node im ONTAP-Cluster Die bisherigen Empfehlungen eines LIF pro Datenspeicher sind nicht mehr erforderlich. Während der direkte Zugriff (LIF und Datastore auf demselben Knoten) am besten ist, keine Sorge über indirekten Zugriff, weil der Performance-Effekt ist in der Regel minimal (Mikrosekunden).</block>
  <block id="83deede0d0158f0f2469080b6208e88a" category="list-text">VMware unterstützt NFSv3 seit VMware Infrastructure 3. VSphere 6.0 bietet zusätzlich Unterstützung für NFSv4.1 und ermöglicht damit einige erweiterte Funktionen wie Kerberos Sicherheit. In NFSv3 wird „Client-side locking“ verwendet, in NFSv4.1 „Server-side locking“. Ein ONTAP Volume kann zwar mit beiden Protokollen exportiert werden, doch ESXi kann nur durch ein Protokoll gemountet werden. Bei diesem Einzelprotokoll-Mounting ist jedoch nicht ausgeschlossen, dass ESXi Hosts denselben Datastore auch durch eine andere Version mounten. Denken Sie daran, die beim Mounten verwendete Protokollversion anzugeben, damit alle Hosts dieselbe Version und somit auch denselben Sperrungsstil anwenden. Verwenden Sie auf verschiedenen Hosts nicht unterschiedliche NFS-Versionen. Falls möglich, prüfen Sie mithilfe von Hostprofilen die Compliance.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Da keine automatische Datastore-Konvertierung zwischen NFSv3 und NFSv4.1 stattfindet, erstellen Sie einen neuen Datastore für NFSv4.1 und migrieren Sie die VMs mithilfe von Storage vMotion zum neuen Datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">NetApp Interoperabilitäts-Matrix-Tool</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Weitere Informationen finden Sie in den Anmerkungen zur Interoperabilität von NFS v4.1<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Für bestimmte ESXi-Patch-Level, die zur Unterstützung erforderlich sind.</block>
  <block id="04826f858f8ad9c66b9d805ca9ff88a3" category="list-text">Zur Steuerung des Zugriffs durch vSphere Hosts kommen NFS-Exportrichtlinien zur Anwendung. Sie können eine Richtlinie für mehrere Volumes (Datastores) nutzen. Bei NFSv3 verwendet ESXi den Sicherheitsstil „sys“ (UNIX). Zur Ausführung von VMs ist dabei die Root-Mount-Option erforderlich. In ONTAP wird diese Option als Superuser bezeichnet. Wenn die Option Superuser verwendet wird, ist es nicht erforderlich, die anonyme Benutzer-ID anzugeben. Beachten Sie, dass Exportrichtlinien mit unterschiedlichen Werten für gelten<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> Und<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Die ONTAP-Tools können zu Problemen bei der SVM-Erkennung führen. Hier ist eine Beispielpolitik:</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Access Protocol: nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Client Match Spec: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">RO-Zugriffsregel: Sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">RW Access Rule: Sys</block>
  <block id="0fd74b9f6a61e12b4a204b3489bd05a9" category="list-text">Anonyme UID:</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superuser: Sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Wenn das NetApp NFS-Plug-in für VMware VAAI verwendet wird, sollte das Protokoll auf eingestellt werden<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Wenn die Regel für die Exportrichtlinie erstellt oder geändert wird. Damit der Copy-Offload funktioniert, wird das NFSv4-Protokoll benötigt und das Protokoll als angegeben<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Beinhaltet automatisch sowohl die NFSv3- als auch die NFSv4-Versionen.</block>
  <block id="44e8816851b6d24723bf0e06c3b8b40d" category="list-text">NFS-Datastore-Volumes werden aus dem Root-Volume der SVM heraus verbunden. Daher muss ESXi zum Navigieren und Mounten von Datastore Volumes auch Zugriff auf das Root-Volume haben. Die Exportrichtlinie für das Root-Volume und für alle anderen Volumes, in denen die Verbindung des Datastore Volumes geschachtelt ist, muss eine oder mehrere Regeln für die ESXi-Server einschließen, die ihnen schreibgeschützten Zugriff gewähren. Hier ist eine Beispielpolitik für das Root-Volumen, auch mit dem VAAI Plug-in:</block>
  <block id="88b77eec23ea926d7dac5b6ec36713d2" category="list-text">Zugriffsprotokoll. nfs (schließt nfs3 und nfs4 ein)</block>
  <block id="2e5d116b123742b0c1f9b9266e3d45e4" category="list-text">Vergleich Der Client-Übereinstimmung: 192.168.42.21</block>
  <block id="e79bd23a286e2e109f901ac7b9fc1052" category="list-text">RO-Zugriffsregel. Sys</block>
  <block id="6854a3cd4d70ef13145d55305c745f1c" category="list-text">RW Access Rule. Nie (höchste Sicherheit für Root-Volume)</block>
  <block id="629cac79e5ae376b5235b5cb87c8c03d" category="list-text">Anonyme UID:</block>
  <block id="e76eb6f8b3ceafc6b70386efb46a8295" category="list-text">Superuser: Sys (auch für Root-Volume mit VAAI erforderlich)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere (die wichtigste Best Practice):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Mit ONTAP Tools für VMware vSphere können Sie Datastores bereitstellen, da es das Management von Richtlinien für den Export automatisch vereinfacht.</block>
  <block id="55cf2206291fced620eed577cb8c8a42" category="list-text">Wählen Sie beim Erstellen von Datastores für VMware Cluster mit dem Plug-in das Cluster anstelle eines einzelnen ESX Servers aus. Bei dieser Auswahl mountet der Datastore automatisch auf alle Hosts im Cluster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Wenden Sie mithilfe der Plug- in-Mount-Funktion vorhandene Datastores auf neue Server an.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Wenn Sie die ONTAP Tools nicht für VMware vSphere verwenden, verwenden Sie eine Exportrichtlinie für alle Server oder für jeden Server-Cluster, wo eine zusätzliche Zugriffs-Kontrolle erforderlich ist.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Obwohl ONTAP eine flexible Namespace-Struktur für Volumes bietet, in der Volumes mithilfe von Verbindungen in einer Baumstruktur angeordnet werden können, ist dieser Ansatz für vSphere nicht praktikabel. Für jede VM im Root-Verzeichnis des Datastores wird unabhängig von der Namespace-Hierarchie des Storage ein Verzeichnis erstellt. Daher besteht die Best Practice darin, den Verbindungspfad für Volumes für vSphere im Root-Volume der SVM zu erstellen. Dies entspricht auch der Art und Weise, wie ONTAP Tools für VMware vSphere Datastores bereitstellt. Ohne geschachtelte Verbindungspfade besteht bei Volumes zudem nur eine Abhängigkeit zum Root-Volume. Wenn ein Volume dann offline geschaltet oder sogar absichtlich zerstört wird, wirkt sich dies also nicht auf den Pfad zu den anderen Volumes aus.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Eine Blockgröße von 4 KB ist für NTFS-Partitionen auf NFS-Datenspeichern gut. In der folgenden Abbildung ist die Konnektivität eines vSphere Hosts zu einem ONTAP NFS-Datastore dargestellt.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">In der folgenden Tabelle sind NFS-Versionen und unterstützte Funktionen aufgeführt.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funktionen von vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion und Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Hochverfügbarkeit</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Fehlertoleranz</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Hostprofile</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Storage-I/O-Steuerung</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Virtual Volumes</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Hardwarebeschleunigung (VAAI)</block>
  <block id="aa32fdb70496d9a7395ef0d3ccb1c986" category="cell">Ja (vSphere 6.5 und höher, NetApp Plug-in 1.1 für VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos Authentifizierung</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Ja (Erweiterung mit vSphere 6.5 und höher zur Unterstützung von AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Multipathing-Unterstützung</block>
  <block id="4cdf980fd6cee432c76402bb142269e9" category="cell">Nein (Unterstützung bei ESXi 6.5 und höher durch Session-Trunking; Unterstützung bei ONTAP durch pNFS)</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 bietet zusätzliche Unterstützung für FlexGroup-Datastores in vSphere sowie für die ONTAP-Tools für VMware vSphere 9.8 Release. FlexGroup vereinfacht die Erstellung großer Datastores und erstellt automatisch eine Reihe von zusammengehörigen Volumes, um die maximale Performance eines ONTAP Systems zu erreichen. Nutzen Sie FlexGroup mit vSphere für einen einzelnen, skalierbaren vSphere Datastore, der die Leistungsfähigkeit eines vollständigen ONTAP-Clusters bietet.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">Neben umfangreichen Systemtests mit vSphere Workloads bietet ONTAP 9.8 auch einen neuen Offload-Mechanismus für FlexGroup Datastores. Hierbei wird eine verbesserte Kopier-Engine verwendet, um Dateien zwischen den Komponenten im Hintergrund zu kopieren, während der Zugriff auf Quelle und Ziel möglich ist. Mehrere Kopien verwenden sofort verfügbare, platzsparende Datei-Klone in einer Komponente, wenn diese je nach Skalierung benötigt werden.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 bietet darüber hinaus neue dateibasierte Performance-Metriken (IOPS, Durchsatz und Latenz) für FlexGroup-Dateien. Diese Kennzahlen können Sie auch in den ONTAP Tools für VMware vSphere Dashboard- und VM-Berichten ansehen. Die ONTAP Tools für VMware vSphere Plug-in ermöglichen Ihnen darüber hinaus die Festlegung von QoS-Regeln (Quality of Service) über eine Kombination aus dem Maximum und/oder dem Minimum von IOPS. Diese können über alle VMs in einem Datenspeicher oder individuell für bestimmte VMs hinweg festgelegt werden.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Im Folgenden finden Sie einige weitere NetApp Best Practices:</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Nutzen Sie die Standardeinstellungen für die FlexGroup-Bereitstellung. Es empfiehlt sich zwar ONTAP-Tools für VMware vSphere, da sie die FlexGroup in vSphere erstellen und gemountet werden. Zudem ist ONTAP System Manager oder die Befehlszeile kann für spezielle Anforderungen verwendet werden. Verwenden Sie dann selbst die Standardwerte wie die Anzahl der zusammengehörigen Mitglieder pro Node, da dies bei vSphere getestet wurde.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Beachten Sie bei der Dimensionierung eines FlexGroup-Datenspeichers, dass die FlexGroup aus mehreren kleineren FlexVol-Volumes besteht, die einen größeren Namespace erstellen. Daher muss die Größe des Datenspeichers bei der größten Virtual Machine mindestens das Achtfache betragen. Wenn Sie beispielsweise eine 6-TB-VM in Ihrer Umgebung haben, geben Sie der FlexGroup-Datenspeicher die Größe nicht kleiner als 48 TB an.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Erlauben Sie FlexGroup, den Datenspeicherplatz zu managen. Autosize und Elastic Sizing wurden mit vSphere Datastores getestet. Sollte der Datenspeicher annähernd die volle Kapazität erhalten, verwenden Sie ONTAP Tools für VMware vSphere oder ein anderes Tool, um die Größe des FlexGroup Volume zu ändern. Bei FlexGroup werden Kapazität und Inodes über die Komponenten hinweg ausgeglichen. So werden die Dateien in einem Ordner (VM) nach Möglichkeit der Kapazität auf dieselbe Komponente priorisiert.</block>
  <block id="c4528ad57baf62254d165d4e907e6f59" category="list-text">VMware und NetApp unterstützen derzeit keinen gemeinsamen Ansatz für Multipath-Netzwerke. Bei NFSv4.1 unterstützt NetApp pNFS, während VMware das Session-Trunking unterstützt. NFSv3 unterstützt nicht mehrere physische Pfade zu einem Volume. Bei FlexGroup mit ONTAP 9.8 empfehlen wir, die ONTAP-Tools für VMware vSphere beim Single Mount zu überlassen, da die Auswirkungen des indirekten Zugriffs in der Regel minimal (Mikrosekunden) sind. Es ist möglich, Round-Robin DNS zu verwenden, um ESXi Hosts über LIFs auf verschiedenen Knoten im FlexGroup zu verteilen, aber dies würde erfordern, dass die FlexGroup erstellt und gemountet werden ohne ONTAP-Tools für VMware vSphere. Dann wären die Leistungsmanagementfunktionen nicht verfügbar.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">Die Unterstützung für FlexGroup vSphere Datastores wurde mit Version 9.8 auf bis zu 1500 VMs getestet.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Nutzen Sie das NFS-Plug-in für VMware VAAI für den Offloaded Data Transfer. Beachten Sie, dass ONTAP während der Erweiterung des Klonens in einem FlexGroup Datastore keine wesentlichen Performance-Vorteile bietet gegenüber ESXi Hostkopien, wenn VMs zwischen FlexVol- und/oder FlexGroup-Volumes kopiert werden.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Verwenden Sie ONTAP Tools für VMware vSphere 9.8, um die Performance von FlexGroup VMs mithilfe von ONTAP Kennzahlen (Dashboard- und VM-Berichte) zu überwachen und QoS auf einzelnen VMs zu managen. Diese Metriken sind derzeit nicht über ONTAP-Befehle oder APIs verfügbar.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS (max./min. IOPS) kann auf einzelnen VMs oder auf allen VMs zu diesem Zeitpunkt in einem Datenspeicher festgelegt werden. Die Festlegung der QoS auf allen VMs ersetzt alle separaten Einstellungen pro VM. Einstellungen erweitern nicht auch künftig auf neue oder migrierte VMs. Sie können entweder QoS auf den neuen VMs festlegen oder QoS neu auf alle VMs im Datastore anwenden.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Das SnapCenter Plug-in für VMware vSphere Version 4.4 unterstützt Backup und Recovery von VMs in einem FlexGroup-Datenspeicher auf dem primären Storage-System. Während SnapMirror manuell für die Replizierung einer FlexGroup auf ein sekundäres System verwendet werden kann, verwaltet SCV 4.4 die sekundären Kopien nicht.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Wenn möglich, verwenden Sie immer ONTAP Tools, um Datenspeicher und Volumes bereitzustellen. Damit stellen wir sicher, dass Volumes, Verbindungspfade, LUNs, Initiatorgruppen, Exportrichtlinien Und andere Einstellungen sind kompatibel konfiguriert.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Best Practices für betriebliche Prozesse</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">Datenspeicher und Protokolle</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM unterstützt iSCSI, Fibre Channel und NFS Version 3 mit ONTAP 9 bei Nutzung der Array-basierten Replizierung über SRA. SRM unterstützt nicht die Array-basierte Replizierung für NFS Version 4.1 mit herkömmlichen oder VVols-Datastores.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Zur Bestätigung der Konnektivität überprüfen Sie immer, ob Sie einen neuen Testdatenspeicher am DR-Standort vom Ziel-ONTAP-Cluster aus mounten und wieder mounten können. Testen Sie jedes Protokoll, das Sie für die Datastore-Konnektivität verwenden möchten. Eine Best Practice besteht darin, mit ONTAP-Tools Ihren Testdatenspeicher zu erstellen, da dies die gesamte Datastore-Automatisierung gemäß den Anweisungen von SRM erfolgt.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN-Protokolle sollten für jeden Standort homogen sein. Sie können NFS und SAN mixen, aber die SAN-Protokolle sollten nicht innerhalb eines Standorts gemischt werden. Beispielsweise können Sie FCP in Seite A und iSCSI in Standort B verwenden Sie sollten FCP und iSCSI nicht an Standort A verwenden Der Grund hierfür: Der SRA erstellt nicht gemischte Initiatorgruppen am Recovery-Standort, und SRM filtert nicht die Initiatorliste, die den SRA gegeben wurde.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">Frühere Anleitungen sollten LIF zu Datenlokalität erstellen. Das heißt, mounten Sie immer einen Datenspeicher mit einer LIF auf dem Node, der physisch Eigentümer des Volume ist. In modernen Versionen von ONTAP 9 ist das nicht mehr erforderlich. Sofern möglich und im Rahmen der Zugangsdaten für den Cluster-Umfang festgelegt werden, wählen die ONTAP Tools nach wie vor den Lastausgleich zwischen lokalen LIFs für die Daten aus. Eine Hochverfügbarkeit oder Performance ist jedoch nicht erforderlich.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">NetApp ONTAP 9 kann so konfiguriert werden, dass Snapshot Kopien automatisch entfernt werden, um im Falle eines Speicherplatzfehlenes eine Uptime zu gewährleisten, wenn Autosize nicht in der Lage ist, genügend Notfallkapazität bereitzustellen. Bei der Standardeinstellung für diese Funktion werden die Snapshot Kopien, die von SnapMirror erstellt werden, nicht automatisch gelöscht. Wenn SnapMirror Snapshot Kopien gelöscht werden, kann der NetApp SRA die Replizierung für das betroffene Volume nicht umkehren und neu synchronisieren. Um zu verhindern, dass ONTAP SnapMirror Snapshot Kopien löscht, konfigurieren Sie die Funktion zum Löschen von Snapshots, um es zu versuchen.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 Dokumentationszentrum</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">Die automatische Volume-Größe sollte auf festgelegt werden<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Für Volumes mit SAN-Datastores und<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Für NFS-Datastores. Siehe<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> Für bestimmte Syntax.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM und VVols</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">Ab SRM 8.3 wird der Schutz von VMs mit VVols Datastores unterstützt. SnapMirror Zeitpläne werden über den VASA Provider VM-Storage-Richtlinien ausgesetzt, wenn die VVols Replizierung im Einstellungsmenü der ONTAP Tools aktiviert ist, wie in den folgenden Screenshots dargestellt.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">Im folgenden Beispiel wird die Unterstützung der VVols Replizierung gezeigt.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">Der folgende Screenshot zeigt ein Beispiel zu SnapMirror Zeitplänen, die im Assistenten zur Erstellung von VM-Storage-Richtlinien angezeigt werden.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Der ONTAP VASA Provider unterstützt den Failover auf unterschiedlichen Storage. So kann beispielsweise ein Failover des Systems von ONTAP Select an einem Edge-Standort auf ein AFF System im Core-Datacenter durchgeführt werden. Unabhängig von Ähnlichkeit zum Storage müssen Sie für VM Storage-Richtlinien immer Storage-Richtlinien-Zuordnungen und Reverse-Mappings konfigurieren, damit die Services am Recovery-Standort die Erwartungen und Anforderungen erfüllen. Der folgende Screenshot zeigt ein Beispiel für eine Richtlinienzuordnung.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Erstellung replizierter Volumes für VVols-Datastores</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">Im Gegensatz zu älteren VVols-Datastores müssen replizierte VVols Datastores von Anfang an bei aktivierter Replizierung erstellt werden. Dabei müssen sie Volumes verwenden, die vorab auf den ONTAP Systemen mit SnapMirror Beziehungen erstellt wurden. Hierfür sind vorab-Konfigurationen wie Cluster-Peering und SVM-Peering erforderlich. Diese Aktivitäten sollten von Ihrem ONTAP-Administrator ausgeführt werden, da hierdurch die Zuständigkeiten zwischen denen, die die ONTAP-Systeme über mehrere Standorte hinweg managen, und denen, die in erster Linie für den vSphere-Betrieb verantwortlich sind, streng getrennt werden.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">Dafür muss der vSphere Administrator eine neue Anforderung erfüllen. Da Volumes außerhalb der ONTAP Tools erstellt werden, ist es nicht bekannt, dass die Änderungen, die Ihr ONTAP-Administrator bis zur regelmäßigen planmäßigen Neuerfassungszeit vorgenommen hat. Daher ist es eine Best Practice, immer wieder neu zu ermitteln, wenn Sie eine Volume- oder SnapMirror Beziehung erstellen, die mit VVols verwendet werden soll. Klicken Sie einfach mit der rechten Maustaste auf den Host oder Cluster und wählen Sie die NetApp ONTAP Tools &gt; Aktualisieren von Host- und Speicherdaten aus, wie im folgenden Screenshot dargestellt.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Bei VVols und SRM ist Vorsicht geboten. Niemals geschützte und ungesicherte VMs in demselben VVols Datastore zusammen Der Grund dafür: Wenn Sie SRM für das Failover an Ihrem DR-Standort verwenden, werden nur die VMs, die Teil der Sicherungsgruppe sind, in die DR online geschaltet. Wenn Sie die Sicherung rückgängig machen (das SnapMirror aus der DR wieder in die Produktionsumgebung verschieben), können die VMs, die nicht Failover waren, überschrieben werden und wertvolle Daten enthalten.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Allgemeines zu Array-Paaren</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">Für jedes Array-Paar wird ein Array-Manager erstellt. Zusammen mit SRM und ONTAP Tools erfolgt die Kopplung jedes Arrays mit dem Umfang einer SVM, auch wenn Cluster-Anmeldedaten verwendet werden. So können Sie DR-Workflows zwischen Mandanten segmentieren, basierend auf den ihnen zugewiesenen SVMs. Sie können mehrere Array-Manager für ein bestimmtes Cluster erstellen und sie können asymmetrisch sein. Sie können Fan-out oder Fan-in zwischen verschiedenen ONTAP 9 Clustern. So können beispielsweise SVM-A und SVM-B auf Cluster-1 und damit auf SVM-C auf Cluster-2, SVM-D auf Cluster-3 oder umgekehrt genutzt werden.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Wenn Sie Array-Paare in SRM konfigurieren, sollten Sie sie immer in SRM auf die gleiche Weise hinzufügen, wie Sie sie den ONTAP Tools hinzugefügt haben. Das bedeutet, dass sie denselben Benutzernamen, dasselbe Passwort und dieselbe Management-LIF verwenden müssen. Diese Anforderung stellt sicher, dass SRA ordnungsgemäß mit dem Array kommuniziert. Der folgende Screenshot veranschaulicht, wie ein Cluster in ONTAP-Tools angezeigt wird und wie es zu einem Array Manager hinzugefügt werden kann.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Allgemeines zu Replikationsgruppen</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Replikationsgruppen enthalten logische Sammlungen von virtuellen Maschinen, die zusammen wiederhergestellt werden. Mit den ONTAP Tools VASA Provider werden automatisch Replikationsgruppen für Sie erstellt. Da die ONTAP SnapMirror Replizierung auf Volume-Ebene stattfindet, befinden sich alle VMs in einem Volume in derselben Replizierungsgruppe.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">Es gibt mehrere Faktoren, die bei Replizierungsgruppen berücksichtigt werden müssen und die Art und Weise, wie VMs über FlexVol Volumes verteilt werden. Durch die Gruppierung ähnlicher VMs in demselben Volume kann die Storage-Effizienz bei älteren ONTAP Systemen erhöht werden, bei denen es keine Deduplizierung auf Aggregatebene gibt. Durch Gruppierung wird jedoch die Größe des Volumes erhöht und die Parallelität der Volume I/O verringert. Moderne ONTAP Systeme bieten ein optimales Gleichgewicht aus Performance und Storage-Effizienz, indem VMs über FlexVol Volumes im selben Aggregat verteilt werden. Dadurch werden die Deduplizierung auf Aggregatebene genutzt und die I/O-Parallelisierung über mehrere Volumes hinweg verbessert. Sie können VMs in den Volumes zusammen wiederherstellen, da eine (nachfolgend erläutert) Sicherungsgruppe mehrere Replizierungsgruppen enthalten kann. Der Nachteil an dieses Layout ist, dass Blöcke mehrfach über das Netzwerk übertragen werden könnten, da Volume SnapMirror die Aggregat-Deduplizierung nicht berücksichtigt.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Eine letzte Überlegung für Replikationsgruppen besteht darin, dass jede von Natur aus eine logische Konsistenzgruppe ist (nicht zu verwechseln mit SRM-Konsistenzgruppen). Das liegt daran, dass alle VMs im Volume mithilfe desselben Snapshots zusammen übertragen werden. Wenn Sie also VMs haben, die stets konsistent sein müssen, sollten Sie sie in der gleichen FlexVol speichern.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">Allgemeines zu Schutzgruppen</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Sicherungsgruppen definieren VMs und Datastores in Gruppen, die am geschützten Standort zusammen wiederhergestellt werden. Am geschützten Standort befinden sich die VMs, die in einer Schutzgruppe konfiguriert sind, im normalen Steady-State-Betrieb. Es ist wichtig zu beachten, dass eine Schutzgruppe nicht mehrere Array-Manager umfassen kann, obwohl SRM möglicherweise mehrere Array-Manager für eine Schutzgruppe anzeigt. Aus diesem Grund sollten Sie VM-Dateien nicht über Datastores auf unterschiedlichen SVMs verteilen.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Recovery-Pläne sprechen</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Recovery-Pläne legen fest, welche Schutzgruppen im gleichen Prozess wiederhergestellt werden. Mehrere Sicherungsgruppen können im selben Recovery-Plan konfiguriert werden. Um darüber hinaus mehr Optionen für die Ausführung von Recovery-Plänen zu aktivieren, kann eine einzige Sicherungsgruppe in mehreren Recovery-Plänen enthalten sein.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Durch Recovery-Pläne können SRM-Administratoren Recovery-Workflows definieren, indem VMs einer Prioritätsgruppe von 1 (hoch) bis 5 (niedrig) zugewiesen werden, wobei 3 (mittel) standardmäßig verwendet wird. Innerhalb einer Prioritätsgruppe können VMs für Abhängigkeiten konfiguriert werden.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">So könnte Ihr Unternehmen beispielsweise über eine geschäftskritische Tier-1-Applikation für seine Datenbank auf einen Microsoft SQL Server zurückgreifen. Sie entscheiden also, Ihre VMs in Prioritätsgruppe 1 einzufügen. Innerhalb der Prioritätsgruppe 1 beginnen Sie mit der Planung des Auftrages der Dienste. Sie möchten wahrscheinlich, dass Ihr Microsoft Windows Domain Controller vor Ihrem Microsoft SQL Server hochgefahren wird, was vor Ihrem Anwendungsserver online sein müsste, usw. Sie würden all diese VMs zur Prioritätsgruppe hinzufügen und dann die Abhängigkeiten einstellen, da Abhängigkeiten nur innerhalb einer bestimmten Prioritätsgruppe gelten.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp empfiehlt besonders, mit Ihren Applikationsteams zusammenarbeiten zu müssen, um die Reihenfolge der für ein Failover-Szenario erforderlichen Operationen zu ermitteln und die Recovery-Pläne entsprechend zu erstellen.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Testen Sie den Failover</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">Als Best Practice empfiehlt es sich, immer einen Test-Failover durchzuführen, wenn die Konfiguration eines geschützten VM Storage geändert wird. So wird sichergestellt, dass Sie bei einem Notfall darauf vertrauen können, dass Site Recovery Manager Services innerhalb des erwarteten RTO-Ziels wiederherstellen kann.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp empfiehlt zudem, die Funktion der in Gast-Applikationen gelegentlich zu bestätigen, insbesondere nach der Neukonfiguration von VM-Storage.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Wenn ein Test-Recovery-Vorgang ausgeführt wird, wird auf dem ESXi Host für die VMs ein privates Test-Bubble-Netzwerk erstellt. Dieses Netzwerk wird jedoch nicht automatisch mit physischen Netzwerkadaptern verbunden und bietet daher keine Verbindung zwischen den ESXi Hosts. Um die Kommunikation zwischen VMs zu ermöglichen, die während des DR-Tests auf verschiedenen ESXi Hosts ausgeführt werden, wird ein physisches privates Netzwerk zwischen den ESXi Hosts am DR-Standort erstellt. Um zu überprüfen, ob das Testnetzwerk privat ist, kann das Testblasennetzwerk physisch oder mittels VLANs oder VLAN-Tagging getrennt werden. Dieses Netzwerk muss von dem Produktionsnetzwerk getrennt werden, da die VMs wiederhergestellt werden und nicht mit IP-Adressen im Produktionsnetzwerk platziert werden können, die mit den tatsächlichen Produktionssystemen kollidieren können. Nach dem Erstellen eines Recovery-Plans in SRM kann das erstellte Testnetzwerk als privates Netzwerk ausgewählt werden, um die VMs mit während des Tests zu verbinden.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Nachdem der Test validiert und nicht mehr erforderlich ist, führen Sie eine Bereinigung durch. Bei der Durchführung der Bereinigung werden die geschützten VMs in ihren Ausgangszustand zurückversetzt und der Recovery-Plan wird auf den Status „bereit“ zurückgesetzt.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Überlegungen zum Failover</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Wenn es um Failover an einem Standort zusätzlich zur in diesem Leitfaden beschriebenen Reihenfolge geht, müssen noch einige weitere Aspekte berücksichtigt werden.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Ein Problem, mit dem Sie möglicherweise zu kämpfen haben, ist die Netzwerkunterschiede zwischen den Standorten. In einigen Umgebungen können am primären Standort und am DR-Standort dieselben Netzwerk-IP-Adressen verwendet werden. Diese Fähigkeit wird als Stretched Virtual LAN (VLAN) oder Stretched Network Setup bezeichnet. Andere Umgebungen müssen möglicherweise unterschiedliche Netzwerk-IP-Adressen (z. B. in unterschiedlichen VLANs) am primären Standort relativ zum DR-Standort verwenden.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware bietet verschiedene Möglichkeiten zur Lösung dieses Problems. Netzwerkvirtualisierungstechnologien wie VMware NSX-T Data Center abstrahieren den gesamten Netzwerk-Stack von Ebene 2 bis 7 von der Betriebsumgebung und ermöglichen so portablere Lösungen. Weitere Informationen zu NSX-T-Optionen mit SRM<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM ermöglicht es Ihnen auch, die Netzwerkkonfiguration einer VM wie das Recovery zu ändern. Diese Neukonfiguration umfasst Einstellungen wie IP-Adressen, Gateway-Adresse und DNS-Server-Einstellungen. Verschiedene Netzwerkeinstellungen, die auf einzelne VMs angewendet werden, während sie wiederhergestellt werden, können in den Eigenschaftseinstellungen einer VM im Wiederherstellungsplan angegeben werden.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">Um SRM so zu konfigurieren, dass verschiedene Netzwerkeinstellungen auf mehrere VMs angewendet werden können, ohne die Eigenschaften der einzelnen im Recovery-Plan bearbeiten zu müssen, stellt VMware ein Tool namens dr-ip-Customizer bereit. Weitere Informationen zur Verwendung dieses Dienstprogramms finden Sie in der Dokumentation von VMware<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Schützen</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Nach einem Recovery wird der Recovery-Standort zum neuen Produktionsstandort. Da der Recovery-Vorgang die SnapMirror Replizierung ausbrach, ist der neue Produktionsstandort nicht vor zukünftigen Ausfällen geschützt. Als Best Practice wird empfohlen, den neuen Produktionsstandort unmittelbar nach dem Recovery auf einen anderen Standort zu schützen. Wenn der ursprüngliche Produktionsstandort betriebsbereit ist, kann der VMware Administrator den ursprünglichen Produktionsstandort als neuen Recovery-Standort zum Schutz des neuen Produktionsstandorts verwenden und damit die Richtung des Schutzes umkehren. Repschutz ist nur bei nicht-katastrophalen Ausfällen verfügbar. Daher müssen die ursprünglichen vCenter Server, ESXi Server, SRM Server und entsprechenden Datenbanken irgendwann wiederhergestellt werden können. Falls diese nicht verfügbar sind, müssen eine neue Schutzgruppe und ein neuer Recovery-Plan erstellt werden.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Failback</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Ein Failback-Vorgang ist im Grunde ein Failover in eine andere Richtung als zuvor. Als Best Practice überprüfen Sie, ob der ursprüngliche Standort wieder zu akzeptablen Funktionsstufen zurückkehrt, bevor Sie ein Failback durchführen, oder, anders ausgedrückt, ein Failover zum ursprünglichen Standort durchführen. Falls der ursprüngliche Standort weiterhin kompromittiert wird, sollten Sie ein Failback verzögern, bis der Ausfall ausreichend behoben ist.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Eine weitere Failback Best Practice besteht darin, immer einen Test-Failover auszuführen, nachdem der erneute Schutz abgeschlossen und bevor das endgültige Failback durchgeführt wurde. Dadurch wird sichergestellt, dass die vorhandenen Systeme am ursprünglichen Standort den Betrieb abschließen können.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Wiederherstellung der Originalseite</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">Nach dem Failback sollten Sie mit allen Beteiligte bestätigen, dass ihre Services wieder normal sind, bevor Sie erneut den Schutz starten.</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">Wenn eine erneute Sicherung nach dem Failback ausgeführt wird, befindet sich die Umgebung im Wesentlichen in dem Zustand, in dem sie sich zu Beginn befand. Die SnapMirror Replizierung wird erneut vom Produktionsstandort zum Recovery-Standort ausgeführt.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">In ONTAP 9 sind die physischen Komponenten eines Clusters für Cluster-Administratoren sichtbar, sind aber für die Applikationen und Hosts, die das Cluster nutzen, nicht direkt sichtbar.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Replizierungstopologien</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">In ONTAP 9 sind die physischen Komponenten eines Clusters für Cluster-Administratoren sichtbar, sind aber für die Applikationen und Hosts, die das Cluster nutzen, nicht direkt sichtbar. Die physischen Komponenten stellen einen Pool mit gemeinsam genutzten Ressourcen bereit, anhand dessen die logischen Clusterressourcen erstellt werden. Applikationen und Hosts greifen ausschließlich über SVMs auf Daten zu, die Volumes und LIFs enthalten.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Jede NetApp SVM wird im VMware vCenter Site Recovery Manager als Array behandelt. SRM unterstützt bestimmte Array-to-Array (oder SVM-zu-SVM) Replizierungslayouts.</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Eine einzelne VM kann aus den folgenden Gründen keine Daten besitzen – Virtual Machine Disk (VMDK) oder RDM – auf mehr als einem SRM Array:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM sieht nur die SVM, nicht einen individuellen physischen Controller.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Eine SVM kann LUNs und Volumes steuern, die mehrere Nodes in einem Cluster umfassen.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Best Practices In Sich</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Bedenken Sie bei der Ermittlung von Supportmöglichkeiten diese Regel: Um eine VM mithilfe von SRM und der NetApp SRA zu schützen, müssen alle Bestandteile der VM nur auf einer SVM vorhanden sein. Diese Regel gilt sowohl für den geschützten Standort als auch für den Recovery-Standort.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Unterstützte SnapMirror Layouts</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Die folgenden Abbildungen zeigen die Szenarien des SnapMirror Beziehungs-Layouts, die von SRM und SRA unterstützt werden. Jede VM in den replizierten Volumes besitzt die Daten auf nur einem SRM Array (SVM) an jedem Standort.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Unterstützte Array Manager-Layouts</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Wenn Sie in SRM Array-basierte Replizierung (ABR) verwenden, werden Schutzgruppen auf ein einzelnes Array-Paar isoliert, wie im folgenden Screenshot dargestellt. In diesem Szenario<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> Und<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> Werden mit Peering durchgeführt<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> Und<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> Am Recovery-Standort. Sie können jedoch nur eines der beiden Array-Paare auswählen, wenn Sie eine Schutzgruppe erstellen.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Nicht unterstützte Layouts</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Nicht unterstützte Konfigurationen beinhalten Daten (VMDK oder RDM) auf mehreren SVMs, die sich im Besitz einer individuellen VM befinden. In den folgenden Abbildungen sind<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Kann aus dem Grund nicht für den Schutz mit SRM konfiguriert werden<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Verfügt über Daten auf zwei SVMs.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Jegliche Replizierungsbeziehungen, bei denen ein einzelnes NetApp Volume von einer Quell-SVM auf mehrere Ziele in derselben SVM oder in verschiedenen SVMs repliziert wird, werden als SnapMirror Fan-out bezeichnet. Fan-out wird mit SRM nicht unterstützt. In der folgenden Abbildung ist das Beispiel dargestellt.<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Kann nicht für den Schutz in SRM konfiguriert werden, da es mit SnapMirror an zwei verschiedenen Standorten repliziert wird.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror Kaskadierung</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM unterstützt keine Kaskadierung von SnapMirror Beziehungen, bei denen ein Quell-Volume auf einem Ziel-Volume repliziert wird und das Ziel-Volume ebenfalls mit SnapMirror auf einem anderen Ziel-Volume repliziert wird. In dem in der folgenden Abbildung gezeigten Szenario kann SRM nicht für das Failover zwischen mehreren Standorten verwendet werden.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror und SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Die NetApp SnapVault Software ermöglicht festplattenbasierte Backups von Unternehmensdaten zwischen NetApp Storage-Systemen. SnapVault und SnapMirror können in derselben Umgebung nebeneinander bestehen. SRM unterstützt jedoch nur das Failover der SnapMirror Beziehungen.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">Die NetApp SRA unterstützt das<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> Richtlinientyp.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault wurde für ONTAP 8.2 von Grund auf neu aufgebaut. Obwohl frühere Benutzer von Data ONTAP 7-Mode Ähnlichkeiten finden sollten, wurden in dieser Version von SnapVault wesentliche Verbesserungen vorgenommen. Eine wichtige Verbesserung ist die Möglichkeit zur Wahrung der Storage-Effizienz von Primärdaten während der SnapVault Transfers.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Eine wichtige Architekturänderung ist, dass SnapVault in ONTAP 9 wie bei 7-Mode SnapVault auf Volume-Ebene repliziert, nicht auf qtree-Ebene. Bei diesem Setup muss die Quelle einer SnapVault Beziehung ein Volume sein, und das Volume muss auf sein eigenes Volume auf dem sekundären SnapVault System repliziert werden.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">In einer Umgebung, in der SnapVault verwendet wird, werden speziell benannte Snapshot Kopien auf dem primären Storage-System erstellt. Je nach implementierter Konfiguration können die benannten Snapshot Kopien auf dem Primärsystem durch einen SnapVault Zeitplan oder durch eine Applikation wie NetApp Active IQ Unified Manager erstellt werden. Die benannten Snapshot Kopien, die auf dem primären System erstellt werden, werden dann zum SnapMirror Ziel repliziert und von dort aus zum SnapVault Ziel verlagert.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Ein Quell-Volume kann in einer Kaskadenkonfiguration erstellt werden, bei der ein Volume auf ein SnapMirror Ziel am DR-Standort repliziert wird und von dort aus auf ein SnapVault Ziel verlagert wird. Ein Quell-Volume kann auch in einer Fan-out-Beziehung erstellt werden, wobei ein Ziel ein SnapMirror Ziel ist und das andere Ziel eine SnapVault Ziel ist. SRA rekonfiguriert jedoch nicht automatisch die SnapVault-Beziehung neu, um das SnapMirror Ziel-Volume als Quelle für den Vault zu verwenden, wenn das SRM Failover oder eine Umkehrung der Replizierung stattfindet.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 SnapMirror Configuration Best Practice Guide für ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Aktuelle Informationen zu SnapMirror und SnapVault für ONTAP 9 finden Sie unter<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Wenn in derselben Umgebung SnapVault und SRM eingesetzt werden, empfiehlt NetApp, eine Kaskadenkonfiguration von SnapMirror auf SnapVault zu verwenden, bei der SnapVault Backups normalerweise über das SnapMirror Ziel am DR-Standort ausgeführt werden. Bei einem Notfall kann der primäre Standort durch diese Konfiguration nicht mehr zugänglich sein. Indem das SnapVault Ziel am Recovery-Standort gehalten wird, können SnapVault Backups nach dem Failover neu konfiguriert werden, sodass SnapVault Backups weiterhin am Recovery-Standort ausgeführt werden können.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">In einer VMware Umgebung verfügt jeder Datenspeicher über eine universelle eindeutige Kennung (Universal Unique Identifier, UUID) und jede VM über eine eindeutige Managed Object ID (MOID). Diese IDs werden während Failover oder Failback durch SRM nicht gepflegt. Da Datastore-UIDs und VM-MOIDs beim Failover durch SRM nicht gepflegt werden, müssen nach dem SRM Failover alle Applikationen, die von diesen IDs abhängen, neu konfiguriert werden. Eine Beispielapplikation ist NetApp Active IQ Unified Manager, wo die SnapVault Replizierung mit der vSphere Umgebung koordiniert wird.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">Die folgende Abbildung zeigt die Kaskadenkonfiguration von SnapMirror auf SnapVault. Wenn sich das SnapVault Ziel am DR-Standort oder an einem tertiären Standort befindet, der nicht von einem Ausfall am primären Standort betroffen ist, kann die Umgebung neu konfiguriert werden, sodass Backups nach dem Failover fortgesetzt werden können.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">In der folgenden Abbildung wird die Konfiguration dargestellt, nachdem SRM die SnapMirror Replizierung zurück auf den primären Standort umgekehrt hat. Die Umgebung wurde außerdem neu konfiguriert, sodass SnapVault Backups von der jetzt SnapMirror Quelle durchgeführt werden. Bei dieser Einrichtung handelt es sich um eine Fan-out-Konfiguration für SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Nachdem SRM ein Failback und eine zweite Umkehrung der SnapMirror Beziehungen durchführt, sind die Produktionsdaten am primären Standort zurück. Die Daten werden jetzt auf dieselbe Weise gesichert wie vor dem Failover zum DR-Standort – über SnapMirror und SnapVault Backups.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Verwendung von Qtrees in Site Recovery Manager-Umgebungen</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Qtrees sind spezielle Verzeichnisse, die die Anwendung von Filesystem-Kontingenten für NAS ermöglichen. ONTAP 9 ermöglicht die Erstellung von qtrees und qtrees in Volumes, die mit SnapMirror repliziert werden. SnapMirror ermöglicht jedoch nicht die Replizierung einzelner qtrees oder Qtree-Level-Replikationen. Alle SnapMirror Replikation befindet sich nur auf Volume-Ebene. Aus diesem Grund empfiehlt NetApp die Verwendung von qtrees mit SRM nicht.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Gemischte FC- und iSCSI-Umgebungen</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Mit den unterstützten SAN-Protokollen (FC, FCoE und iSCSI) bietet ONTAP 9 LUN-Services an, d. h. die Möglichkeit, LUNs zu erstellen und angebundenen Hosts zuzuweisen. Da das Cluster aus mehreren Controllern besteht, gibt es mehrere logische Pfade, die von Multipath I/O zu einer beliebigen einzelnen LUN gemanagt werden. Auf den Hosts wird mithilfe des Asymmetric Logical Unit Access (ALUA) der optimale Pfad zu einer LUN ausgewählt und für den Datentransfer aktiviert. Wenn sich der optimierte Pfad zu einer LUN ändert (z. B. weil das zugehörige Volume verschoben wird), erkennt ONTAP 9 diese Änderung automatisch und passt sich unterbrechungsfrei an. Wenn der optimierte Pfad nicht mehr verfügbar ist, kann ONTAP ohne Unterbrechungen zu einem anderen verfügbaren Pfad wechseln.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM und NetApp SRA unterstützen die Nutzung des FC-Protokolls an einem Standort und das iSCSI-Protokoll am anderen Standort. Eine Kombination aus FC-Attached Datastores und iSCSI-Attached Datastores wird jedoch auf demselben ESXi Host oder auf verschiedenen Hosts im selben Cluster nicht unterstützt. Diese Konfiguration wird mit SRM nicht unterstützt, da SRM während des SRM Failover oder des Test-Failovers alle FC- und iSCSI-Initiatoren in den ESXi-Hosts in der Anforderung enthält.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM und SRA unterstützen gemischte FC- und iSCSI-Protokolle zwischen den geschützten und den Recovery-Standorten. Allerdings sollte jeder Standort nur mit einem Protokoll, entweder FC oder iSCSI, konfiguriert werden, nicht mit beiden Protokollen am selben Standort. Wenn FC- und iSCSI-Protokolle am selben Standort konfiguriert werden müssen, empfiehlt NetApp, dass einige Hosts iSCSI verwenden und andere Hosts FC verwenden. NetApp empfiehlt in diesem Fall außerdem die SRM-Ressourcenzuordnung, damit die VMs für das Failover in eine Gruppe von Hosts oder die andere konfiguriert werden.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Virtual Volumes (VVols) und richtlinienbasiertes Storage-Management (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">Über VVols und SPBM</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp war schon früh als Design-Partner von VMware an der Entwicklung von vSphere Virtual Volumes (VVols) beteiligt und stellte architekturspezifischen Input und frühzeitig Unterstützung für VVols und VMware vSphere APIs for Storage Awareness (VASA) bereit. Durch diesen Ansatz wurde einerseits das granulare Storage-Management von VMs in VMFS integriert und andererseits auch die Automatisierung der Storage-Bereitstellung durch richtlinienbasiertes Storage-Management (SPBM) unterstützt.</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM bietet ein Framework, das als Abstraktionsebene zwischen den für Ihre Virtualisierungsumgebung verfügbaren Storage-Services und den über Richtlinien bereitgestellten Storage-Elementen dient. Storage-Architekten können mit diesem Ansatz Storage-Pools mit unterschiedlichen Funktionen entwerfen, die von VM-Administratoren einfach genutzt werden können. Administratoren können die Workload-Anforderungen von Virtual Machines an die bereitgestellten Storage Pools anpassen, wodurch verschiedene Einstellungen pro VM oder Virtual Disk granular kontrolliert werden können.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">Bei VVols ist ONTAP eine der führenden Lösungen in der Storage-Branche, da es Hunderttausende VVols in einem einzigen Cluster unterstützt. Anbieter von Enterprise-Arrays und kleineren Flash-Arrays hingegen unterstützen gerade einmal mehrere Tausend VVols pro Array. Zudem bringt NetApp mit neuen Funktionen bei der Unterstützung von VVols 3.0 die Weiterentwicklung des granularen VM-Managements voran.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: VMware vSphere Virtual Volumes with ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Weitere Informationen zu VMware vSphere Virtual Volumes, SPBM und ONTAP finden Sie unter<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="3e23a542d0c1cb3dc87ca41f7ec8dc9c" category="doc">NetApp SnapCenter Plug-in für VMware vSphere – SQL Server Restore Workflow</block>
  <block id="d16efdedacbd64c8b85d50f0b58e4c60" category="inline-link-macro">Früher: Zusätzliche Informationen: SnapCenter-Plug-in für VMware vSphere - Workflow wiederherstellen.</block>
  <block id="553f0bde4f032f393b8659c8440bae26" category="paragraph"><block ref="553f0bde4f032f393b8659c8440bae26" category="inline-link-macro-rx"></block></block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">Auf dieser Seite wird die ONTAP Storage-Effizienz beschrieben.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">ONTAP Storage-Effizienzfunktionen</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Über Storage-Effizienz</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">NetApp stellte als erster Anbieter die Deduplizierung für Produktions-Workloads bereit, allerdings war diese Innovation weder die erste noch die letzte in diesem Bereich. Es begann mit ONTAP Snapshot Kopien, einem platzsparenden Datensicherungsmechanismus ohne Performance-Effekt, sowie mit FlexClone Technologie, bei der sofort Lese-/Schreibkopien von VMs für die Produktion und die Nutzung von Backups erstellt werden können. Danach stellte NetApp Inline-Funktionen bereit, darunter Deduplizierung, Komprimierung und Zero-Block-Deduplizierung, mit denen sich der Storage kostspieliger SSDs maximal ausschöpfen lässt. Kürzlich hat ONTAP die Data-Compaction hinzugefügt, um unsere Storage-Effizienz zu verbessern.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">*Inline-Zero-Block-Deduplizierung.* vermeidet die Verschwendung von Speicherplatz durch All-Zero-Blöcke.</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">*Inline-Komprimierung.* komprimiert Datenblöcke, um den erforderlichen physischen Speicher zu verringern.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">*Inline-Deduplizierung.* eliminiert eingehende Blöcke mit vorhandenen Blöcken auf der Festplatte.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">* Inline-Data-Compaction.* packt kleinere I/O-Vorgänge und Dateien in jeden physischen Block.</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">Storage-Effizienz</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">Deduplizierung, Datenkomprimierung und Data-Compaction können zusammen oder unabhängig durchgeführt werden, um die optimale Speicherersparnis auf einem FlexVol Volume zu erzielen. Dank der Kombination dieser Funktionen verzeichnen Kunden Einsparungen im Verhältnis von bis zu 5:1 für VSI und von bis zu 30:1 für VDI.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">Mittels Deduplizierung, Datenkomprimierung und Data-Compaction wird die Storage-Effizienz verbessert</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">Weitere Informationen zu ONTAP Storage-Effizienz finden Sie unter<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> Im Dokumentationszentrum ONTAP 9.</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">VMware-Produktdokumentation<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">NetApp Produktdokumentation<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Sehen Sie sich die folgenden Dokumente und/oder Websites an, um mehr über die in diesem Dokument beschriebenen Informationen zu erfahren.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Weitere Informationen</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: VMware vSphere für ONTAP<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: VMware vSphere Virtual Volumes with ONTAP<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">TR-4015 SnapMirror Configuration Best Practice Guide für ONTAP 9<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC Benutzer-Creator für ONTAP<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">ONTAP Tools für VMware vSphere Ressourcen<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager - Dokumentation<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">Siehe<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Überprüfen Sie auf der NetApp Support-Website, ob die in diesem Dokument angegebenen Produktversionen und Funktionen in Ihrer IT-Umgebung unterstützt werden. Das NetApp IMT definiert die Produktkomponenten und -Versionen, die für von NetApp unterstützte Konfigurationen verwendet werden können. Die spezifischen Ergebnisse hängen von der Installation des jeweiligen Kunden gemäß den technischen Daten ab.</block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">Auf dieser Seite finden Sie Schritte zur Bereitstellung eines NetApp ONTAP Storage FCoE VMFS-Datenspeichers in einer VMware vSphere Umgebung.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">VSphere VMFS Datenspeicher – Fibre Channel over Ethernet Storage-Protokoll mit ONTAP</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">In diesem Abschnitt wird die Erstellung eines VMFS-Datenspeichers mit dem FCoE-Transportprotokoll (Fibre Channel over Ethernet) zu ONTAP Storage behandelt.</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">ONTAP Storage-System (FAS/AFF/CVO/ONTAP Select) mit {ontap_Version}</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">Eine unterstützte FCoE-Kombination</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">Ein ausgefülltes Konfigurationsarbeitsblatt</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">Mit ONTAP FC-Daten-Ports oder vSphere-Hosts verbunden</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">FC/FCoE-Zoning konfiguriert</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">Netzwerk-Switch(e)</block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">FCoE-Support</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">DCB-Support</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">Jumbo Frames für FCoE</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">ONTAP Tool für VMware vSphere – implementiert, konfiguriert und betriebsbereit</block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">Bereitstellung eines VMFS-Datenspeichers</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">Vergewissern Sie sich, dass die FCoE-Konfiguration unterstützt wird</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">Verwenden Sie die<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Befehl zum Überprüfen, ob das FCP aufgeführt ist.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">Nutzung<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> Um eine Lizenz hinzuzufügen.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">Vergewissern Sie sich, dass das FCP-Protokoll auf der SVM aktiviert ist.</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">Erstellen Sie eine neue SVM mit dem FCP.</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">Vergewissern Sie sich, dass auf der SVM logische FCP-Schnittstellen verfügbar sind.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">Wird mit der GUI eine SVM erstellt, sind logische Schnittstellen Teil dieses Prozesses.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">Verwenden Sie zum Umbenennen der Netzwerkschnittstelle<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">Erstellen und Zuordnen einer LUN</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>; überspringen Sie diesen Schritt, wenn Sie ONTAP-Tools für VMware vSphere nutzen.</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">Informationen zu Storage-Adaptern</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">Vergewissern Sie sich, dass die HBA-Treiber installiert sind. Bei den von VMware unterstützten HBAs sind die Treiber Out-of-the-Box implementiert und sollten im sichtbar sein <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">Auf dieser Seite finden Sie Schritte zur Bereitstellung eines NetApp ONTAP NFS Version 3-Datenspeichers in einer VMware vSphere-Umgebung.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">VSphere NFS Datastore - Version 3 mit ONTAP</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">Erstellung von NFS-Data-Version-3-Datenspeichern mit ONTAP-NAS-Storage</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">Grundkenntnisse für das Management einer vSphere Umgebung und ONTAP</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">Ein ONTAP Storage-System (FAS/AFF/CVO/ONTAP Select/Cloud-Volume-Service/Azure NetApp Files) mit ONTAP 9.8 oder höher</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP-Anmeldedaten (SVM-Name, Benutzer-ID, Passwort)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">ONTAP Netzwerkport, SVM und LUN-Informationen für NFS</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">Ein ausgefülltes NFS-Konfigurationsarbeitsblatt</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">VSphere Host(s)-Informationen für vSphere 7.0 oder höher</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">IP-Informationen für den NFS VMkernel Adapter</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">Mit Netzwerk-Daten-Ports des ONTAP Systems und verbundenen vSphere Hosts</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">Für NFS konfigurierte VLANs</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(Optional) Link Aggregation konfiguriert für ONTAP Netzwerkdatenports</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">Schritte</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">Prüfen Sie die Kompatibilität mit dem<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">Vergewissern Sie sich, dass die NFS-Konfiguration unterstützt wird.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">Führen Sie die folgenden Aufgaben für ONTAP und vSphere aus.</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">Überprüfen Sie die ONTAP Lizenz für NFS.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">Verwenden Sie die<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Führen Sie einen Befehl aus und überprüfen Sie, ob NFS aufgelistet ist.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">Folgen Sie dem NFS-Konfigurations-Workflow.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">Folgen Sie dem Workflow der NFS Client-Konfiguration für vSphere.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">Referenz</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">VSphere Datastore- und Protokollfunktionen: NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">Nach Abschluss dieser Aufgaben kann der NFS-Datenspeicher zur Bereitstellung von Virtual Machines genutzt werden.</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">Auf dieser Seite werden die Hybrid-Cloud-Funktionen beschrieben, die für ONTAP und VMware vSphere verfügbar sind.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">Hybrid Cloud mit ONTAP und vSphere</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">Informationen Zur Hybrid Cloud</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">ONTAP Lösungen unterstützen Sie beim Aufbau Ihrer eigenen Data Fabric zur Optimierung und Optimierung des Datenmanagements. Ganz gleich, ob Sie in einer Private Cloud vor Ort, in einer Public-Cloud-Infrastruktur oder in einer Hybrid Cloud, die die Vorteile der beiden Lösungen vereint. Den Anfang machen hochperformante All-Flash-Systeme, die dann für die Datensicherung und das Cloud-Computing mit Festplatten- oder Cloud-Storage-Systemen gekoppelt werden.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Zur Kostenoptimierung und Vermeidung einer Anbieterbindung stehen hierbei Azure, AWS, IBM oder Google Clouds zur Auswahl. Bei Bedarf kann die erweiterte Unterstützung für OpenStack und Containertechnologien genutzt werden.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">Die Datensicherung ist häufig der erste Versuch, den Kunden auf ihrem Weg zur Cloud zu begleiten. Die Sicherung kann einfach sein wie die asynchrone Replizierung wichtiger Daten oder so komplex wie ein vollständiger Hot-Backup-Standort. Die Datensicherung basiert in erster Linie auf NetApp SnapMirror Technologie.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">Einige Kunden entscheiden sich für die Migration vollständiger Workloads in die Cloud. Dies ist zwar komplizierter als die Datensicherung, wenn die Cloud nur verwendet wird. Mit ONTAP wird dies jedoch einfacher, da Sie Ihre Applikationen nicht erneut auf Cloud-basierten Storage verwenden müssen. ONTAP in der Cloud funktioniert wie On-Premises ONTAP. Ihr lokales ONTAP System bietet Dateneffizienzfunktionen, mit denen Sie mehr Daten mit weniger physischen Speicherplatz speichern und selten genutzte Daten Tiering-Daten auf kostengünstigeren Storage verschieben können. Unabhängig davon, ob Sie eine Hybrid-Cloud-Konfiguration verwenden oder Ihren gesamten Workload in die Cloud verschieben: ONTAP maximiert die Storage-Performance und -Effizienz.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">NetApp bietet darüber hinaus Cloud-basiertes Tiering und Archivierungstools (SnapMirror Cloud, Cloud Backup Service und Cloud Sync) sowie Storage-Systeme (FabricPool) für ONTAP, um die Betriebskosten zu senken und die große Reichweite der Cloud auszuschöpfen.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">Die folgende Abbildung zeigt einen Beispiel für einen Hybrid-Cloud-Anwendungsfall.</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">Hybrid Cloud</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP und die Cloud</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">Weitere Informationen zu ONTAP und Hybrid Clouds finden Sie unter<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> Im ONTAP 9 Dokumentationszentrum.</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">Auf dieser Seite finden Sie Schritte zur Bereitstellung eines NetApp ONTAP NFS Version 4-Datenspeichers in einer VMware vSphere-Umgebung.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">VSphere NFS Datastore - Version 4.1 mit ONTAP</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">In diesem Abschnitt wird die Erstellung eines NFS-Version 4.1-Datenspeichers mit ONTAP-NAS-Speicher beschrieben.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">Grundkenntnisse für das Management einer vSphere Umgebung und einer ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">ONTAP Storage-System (FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files) mit {ontap_Version}</block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">Informationen zu vSphere-Hosts {vsphere_Version}</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">Mit ONTAP System-Netzwerk-Daten-Ports, vSphere-Hosts und verbunden</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">ONTAP Tools für VMware vSphere Implementierung, Konfiguration und Einsatzbereitschaft</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Interoperabilitäts-Matrix-Tool (IMT):</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">Prüfen Sie die Kompatibilität mit dem<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">Führen Sie die im Folgenden aufgeführten ONTAP- und vSphere-Aufgaben aus.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">Überprüfen Sie die ONTAP Lizenz für NFS</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">Einsatzthe<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Befehl zum Überprüfen, ob NFS aufgelistet ist.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">Folgen Sie dem NFS-Konfigurations-Workflow</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">Folgen Sie dem NFS Client Configuration für vSphere Workflow.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">ONTAP Unified Storage</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">Informationen Zu Unified Storage</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">Systeme mit ONTAP Software sind auf mehrere signifikante Arten vereinheitlicht. Dieser Ansatz bezog sich ursprünglich auf die Unterstützung von NAS- und SAN-Protokollen auf einem Storage-System. ONTAP ist dabei weiterhin eine der führenden Plattformen für SAN und bietet in Bezug auf NAS die ursprünglichen Stärken. Eine Storage Virtual Machine (SVM) ist logisch aufgebaut, um Client-Zugriff auf Systeme zu ermöglichen, auf denen die ONTAP Software ausgeführt wird. SVMs können Daten gleichzeitig über mehrere Datenzugriffsprotokolle über logische Schnittstellen (Logical Interfaces, LIFs) bereitstellen. SVMs ermöglichen den Datenzugriff auf Dateiebene über NAS-Protokolle wie CIFS und NFS sowie den Datenzugriff auf Blockebene über SAN-Protokolle wie iSCSI, FC/FCoE und NVMe. SVMs können Daten sowohl für SAN- als auch für NAS-Clients unabhängig gleichzeitig bereitstellen.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">Unified Storage</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">Bei vSphere könnte dieser Ansatz auch für ein einheitliches System für Virtual Desktop Infrastructure (VDI) in Kombination mit einer virtuellen Serverinfrastruktur (VSI) stehen. Systeme mit ONTAP Software sind bei VSI in der Regel kostengünstiger als herkömmliche Enterprise-Arrays, bieten zugleich aber fortschrittliche Storage-Effizienzfunktionen, mit denen Sie im selben System auch VDI gerecht werden können. ONTAP vereint außerdem eine Reihe von Storage-Medien – von SSDs bis SATA – und kann diese problemlos in die Cloud erweitern. Es gibt keine Notwendigkeit, ein Flash-Array für Performance zu kaufen, ein SATA-Array für Archive und separate Systeme für die Cloud. Sie alle sind in ONTAP integriert.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Storage-Virtualisierung</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Weitere Informationen zu SVMs, Unified Storage und Client-Zugriff finden Sie unter<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Im Dokumentationszentrum ONTAP 9.</block>
  <block id="6f3666cf392f9aa79924b94f433b64ed" category="doc">NetApp SnapCenter Plug-in für VMware vSphere – Implementierung auf VMware</block>
  <block id="a1dd31a3dca44eb1fe27b895521130ae" category="inline-link-macro">Nächste: Zusätzliche Informationen – SnapCenter Plug-in für VMware vSphere – Voraussetzungen für die Lösung</block>
  <block id="874d68c7d23e9e2e452ff6efaf757dee" category="paragraph"><block ref="874d68c7d23e9e2e452ff6efaf757dee" category="inline-link-macro-rx"></block></block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">Diese Seite bietet Unterstützung für NFS-Datenspeicher in einer VMware vSphere Umgebung.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">VSphere herkömmliche File Storage-Bereitstellung mit ONTAP</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere unterstützt folgende NFS-Protokolle: Beide unterstützen ONTAP.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS-Version 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS-Version 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">Diesen Vergleich der NFS Client-Versionen</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">Wenn Sie Hilfe bei der Auswahl der richtigen NFS-Version für vSphere benötigen, prüfen Sie die Version <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">Dieser Abschnitt enthält eine Anleitung zu den Funktionen, die von spezifischen Versionen von ONTAP und vSphere unterstützt werden. NetApp empfiehlt, eine bestimmte Kombination von Versionen mithilfe der NetApp Interoperabilitäts-Matrix zu überprüfen.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="doc">Release-spezifische Informationen zu ONTAP und vSphere</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">NetApp Interoperabilitätsmatrix</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">Dieser Abschnitt enthält eine Anleitung zu den Funktionen, die von spezifischen Versionen von ONTAP und vSphere unterstützt werden. NetApp empfiehlt, eine bestimmte Kombination von Versionen mit dem zu überprüfen<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">ONTAP-Versionen</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">Zum Zeitpunkt der Veröffentlichung bietet NetApp vollständige Unterstützung für die folgenden Versionsfamilien:</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">Unterstützung von vSphere und ESXi</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP bietet umfassende Unterstützung für vSphere ESXi Hosts. Die vier gerade beschriebenen Hauptversionsfamilien (9.5, 9.6, 9.7 und 9.8) werden vollständig als Daten-Storage-Plattformen für neue vSphere Versionen unterstützt, einschließlich 6.0, 6.5 und 7.0 (inklusive Updates für diese Versionen). Die NFSv3-Interoperabilität ist weit gefasst. NetApp unterstützt alle Clients, darunter auch Hypervisoren, die mit dem NFSv3-Standard kompatibel sind. Die Unterstützung für NFSv4.1 ist auf vSphere 6.0 bis 7.0 beschränkt.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">Für SAN-Umgebungen führt NetApp umfassende Tests der SAN-Komponenten durch. Im Allgemeinen unterstützt NetApp standardmäßige X86-64-Rack-Server und Cisco UCS Server zusammen mit Ethernet-Standardadaptern für iSCSI-Verbindungen. Aufgrund der erforderlichen HBA-Firmware und -Treiber verfügen FC-, FCoE- und NVMe/FC-Umgebungen über eine spezifischer definierte Unterstützung.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">Prüfen Sie immer das<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> Bestätigen des Supports für eine bestimmte Hardware- und Softwarekonfiguration.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">NFS-Plug-in für VMware VAAI</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">Dieses Plug-in für ESXi Hosts hilft beim verlagern von Vorgängen zu ONTAP mithilfe von VAAI. Die neueste Version, 1.1.2, unterstützt NFSv4.1-Datastores, einschließlich Unterstützung für Kerberos (krb5 und krb5i). Das Plug-in wird mit ESXi 6.0, 6.5 und 7.0 zusammen mit ONTAP 9.5-9.8 unterstützt.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">VASA Provider</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">NetApp VASA Provider unterstützt die Bereitstellung und das Management von vVol (siehe Abschnitt 3.7). Die neuen VASA Provider Versionen unterstützen ESXi 6.0, 6.5 und 7.0 zusammen mit ONTAP 9.5-9.8.</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">ONTAP Tools für VMware vSphere sind für das Management von ONTAP Storage zusammen mit vSphere entscheidend (die Nutzung dieses Tools ist eine Best Practice). Die neueste Version, 9.8, wird mit vSphere 6.5 und 7.0 zusammen mit ONTAP 9.5-9.8 unterstützt.</block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Dieses Dokument beschreibt die Produktsicherheit für ONTAP Tools für VMware vSphere.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353: ONTAP Tools for VMware vSphere - Product Security</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tulledge, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Aktivitäten zur sicheren Entwicklung</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">Das Software-Engineering mit NetApp ONTAP Tools für VMware vSphere nutzt folgende sichere Entwicklungsaktivitäten:</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Threat Modeling.* der Zweck der Bedrohungsmodellierung ist es, Sicherheitslücken in einem Feature, einer Komponente oder einem Produkt frühzeitig im Lebenszyklus der Softwareentwicklung zu entdecken. Ein Bedrohungsmodell ist eine strukturierte Darstellung aller Informationen, die die Sicherheit einer Anwendung beeinflussen. Im Wesentlichen ist es ein Blick auf die Anwendung und ihre Umgebung durch die Linsen der Sicherheit.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic Application Security Testing (DAST).* Diese Technologie wurde entwickelt, um gefährdete Bedingungen für Anwendungen im laufenden Zustand zu erkennen. DAST testet die freigesetzten HTTP- und HTML-Schnittstellen von Web-enable-Anwendungen.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Codewährung von Drittanbietern.* im Rahmen der Softwareentwicklung mit Open-Source-Software (OSS) müssen Sie Sicherheitslücken schließen, die mit jedem OSS in Ihr Produkt integriert werden könnten. Dies ist ein fortdauernde Bemühung, da bei einer neuen OSS-Version möglicherweise jederzeit eine neu entdeckte Sicherheitsanfälligkeit gemeldet wird.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Schwachstellenscans.* Zweck der Schwachstellenanalyse ist es, häufige und bekannte Sicherheitslücken in NetApp Produkten zu erkennen, bevor diese bei den Kunden freigegeben werden.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">*Penetrationstest.* Penetrationstest ist der Prozess, um ein System, eine Web-Anwendung oder ein Netzwerk zu bewerten, um Sicherheitslücken zu finden, die von einem Angreifer ausgenutzt werden könnten. Penetrationstests (Penetrationstests) bei NetApp werden von einer Gruppe genehmigter und vertrauenswürdiger Drittanbieter durchgeführt. Ihr Testumfang umfasst die Einleitung von Angriffen gegen eine Anwendung oder Software ähnlich wie feindliche Eindringlinge oder Hacker mit ausgereiften Methoden oder Tools zur Ausbeutung.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Produktsicherheitsfunktionen</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">Die NetApp ONTAP Tools für VMware vSphere umfassen die folgenden Sicherheitsfunktionen in jeder Version.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Anmeldebanner* SSH ist standardmäßig deaktiviert und erlaubt nur einmalige Anmeldungen, wenn sie über die VM-Konsole aktiviert sind. Das folgende Anmeldebanner wird angezeigt, nachdem der Benutzer einen Benutzernamen in die Anmeldeaufforderung eingegeben hat:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*WARNUNG:* der unerlaubte Zugriff auf dieses System ist verboten und wird gesetzlich verfolgt. Durch den Zugriff auf dieses System erklären Sie sich damit einverstanden, dass Ihre Maßnahmen überwacht werden können, wenn eine unbefugte Nutzung vermutet wird.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Nachdem der Benutzer die Anmeldung über den SSH-Kanal abgeschlossen hat, wird der folgende Text angezeigt:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC).* ONTAP Tools verfügen über zwei Arten von RBAC-Steuerungsoptionen:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Native vCenter Server-Berechtigungen</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Spezifische Berechtigungen für vCenter Plug-in Weitere Informationen finden Sie unter<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Verschlüsselte Kommunikationskanäle.* Alle externen Kommunikation erfolgt über HTTPS mit Version 1.2 von TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Minimal Port Exposure.* nur die benötigten Ports sind an der Firewall geöffnet.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">In der folgenden Tabelle werden die Details zum offenen Anschluss beschrieben.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4/v6-Port #</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Richtung</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Funktion</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">Eingehend</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">HTTPS-Verbindungen für REST-API</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS-Verbindungen</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">HTTPS-Verbindungen für SOAP über HTTPS-Verbindungen dieser Port muss geöffnet werden, damit ein Client eine Verbindung zum API-Server der ONTAP-Tools herstellen kann.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (standardmäßig deaktiviert)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS-Verbindungen - VP und SRA - nur interne Verbindungen von Loopback</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">HTTPS-Verbindungen – VP und SRA, die für SOAP über HTTPS-Verbindungen verwendet werden</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP-Trap-Pakete</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">Nur zur internen Nutzung</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby-Datenbank-Port, nur zwischen diesem Computer und sich selbst, externe Verbindungen nicht akzeptiert -- nur interne Verbindungen</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">Bidirektional</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Wird für Verbindungen zu ONTAP-Clustern verwendet</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">kb-Artikel</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Unterstützung für Zertifizierungsstelle (CA) signierte Zertifikate.* ONTAP Tools für VMware vSphere unterstützt CA signierte Zertifikate. Siehe das<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Audit Logging.* Supportpakete können heruntergeladen werden und sind äußerst detailliert. Die ONTAP Tools protokollieren alle Benutzer-Login- und -Abmeldeaktivitäten in einer separaten Protokolldatei. VASA API-Aufrufe werden in einem dedizierten VASA Audit Log (Local cxf.log) protokolliert.</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Passwortrichtlinien.* folgende Kennwortrichtlinien werden befolgt:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Passwörter werden nicht in Protokolldateien protokolliert.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Passwörter werden nicht im Klartext kommuniziert.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Während des Installationsvorgangs selbst werden Passwörter konfiguriert.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">Der Passwortverlauf ist ein konfigurierbarer Parameter.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">Das Mindestalter des Kennworts ist auf 24 Stunden festgelegt.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">Die Felder für das Kennwort werden automatisch ausgefüllt.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP-Tools verschlüsselt alle gespeicherten Anmeldeinformationen mithilfe von SHA256 Hashing.</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">November 2021</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Seit fast zwei Jahrzehnten ist die NetApp ONTAP Software eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die nicht nur zur Vereinfachung des Managements, sondern auch zu Kostensenkungen beitragen. Dieses Dokument bietet eine Einführung in die ONTAP Lösung für vSphere sowie in die neuesten Produktinformationen und Best Practices zur Optimierung der Implementierung, Risikominderung und Vereinfachung des Managements.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597: VMware vSphere für ONTAP</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">Karl Konnerth, NetApp</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Andere Dokumente wie Leitfäden und Kompatibilitätslisten werden durch Best Practices ergänzt. Sie werden basierend auf Labortests und umfassenden praktischen Erfahrungen der NetApp Ingenieure und Kunden entwickelt. Es handelt sich hierbei unter Umständen nicht nur um die einzigen unterstützten Praktiken, die in jeder Umgebung funktionieren. Im Allgemeinen sind sie aber die einfachsten Lösungen, die die Anforderungen der meisten Kunden erfüllen.</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">Der Schwerpunkt dieses Dokuments liegt auf den Funktionen der neuesten Versionen von ONTAP (9.x), die unter vSphere 6.0 oder höher ausgeführt werden. Siehe Abschnitt <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> Finden Sie Details zu bestimmten Versionen.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Warum ONTAP für vSphere?</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">Es gibt viele Gründe, warum sich Zehntausende Kunden für ONTAP als Storage-Lösung für vSphere entschieden haben, beispielsweise ein Unified-Storage-System, das sowohl SAN- als auch NAS-Protokolle unterstützt und robuste Datensicherungsfunktionen mithilfe platzsparender NetApp Snapshot Kopien, Außerdem bietet zahlreiche Tools, die Sie beim Management von Applikationsdaten unterstützen. Wenn Sie ein Storage-System getrennt vom Hypervisor verwenden, können Sie viele Funktionen verlagern und Ihre Investitionen in vSphere Host-Systeme optimal nutzen. Hierdurch wird sichergestellt, dass Ihre Host-Ressourcen schwerpunktmäßig für Applikations-Workloads verwendet werden. Darüber hinaus werden zufällige Auswirkungen auf die Performance von Applikationen aufgrund des Storage-Betriebs vermieden.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">Die Kombination von ONTAP und vSphere ermöglicht Kosteneinsparungen für Host-Hardware und VMware Software. Schützen Sie Ihre Daten außerdem zu geringeren Kosten mit konstant hoher Performance. Da virtualisierte Workloads mobil sind, können Sie mit Storage vMotion verschiedene Ansätze nutzen, um VMs auf VMFS-, NFS- oder VVols-Datastores zu verschieben. Und das alles auf ein und demselben Storage-System.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Im Folgenden sind wichtige Faktoren aufgeführt, die heutzutage von Kunden wertvoll sind:</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">*Unified Storage.* Systeme mit ONTAP Software sind auf mehrere signifikante Arten vereinheitlicht. Dieser Ansatz bezog sich ursprünglich auf NAS- und SAN-Protokolle. ONTAP ist dabei weiterhin eine der führenden Plattformen für SAN und bietet in Bezug auf NAS die ursprünglichen Stärken. Bei vSphere könnte dieser Ansatz auch für ein einheitliches System für Virtual Desktop Infrastructure (VDI) in Kombination mit einer virtuellen Serverinfrastruktur (VSI) stehen. Systeme mit ONTAP Software sind bei VSI in der Regel kostengünstiger als herkömmliche Enterprise-Arrays, bieten zugleich aber fortschrittliche Storage-Effizienzfunktionen, mit denen Sie im selben System auch VDI gerecht werden können. ONTAP vereint außerdem eine Reihe von Storage-Medien – von SSDs bis SATA – und kann diese problemlos in die Cloud erweitern. Es gibt keine Notwendigkeit, ein Flash-Array für Performance zu kaufen, ein SATA-Array für Archive und separate Systeme für die Cloud. Sie alle sind in ONTAP integriert.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">*Virtual Volumes und richtlinienbasiertes Storage-Management.* NetApp war schon früh Design-Partner von VMware bei der Entwicklung von vSphere Virtual Volumes (VVols). NetApp bot Architektureingaben und frühzeitig Unterstützung für VVols und VMware vSphere APIs for Storage Awareness (VASA). Durch diesen Ansatz wurde einerseits das granulare VM-Storage-Management in VMFS integriert und andererseits auch die Automatisierung der Storage-Bereitstellung durch richtlinienbasiertes Storage-Management unterstützt. Storage-Architekten können mit diesem Ansatz Storage-Pools mit unterschiedlichen Funktionen entwerfen, die von VM-Administratoren einfach genutzt werden können. ONTAP ist einer der führenden Anbieter von vVol Storage-Lösungen in der Storage-Branche, da es Hunderttausende VVols in einem einzigen Cluster unterstützt. Anbieter von Enterprise-Arrays und kleineren Flash-Arrays hingegen unterstützen gerade einmal mehrere Tausend VVols pro Array. Zudem bringt NetApp mit neuen Funktionen bei der Unterstützung von VVols 3.0 die Weiterentwicklung des granularen VM-Managements voran.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*Storage-Effizienz.* Obwohl NetApp der erste Anbieter war, der die Deduplizierung für Produktions-Workloads ausstellte, war diese Innovation weder die erste noch die letzte in diesem Bereich. Es begann mit ONTAP Snapshot Kopien, einem platzsparenden Datensicherungsmechanismus ohne Performance-Effekt, sowie mit FlexClone Technologie, bei der sofort Lese-/Schreibkopien von VMs für die Produktion und die Nutzung von Backups erstellt werden können. Danach stellte NetApp Inline-Funktionen bereit, darunter Deduplizierung, Komprimierung und Zero-Block-Deduplizierung, mit denen sich der Storage kostspieliger SSDs maximal ausschöpfen lässt. Zuletzt wurde ONTAP um die Möglichkeit erweitert, kleinere I/O-Vorgänge und Dateien durch Data-Compaction in einen Festplattenblock zu packen. Dank der Kombination dieser Funktionen verzeichnen Kunden Einsparungen im Verhältnis von bis zu 5:1 für VSI und von bis zu 30:1 für VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Hybrid Cloud.* ob in der Private Cloud vor Ort, in einer Public-Cloud-Infrastruktur oder in einer Hybrid Cloud, die das Beste der beiden Lösungen vereint – ONTAP Lösungen helfen Ihnen, Ihre Data Fabric zur Optimierung und zum Optimieren des Datenmanagements aufzubauen. Den Anfang machen hochperformante All-Flash-Systeme, die dann für die Datensicherung und das Cloud-Computing mit Festplatten- oder Cloud-Storage-Systemen gekoppelt werden. Zur Kostenoptimierung und Vermeidung einer Anbieterbindung stehen hierbei Azure, AWS, IBM oder Google Clouds zur Auswahl. Bei Bedarf kann die erweiterte Unterstützung für OpenStack und Containertechnologien genutzt werden. NetApp bietet darüber hinaus Cloud-basiertes Tiering und Archivierungstools (SnapMirror Cloud, Cloud Backup Service und Cloud Sync) sowie Storage-Systeme (FabricPool) für ONTAP, um die Betriebskosten zu senken und die große Reichweite der Cloud auszuschöpfen.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">* Und mehr.* Nutzen Sie die extreme Performance von NetApp AFF A-Series Arrays, um Ihre virtualisierte Infrastruktur zu beschleunigen und gleichzeitig die Kosten im Griff zu haben. Mit horizontal skalierbaren ONTAP Clustern profitieren Sie bei der Wartung, bei Upgrades und selbst beim kompletten Ersatz Ihres Storage-Systems von einem durchgängig unterbrechungsfreien Betrieb. Daten im Ruhezustand werden mit NetApp Verschlüsselungsfunktionen ohne zusätzliche Kosten geschützt. Durch fein abgestimmte Quality-of-Service- Funktionen stellen Sie sicher, dass die Performance den geschäftlichen Service-Levels entspricht. Sie alle sind Teil der breiten Palette an Funktionen, die mit ONTAP, der branchenführenden Software für Enterprise-Datenmanagement, geliefert werden.</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">Kontaktieren Sie uns</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">Haben Sie Anmerkungen zu diesem technischen Bericht?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">Senden Sie uns Ihre Kommentare an doccomments@netapp.com und geben Sie im Betreff „TR-4597“ an.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">Seit seiner Einführung ins moderne Datacenter im Jahr 2002 ist NetApp ONTAP eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die das Management vereinfachen und gleichzeitig die Kosten senken.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900: VMware Site Recovery Manager mit NetApp ONTAP 9</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP für vSphere</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">Seit seiner Einführung ins moderne Datacenter im Jahr 2002 ist NetApp ONTAP eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die das Management vereinfachen und gleichzeitig die Kosten senken. In diesem Dokument wird die ONTAP-Lösung für VMware Site Recovery Manager (SRM) vorgestellt, die branchenführende Disaster Recovery-Software (DR) von VMware, einschließlich der neuesten Produktinformationen und Best Practices zur Optimierung der Bereitstellung, Risikominderung und Vereinfachung des fortlaufenden Managements.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Andere Dokumente wie Leitfäden und Kompatibilitäts-Tools werden durch Best Practices ergänzt. Sie werden basierend auf Labortests und umfassenden praktischen Erfahrungen der NetApp Ingenieure und Kunden entwickelt. In einigen Fällen passen empfohlene Best Practices möglicherweise nicht zu Ihrer Umgebung. Sie sind jedoch im Allgemeinen die einfachsten Lösungen, die die Anforderungen der meisten Kunden erfüllen.</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">Der Schwerpunkt dieses Dokuments liegt auf den Funktionen der neuesten Versionen von ONTAP 9, wenn dieses zusammen mit unterstützten Versionen von ONTAP Tools für VMware vSphere (einschließlich NetApp Storage Replication Adapter [SRA] und VASA Provider [VP]) und VMware Site Recovery Manager 8 verwendet wird. 4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Vorteile von ONTAP mit SRM</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">Die NetApp Datenmanagementplattformen auf der Basis von ONTAP Software sind eine der am weitesten verbreiteten Storage-Lösungen für SRM. Die Gründe dafür sind reichlich: Eine sichere, hochperformante, einheitliche Datenmanagement-Plattform (NAS und SAN zusammen), die branchenweit folgende Möglichkeiten bietet: Storage-Effizienz, Mandantenfähigkeit, Quality of Service Controls, Datensicherung mit platzsparenden Snapshot Kopien und Replizierung mit SnapMirror. Dabei werden native Hybrid-Multi-Cloud-Integrationen für die Sicherung von VMware Workloads sowie eine Fülle von Automatisierungs- und Orchestrierungs-Tools blitzschnell verfügbar.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">Wenn Sie SnapMirror für die Array-basierte Replizierung einsetzen, profitieren Sie von einer der bewährten und ausgereiftesten Technologien von ONTAP. Mit SnapMirror profitieren Sie von sicheren und hocheffizienten Datentransfers, wobei nur geänderte Datenblöcke kopiert werden, nicht die gesamten VMs oder Datastores. Selbst diese Blöcke profitieren von Platzeinsparungen wie Deduplizierung, Komprimierung und Data-Compaction. Moderne ONTAP Systeme verwenden jetzt versionsunabhängiges SnapMirror für die flexible Auswahl von Quell- und Ziel-Clustern. SnapMirror hat sich tatsächlich zu einem der leistungsstärksten Tools für Disaster Recovery entwickelt.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Ganz gleich, ob Sie herkömmliche NFS-, iSCSI- oder Fibre Channel-Attached Datastores verwenden (jetzt mit Unterstützung für VVols Datastores) – SRM bietet Ihnen einen robusten Erstanbieter, der die besten ONTAP Funktionen für Disaster Recovery oder Planung der Datacenter-Migration und -Orchestrierung nutzt.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Wie SRM ONTAP 9 nutzt</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM nutzt die erweiterten Datenmanagement-Technologien von ONTAP Systemen. Die Integration mit ONTAP Tools für VMware vSphere, einer virtuellen Appliance mit drei Hauptkomponenten:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Das vCenter Plug-in, ehemals Virtual Storage Console (VSC), vereinfacht Storage-Management- und Effizienzfunktionen, verbessert die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert ESXi Hosteinstellungen für NFS- und Block-Storage-Umgebungen. Wegen all dieser Vorteile empfiehlt NetApp dieses Plug-in bei der Verwendung von vSphere bei Systemen mit ONTAP Software.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Vasa Provider für ONTAP unterstützt das VMware vStorage APIs for Storage Awareness (VASA) Framework. VASA Provider verbindet vCenter Server mit ONTAP und erleichtert so die Bereitstellung und das Monitoring von VM-Storage. Es unterstützt die Unterstützung von VMware Virtual Volumes (VVols) und das Management von Storage-Funktionsprofilen (einschließlich VVols Replizierungsfunktionen) und der individuellen VM VVols Performance. Außerdem gibt es Alarme zur Überwachung der Kapazität und der Konformität mit den Profilen. In Verbindung mit SRM ermöglicht der VASA Provider for ONTAP Unterstützung für VVols basierte Virtual Machines, ohne dass ein SRA Adapter auf dem SRM Server installiert werden muss.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA wird zusammen mit SRM eingesetzt, um die Replizierung von VM-Daten zwischen Produktions- und Disaster-Recovery-Standorten bei herkömmlichen VMFS- und NFS-Datenspeichern sowie zum unterbrechungsfreien Testen von DR-Replikaten zu managen. Diese Software hilft bei der Automatisierung der Erkennungs-, Recovery- und Sicherungsaufgaben. Sie enthält sowohl eine SRA Server-Appliance als auch SRA Adapter für den Windows SRM Server und die SRM Appliance.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Nachdem Sie die SRA Adapter auf dem SRM-Server zum Schutz von Datastores außerhalb von VVols sowie zur aktivierten VVols-Replizierung in den VASA Provider-Einstellungen installiert und konfiguriert haben, können Sie mit der Aufgabe beginnen, Ihre vSphere Umgebung für die Disaster Recovery zu konfigurieren.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA und VASA Provider bieten eine Befehlszeilenschnittstelle für den SRM Server zum Managen der ONTAP FlexVols, die Ihre VMware Virtual Machines (VMs) enthalten, sowie zur SnapMirror Replizierung, die sie sichern.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">Ab SRM 8.3 wurde ein neuer SRM VVols Provider-Kontrollpfad in den SRM Server eingeführt, der die IT in die Lage versetzt, mit dem vCenter Server und darüber hinaus ohne SRA mit dem VASA Provider zu kommunizieren. Auf diese Weise konnte der SRM Server eine wesentlich umfassendere Kontrolle über das ONTAP Cluster nutzen als bisher möglich, da VASA eine vollständige API für eine nahtlose Integration bietet.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM kann Ihren DR-Plan unterbrechungsfrei testen, indem die proprietäre FlexClone Technologie von NetApp dazu verwendet wird, nahezu sofort Klone Ihrer geschützten Datenspeicher an Ihrem DR-Standort zu erstellen. SRM erstellt eine Sandbox-Umgebung für sichere Tests, damit sowohl Ihre Organisation als auch Ihre Kunden bei einem echten Ausfall geschützt sind. So können Ihre Unternehmen sicher sein, dass bei einem Ausfall ein Failover ausgeführt werden kann.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">Bei einem echten Ausfall oder sogar einer geplanten Migration können Sie mit SRM alle Last-Minute-Änderungen am Datensatz über ein letztes SnapMirror Update senden (sofern Sie dies tun). Dann wird die Spiegelung unterbrochen und der Datenspeicher wird Ihren DR-Hosts gemountet. An diesem Punkt können Ihre VMs automatisch in beliebiger Reihenfolge gemäß Ihrer vorab geplanten Strategie hochgefahren werden.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM mit ONTAP und anderen Anwendungsfällen: Hybrid Cloud und Migration</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">NetApp Private Storage in Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">Durch Integration Ihrer SRM-Implementierung mit erweiterten Datenmanagement-Funktionen von ONTAP lassen sich im Vergleich zu lokalen Storage-Optionen deutlich bessere Skalierungs- und Performance-Möglichkeiten erzielen. Darüber hinaus bringt sie jedoch noch mehr die Flexibilität der Hybrid Cloud. Mit der Hybrid Cloud können Sie Geld sparen, indem Sie ungenutzte Datenblöcke des High-Performance-Arrays mittels FabricPool in den bevorzugten Hyperscaler verschieben, was ein lokaler S3-Speicher wie NetApp StorageGRID sein könnte. Außerdem können Edge-basierte Systeme mit softwaredefiniertem ONTAP Select oder Cloud-basierter DR mithilfe von Cloud Volumes ONTAP (CVO) oder verwendet werden<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Um einen vollständig integrierten Storage-, Networking- und Computing-Service-Stack in der Cloud zu erstellen, führt Amazon Web Services (AWS), Microsoft Azure und Google Cloud Platform (GCP) zum Vorteil.</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">So konnte mithilfe von FlexClone ein Test-Failover innerhalb des Datacenters eines Cloud-Service-Providers durchgeführt werden – der Storage-Platzbedarf sinkt nahezu auf Null. Der Schutz Ihres Unternehmens ist jetzt günstiger als je zuvor.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">Mit SRM können auch geplante Migrationen durchgeführt werden, indem VMs mit SnapMirror effizient von einem Datacenter in ein anderes oder sogar innerhalb desselben Datacenters übertragen werden, unabhängig davon, ob es sich um Ihr eigenes Datacenter oder über eine beliebige Anzahl an Service Providern von NetApp Partnern handelt.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">Bei VMware vCenter Site Recovery Manager handelt es sich um ein Disaster Recovery-Angebot, das eine automatisierte Orchestrierung und unterbrechungsfreies Testen zentralisierter Recovery-Pläne bietet, um das Disaster Recovery Management aller virtualisierten Applikationen zu vereinfachen.</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">Durch die Implementierung von Site Recovery Manager auf NetApp ONTAP Systemen können Sie die Kosten und die Komplexität des Disaster Recovery deutlich senken. Mit hochperformanten, einfach zu managenden und skalierbaren Storage-Appliances und dem Angebot an leistungsstarker Software bietet NetApp flexible Storage- und Datenmanagement-Lösungen zur Unterstützung von vSphere Umgebungen.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">Die in diesem Leitfaden enthaltenen Best Practices und Empfehlungen sind keine Einheitslösung. Dieses Dokument enthält eine Sammlung von Best Practices und Empfehlungen, die Richtlinien für die Planung, Implementierung und das Management von SRM DR-Plänen bereitstellen. Wenden Sie sich bei der Planung und Implementierung von VMware vCenter Site Recovery-Umgebungen auf NetApp Storage an einen örtlichen NetApp VMware Experten. NetApp VMware Experten können die Bedürfnisse und Anforderungen jeder vSphere Umgebung rasch identifizieren und die Storage-Lösung entsprechend anpassen.</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">Mit SnapCenter können Sie Backup-Richtlinien erstellen, die auf mehrere Jobs angewendet werden können. In diesen Richtlinien können ein Zeitplan, die Aufbewahrung, die Replizierung und andere Funktionen definiert werden. Sie erlauben weiterhin die optionale Auswahl von VM-konsistenten Snapshots, was die Fähigkeit des Hypervisors nutzt, I/O vor dem Erstellen eines VMware Snapshots stillzulegen.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">Andere Funktionen für vSphere</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">Datensicherung</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">Zu den größten Stärken von ONTAP für vSphere zählt, dass Sie Ihre VMs sichern und schnell wiederherstellen können und dass Sie diese Funktion mit dem SnapCenter Plug-in für VMware vSphere einfach in vCenter managen können. Mit Snapshot Kopien können Sie ohne Auswirkungen auf die Performance schnell Kopien Ihrer VMs oder Datastores erstellen und diese dann zur längerfristigen externen Datensicherung mit SnapMirror an ein sekundäres System senden. Durch diesen Ansatz werden der Storage-Platzbedarf und die Netzwerkbandbreite minimiert, da nur geänderte Informationen gespeichert werden.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">Empfehlenswert</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">Mit SnapCenter können Sie Backup-Richtlinien erstellen, die auf mehrere Jobs angewendet werden können. In diesen Richtlinien können ein Zeitplan, die Aufbewahrung, die Replizierung und andere Funktionen definiert werden. Sie erlauben weiterhin die optionale Auswahl von VM-konsistenten Snapshots, was die Fähigkeit des Hypervisors nutzt, I/O vor dem Erstellen eines VMware Snapshots stillzulegen. Aufgrund der Performance-Auswirkungen von VMware Snapshots werden diese jedoch im Allgemeinen nicht empfohlen, es sei denn, Sie müssen das Gast-Betriebssystem stilllegen. Verwenden Sie stattdessen ONTAP Snapshot Kopien für die allgemeine Sicherung und Applikationstools wie SnapCenter Plug-ins, um transaktionsorientierte Daten – beispielsweise SQL Server oder Oracle Daten – zu sichern. Diese Snapshot-Kopien unterscheiden sich von VMware (Konsistenz) Snapshots und sind für längerfristigen Schutz geeignet. VMware Snapshots sind nur<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> Für den kurzfristigen Einsatz aufgrund von Performance und anderen Auswirkungen.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Diese Plug-ins bieten erweiterte Funktionen zur Sicherung von Datenbanken in physischen und virtuellen Umgebungen. Bei vSphere können Sie sie zur Sicherung von SQL Server oder Oracle Datenbanken heranziehen, in denen die Daten in RDM-LUNs, direkt mit dem Gastbetriebssystem verbundenen iSCSI-LUNs oder VMDK-Dateien in VMFS oder NFS-Datastores gespeichert werden. Mit den Plug-ins können unterschiedliche Typen von Datenbank-Backups angegeben, Online- oder Offline-Backups unterstützt und neben Protokolldateien auch Datenbankdateien gesichert werden. Zusätzlich zum Backup und Recovery unterstützen die Plug-ins auch das Klonen von Datenbanken zu Entwicklungs- oder Testzwecken.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">Die folgende Abbildung zeigt ein Beispiel für die Implementierung von SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Falls Sie erweiterte Disaster-Recovery-Funktionen nutzen möchten, sollten Sie in Betracht ziehen, NetApp SRA für ONTAP mit VMware Site Recovery Manager zu kombinieren. Dadurch wird die Replizierung von Datastores an einen DR-Standort unterstützt. Darüber hinaus werden unterbrechungsfreie Tests in der DR-Umgebung ermöglicht, indem die replizierten Datastores geklont werden. Das Recovery nach einem Ausfall und die erneute Sicherung der Produktion nach Behebung des Ausfalls wurden durch die in SRA integrierte Automatisierung ebenfalls vereinfacht.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Um ein Höchstmaß an Hochverfügbarkeit zu gewährleisten, ziehen Sie eine VMware vSphere Metro Storage Cluster (vMSC) Konfiguration mit NetApp MetroCluster in Erwägung. VMSC ist eine von VMware zertifizierte Lösung mit einer Kombination aus synchroner Replizierung und Array-basiertem Clustering. Sie bietet dieselben Vorteile wie ein Hochverfügbarkeits-Cluster, ist aber zum Schutz vor Standortausfällen auf separate Standorte verteilt. NetApp MetroCluster bietet kostengünstige Konfigurationen für die synchrone Replizierung mit transparentem Recovery nach dem Ausfall einer einzelnen Storage-Komponente sowie Recovery mit nur einem Befehl im Falle eines Standortausfalls. VMSC wird in ausführlicher beschrieben<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Speicherplatzrückgewinnung</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">Wenn VMs aus einem Datastore gelöscht werden, kann Speicherplatz für andere Zwecke zurückgewonnen werden. Bei Verwendung von NFS-Datastores wird Speicherplatz sofort zurückgewonnen, wenn eine VM gelöscht wird (wobei dieser Ansatz natürlich nur sinnvoll ist, wenn das Volume mittels Thin Provisioning bereitgestellt wird, die Volume-Garantie also deaktiviert wird). Wenn Dateien jedoch innerhalb des VM-Gastbetriebssystems gelöscht werden, wird der Speicherplatz nicht automatisch durch einen NFS-Datastore zurückgewonnen. Für LUN-basierte VMFS Datastores kann ESXi sowie das Gast-Betriebssystem VAAI UNMAP primitives gegen den Storage triggern (ebenfalls unter Verwendung von Thin Provisioning), um Speicherplatz zurückzugewinnen. Je nach Version erfolgt die Unterstützung hierfür entweder manuell oder automatisch.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">Speicherplatzrückgewinnung</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">Das</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">In vSphere 5.5 und höher wurde das<block ref="6f8212383775d45bd700d7b24be4f64e" prefix=" " category="inline-code"></block> Befehl wird durch das ersetzt<block ref="d92a762ce0274ace04ac012fc760e989" prefix=" " category="inline-code"></block> Befehl, der die Anzahl der freien Blöcke angibt (siehe VMware KB<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> Für weitere Informationen). In vSphere 6.5 und höher, wenn VMFS 6 genutzt wird, sollte der Speicherplatz automatisch asynchron zurückgewonnen werden (siehe<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> In der vSphere-Dokumentation), kann aber bei Bedarf auch manuell ausgeführt werden. Diese automatische UNMAP wird von ONTAP unterstützt, und ONTAP Tools für VMware vSphere setzen sie auf niedrige Priorität. Beachten Sie, dass Sie bei der Bereitstellung einer LUN für die Nutzung als VMFS-Datenspeicher die Option für die Speicherplatzzuweisung auf der LUN manuell aktivieren müssen. Bei Verwendung von ONTAP Tools für VMware vSphere wird die LUN automatisch so konfiguriert, dass diese den erforderlichen Speicherplatz zurückforderbar unterstützt. Es sind keine weiteren Maßnahmen erforderlich. Siehe<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> Knowledge Base-Artikel für weitere Details.</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">Klonen von VMs und Datastores</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">Durch das Klonen eines Storage-Objekts können Sie schnell Kopien für andere Zwecke erstellen, beispielsweise zum Provisionieren weiterer VMs, für Backup- und Recovery-Vorgänge usw. In vSphere können Sie VMs, virtuelle Festplatten, vVol oder Datastores klonen. Nach dem Klonen kann das betreffende Objekt weiter angepasst werden. Dies geschieht häufig durch einen automatisierten Prozess. VSphere unterstützt sowohl vollständige Klone als auch Linked Clones, bei denen Änderungen separat vom ursprünglichen Objekt verfolgt werden.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">Linked Clones eignen sich sehr gut, um Speicherplatz zu sparen, aber sie erhöhen die Menge der I/O-Vorgänge, die vSphere für die VM verarbeitet. Dies wirkt sich auf die Performance der betreffenden VM und vielleicht auch des gesamten Hosts aus. Aus diesem Grund nutzen NetApp Kunden häufig Klone, die auf Storage-Systemen basieren, um das Beste aus beiden Welten zu erhalten: Effiziente Storage-Nutzung und höhere Performance.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">In der folgenden Abbildung ist das Klonen von ONTAP dargestellt.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Das Klonen kann – in der Regel auf VM-, vVol oder Datastore-Ebene – durch mehrere Verfahren auf Systeme mit ONTAP Software verlagert werden. Hierzu zählen:</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">VVols, die den NetApp vSphere APIs for Storage Awareness (VASA) Provider verwenden. Durch ONTAP Klone werden von vCenter gemanagte vVol Snapshot Kopien unterstützt, die platzsparend sind und bei der Erstellung und Löschung eine minimale Auswirkung auf I/O-Vorgänge haben. VMs können auch mit vCenter geklont werden. Sie werden dann auch zu ONTAP verlagert, sei es innerhalb eines einzelnen Datastores/Volumes oder zwischen Datastores/Volumes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">VSphere Klone und Migration mit vSphere APIs – Array Integration (VAAI). VM-Klonvorgänge können in SAN- und NAS-Umgebungen zu ONTAP verlagert werden (NetApp stellt ein ESXi Plug-in zur Aktivierung von VAAI für NFS bereit). VSphere verlagert den Betrieb nur auf „kalte“ (ausgeschalteten) VMs in einem NAS-Datastore, während Vorgänge auf heißen VMs (Klonen und Storage vMotion) ebenfalls für SAN verlagert werden. ONTAP nutzt je nach Quelle, Ziel und installierten Produktlizenzen den effizientesten Ansatz. Diese Funktion wird auch von VMware Horizon View unterstützt.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (wird mit VMware Site Recovery Manager verwendet). Hier werden Klone zum unterbrechungsfreien Testen der Recovery des DR-Replikats herangezogen.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup und Recovery mit NetApp Tools wie SnapCenter. Mit VM-Klonen werden Backup-Vorgänge sichergestellt. Darüber hinaus können VM-Backups gemountet werden, so dass einzelne Dateien kopiert / zurückgesichert werden können.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">Verlagerte ONTAP Klone können durch VMware, NetApp und Drittanbietertools aufgerufen werden. Zu ONTAP verlagerte Klone haben mehrere Vorteile. Sie sind in den meisten Fällen platzsparend, da sie nur für Änderungen am Objekt Storage benötigen. Es entstehen keine zusätzlichen Performance-Einbußen, wenn sie gelesen und geschrieben werden, und in einigen Fällen wird die Performance durch die Freigabe von Blöcken in High-Speed-Caches erhöht. Zudem verlagern sie CPU-Zyklen und Netzwerk-I/O-Vorgänge vom ESXi Server. Die Verlagerung von Kopien in einen herkömmlichen Datastore, bei dem ein FlexVol Volume verwendet wird, kann mit einer Lizenzierung von FlexClone schnell und effizient sein. Kopien zwischen FlexVol Volumes sind jedoch unter Umständen langsamer. Wenn Sie VM-Vorlagen als Klonquelle bereithalten, sollten Sie sie in Betracht ziehen, sie im Datastore-Volume zu platzieren (Ordner oder Inhaltsbibliotheken zur Organisation dieser Klone einsetzen), um schnelle, platzsparende Klone zu erstellen.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">Zum Klonen eines Datastores können Sie ein Volume oder eine LUN auch direkt in ONTAP klonen. Mithilfe der FlexClone Technologie kann bei NFS-Datastores ein gesamtes Volume geklont und der Klon anschließend aus ONTAP exportiert und von ESXi als weiterer Datastore gemountet werden. Bei VMFS Datastores kann in ONTAP eine LUN innerhalb eines Volumes oder das gesamte Volume (einschließlich einer oder mehrerer darin enthaltener LUNs) geklont werden. Eine LUN, die ein VMFS enthält, muss einer ESXi Initiatorgruppe zugeordnet und dann von ESXi neu signiert werden, damit sie gemountet und als regulärer Datastore verwendet werden kann. Ein geklontes VMFS kann für einige temporäre Anwendungsfällte ohne erneute Signatur gemountet werden. Nachdem ein Datastore geklont wurde, können die darin enthaltenen VMs registriert, neu konfiguriert und angepasst werden, als wären sie einzeln geklonte VMs.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">In einigen Fällen kann das Klonen durch zusätzliche lizenzierte Funktionen wie SnapRestore für Backups oder FlexClone optimiert werden. Diese Lizenzen sind oft in Lizenz-Bundles ohne zusätzliche Kosten enthalten. Für vVol Klonvorgänge und zur Unterstützung gemanagter Snapshot Kopien eines vVol (die vom Hypervisor zu ONTAP verlagert werden) ist eine FlexClone Lizenz erforderlich. Durch eine FlexClone Lizenz können auch bestimmte VAAI basierte Klone optimiert werden, wenn sie in einem Datastore/Volume verwendet werden. Dabei werden sofortige platzsparende Kopien anstelle von Blockkopien erstellt. Sie wird zudem von SRA beim Testen der Recovery eines DR-Replikats sowie von SnapCenter für Klonvorgänge und zum Durchsuchen von Backup-Kopien zum Wiederherstellen einzelner Dateien genutzt.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">Storage-Effizienz und Thin Provisioning</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp gehört mit Innovationen im Bereich Storage-Effizienz schon branchenweit zu den Branchenführern – beispielsweise mit der ersten Deduplizierung für primäre Workloads und der Inline-Data-Compaction, durch die eine stärkere Komprimierung erzielt und kleine Dateien sowie I/O-Daten effizient gespeichert werden. ONTAP unterstützt sowohl die Inline-Hintergrund-Deduplizierung als auch die Inline- und Hintergrund-Komprimierung.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">Die folgende Abbildung zeigt die kombinierte Auswirkung der ONTAP Storage-Effizienzfunktionen.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">Im Folgenden finden Sie Empfehlungen zur Nutzung der ONTAP Storage-Effizienz in einer vSphere Umgebung:</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">Die Höhe der durch Datendeduplizierung erzielten Einsparungen basiert auf den Gemeinsamkeiten der Daten. Bei ONTAP bis Version 9.1 erfolgte die Datendeduplizierung auf Volume-Ebene, doch mit der Aggregat-Deduplizierung ab ONTAP 9.2 werden die Daten über alle Volumes hinweg in einem Aggregat auf AFF Systemen dedupliziert. Es ist daher nicht mehr nötig, zur Maximierung der Einsparungen ähnliche Betriebssysteme und Applikationen innerhalb eines einzelnen Datastores zu gruppieren.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">Um die Vorteile der Deduplizierung in einer Blockumgebung ganz auszuschöpfen, müssen die LUNs einem Thin Provisioning unterzogen werden. Die jeweilige LUN wird dem VM-Administrator weiter so angezeigt, als ob sie die bereitgestellte Kapazität in Anspruch nimmt, allerdings werden die durch Deduplizierung erzielten Einsparungen dem Volume zugeführt und stehen dann für andere Zwecke zur Verfügung. NetApp empfiehlt, diese LUNs in FlexVol Volumes zu implementieren, die auch Thin Provisioning verwenden (ONTAP-Tools für VMware vSphere Größe des Volumes ca. 5 % größer als die LUN).</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">Thin Provisioning wird auch für NFS FlexVol Volumes empfohlen (und ist dafür auch der Standard). In einer NFS-Umgebung sind die Einsparungen durch Deduplizierung bei Volumes mit Thin Provisioning für Storage- und VM-Administratoren sofort ersichtlich.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">Thin Provisioning gilt auch für die VMs, für die NetApp im Allgemeinen VMDKs mit Thin statt Thick Provisioning empfiehlt. Denken Sie bei der Nutzung von Thin Provisioning daran, dass Sie den verfügbaren Speicherplatz mit ONTAP Tools für VMware vSphere, ONTAP oder anderen verfügbaren Tools überwachen, um Probleme durch nicht genügend Speicherplatz zu vermeiden.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">Beachten Sie, dass die Performance beim Thin Provisioning von ONTAP Systemen nicht beeinträchtigt wird. Die Daten werden in verfügbare Speicherplatzbereiche geschrieben, sodass die Schreib- und Lese-Performance maximiert wird. Trotzdem erfordern manche Produkte wie Microsoft Failover Clustering oder andere Applikationen mit niedriger Latenz eventuell garantiertes oder festes Provisioning. In diesem Fall empfiehlt es sich, diese Anforderungen zu erfüllen, um Support-Probleme zu vermeiden.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">Um maximale Einsparungen durch Deduplizierung zu erzielen, sollten Sie eventuell Hintergrund-Deduplizierung auf festplattenbasierten Systemen oder automatische Hintergrund-Deduplizierung für AFF Systeme planen. Während die geplanten Prozesse laufen, werden jedoch Systemressourcen verbraucht. Sie sollten daher im Idealfall für Zeiten mit geringerer Aktivität (etwa an Wochenenden) geplant oder häufiger ausgeführt werden, damit weniger geänderte Daten verarbeitet werden müssen. Die automatische Hintergrund-Deduplizierung für AFF Systeme hat geringere Auswirkungen auf Vordergrundaktivitäten. Die Hintergrund-Komprimierung (für festplattenbasierte Systeme) verbraucht ebenfalls Ressourcen und sollte daher nur für sekundäre Workloads mit begrenzten Performance-Anforderungen in Betracht gezogen werden.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">KB-Artikel</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">NetApp AFF Systeme nutzen in erster Linie Inline-Storage-Effizienzfunktionen. Wenn die Datenverschiebung dorthin mithilfe von NetApp Tools erfolgt, die Blockreplizierung nutzen, beispielsweise mit dem 7-Mode Transition Tool, SnapMirror oder Volume Move, kann es zur Maximierung der effizienzbedingten Einsparungen hilfreich sein, Komprimierungs- und Data-Compaction-Scanner auszuführen. Lesen Sie diesen NetApp Support<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> Entnehmen.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">Snapshot Kopien sperren möglicherweise Blöcke, die durch Komprimierung und Deduplizierung verkleinert werden könnten. Stellen Sie beim Einsatz von geplanten Hintergrundeffizienz- oder Einmalscannern sicher, dass sie vor dem Erstellen der nächsten Snapshot Kopie ausgeführt und abgeschlossen wurden. Prüfen Sie die Snapshot Kopien und deren Aufbewahrung und achten Sie darauf, dass Sie nur benötigte Snapshot Kopien behalten. Dies gilt insbesondere vor der Ausführung eines Hintergrund- oder Scannerjobs.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">Die folgende Tabelle enthält Richtlinien zur Storage-Effizienz für virtualisierte Workloads für verschiedene Typen von ONTAP Storage:</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Workload</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Richtlinien für Storage-Effizienz</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">Festplatten</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI und SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">Für primäre und sekundäre Workloads:</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">Anpassungsfähige Inline-Komprimierung</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">Inline-Deduplizierung</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">Hintergrund-Deduplizierung</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">Inline-Data-Compaction</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">Für primäre Workloads:</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">Für sekundäre Workloads:</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">Anpassungsfähige Hintergrund-Komprimierung</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">Servicequalität (QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">Systeme mit ONTAP Software nutzen die ONTAP Storage-QoS-Funktion, um den Durchsatz in Megabit pro Sekunde und/oder die Anzahl der I/O-Vorgänge pro Sekunde (IOPS) für unterschiedliche Storage-Objekte wie Dateien, LUNs, Volumes oder ganze SVMs zu beschränken.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">Durchsatzbegrenzungen sind bei der Steuerung unbekannter Workloads oder von Test-Workloads vor der Implementierung nützlich, wenn sichergestellt werden soll, dass sie sich nicht auf andere Workloads auswirken. Sie können auch zur Beschränkung eines als problematisch identifizierten Workloads eingesetzt werden. Minimale Service-Level auf Basis der IOPS werden ebenfalls unterstützt, um SAN-Objekten in ONTAP 9.2 und NAS-Objekten in ONTAP 9.3 eine konsistente Performance bereitzustellen.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Bei einem NFS-Datastore kann eine QoS-Richtlinie auf das gesamte FlexVol Volume oder auf einzelne VMDK-Dateien darin angewendet werden. Die QoS-Richtlinien können bei VMFS Datastores mit ONTAP LUNs auf das FlexVol Volume, das die LUNs enthält, oder auf einzelne LUNs angewendet werden, jedoch nicht auf einzelne VMDK-Dateien, weil ONTAP das VMFS Filesystem nicht erkennt. Bei Verwendung von VVols kann über das Storage-Funktionsprofil und die VM-Storage-Richtlinie für einzelne VMs die minimale und/oder maximale QoS festgelegt werden.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Die maximale QoS-Durchsatzbegrenzung für ein Objekt kann in Megabit pro Sekunde und/oder IOPS festgelegt werden. Wenn beide verwendet werden, wird das erste erreichte Limit von ONTAP durchgesetzt. Ein Workload kann mehrere Objekte umfassen. Auf einen oder mehrere Workloads kann eine QoS-Richtlinie angewendet werden. Wird eine Richtlinie auf mehrere Workloads angewendet, teilen diese das in der Richtlinie zulässige Gesamtlimit. Geschachtelte Objekte werden nicht unterstützt (so können beispielsweise nicht jede Datei in einem Volume eine eigene Richtlinie aufweisen). QoS-Mindestwerte können nur als IOPS angegeben werden.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Derzeit sind folgende Tools für das Management von ONTAP QoS-Richtlinien und deren Anwendung auf Objekte verfügbar:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI VON ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP System Manager</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow-Automatisierung</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">NetApp PowerShell Toolkit für ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">ONTAP-Tools für VMware vSphere VASA Provider</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Beachten Sie folgende Vorgaben, wenn Sie eine QoS-Richtlinie auf eine VMDK in NFS anwenden:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">Die Politik muss auf das angewendet werden<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> Die das tatsächliche Image des virtuellen Laufwerks enthält, nicht das<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (Deskriptordatei für virtuelle Festplatten) oder<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (VM-Deskriptordatei).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">Wenden Sie keine Richtlinien auf andere VM-Dateien wie virtuelle Swap-Dateien an <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Wenn Sie Dateipfade mithilfe des vSphere Webclients ermitteln („Datastore“ &gt; „Files“), denken Sie daran, dass dieser die Informationen der zusammenfasst<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> Und<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> Und zeigt einfach eine Datei mit dem Namen des an<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> Aber die Größe der<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Zusatz<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> In den Dateinamen, um den richtigen Pfad zu erhalten.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Wenn Sie eine QoS-Richtlinie einschließlich VMFS und RDM einer LUN zuweisen möchten, können Sie die ONTAP SVM (angezeigt als „vServer“), den LUN-Pfad und die Seriennummer auf der ONTAP Tools für VMware vSphere Startseite aus dem Menü „Storage Systems“ abrufen. Wählen Sie das Storage-System (SVM) und anschließend „Related Objects“ &gt; „SAN“ aus. Verwenden Sie diesen Ansatz, wenn Sie die QoS mit einem der ONTAP Tools angeben.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">Die maximale und minimale QoS kann einer vVol-basierten VM mit ONTAP Tools für VMware vSphere oder Virtual Storage Console 7.1 und höher problemlos zugewiesen werden. Wenn Sie das Storage-Funktionsprofil für den vVol Container erstellen, geben Sie unter der Performance-Funktion einen maximalen und/oder minimalen IOPS-Wert an und verweisen dann mit der Storage-Richtlinie der VM auf dieses SCP. Verwenden Sie diese Richtlinie beim Erstellen der VM oder beim Anwenden der Richtlinie auf eine vorhandene VM.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup Datastores bieten erweiterte QoS-Funktionen, wenn ONTAP Tools für VMware vSphere 9.8 und höher verwendet werden. Sie können ganz einfach QoS für alle VMs in einem Datastore oder für bestimmte VMs festlegen. Weitere Informationen finden Sie im Abschnitt „FlexGroup“ dieses Berichts.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS und VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP QoS und VMware vSphere Storage I/O Control (SIOC) sind Technologien, die sich gegenseitig ergänzen und die vSphere und Storage-Administratoren gemeinsam nutzen können, um die Performance von vSphere VMs zu managen, die auf Systemen mit ONTAP Software ausgeführt werden. Wie in der folgenden Tabelle zu sehen ist, hat jedes Tool seine eigenen Stärken. Aufgrund des unterschiedlichen Umfangs von VMware vCenter und ONTAP kann es sein, dass einige Objekte von einem System erkannt und gemanagt werden können, vom anderen jedoch nicht.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Eigenschaft</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP-QoS</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Wenn aktiv</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">Richtlinie ist immer aktiv</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Aktiv, wenn ein Konflikt besteht (Datastore-Latenz über Schwellenwert)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Einheiten</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, MB/Sek.</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, Freigaben</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Umfang von vCenter oder Applikation</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Mehrere vCenter Umgebungen, andere Hypervisoren und Applikationen</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Einzelner vCenter Server</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">QoS auf VM festlegen?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK nur auf NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK auf NFS oder VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">QoS auf LUN festlegen (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">QoS auf LUN festlegen (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">QoS auf Volume festlegen (NFS-Datastore)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">QoS auf SVM festlegen (Mandant)?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">Richtlinienbasierter Ansatz?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Ja – kann von allen Workloads in der Richtlinie geteilt oder vollständig auf jeden Workload in der Richtlinie angewendet werden.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Ja, mit vSphere 6.5 und höher.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Lizenz erforderlich</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">In ONTAP enthalten</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware Storage Distributed Resource Scheduler</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) ist eine Funktion von vSphere, die VMs auf Storage basierend auf der aktuellen I/O-Latenz und der Speicherplatznutzung platziert. Danach werden die VM oder VMDKs unterbrechungsfrei zwischen den Datastores in einem Datastore-Cluster (auch Pod genannt) verschoben und es wird der beste Datastore ausgewählt, in dem die VM oder die VMDKs im Datastore-Cluster platziert werden sollen. Ein Datastore-Cluster ist eine Sammlung ähnlicher Datastores, die aus Sicht des vSphere-Administrators in einer einzigen Verbrauchseinheit aggregiert werden.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Wenn Sie SDRS mit den NetApp ONTAP Tools für VMware vSphere verwenden, müssen Sie zuerst einen Datastore mit dem Plug-in erstellen, vCenter verwenden, um das Datastore-Cluster zu erstellen und dann den Datastore hinzufügen. Nach der Erstellung des Datastore-Clusters können diesem direkt aus dem Assistenten für die Datastore-Bereitstellung auf der Seite „Details“ weitere Datastores hinzugefügt werden.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Weitere ONTAP Best Practices für SDRS:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Alle Datastores im Cluster sollten denselben Storage-Typ (beispielsweise SAS, SATA oder SSD) verwenden. Zudem sollte es sich bei allen entweder um VMFS oder NFS-Datastores handeln und sie sollten dieselben Replizierungs- und Sicherungseinstellungen aufweisen.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Sie sollten SDRS eventuell im Standardmodus (manuell) verwenden. Mit diesem Ansatz können Sie die Empfehlungen prüfen und entscheiden, ob Sie sie anwenden oder nicht. Beachten Sie diese Auswirkungen von VMDK Migrationen:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Wenn VMDKs VON SDRS zwischen Datastores verschoben werden, gehen sämtliche Speicherersparnisse durch ONTAP Klone oder Deduplizierung verloren. Sie können die Deduplizierung erneut ausführen, um diese Einsparungen zurückzugewinnen.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">Nachdem SDRS die VMDKs verschoben hat, empfiehlt NetApp, die Snapshot Kopien im Quell-Datastore neu zu erstellen, da der Speicherplatz anderenfalls von der verschobenen VM gesperrt wird.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Die Verschiebung von VMDKs zwischen Datastores im selben Aggregat bietet nur wenige Vorteile. Zudem sind andere Workloads, die das Aggregat möglicherweise teilen, FÜR SDRS nicht sichtbar.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">Richtlinienbasiertes Storage-Management und VVols</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">VMware vSphere APIs for Storage Awareness (VASA) erleichtern einem Storage-Administrator die Konfiguration von Datastores mit klar definierten Funktionen. Der VM-Administrator kann sie zudem im Bedarfsfall jederzeit nutzen, um VMs bereitzustellen, ohne dass eine Interaktion stattfinden muss. Eine genauere Betrachtung dieses Ansatzes lohnt sich für Sie, wenn Sie feststellen möchten, wie er Ihre Storage-Virtualisierungsvorgänge optimieren und Ihnen viele banale Arbeiten ersparen kann.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Vor VASA konnten VM-Administratoren VM-Storage-Richtlinien definieren, mussten dann aber gemeinsam mit dem Storage-Administrator geeignete Datastores ermitteln – oft anhand der Dokumentation oder von Namenskonventionen. Mit VASA kann der Storage-Administrator eine Reihe von Storage-Funktionen definieren, darunter Performance, Tiering, Verschlüsselung und Replizierung. Ein Satz von Funktionen für ein Volume oder eine Gruppe von Volumes wird als Storage-Funktionsprofil (Storage Capability Profile, SCP) bezeichnet.</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">Das SCP unterstützt eine minimale und/oder maximale QoS für Data VVols einer VM. Minimale QoS wird nur auf AFF Systemen unterstützt. ONTAP Tools für VMware vSphere umfassen ein Dashboard, in dem die granulare VM-Performance und logische Kapazität für VVols auf ONTAP Systemen angezeigt werden.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">In der folgenden Abbildung sind die ONTAP Tools für das Dashboard von VMware vSphere 9.8 VVols dargestellt.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">Nachdem ein Storage-Funktionsprofil definiert wurde, können damit anhand der Storage-Richtlinie, in der die entsprechenden Anforderungen angegeben sind, VMs bereitgestellt werden. Durch die Zuordnung zwischen der VM-Storage-Richtlinie und dem Datastore-Storage-Funktionsprofil kann in vCenter eine Liste kompatibler Datastores zur Auswahl angezeigt werden. Dieser Ansatz wird als richtlinienbasiertes Storage-Management bezeichnet.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA stellt die Technologie bereit, mit der der Storage abgefragt und eine Reihe von Storage-Funktionen an vCenter zurückgegeben werden können. VASA Provider stellen die Übersetzung zwischen den Storage-System-APIs und -Konstrukten einerseits und den von vCenter erkannten VMware APIs bereit. NetApp VASA Provider für ONTAP wird als Teil der ONTAP Tools für VMware vSphere Appliance VM angeboten. Das vCenter Plug-in stellt die Schnittstelle zum Bereitstellen und Managen von vVol Datastores bereit und bietet die Möglichkeit, Storage-Funktionsprofile (SCPs) zu definieren.</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP unterstützt sowohl VMFS als auch NFS vVol Datastores. Bei gemeinsamer Verwendung von VVols und SAN-Datastores profitieren Sie von einigen der Vorteile von NFS, beispielsweise von Granularität auf VM-Ebene. Im Folgenden werden einige der zu berücksichtigende Best Practices beschrieben. Weitere Informationen finden Sie unter<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Ein vVol Datastore kann aus mehreren FlexVol Volumes auf mehreren Cluster-Nodes bestehen. Den einfachsten Ansatz stellt ein einzelner Datastore dar, selbst wenn die Volumes unterschiedliche Funktionen haben. SPBM stellt sicher, dass ein kompatibles Volume für die VM verwendet wird. Die Volumes müssen allerdings alle einer einzigen ONTAP SVM angehören und es muss über ein einziges Protokoll auf sie zugegriffen werden. Für jedes Protokoll reicht eine logische Schnittstelle pro Node aus. Es empfiehlt sich nicht, mehrere ONTAP Versionen in einem einzelnen vVol Datastore zu nutzen, da sich die Storage-Funktionen in verschiedenen Versionen unter Umständen unterscheiden.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Verwenden Sie die ONTAP Tools für VMware vSphere Plug-in, um vVol Datastores zu erstellen und zu managen. Neben dem Management des Datastores und dessen Profil erstellt es bei Bedarf automatisch einen Protokollendpunkt für den Zugriff auf die VVols. Falls LUNs verwendet werden, werden LUN-Protokollendpunkte (PES) mit LUN-IDs ab 300 zugeordnet. Vergewissern Sie sich, dass die erweiterte Systemeinstellung des ESXi-Hosts aktiviert ist<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Ermöglicht eine LUN-ID-Nummer, die über 300 liegt (Standard ist 1,024). Wählen Sie diesen Schritt aus: ESXi Host in vCenter, dann Registerkarte „Configure“ und suchen Sie<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> In der Liste der erweiterten Systemeinstellungen.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">Installieren oder migrieren Sie VASA Provider, vCenter Server (Appliance oder Windows basierte Version) oder ONTAP Tools für VMware vSphere selbst nicht auf einem VVols Datastore, da diese dann voneinander abhängen. Im Falle eines Stromausfalls oder einer anderen Störung im Datacenter könnten Sie sie dann nur begrenzt managen.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">Sichern Sie die VASA Provider VM in regelmäßigen Abständen. Erstellen Sie mindestens stündlich Snapshot Kopien des herkömmlichen Datastores, der VASA Provider umfasst. Weitere Informationen zum Sichern und Wiederherstellen von VASA Provider finden Sie in diesem Abschnitt<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">In der folgenden Abbildung werden die VVols Komponenten angezeigt.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Cloud-Migration und -Backup</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Eine weitere Stärke von ONTAP ist die umfassende Unterstützung für die Hybrid Cloud, bei der Systeme in Ihrer Private Cloud vor Ort mit Public-Cloud-Funktionen vereint werden. Im Folgenden sind einige NetApp Cloud-Lösungen aufgeführt, die gemeinsam mit vSphere verwendet werden können:</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">*Cloud Volumes.* NetApp Cloud Volumes Service für AWS oder GCP und Azure NetApp Files für ANF bieten in den führenden Public-Cloud-Umgebungen hochperformante, über mehrere Protokolle gemanagte Storage-Services. Sie können direkt von den Gästen der VMware Cloud VM verwendet werden.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">*Cloud Volumes ONTAP.* die NetApp Cloud Volumes ONTAP Datenmanagement-Software bietet Kontrolle, Schutz, Flexibilität und Effizienz für Ihre Unternehmensdaten in der gewünschten Cloud. Cloud Volumes ONTAP ist eine Cloud-native Datenmanagement-Software auf der Basis der Storage-Software NetApp ONTAP. Nutzen Sie diese Technologie zusammen mit Cloud Manager, um Cloud Volumes ONTAP Instanzen gemeinsam mit Ihren lokalen ONTAP Systemen zu implementieren und zu managen. Nutzen Sie die erweiterten NAS- und iSCSI-SAN-Funktionen in Kombination mit einheitlichem Datenmanagement einschließlich Snapshot-Kopien und SnapMirror Replizierung.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Cloud-Services.* Verwenden Sie Cloud Backup Service oder SnapMirror Cloud, um Daten mithilfe von Public-Cloud-Storage vor lokalen Systemen zu schützen. Cloud Sync hilft bei der Migration und bei der Synchronisierung Ihrer Daten in NAS-, Objektspeicher- und Cloud Volumes Service-Storage.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">Speichern Sie mehr Snapshot Kopien Ihrer VMs</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">*FabricPool.* FabricPool bietet schnelles und einfaches Tiering für ONTAP Daten. Selten genutzte, „kalte“ Blöcke in Snapshot Kopien können zu einem Objektspeicher in Public Clouds oder zu einem privaten StorageGRID Objektspeicher migriert werden und beim erneuten Zugriff auf die ONTAP Daten automatisch wieder abgerufen werden. Alternativ können Sie die Objekt-Tier als dritte Schutzebene für Daten verwenden, die bereits von SnapVault gemanagt werden. Dieser Ansatz kann Ihnen ermöglichen<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> Auf primären und/oder sekundären ONTAP-Storage-Systemen.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* mit softwaredefiniertem NetApp Storage erweitern Sie Ihre Private Cloud über das Internet auf Remote-Einrichtungen und Niederlassungen, in denen Sie ONTAP Select zur Unterstützung von Block- und Fileservices sowie denselben vSphere Datenmanagementfunktionen nutzen können, die Sie in Ihrem Unternehmens-Datacenter haben.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Ziehen Sie bei dem Entwurf Ihrer VM-basierten Applikationen zukünftige Cloud-Mobilität in Erwägung. Anstatt beispielsweise Applikations- und Datendateien gemeinsam zu platzieren, verwenden Sie einen separaten LUN- oder NFS-Export für die Daten. Damit können Sie VM und Daten getrennt zu Cloud-Services migrieren.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Verschlüsselung für vSphere Daten</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">Heute besteht eine wachsende Nachfrage, Daten im Ruhezustand durch Verschlüsselung zu sichern. Obwohl der Schwerpunkt zunächst auf Finanz- und Gesundheitsinformationen lag, gibt es ein wachsendes Interesse an dem Schutz aller Informationen, ob sie in Dateien, Datenbanken oder anderen Datentypen gespeichert sind.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">Systeme mit ONTAP Software vereinfachen die Sicherung sämtlicher Daten durch Verschlüsselung im Ruhezustand. NetApp Storage Encryption (NSE) verwendet Self-Encrypting Drives mit ONTAP, um SAN- und NAS-Daten zu sichern. NetApp bietet darüber hinaus NetApp Volume Encryption und NetApp Aggregate Encryption als einen einfachen, softwarebasierten Ansatz zur Verschlüsselung von Volumes auf Festplattenlaufwerken. Diese Softwareverschlüsselung erfordert keine speziellen Festplatten oder externen Schlüsselmanager und ist für ONTAP Kunden ohne zusätzliche Kosten verfügbar. Sie können ein Upgrade durchführen und mit der Nutzung von IT beginnen, ohne dass es zu Unterbrechungen für Ihre Clients oder Applikationen kommt. Außerdem sind sie gemäß FIPS 140-2 Level 1 Standard validiert, einschließlich Onboard Key Manager.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Für die Sicherung der Daten virtualisierter Applikationen unter VMware vSphere gibt es verschiedene Ansätze. Einer besteht darin, die Daten mit Software innerhalb der VM auf der Ebene des Gastbetriebssystems zu sichern. Alternativ dazu unterstützen neuere Hypervisoren wie vSphere 6.5 jetzt auch Verschlüsselung auf VM-Ebene. Die NetApp Softwareverschlüsselung ist jedoch eine einfache und bietet folgende Vorteile:</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">*Keine Auswirkung auf die virtuelle Server-CPU.* in einigen virtuellen Server-Umgebungen ist jeder verfügbare CPU-Zyklus für ihre Anwendungen erforderlich, aber Tests haben ergeben, dass bei Verschlüsselung auf Hypervisor-Ebene bis zu 5x CPU-Ressourcen benötigt werden. Selbst wenn die Verschlüsselungssoftware zur Verlagerung von Verschlüsselungs-Workloads den AES-NI Befehlssatz von Intel unterstützt (wie dies bei der NetApp Softwareverschlüsselung der Fall ist), ist dieser Ansatz aufgrund der Notwendigkeit neuer CPUs, die nicht mit älteren Servern kompatibel sind, unter Umständen nicht realisierbar.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Onboard Key Manager inbegriffen.* die NetApp Software-Verschlüsselung umfasst einen Onboard-Schlüsselmanager ohne zusätzliche Kosten und erleichtert den Einstieg ohne hochverfügbare Verschlüsselungsmanagement-Server, deren Erwerb und Nutzung ein hohes Maß an Komplexität mit sich bringt.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Keine Auswirkungen auf die Storage-Effizienz.* Storage-Effizienztechniken wie Deduplizierung und Komprimierung werden heute weit verbreitet und sind für eine kostengünstige Nutzung von Flash-Speicher von zentraler Bedeutung. Verschlüsselte Daten können in der Regel jedoch nicht dedupliziert oder komprimiert werden. Die Hardware- und Storage-Verschlüsselung von NetApp arbeitet auf niedrigerer Ebene und ermöglicht im Gegensatz zu anderen Ansätzen die vollständige Nutzung der branchenführenden NetApp Storage-Effizienzfunktionen.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Einfache granulare Datastore-Verschlüsselung.* mit NetApp Volume Encryption erhält jedes Volume einen eigenen AES 256-Bit-Schlüssel. Wenn Sie diesen ändern müssen, müssen Sie dazu nur einen einzigen Befehl ausführen. Dieser Ansatz eignet sich ideal, wenn Sie mehrere Mandanten haben oder für unterschiedliche Abteilungen oder Apps eine unabhängige Verschlüsselung nachweisen müssen. Diese Verschlüsselung wird auf Datastore-Ebene gemanagt, was viel einfacher ist als das Management einzelner VMs.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">Es ist einfach, mit der Softwareverschlüsselung zu beginnen. Nach der Installation der Lizenz konfigurieren Sie einfach das Onboard-Verschlüsselungsmanagement, indem Sie eine Passphrase angeben und dann entweder ein neues Volume erstellen oder ein Storage-seitiges Volume verschieben, um die Verschlüsselung zu aktivieren. NetApp arbeitet daran, künftige Versionen seiner VMware Tools um zusätzliche integrierte Unterstützung von Verschlüsselungsfunktionen zu erweitern.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager bietet einen Überblick über die VMs in Ihrer virtuellen Infrastruktur und ermöglicht die Überwachung und Fehlerbehebung von Storage- und Performance-Problemen in Ihrer virtuellen Umgebung.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Eine typische Implementierung einer virtuellen Infrastruktur auf ONTAP setzt auf verschiedene Komponenten, die auf Computing-, Netzwerk- und Storage-Ebenen verteilt sind. Alle Performance-Einbußen bei einer VM-Applikation können aufgrund einer Kombination aus Latenzen auftreten, die bei den verschiedenen Komponenten auf den jeweiligen Ebenen auftreten.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">Der folgende Screenshot zeigt die Ansicht der virtuellen Active IQ Unified Manager Machines.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager stellt das zugrunde liegende Untersystem einer virtuellen Umgebung in einer topologischen Übersicht vor, um zu ermitteln, ob beim Computing-Node, Netzwerk oder Storage ein Latenzproblem aufgetreten ist. Die Ansicht zeigt außerdem das spezifische Objekt, das aufgrund der Performance-Verzögerung Korrekturmaßnahmen ergreifen und das zugrunde liegende Problem lösen kann.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">Der folgende Screenshot zeigt die erweiterte AIQUM-Topologie.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp hat für ESXi Hosts einen Satz von Einstellungen für Multipathing und HBA-Zeitüberschreitungen entwickelt, um auf der Grundlage eigener Tests für das richtige Verhalten bei ONTAP zu sorgen. Diese Einstellungen lassen sich mit ONTAP Tools für VMware vSphere problemlos konfigurieren. Klicken Sie im Übersichtskonsole im Portlet „Host-Systeme“ auf „Einstellungen bearbeiten“ oder klicken Sie in vCenter mit der rechten Maustaste auf den Host und navigieren Sie zu „ONTAP-Tools“ &gt; „Empfohlene Werte festlegen“. Im Folgenden sind die derzeit empfohlenen Hosteinstellungen für die Version 9.8 angegeben.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Hosteinstellung*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Von NetApp empfohlener Wert*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Neustart Erforderlich*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*ESXi Advanced Configuration*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAcceleratLocking</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">Als festgelegt belassen (VMware ist Standard 1)</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">Als festgelegt belassen (VMware Standardwert ist 0, ist aber nicht erforderlich für VMFS6). Weitere Informationen finden Sie unter <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*NFS-Einstellungen*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 oder höher: Auf 32 einstellen. Alle anderen NFS-Konfigurationen: Auf 30 einstellen</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Sind die meisten vSphere 6.X Versionen auf 512 MB eingestellt. Stellen Sie auf 1024 MB für 6.5U3, 6.7U3 und 7.0 oder höher ein.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">MaxVolumes: NFS</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 oder höher: Auf 256 Alle anderen NFS-Konfigurationen einstellen. Auf 64 einstellen.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 oder höher: Auf 256 einstellen.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 oder höher: Auf 128 einstellen</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Alle NFS-Konfigurationen: Auf 10 einstellen</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">HeartbeatFrequency NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Alle NFS-Konfigurationen: Auf 12 einstellen</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">HeartbeatTimeout NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Alle NFS-Konfigurationen: Auf 5 einstellen.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 oder höher: Auf 128 einstellen.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*FC/FCoE-Einstellungen*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Pfadauswahl-Richtlinie</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Wenn FC-Pfade mit ALUA verwendet werden: Auf RR (Round Robin) einstellen. Alle anderen Konfigurationen: Auf FIXED einstellen. Wenn Sie diesen Wert auf RR einstellen, ist für alle aktiven/optimierten Pfade ein besserer Lastausgleich möglich. Der Wert FIXED wird für ältere Konfigurationen ohne ALUA verwendet und verhindert Proxy-I/O-Vorgänge Er trägt also dazu bei, dass I/O-Vorgänge bei einem HA-Paar in einer Umgebung, in der Data ONTAP im 7-Mode ausgeführt wird, nicht auf den anderen Node verlagert werden</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Alle Konfigurationen: Auf 32 einstellen. Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Alle Konfigurationen: Auf 8 einstellen. Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC-HBA-Zeitüberschreitungen</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Standardwert verwenden.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC-HBA-Zeitüberschreitungen</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*ISCSI-Einstellungen*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Alle iSCSI-Pfade: Auf RR (Round Robin) einstellen. Wenn Sie diesen Wert auf RR einstellen, ist für alle aktiven/optimierten Pfade ein besserer Lastausgleich möglich.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Alle Konfigurationen: Auf 32 einstellen. Durch die Festlegung dieses Wertes werden I/O-Fehler verhindert</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 - die erweiterte NFS-Konfigurationsoption MaxQueueDepth funktioniert möglicherweise nicht wie vorgesehen bei der Verwendung von VMware vSphere ESXi 7.0.1 und VMware vSphere ESXi 7.0. Bitte referenzieren <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP-Tools legen beim Erstellen von ONTAP FlexVol Volumes und LUNs bestimmte Standardeinstellungen fest:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*ONTAP-Tool*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Standardeinstellung*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Snapshot-Reserve (-percent-Snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Fraktionale Reserve (-fractional-Reserve)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Aktualisierung der Zugriffszeit (-atime-Update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falsch</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Minimales Vorauslesen (-min-readahead)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">Zeitprogrammierte Snapshot Kopien</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Storage-Effizienz</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Aktiviert</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Volume-Garantie</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Keine (Thin Provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Automatische Volumengröße</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">Vergrößern_verkleinern</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN-Speicherplatzreservierung</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Deaktiviert</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Zuweisung von LUN-Speicherplatz</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">Andere Überlegungen zur Multipath-Konfiguration für Hosts</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">Obwohl derzeit nicht von verfügbaren ONTAP Tools konfiguriert, empfiehlt NetApp, diese Konfigurationsoptionen zu berücksichtigen:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">In hochperformanten Umgebungen oder bei Tests der Performance mit einem einzelnen LUN-Datastore sollte die Einstellung der Lastverteilung für die Round-Robin (VMW_PSP_RR) Path Selection Policy (PSP) von der standardmäßigen IOPS-Einstellung 1000 auf einen Wert 1 geändert werden. Siehe VMware KB<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Pfadauswahl-Plug-ins und -Richtlinien</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">In vSphere 6.7 Update 1 hat VMware einen neuen Lastausgleichsmechanismus für das Round Robin PSP System eingeführt. Bei der Auswahl des optimalen Pfads für I/O berücksichtigt die neue Option die I/O-Bandbreite und die Pfadlatenz Möglicherweise profitieren Sie von der Verwendung in Umgebungen mit nicht äquivalenter Pfadkonnektivität. So können Sie beispielsweise mehr Netzwerk-Hops auf einem Pfad als auf einem anderen verwenden oder ein NetApp All SAN Array System nutzen. Siehe<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="10408567d24e2dd65731b1e2f0508a5d" category="doc">NetApp SnapCenter Plug-in für VMware vSphere – Vorabanforderungen der Lösung</block>
  <block id="0a70bb0111bccb302f68cc327b0527f8" category="inline-link-macro">Zurück: Zusätzliche Informationen - SnapCenter Plug-in für VMware vSphere - Implementierung.</block>
  <block id="dc69c4899210bca949880d9753e92b35" category="paragraph"><block ref="dc69c4899210bca949880d9753e92b35" category="inline-link-macro-rx"></block></block>
  <block id="8eaab69b7b060fb16ac9ba9484edb36e" category="inline-link-macro">Weiter: Weitere Informationen - SnapCenter Plug-in für VMware vSphere - Backup-Workflow.</block>
  <block id="4602e4aeb078cfce115f5bcaf3d65ba7" category="paragraph"><block ref="4602e4aeb078cfce115f5bcaf3d65ba7" category="inline-link-macro-rx"></block></block>
  <block id="e7f47d4d003703cc37a3f472bf362522" category="doc">NetApp SnapCenter Plug-in für VMware vSphere – Backup-Workflow</block>
  <block id="b80c59ad5be93a14a5e884c9617272bd" category="inline-link-macro">Früher: Zusätzliche Informationen – SnapCenter Plug-in für VMware vSphere – Voraussetzungen für die Lösung</block>
  <block id="b8c179b73c48ccf857c179c753fc7866" category="paragraph"><block ref="b8c179b73c48ccf857c179c753fc7866" category="inline-link-macro-rx"></block></block>
  <block id="7889fbe4fe01425f9ecdef9442f812b8" category="inline-link-macro">Weiter: Zusätzliche Informationen - SnapCenter Plug-in für VMware vSphere - Workflow wiederherstellen.</block>
  <block id="907647e9678147c153e1b1f855122048" category="paragraph"><block ref="907647e9678147c153e1b1f855122048" category="inline-link-macro-rx"></block></block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">ONTAP Funktionen für vSphere</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">Protokolle</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">Funktionen</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">ONTAP bietet viele für das Management von virtualisierten Workloads nützliche Funktionen. Einige, für die zusätzliche Produktlizenzen erforderlich sind, werden im nächsten Abschnitt beschrieben. Andere als Standalone-Tools in Paketen integriert – einige für ONTAP und andere für das gesamte NetApp Portfolio – werden im übernächsten Abschnitt beschrieben.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">Im Folgenden finden Sie weitere Details zu grundlegenden Funktionen von ONTAP:</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">*Storage-Effizienz.* ONTAP unterstützt Inline- und Hintergrund-Deduplizierung und -Komprimierung, Zero-Block-Deduplizierung und Data-Compaction.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">*Volume und LUN-Verschiebung.* ermöglicht das unterbrechungsfreie Verschieben von Volumes und LUNs, die vSphere Datastores und VVols im ONTAP Cluster unterstützen. Dadurch können die Performance und Kapazität ausgeglichen und Upgrades unterbrechungsfrei durchgeführt werden.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">*QoS.* QoS ermöglicht das Performance Management einzelner LUNs, Volumes oder Dateien. Mit dieser Funktion kann eine unbekannte oder problematische VM beschränkt werden oder es kann sichergestellt werden, dass einer wichtigen VM genügend Performance-Ressourcen zugewiesen werden.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">*FabricPool.* Diese Funktion führt das automatische Tiering kälterer Daten auf Blockebene in einen separaten Objektspeicher durch, um kostspieligen Flash-Storage freizugeben.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">ONTAP REST-APIs</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Ansible-Module</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">ONTAP Lizenzierung</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">Für einige ONTAP Funktionen, die für das Management von virtualisierten Workloads wertvoll sind, ist eine zusätzliche Lizenz erforderlich, die entweder ohne Zusatzkosten, in einem Lizenz-Bundle oder als individuelles Angebot verfügbar ist. Für viele Kunden besteht der kostengünstigste Ansatz aus einem Lizenzpaket. Im Folgenden sind die wichtigsten Lizenzen, die für vSphere relevant sind, und deren Nutzung beschrieben:</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">*FlexClone.* FlexClone ermöglicht sofortige, platzsparende Klone von ONTAP Volumes und Dateien. Wenn Vorgänge durch VMware vSphere Storage APIs – Array-Integration (VAAI) in das Storage-System verlagert werden, werden diese Klone zur Backup-Verifizierung und -Recovery (SnapCenter Software) sowie für VVols Klone und Snapshot Kopien verwendet. So werden die verwendeten Daten genutzt:</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">Für verlagerte Kopien mit Unterstützung von vSphere Klon- und Migrationsvorgängen (Storage vMotion) wird VAAI mit ONTAP unterstützt. Die FlexClone Lizenz ermöglicht schnelle Klone in einem NetApp FlexVol Volume. Ohne Lizenzierung können trotzdem Klone mit langsameren Blockkopien erstellt werden.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">Für VVols Funktionen ist eine FlexClone Lizenz erforderlich. Damit können Klone von VVols in einem einzigen Datastore oder zwischen Datastores erstellt werden. Zudem sind durch vSphere gemanagte Snapshot Kopien von VVols möglich, die in ein Storage-System verlagert werden.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">Storage Replication Adapter (SRA) wird gemeinsam mit VMware Site Recovery Manager eingesetzt. Zum Testen der Recovery in NAS- und SAN-Umgebungen ist eine FlexClone Lizenz erforderlich. SRA kann ohne FlexClone für Workflows zu Bestandsaufnahme, Recovery und Sicherung genutzt werden.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">*SnapRestore.* die SnapRestore-Technologie ermöglicht eine sofortige Wiederherstellung eines Volumens ohne Kopieren von Daten. Sie ist für NetApp Backup- und Recovery-Tools wie SnapCenter erforderlich und wird bei diesen zum Mounten des Datastore für Verifizierungs- und Restore-Vorgänge genutzt.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">*SnapMirror.* mit der SnapMirror Technologie lässt sich Daten einfach und schnell zwischen ONTAP Systemen vor Ort und in der Cloud replizieren. SnapMirror unterstützt die Versionsflexibilität der logischen Replizierung mit der Performance der Blockreplizierung. Dabei werden nur geänderte Daten an das sekundäre System gesendet. Daten können durch Spiegel- und/oder Vault-Richtlinien gesichert werden. Dies ermöglicht Disaster Recovery und eine langfristige Datenaufbewahrung für Backups. SnapMirror unterstützt sowohl asynchrone als auch synchrone Beziehungen. ONTAP 9.8 führt ein transparentes Applikations-Failover mit SnapMirror Business Continuity ein.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror ist für die SRA Replizierung mit Site Recovery Manager erforderlich. Zudem wird es benötigt, damit SnapCenter Snapshot Kopien auf ein sekundäres Storage-System replizieren kann.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">*SnapCenter.* SnapCenter Software bietet eine einheitliche, skalierbare Plattform- und Plug-in-Suite für applikationskonsistente Datensicherung und Klonmanagement. Die Datensicherungs-Lizenzpakete für AFF und FAS Systeme enthalten eine SnapCenter Lizenz. Das SnapCenter Plug-in für VMware vSphere ist ein kostenloses Produkt, wenn Sie die folgenden Storage-Systeme verwenden: FAS, AFF, Cloud Volumes ONTAP oder ONTAP Select. Es sind jedoch SnapRestore und FlexClone Lizenzen erforderlich.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">*MetroCluster.* NetApp MetroCluster ist eine synchrone Replizierungslösung, die Hochverfügbarkeit und Disaster Recovery auf einem Campus oder in einem Großraumgebiet kombiniert und so vor Standort- und Hardware-Ausfällen schützt. Es stellt Lösungen mit transparentem Recovery nach Ausfällen bereit – ohne Datenverluste (RPO von 0) und mit schneller Recovery (RTO innerhalb von Minuten). MetroCluster wird in vSphere Umgebungen als Teil einer vSphere Metro Storage Cluster Konfiguration eingesetzt.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">Virtualisierungstools für ONTAP</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp bietet verschiedene Standalone-Softwaretools, die gemeinsam mit ONTAP und vSphere für das Management Ihrer virtualisierten Umgebung verwendet werden können. Die folgenden Tools sind ohne Aufpreis in der ONTAP Lizenz enthalten. In Abbildung 1 sehen Sie eine Darstellung, wie diese Tools in Ihrer vSphere Umgebung zusammenarbeiten.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">In der folgenden Abbildung sind die ONTAP Tools für vSphere dargestellt.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3b0a496a8cf35e38aa2e2195dec2f94" category="doc">NetApp SnapCenter Plug-in für VMware vSphere – Workflow wiederherstellen</block>
  <block id="eee0a010c96cd5f8a48024b64979138a" category="inline-link-macro">Früher: Zusätzliche Informationen - SnapCenter Plug-in für VMware vSphere - Backup-Workflow.</block>
  <block id="db5a03b9e1de0d20dc54468940b207eb" category="paragraph"><block ref="db5a03b9e1de0d20dc54468940b207eb" category="inline-link-macro-rx"></block></block>
  <block id="5f01983db70d04ee21145e7d21902fb2" category="inline-link-macro">Weiter: Zusätzliche Informationen - SnapCenter Plug-in für VMware vSphere - SQL Restore Workflow.</block>
  <block id="724a2f2542f99df4a44d9ad7cfb15363" category="paragraph"><block ref="724a2f2542f99df4a44d9ad7cfb15363" category="inline-link-macro-rx"></block></block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">Auf dieser Seite finden Sie Schritte zur Bereitstellung eines NetApp ONTAP Storage iSCSI VMFS-Datenspeichers in einer VMware vSphere Umgebung.</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">VSphere VMFS Datenspeicher – iSCSI-Storage-Back-End mit ONTAP</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">In diesem Abschnitt wird die Erstellung eines VMFS-Datenspeichers mit ONTAP iSCSI-Speicher behandelt.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">Grundkenntnisse für das Management einer vSphere Umgebung und einer ONTAP</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">ONTAP Netzwerkport, SVM und LUN-Informationen für iSCSI</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">Ein ausgefülltes iSCSI-Konfigurationsarbeitsblatt</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">IP-Format für iSCSI VMkernel-Adapter</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">Mit Netzwerk-Daten-Ports des ONTAP Systems und verbundenen vSphere Hosts</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">Für iSCSI konfigurierte VLANs</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">Vergewissern Sie sich, dass die iSCSI-Konfiguration unterstützt wird.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">Überprüfen Sie die ONTAP Lizenz für iSCSI</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">Verwenden Sie die<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Befehl, um zu überprüfen, ob iSCSI aufgeführt ist.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">Nutzung<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> Um die Lizenz hinzuzufügen.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">Vergewissern Sie sich, dass das iSCSI-Protokoll auf der SVM aktiviert ist.</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">Vergewissern Sie sich, dass auf der SVM logische iSCSI-Netzwerk-Schnittstellen verfügbar sind.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">Wenn über die GUI eine SVM erstellt wird, werden auch iSCSI-Netzwerkschnittstellen erstellt.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">Verwenden Sie die<block ref="ba500174804680d403063e56bca3cea6" prefix=" " category="inline-code"></block> Befehl zum Anzeigen oder Ändern der Netzwerkschnittstelle.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">Es werden zwei iSCSI-Netzwerkschnittstellen pro Node empfohlen.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">Erstellen Sie eine iSCSI-Netzwerkschnittstelle.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> Sie können die Service-Richtlinie für Standarddatenblöcke verwenden.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">Überprüfen Sie, ob der Daten-iscsi-Service in der Service-Richtlinie enthalten ist.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> Verwenden Sie können<block ref="4e5efd8167f08c488fa3bc6f718e7db8" prefix=" " category="inline-code"></block> Zu überprüfen.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">Vergewissern Sie sich, dass Jumbo Frames aktiviert sind.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">Erstellen und Zuordnen der LUN.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> Überspringen Sie diesen Schritt, wenn Sie ONTAP-Tools für VMware vSphere verwenden. Wiederholen Sie diesen Schritt für jede LUN.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">Stellen Sie sicher, dass mindestens eine NIC für das iSCSI-VLAN verfügbar ist. Zwei NICs werden bevorzugt, um eine bessere Performance und Fehlertoleranz zu schaffen.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">Ermitteln Sie die Anzahl der physischen NICs, die auf dem vSphere-Host verfügbar sind.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">Konfigurieren Sie den iSCSI-Initiator.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> Ein typischer Anwendungsfall ist ein Software-iSCSI-Initiator.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">Stellen Sie sicher, dass der TCPIP-Stack für iSCSI verfügbar ist</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">Vergewissern Sie sich, dass iSCSI-Portgruppen verfügbar sind</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">In der Regel verwenden wir einen einzelnen virtuellen Switch mit mehreren Uplink-Ports.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">Verwenden Sie 1:1-Adapterzuordnung.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">Vergewissern Sie sich, dass die iSCSI-VMkernel-Adapter für die Anzahl der NICs aktiviert sind und IP-Adressen zugewiesen sind.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">Binden Sie den iSCSI-Software-Adapter an die iSCSI-VMkernel-Adapter.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">Stellen Sie den VMFS-Datenspeicher mit ONTAP Tools bereit</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. Wiederholen Sie diesen Schritt für alle Datenspeicher.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">Prüfen Sie, ob die Hardware-Beschleunigung unterstützt wird.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">Nach Abschluss dieser Aufgaben kann der VMFS-Datenspeicher für die Bereitstellung von Virtual Machines genutzt werden.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible Playbook</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Der Workflow in SRM unterscheidet sich deutlich, wenn VVols Replizierung mit dem verwendet wird, was mit SRA und herkömmlichen Datastores verwendet wird.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Fehlerbehebung bei SRM bei Nutzung der VVols-Replizierung</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Der Workflow in SRM unterscheidet sich deutlich, wenn VVols Replizierung mit dem verwendet wird, was mit SRA und herkömmlichen Datastores verwendet wird. Zum Beispiel gibt es kein Konzept für Array-Manager. So,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> Und<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> Befehle werden nie gesehen.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Bei der Fehlerbehebung sind die neuen Workflows zu verstehen, die im Folgenden aufgeführt sind:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Ermittelt die Replikationsvereinbarungen zwischen zwei Fehlerdomänen.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Ermittelt die Fehlerdomäne-Hierarchie.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Ermittelt die in den Quell- oder Zieldomänen vorhandenen Replikationsgruppen.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Synchronisiert die Daten zwischen Quelle und Ziel.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Ermittelt die Point-in-Time-Replikate auf einem Ziel.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Startet Test Failover.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Beendet das Test-Failover.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Fördert eine Gruppe, die sich derzeit in der Produktion befindet.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PreparreFailoverReplicationGroup: Bereitet sich auf eine Notfallwiederherstellung vor.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">Failover ReplicationGroup: Durchführung einer Disaster Recovery</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Initiiert Reverse-Replikation.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Sucht Container (zusammen mit Hosts oder Replikationsgruppen), die eine Bereitstellungsanfrage mit einer bestimmten Richtlinie erfüllen können.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadaten: Ermittelt die Metadaten aller Ressourcen des VASA Providers, kann die Ressourcenauslastung als Antwort auf die queryMatchingContainer-Funktion zurückgegeben werden.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">Der häufigste Fehler bei der Konfiguration der VVols-Replizierung ist das Erkennen der SnapMirror Beziehungen. Dies geschieht, weil die Volumes und SnapMirror Beziehungen außerhalb der ONTAP Tools-Ansicht erstellt werden. Daher empfiehlt es sich, immer sicherzustellen, dass die SnapMirror Beziehung vollständig initialisiert ist und dass Sie an beiden Standorten eine erneute Bestandsaufnahme in ONTAP Tools ausführen, bevor Sie versuchen, einen replizierten VVols Datastore zu erstellen.</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">Auf dieser Seite werden die Vorteile der Automatisierung der grundlegenden ONTAP Funktionen in einer VMware vSphere Umgebung beschrieben.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">Einführung in die Automatisierung für ONTAP und vSphere</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware Automatisierung</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">Seit den ersten Tagen von VMware ESX ist die Automatisierung ein integraler Bestandteil des Managements von VMware Umgebungen. Die Möglichkeit, Infrastruktur als Code zu implementieren und Verfahren auf private Cloud-Vorgänge auszuweiten, um Bedenken hinsichtlich Skalierbarkeit, Flexibilität, Self-Provisioning und Effizienz zu zerstreuen.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">Die Automatisierung kann in die folgenden Kategorien eingeteilt werden:</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* Bereitstellung virtueller Infrastrukturen*</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">*Betrieb der Gastmaschine*</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">*Cloud-Betrieb*</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">Administratoren stehen im Hinblick auf die Automatisierung ihrer Infrastruktur viele Optionen zur Verfügung. Ob durch die Nutzung nativer vSphere Funktionen wie Host-Profile oder Anpassungsspezifikationen für Virtual Machines über verfügbare APIs auf den VMware Software-Komponenten, Betriebssystemen und NetApp Storage-Systemen verfügen - hier sind umfangreiche Dokumentationen und Anleitungen verfügbar.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 und höher unterstützt bestimmte VMware vSphere APIs for Array Integration (VAAI)-Funktionen, wenn der ESX-Host ESX 4.1 oder höher ausführt. VAAI ist eine Reihe von APIs für die Kommunikation zwischen VMware vSphere ESXi Hosts und Storage-Geräten. Diese Funktionen helfen, Vorgänge vom ESX Host zum Storage-System zu verlagern und den Netzwerkdurchsatz zu steigern. Der ESX-Host aktiviert die Funktionen automatisch in der richtigen Umgebung. Sie können bestimmen, in welchem Umfang Ihr System VAAI-Funktionen verwendet, indem Sie die Statistiken in den VAAI-Zählern prüfen.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">Der häufigste Ausgangspunkt für die Automatisierung der Implementierung einer VMware-Umgebung ist die Bereitstellung von Block- oder dateibasierten Datastores. Vor der Entwicklung der entsprechenden Automatisierung ist es wichtig, die Anforderungen der eigentlichen Aufgaben abzubilden.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">Weitere Informationen zur Automatisierung von VMware-Umgebungen finden Sie in den folgenden Ressourcen:</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">„NetApp Pub“</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. NetApp Konfigurationsmanagement und Automatisierung:</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">Ansible Galaxy Community für VMware</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. Eine Sammlung von Ansible-Ressourcen für VMware.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware {Code} Ressourcen</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. Ressourcen, die zum entwickeln von Lösungen für das softwaredefinierte Datacenter erforderlich sind, einschließlich Foren, Designstandards, Beispielcode und Entwickler-Tools</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">Einführung in ONTAP für vSphere Administratoren</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP vereinfacht das Storage- und Datenmanagement und ergänzt VMware Umgebungen deutlich, ob On-Premises oder in der Cloud bereitgestellt werden. Zu den Gründen, warum sich Zehntausende Kunden für ONTAP als Storage-Lösung für vSphere Implementierungen entschieden haben, zählen erstklassige Datensicherung, Innovationen zur Storage-Effizienz und herausragende Performance in SAN- und NAS-basierten VMware Architekturen.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp bietet zahlreiche VMware Plug-ins, Validierungen und Qualifikationen verschiedener VMware Produkte, um Kunden bei der Administration einer Virtualisierungsumgebung zu unterstützen. NetApp bietet für das Storage- und Datenmanagement, was VMware für die Virtualisierung ist. Kunden können sich auf ihre Kernkompetenzen konzentrieren, anstatt auf das Management von physischem Storage. Die fast 20 Jahre andauernde Partnerschaft zwischen VMware und NetApp entwickelt sich weiter und steigert den Mehrwert für Kunden als neue Technologien wie VMware Cloud Foundation und Tanzu. Dabei unterstützt NetApp auch weiterhin die Basis von vSphere.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">Zu den wichtigsten Faktoren für Kunden gehören:</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">*Unified Storage*</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">* Storage-Effizienz*</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">*Virtuelle Volumes und richtlinienbasiertes Storage-Management*</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">*Hybrid Cloud*</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">Weitere Informationen zu unterstützten NetApp und VMware Lösungen finden Sie in den folgenden Ressourcen:</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">Das NetApp Interoperabilitäts-Matrix-Tool</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). Das IMT definiert die qualifizierten Komponenten und Versionen der FC/FCoE-, iSCSI-, NFS- und CIFS-Konfigurationen.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">Der VMware Compatibility Guide</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. Im VMware Compatibility Guide sind die System-, I/O-, Storage/SAN- und Backup-Kompatibilität mit VMware-Infrastruktur- und Softwareprodukten aufgeführt</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">NetApp ONTAP Tools für VMware</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. ONTAP Tools für VMware vSphere ist ein einzelnes vCenter Server Plug-in, das die Erweiterungen VSC, VASA Provider und Storage Replication Adapter (SRA) enthält.</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">Legen Sie los – mit NetApp &amp; VMware</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware auf NetApp: Ihr Weg beginnt hier!</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">Wenn Sie bereit sind, Ihre VMware Umgebung zu transformieren, schauen Sie sich die neuesten Lösungen und Produktvorführungen an. Wenn Sie bereit für den nächsten Schritt sind, setzen Sie sich mit Experten von NetApp und VMware in Verbindung, die Sie bei der Planung und Ausführung der Modernisierung Ihres Datacenters, Hybrid-Cloud- oder Container-Applikationsinitiativen unterstützen.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">Kontakt</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">Sie sind nicht sicher, wo Sie anfangen sollen? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> Ein Mitglied der VMware Experten von NetApp</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF-Format</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">Der Inhalt auf dieser Seite kann auch in heruntergeladen werden <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">Link=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">Erfahren Sie mehr über Lösungen von NetApp und VMware</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp &amp;amp; VMware: Gemeinsam besser</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">ONTAP 9.8 Aktuelle Funktionen von VMware – Überblick</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">Nutzung des SnapCenter Plug-ins für VMware vSphere</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">Neue Definition von VMware Performance mit NetApp und NVMe</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">Eine kostengünstige Performance-Welt für VMware Cloud auf AWS</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">Vorstellung von VMware Tanzu mit NetApp</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">Virtual Desktop Infrastructure (VDI): Bedarfsgerechtes Bereitstellen von Workstops für Mitarbeiter</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">VMware auf AWS: Architektur- und Service-Optionen</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">Programmierung mit NetApp Cloud Volumes Service APIs zur optimalen Nutzung von AWS</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes: Ausführen von K8s auf vSphere und Tanzu</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">Bauen Sie Ihre Virtualisierte Data Fabric Auf</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">Lesen Sie unsere neuesten NetApp Lösungen für VMware</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">VMware vSphere mit ONTAP: NetApp Lösungen</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">VMware vSphere Virtual Volumes with ONTAP</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">NetApp Modern NVMeoF VMware vSphere Workload Design &amp;amp; Validation</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">Die moderne NVMeoF Cloud-vernetzte Flash-Lösung von NetApp für VMware und SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">Beschleunigen Sie Ihren Kubernetes-Weg mit VMware Tanzu &amp;amp; ONTAP</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">Senken Sie die Kosten für den Betrieb von VMware Cloud auf AWS</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">Sehen Sie sich die Videos der neuesten VMware Lösungen an</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">Best Practices für VMware vSphere und NetApp ONTAP</block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">Ihre VMware Umgebung – Let's Run on NVMe-of with ONTAP</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">VVols Disaster Recovery mit ONTAP Tools und VMware SRM</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">VMware Backup und Recovery für die Data-Fabric-Strategie</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">Flexible Hybrid-Cloud-Lösungen und modernisierte Anwendungsinfrastrukturen für VMware</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">Videos</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">Architektur von VMware Datastores auf NetApp All Flash FAS</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">Migrieren Sie Ihre VMware VMs zu Google Cloud</block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">Deploying Dynamic Persistent NetApp Storage for VMware Tanzu, Teil 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">Deploying Dynamic Persistent NetApp Storage for VMware Tanzu, Teil 2</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Deploying Dynamic Persistent NetApp Storage for VMware Tanzu, Teil 3</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">Blogs</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud auf AWS: Wie Fujitsu mithilfe von CVO Millionen spart</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">Arbeiten Sie mit Experten von NetApp und VMware zusammen</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">Nehmen Sie am Diskussionsforum zu VMware Lösungen Teil</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">Das NetApp Global Services Team hilft Ihnen gerne weiter</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Mit ONTAP sorgt das Konzept der Storage Virtual Machine (SVM) für eine strenge Segmentierung in sicheren mandantenfähigen Umgebungen.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Best Practices für die Implementierung</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SVM-Layout und Segmentierung für SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Mit ONTAP sorgt das Konzept der Storage Virtual Machine (SVM) für eine strenge Segmentierung in sicheren mandantenfähigen Umgebungen. SVM-Benutzer auf einer SVM können nicht auf Ressourcen einer anderen SVM zugreifen bzw. diese managen. Auf diese Weise können Sie die ONTAP Technologie nutzen, indem Sie separate SVMs für verschiedene Geschäftseinheiten erstellen, die ihre eigenen SRM Workflows im selben Cluster managen, um eine größere Storage-Effizienz zu erzielen.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Erwägen Sie die Verwaltung von ONTAP mit SVM-Scoped-Konten und SVM-Management-LIFs, um nicht nur die Sicherheitskontrolle zu verbessern, sondern auch die Performance zu verbessern. Die Performance ist bei der Nutzung von Verbindungen mit SVM-Umfang höher, da der SRA nicht erforderlich ist, alle Ressourcen eines gesamten Clusters – einschließlich physischer Ressourcen – zu verarbeiten. Stattdessen müssen sie nur die logischen Ressourcen verstehen, die zu der jeweiligen SVM abstrahiert sind.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Nur bei der Verwendung von NAS-Protokollen (kein SAN-Zugriff) können Sie sogar den neuen NAS-optimierten Modus nutzen, indem Sie den folgenden Parameter einstellen (beachten Sie, dass der Name so ist, da SRA und VASA dieselben Backend-Services in der Appliance nutzen):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Melden Sie sich am Bedienfeld unter an<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Und klicken Sie auf webbasierte CLI-Schnittstelle.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Führen Sie den Befehl aus<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Führen Sie den Befehl aus<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Führen Sie den Befehl aus<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementieren von ONTAP-Tools und Überlegungen für VVols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Falls Sie SRM mit VVols verwenden möchten, müssen Sie den Storage mit Anmeldedaten für den Cluster-Umfang und einer Cluster-Management-LIF managen. Der Grund dafür ist, dass VASA Provider die zugrunde liegende physische Architektur verstehen muss, um die für VM Storage-Richtlinien erforderlichen Richtlinien erfüllen zu können. Wenn Sie beispielsweise eine Richtlinie haben, die All-Flash-Storage erfordert, muss der VASA Provider in der Lage sein, zu sehen, welche All-Flash-Systeme sind.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Eine weitere Best Practice bei der Implementierung besteht darin, Ihre ONTAP Tools Appliance niemals auf einem VVols Datastore zu speichern, den sie managen. Dies kann dazu führen, dass Sie den VASA Provider nicht einschalten können, da Sie die Swap-vVol für die Appliance nicht erstellen können, da die Appliance offline ist.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Best Practices für das Management von ONTAP 9 Systemen</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">Wie bereits erwähnt, können Sie ONTAP Cluster mit Anmeldedaten im Cluster oder SVM-Umfang und Management-LIFs managen. Für eine optimale Performance sollten Sie die Anmeldedaten mit SVM-Umfang in Betracht ziehen, wenn Sie VVols nicht verwenden. Dabei sollten Sie sich jedoch einigen Anforderungen bewusst sein und dass einige Funktionen verloren gehen.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">Das Standard-vsadmin SVM-Konto verfügt nicht über die erforderliche Zugriffsebene, um ONTAP-Tools-Aufgaben durchzuführen. Daher müssen Sie ein neues SVM-Konto erstellen.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">Wenn Sie ONTAP 9.8 oder höher verwenden, empfiehlt NetApp die Erstellung eines RBAC mit den wenigsten privilegierten Benutzerkontos unter Verwendung des Benutzermenüs des ONTAP System Managers sowie der JSON-Datei, die auf Ihrer ONTAP Tools Appliance unter verfügbar ist<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Verwenden Sie Ihr Administratorpasswort, um die JSON-Datei herunterzuladen. Diese Option kann für SVM oder Konten mit Cluster-Umfang verwendet werden.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">NetApp Support Site Tool</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Wenn Sie ONTAP 9.6 oder eine frühere Version verwenden, sollten Sie das RUC-Tool (RBAC User Creator) verwenden, das im verfügbar ist<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Da die vCenter UI Plug-in, VASA Provider und SRA Server vollständig integrierte Services sind, müssen Sie den SRA-Adapter in SRM um Storage ebenso ergänzen wie in der vCenter UI für ONTAP-Tools. Andernfalls erkennt der SRA-Server möglicherweise nicht die Anfragen, die von SRM über den SRA-Adapter gesendet werden.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">Die NFS-Pfadprüfung wird bei der Verwendung der SVM-Scoped-Anmeldedaten nicht durchgeführt. Der Grund dafür ist, dass der physische Standort logisch von der SVM abstrahiert ist. Dies stellt jedoch keine Sorge mehr dar, da bei der Verwendung von indirekten Pfaden nicht mehr deutliche Performance-Einbußen bei modernen ONTAP Systemen auftreten.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Es werden möglicherweise keine Aggregat-Platzeinsparungen aufgrund von Storage-Effizienz gemeldet.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Wenn unterstützt, können Spiegelungen zur Lastverteilung nicht aktualisiert werden.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Die EMS-Protokollierung wird möglicherweise nicht auf ONTAP Systemen durchgeführt, die mit den Anmeldedaten im Umfang des SVM-Service gemanagt werden.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">VSphere herkömmliche Block-Storage-Bereitstellung mit ONTAP</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere unterstützt die folgenden VMFS-Datastore-Optionen, wobei die Unterstützung für das ONTAP-SAN-Protokoll angegeben ist.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS-Datenspeicher-Optionen</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">Unterstützte ONTAP SAN-Protokolle</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel (FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">ja</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">Fibre Channel over Ethernet (FCoE)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">ISCSI-Erweiterungen für RDMA (iSER)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">Nein</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe over Fabric mit FC (NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">NVMe over Fabric mit RDMA over Converged Ethernet (NVMe/RoCE)</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">Wenn iSER- oder NVMe/RoCE-VMFS erforderlich ist, prüfen Sie SANtricity-basierte Storage-Systeme.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Seit dem Übergang von der älteren virtuellen Appliance bieten ONTAP Tools zahlreiche neue Funktionen, höhere Limits und neue VVols Unterstützung.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Neue Funktionen mit SRM und ONTAP Tools</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Aktuelle Versionen von vSphere und Site Recovery Manager</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">Mit der Veröffentlichung von SRM 8.3 und höher und den 9.7.1 bzw. höheren Versionen von ONTAP Tools sind Sie jetzt in der Lage, VMs unter VMware vSphere 7 zu sichern.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp verbindet seit nahezu zwei Jahrzehnten eine enge Partnerschaft mit VMware und ist bestrebt, die neuesten Versionen so schnell wie möglich zu unterstützen. Aktuelle Kombinationen der Software sind im NetApp Interoperabilitäts-Matrix-Tool (IMT) verfügbar.</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">Der NetApp IMT wurde gefunden<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">VVols Unterstützung (und warum SPBM, sogar mit SRM wichtig ist)</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">Ab der Version 8.3 unterstützt SRM jetzt das Storage Policy-basierte Management (SPBM) der Replizierung mit VVols und Array-basierter Replizierung. Um dies zu erreichen, wurde der SRM-Server aktualisiert, der einen neuen SRM VVols Provider-Service umfasst, der mit dem SMS-Dienst des vCenter-Servers für VASA bezogene Aufgaben kommuniziert.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Ein Vorteil dieser Architektur besteht darin, dass SRA nicht mehr benötigt wird, da alles mit VASA behandelt wird.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM ist ein leistungsstarkes Tool in der vSphere Toolbox und bietet vereinfachte, vorhersehbare und konsistente Storage-Services für die Nutzung durch Automatisierungs-Frameworks in Private- und Hybrid-Cloud-Umgebungen. Im Grunde können Sie mit SPBM Serviceklassen definieren, die die Anforderungen Ihres vielfältigen Kundenstamms erfüllen. Mit SRM können Sie Ihren Kunden jetzt Replizierungsfunktionen für kritische Workloads bereitstellen, die eine robuste Disaster-Recovery-Orchestrierung und -Automatisierung erfordern.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">Unterstützung von VVols Architecture 2.3 für Appliance-basierte SRM Server</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Photon OS-basierte SRM-Server werden jetzt zusätzlich zu älteren Windows-basierten Plattformen unterstützt.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Sie können nun SRA Adapter unabhängig vom bevorzugten SRM-Servertyp installieren.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6 wird unterstützt</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 wird jetzt mit folgenden Einschränkungen unterstützt:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 oder höher</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Nicht unterstützt mit SRM 8.2 (8.1, 8.3 und 8. 4 werden unterstützt)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Interoperabilitäts-Matrix-Tool</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Prüfen Sie die<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> Für die neuesten qualifizierten Versionen.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Verbesserte Performance</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">Die betriebliche Performance ist eine wichtige Anforderung für die Ausführung von SRM-Aufgaben. Um die Anforderungen moderner RTOs und RPOs zu erfüllen, hat das SRA mit ONTAP-Tools zwei neue Verbesserungen hinzugefügt.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Unterstützung für gleichzeitige Reprotect-Vorgänge.* Diese Funktion wurde erstmals in SRA 9.7 eingeführt und ermöglicht die gleichzeitige Ausführung von Reprotect auf zwei oder mehr Recovery-Plänen. Dadurch verringert sich der Zeitaufwand für die erneute Sicherung von Datastores nach einem Failover oder einer Migration und bleibt innerhalb der RTO- und RPO-Parameter.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*ONTAP Tools 9.8 fügt einen neuen nur für NAS optimierten Modus hinzu.* Wenn Sie SVM-Scoped-Konten und Verbindungen zu ONTAP-Clustern mit nur NFS-basierten Datastores verwenden, können Sie nur für NAS optimierten Modus für Spitzen-Performance in unterstützten Umgebungen aktivieren.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Besser skalieren</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Die ONTAP-Tools SRA unterstützt jetzt bei der Verwendung mit SRM 8.3 und höher bis zu 500 Schutzgruppen (PGS).</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Synchrone Replizierung</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Eine lang erwartete und viel erwartete neue Funktion ist SnapMirror Synchronous (SM-S) mit ONTAP 9.5 und höher, die eine granulare Band RPO Datenreplizierungslösung für Ihre geschäftskritischen Anwendungen liefert. SM-S erfordert ONTAP-Tools 9.8 oder höher.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST-API-Unterstützung</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">Die SRA Serverkonfiguration kann jetzt durch REST-APIs gemanagt werden. Eine Swagger UI wurde hinzugefügt, um Sie beim Erstellen Ihrer Automatisierungs-Workflows zu unterstützen. Sie finden sie auf Ihrer ONTAP-Tools-Appliance unter<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="c1ba6d72bba1b6f1d94714d4fcc78480" category="doc">TR-4320: NetApp E-Series und CommVault Data Platform V11 – Referenzarchitektur und Storage Best Practices</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Akash Gupta, NetApp Girish Chanchlani, CommVault</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">Im Bericht TR-4320 werden die Referenzarchitektur und Best Practices für den Einsatz von NetApp E-Series Storage in einer CommVault Data Platform V11-Umgebung erläutert. CommVault und NetApp haben diese Referenzarchitektur gemeinsam entwickelt, um Unterstützung für CommVault Data Platform V11 Implementierungen mit NetApp E-Series Storage zu bieten, um die Applikationszeit für diese Lösung zu beschleunigen.</block>
  <block id="df7cf7c589f9721849875c4944ab1b5f" category="inline-link-macro"><block ref="df7cf7c589f9721849875c4944ab1b5f" category="inline-link-rx"></block></block>
  <block id="d08fcd93c2915044da2cb0000a532b24" category="paragraph"><block ref="d08fcd93c2915044da2cb0000a532b24" category="inline-link-macro-rx"></block></block>
  <block id="fd031987b2da91ab23764bc7a2eeb897" category="doc">TR-4471: Referenzarchitektur für E-Series und EF-Series und Storage Best Practices mit Veeam Backup &amp; Replication 9.5</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta, NetApp Shawn Lieu (Nord- und Südamerika), Stefan Renner (EMEA) und Michael Cade (Performance), Veeam</block>
  <block id="a207fab8627637842c817cfbb6e2a3e5" category="paragraph">TR-4471 zeigt die Referenzarchitektur und Best Practices für den Einsatz von NetApp E-Series Storage in einer Veeam Backup &amp; Replication 9.5-Umgebung</block>
  <block id="609999428a14d32b8afba97bbc6a3bd3" category="inline-link-macro"><block ref="609999428a14d32b8afba97bbc6a3bd3" category="inline-link-rx"></block></block>
  <block id="27f4fbfb25a706ee60055e1e7bc5b112" category="paragraph"><block ref="27f4fbfb25a706ee60055e1e7bc5b112" category="inline-link-macro-rx"></block></block>
  <block id="fe85f62ed86fedb2f150ec1a40d67f2e" category="doc">TR-4704: Deploying Veritas NetBackup with NetApp E-Series Storage</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash Gupta und Principled Technologies, NetApp</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704 beschreibt die Implementierung von Veritas NetBackup auf NetApp E-Series Storage.</block>
  <block id="ddc8bf6244e563f16009d9f3993a3651" category="inline-link-macro"><block ref="ddc8bf6244e563f16009d9f3993a3651" category="inline-link-rx"></block></block>
  <block id="f0320db0293afb1c878e6a4fd3127640" category="paragraph"><block ref="f0320db0293afb1c878e6a4fd3127640" category="inline-link-macro-rx"></block></block>
  <block id="6a2c7fa6b0a402c3b9034538d8c9771f" category="doc">NVA-1143: NetApp HCI – NIST-Sicherheitskontrollen für FISMA mit HyTrust for Multitenant Infrastructure – NVA-Design und -Implementierung</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">Arvind Ramakrishnan, Abhinav Singh, NetApp</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143 beschreibt, wie NetApp HCI entworfen und implementiert werden kann, um die Anforderungen des National Institute of Standards and Technology (NIST) SP 800-53 Revision 4 Sicherheits- und Datenschutzkontrollen zu erfüllen. Diese sind für private Cloud-Infrastrukturen und mandantenfähige Implementierungen von entscheidender Bedeutung.</block>
  <block id="7f02c84e9695cb8a35c7deacae1ac60a" category="inline-link-macro"><block ref="7f02c84e9695cb8a35c7deacae1ac60a" category="inline-link-rx"></block></block>
  <block id="d296785b2301f7049b2372228fec21ee" category="paragraph"><block ref="d296785b2301f7049b2372228fec21ee" category="inline-link-macro-rx"></block></block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">Proben von AsciiDoc-Kodierung und -Ausgabe</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">In diesem Dokument sind einige Beispiele für Asciidoc-Quelle und die daraus resultierende Ausgabe enthalten.</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">Steuerkursstufen</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[Blaue Unterstreichung]*Quelle AsciiDoc:*</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[Blue underline]*Generated HTML:*</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">Überschrift Ebene 1 (Titel des Abschnitts)</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">Überschrift Ebene 2 (Titel)</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">Steuerkursebene 3 (Abschnittstitel)</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">Steuerkursebene 4 (Abschnittstitel)</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">Steuerkursebene 5 (Abschnittstitel)</block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">Pro Dokument sollte nur ein Dokumenttitel (Ebene 0) vorhanden sein, und Abschnittstitel können nicht übersprungen werden (die Untertitelung des Abschnitts muss die nächste Überschrift im Abschnitt sein). Aus diesem Grund wird die Probe nicht in der Ausgabe angezeigt, um Build-Fehler während der Verarbeitung zu vermeiden.</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">Listen</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">Nicht geordnete Liste:</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">Dies ist eine nicht geordnete Liste</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">Diese Liste ist immer noch nicht geordnet</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">Dies ist ein Unterelement in einer nicht geordneten Liste</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">Bestellliste:</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">Dies ist eine bestellte Liste</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">Diese Liste ist immer noch bestellt</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">Dies ist ein Unterelement in einer geordneten Liste</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">Bilder</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">Sie können Bilder im Repository oder überall im Internet verlinken. Für Bilder innerhalb des Projektarchivs werden sie im Medienordner abgelegt, daher müssen Sie sicherstellen, dass das ":imagedir: ./media/" entsprechend eingestellt ist.</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">Image innerhalb des Repository</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">Bild außerhalb des Repository</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">Links</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">Ähnlich wie Bilder können Links Dokumente im Repository oder überall im Web referenzieren. Für interne Referenzen ist es wichtig, sicherzustellen, dass der Pfad zur Linkquelle in der Anweisung „Link:“ angegeben wird.</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">Änderungsprotokoll mit NetApp Lösungen (intern)</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">Änderungsprotokoll mit NetApp Lösungen (extern)</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">Zusammenfaltbarer Inhalt (auch bekannt als Zwei)</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">Titel</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">Text, der ausgeblendet werden soll, geht hier.</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">Klicken Sie auf „Titel“, um die erweiterten Inhalte anzuzeigen</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">Erstellen einer Tabelle</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">Spalte A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">Spalte B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">Spalte C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">Text in Spalte A</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">Text in Spalte B</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">Text in Spalte C</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">Hier ein weiteres Beispiel: Eine Zeile umfasst die gesamte Tabelle und andere Zeilen enthalten Daten, die sich über mehrere Spalten erstrecken:</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">Kopfzeile Spalte 1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">Kopfzeile Spalte 2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">Kopfzeilenspalte 3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">Kopfzeilenspalte 4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">Dies ist eine wirklich lange Reihe, die sich über alle 4 Spalten der Tabelle erstreckt. Es ist die einzige Zelle in dieser Zeile und hinterlässt keine leeren Zellen.</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">Dies ist eine lange Reihe, die sich über 3 der Spalten in der Tabelle erstreckt und eine leere Zelle hinterlässt.</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">Diese Zeile umfasst 2 Spalten und hinterlässt 2 Zellen leer.</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">Das</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">Zeile</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">Ist</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">Normal</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">AsciiDoc-Dokumentation</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">Es gibt viele Optionen, die Sie angeben können, um das Layout einer Tabelle zu ändern. Weitere Informationen finden Sie entweder im Repository (HTML-Version), das Sie erreichen möchten, oder unter VScode, um die Quelle anzuzeigen oder den zu besuchen <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">Tabbed Blocks</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">Erste Registerkarte</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">Inhalt der ersten Registerkarte finden Sie hier</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">Zweite Registerkarte</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">Inhalt der zweiten Registerkarte finden Sie hier</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">Klicken Sie auf „Second Tab“, um den Inhalt dieses Abschnitts zu sehen.</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">Rechtliche Hinweise ermöglichen den Zugriff auf Copyright-Erklärungen, Marken, Patente und mehr.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Rechtliche Hinweise</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Urheberrecht</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marken</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, das NETAPP Logo und die auf der NetApp Markenseite aufgeführten Marken sind Marken von NetApp Inc. Andere Firmen- und Produktnamen können Marken der jeweiligen Eigentümer sein.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Patente</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Eine aktuelle Liste der NetApp Patente finden Sie unter:</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Datenschutzrichtlinie</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Open Source</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">In den Benachrichtigungsdateien finden Sie Informationen zu Urheberrechten und Lizenzen von Drittanbietern, die in der NetApp Software verwendet werden.</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">Die Automatisierung von NetApp Lösungen ermöglicht Kunden die Automatisierung von Implementierung, Konfiguration und Ausführung vieler gängiger Infrastruktur- und Applikationsaufgaben.</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">Erste Schritte mit der Automatisierung von NetApp Lösungen</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">Automatisierung von NetApp Lösungen bietet Einfachheit und Zuverlässigkeit für viele der Routineaufgaben, die NetApp Lösungen verwenden.</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">Bevor Sie eine Lösung automatisieren, muss die Umgebung entsprechend der Durchführung der Automatisierung konfiguriert werden. Es gibt Optionen, die Automatisierung von der Befehlszeile aus oder über ein Werkzeug wie AWX oder Tower auszuführen.</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">Die folgenden Abschnitte beschreiben die Schritte zur Konfiguration der Umgebung für jede der angegebenen Umgebungen.</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="example-title">Ansible Control Node für CLI-Implementierungen auf RHEL/CentOS einrichten</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Anforderungen für den Ansible-Kontroll-Node:</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">Eine RHEL/CentOS Maschine mit den folgenden Paketen installiert:</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible (Version größer als 2.10.0)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">Git</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">Wenn Sie eine neue RHEL/CentOS Maschine ohne die oben genannten Anforderungen installiert haben, führen Sie die folgenden Schritte aus, um diese Maschine als Ansible-Steuerungsknoten einzurichten:</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">Ansible-Repository für RHEL-8/RHEL-7 aktivieren</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">Für RHEL-8 (führen Sie den folgenden Befehl als root aus)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">Für RHEL-7 (führen Sie den folgenden Befehl als root aus)</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">Erstellen Sie eine .sh-Datei</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">Fügen Sie den nachstehenden Inhalt in die Datei ein</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">Machen Sie die Datei ausführbar</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">Das Skript ausführen (als root)</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="example-title">Richten Sie den Ansible-Steuerungsknoten für CLI-Bereitstellungen auf Ubuntu / Debian ein</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">Eine Ubuntu/Debian-Maschine mit den folgenden Paketen installiert:</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">Wenn Sie einen neuen Ubuntu/Debian-Rechner ohne die oben genannten Anforderungen installiert haben, führen Sie die folgenden Schritte aus, um diesen Rechner als den Ansible-Steuerungsknoten einzurichten:</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="example-title">Ansible Tower oder AWX für Tower-/AWX-Implementierungen einrichten</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">In diesem Abschnitt werden die Schritte beschrieben, die zur Konfiguration der Parameter im AWX/Ansible Tower erforderlich sind, um die Umgebung für den Einsatz automatisierter NetApp Lösungen vorzubereiten.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">Konfigurieren Sie den Bestand.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Navigieren Sie zu Ressourcen → Inventar → Hinzufügen und klicken Sie auf Inventar hinzufügen.</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">Geben Sie den Namen und die Organisationsdetails an, und klicken Sie auf „Speichern“.</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">Klicken Sie auf der Bestandsseite auf die Ressourcen, die Sie gerade erstellt haben.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">Wenn es Bestandsvariablen gibt, fügen Sie diese in das Feld Variablen ein.</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">Wechseln Sie zum Untermenü Gruppen, und klicken Sie auf Hinzufügen.</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">Geben Sie den Namen der Gruppe ein, kopieren Sie die Gruppenvariablen (falls erforderlich), und klicken Sie auf Speichern.</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">Klicken Sie auf die erstellte Gruppe, gehen Sie zum Untermenü Hosts und klicken Sie auf Neuen Host hinzufügen.</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">Geben Sie den Hostnamen und die IP-Adresse des Hosts an, fügen Sie die Host-Variablen ein (falls erforderlich), und klicken Sie auf Speichern.</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">Erstellen von Anmeldungstypen. Bei Lösungen, die ONTAP, Element, VMware oder andere HTTPS-basierte Transportverbindungen umfassen, müssen Sie den Anmeldeinformationstyp entsprechend den Benutzereingaben und den Kennwörtern konfigurieren.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Navigieren Sie zu Administration → Credential Types, und klicken Sie auf Add.</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">Geben Sie den Namen und eine Beschreibung an.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">Fügen Sie den folgenden Inhalt in die Eingabekonfiguration ein:</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">Fügen Sie folgenden Inhalt in die Konfiguration des Injektors ein:</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">Anmeldedaten konfigurieren.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Navigieren Sie zu Resources → Credentials, und klicken Sie auf Add.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">Geben Sie den Namen und die Organisationsdetails ein.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">Wählen Sie den korrekten Anmeldeinformationstyp aus. Wenn Sie die Standard-SSH-Anmeldung verwenden möchten, wählen Sie den Typ Machine aus, oder wählen Sie alternativ den von Ihnen erstellten benutzerdefinierten Anmeldeinformationstyp aus.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">Geben Sie die anderen entsprechenden Details ein, und klicken Sie auf Speichern.</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">Konfigurieren des Projekts.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Navigieren Sie zu Ressourcen → Projekte, und klicken Sie auf Hinzufügen.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">Wählen Sie Git für den Credential-Typ der Versionskontrolle aus.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">Fügen Sie die Quell-Kontroll-URL (oder git Clone URL) ein, die der spezifischen Lösung entspricht.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">Wenn die Git-URL Zugriffsgesteuert ist, erstellen und hängen Sie die entsprechenden Anmeldeinformationen in der Quellenkontrolle Credential an.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">Klicken Sie auf Speichern .</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">Konfigurieren Sie die Jobvorlage.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Navigieren Sie zu Ressourcen → Vorlagen → Hinzufügen, und klicken Sie auf Job Template hinzufügen.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">Geben Sie den Namen und die Beschreibung ein.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">Wählen Sie den Jobtyp aus. Führen Sie die Konfiguration des Systems auf Basis eines Playbooks durch, und prüfen Sie, ob das Playbook trocken läuft, ohne das System tatsächlich zu konfigurieren.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Wählen Sie den entsprechenden Bestand, das Projekt und die Zugangsdaten für das Playbook aus.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">Wählen Sie das Playbook aus, das Sie als Teil der Job-Vorlage ausführen möchten.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">Normalerweise werden die Variablen während der Laufzeit eingefügt. Um die Eingabeaufforderung zum Befüllen der Variablen während der Laufzeit zu erhalten, müssen Sie die Checkbox-Eingabeaufforderung für Starten entsprechend dem Feld Variable aktivieren.</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">Geben Sie ggf. weitere Details ein, und klicken Sie auf „Speichern“.</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">Starten Sie die Jobvorlage.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">Navigieren Sie zu Ressourcen → Vorlagen.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">Klicken Sie auf die gewünschte Vorlage und dann auf Starten.</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">Geben Sie ggf. beim Start alle Variablen ein, und klicken Sie dann erneut auf Starten.</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">Diese Seite beschreibt die automatisierte Methode zur Implementierung von NetApp Volumes auf Cloud-Providern (AWS, Azure, GCP) mithilfe von Terraform.</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Automatisierung von Cloud Volumes über Terraform</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">Diese Lösung dokumentiert die automatisierten Implementierungen von Cloud Volumes auf AWS (CVO Single Node, CVO HA und FSX ONTAP) und Azure (CVO Single Node, CVO HA und ANF) mithilfe von Terraform-Modulen. Der Code kann unter gefunden werden<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">Voraussetzungen</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;= 0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cloud Manager Konto</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">Cloud-Provider-Konto – AWS, Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">Host-Maschine (alle von Terraform unterstützten Betriebssysteme)</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">Provider-Dokumentation</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">Die Dokumentation des Terraform-Provider für Cloud Manager ist verfügbar unter: <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">Steuern der Provider-Version</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">Beachten Sie, dass Sie auch die Provider-Version steuern können. Dies wird über einen required_Provider-Block in der Terraform-Konfiguration gesteuert.</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">Die Syntax lautet wie folgt:</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">Erfahren Sie mehr über die Versionskontrolle des Anbieters.</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">Ausführung Spezifischer Module</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="example-title">AWS</block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">CVO Single Node-Implementierung</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Implementierung/Konfiguration von NetApp CVO (Cloud Volumes ONTAP) auf AWS (Amazon Web Services) mit einem einzelnen Node.</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Terraform-Dokumentation:<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">So führen Sie die Vorlage aus:</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">Klonen des Repository</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">Navigieren Sie zum gewünschten Ordner</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">Konfigurieren Sie die AWS Zugangsdaten über die CLI.</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS Access Key ID [Keine]: Zugriffschlüssel</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS Secret Access Key [None]: Secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">Standard Region Name [None]: US-West-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">Standardausgabeformat [Keine]: json</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="138255b51837a8bb57dce615f0b58218" prefix=" " category="inline-code"></block></block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">Sie können den Konnektor bereitstellen, indem Sie die Variable „aws_Connector_Deploy_bool“ auf true/false setzen.</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Initialisieren Sie das Terraform-Repository, um alle Voraussetzungen zu installieren und die Implementierung vorzubereiten.</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">Überprüfen Sie die Terraform-Dateien mit dem Terraform-Validierungsbefehl.</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">Führen Sie einen Probelauf der Konfiguration durch, um eine Vorschau aller Änderungen zu erhalten, die von der Bereitstellung erwartet werden.</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">Führen Sie die Implementierung aus</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">Zum Löschen der Bereitstellung</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph"><block ref="edf21d7ecb364e8210ddd3dfaeca6fbf" prefix="" category="inline-code"></block></block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">Terraform-Variablen für die NetApp AWS-Connector-Instanz für die CVO-Implementierung</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">*Name*</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">*Typ*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Beschreibung*</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">*Aws_Connector_devail_bool*</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">Bool</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">(Erforderlich) Prüfen Sie die Installation des Connectors.</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">*Aws_Connector_Name*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">Zeichenfolge</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">(Erforderlich) der Name des Cloud Manager Connectors.</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">*Aws_Connector_Region*</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">(Erforderlich) die Region, in der der Cloud Manager Connector erstellt wird.</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">*Aws_Connector_key_Name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">(Erforderlich) der Name des Schlüsselpaares, das für die Connector-Instanz verwendet werden soll.</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">*Aws_Connector_company*</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">(Erforderlich) der Name der Firma des Benutzers.</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">*Aws_Connector_instance_type*</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">(Erforderlich) der Instanztyp (z. B. t3.xlarge). Mindestens 4 CPU und 16 GB Arbeitsspeicher sind erforderlich.</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">*Aws_Connector_subnet_id*</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">(Erforderlich) die ID des Subnetzes für die Instanz.</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">*Aws_Connector_Security_Group_id*</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">(Erforderlich) die ID der Sicherheitsgruppe für die Instanz können mehrere Sicherheitsgruppen getrennt durch ',' bereitgestellt werden.</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">*Aws_Connector_iam_Instance_Profile_Name*</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">(Erforderlich) der Name des Instanzprofils für den Konnektor.</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">*Aws_Connector_Account_id*</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">(Optional) die NetApp Account-ID, mit der der Connector verknüpft wird. Falls nicht angegeben, verwendet Cloud Manager das erste Konto. Wenn kein Konto vorhanden ist, erstellt Cloud Manager ein neues Konto. Die Account-ID finden Sie auf der Registerkarte „Account“ in Cloud Manager unter<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">*Aws_Connector_public_ip_bool*</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">(Optional) gibt an, ob der Instanz eine öffentliche IP-Adresse zugeordnet werden soll. Wenn nicht angegeben, erfolgt die Zuordnung basierend auf der Konfiguration des Subnetzes.</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph"><block ref="2642a0976dba96af7529d6e1d27bff5f" prefix="" category="inline-code"></block></block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">Terraform-Variablen für eine einzelne NetApp CVO-Instanz.</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">*cvo_Name*</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">(Erforderlich) der Name der Cloud Volumes ONTAP-Arbeitsumgebung.</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">*cvo_Region*</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">(Erforderlich) die Region, in der das Arbeitsumfeld geschaffen wird.</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">*cvo_subnet_id*</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">(Erforderlich) die Subnetz-id, in der die Arbeitsumgebung erstellt wird.</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">*cvo_vpc_id*</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">(Optional) die VPC-ID, in der die Arbeitsumgebung erstellt wird. Wenn dieses Argument nicht angegeben wird, wird die VPC anhand der angegebenen Subnetz-ID berechnet.</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">*cvo_svm_password*</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">(Erforderlich) das Admin-Passwort für Cloud Volumes ONTAP.</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">*cvo_writing_Speed_State*</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">(Optional) die Schreibgeschwindigkeitseinstellung für Cloud Volumes ONTAP: ['NORMAL','HIGH']. Die Standardeinstellung ist „NORMAL“.</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">CVO HA-Implementierung</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Implementierung/Konfiguration von NetApp CVO (Cloud Volumes ONTAP) als Hochverfügbarkeitspaar auf AWS (Amazon Web Services).</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="d8fbe289f1062e79a6ecf2cb41d4650c" prefix=" " category="inline-code"></block>.</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph"><block ref="c6f18f9568d343bc6accef19de501a79" prefix="" category="inline-code"></block></block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">Terraform-Variablen für NetApp CVO Instanzen in HA-Paar.</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">*cvo_is_ha*</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">(Optional) Geben Sie an, ob die Arbeitsumgebung ein HA-Paar ist oder nicht [true, false]. Die Standardeinstellung lautet false.</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">*cvo_node1_subnet_id*</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">(Erforderlich) die Subnetz-id, an der der erste Knoten erstellt wird.</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">*cvo_node2_subnet_id*</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">(Erforderlich) die Subnetz-id, an der der zweite Knoten erstellt wird.</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">*cvo_Failover_Mode*</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">(Optional) für HA, der Failover-Modus für das HA-Paar: ['PrivateIP', 'FloatingIP']. 'PrivateIP' ist für eine einzige Verfügbarkeitszone und 'FloatingIP' für mehrere Verfügbarkeitszonen.</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">*cvo_Mediator_Subnetz_id*</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">(Optional) für HA, die Subnetz-ID des Mediators.</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">*cvo_Mediator_Key_Pair_Name*</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">(Optional) für HA, den Namen des Schlüsselpaars für die Instanz des Mediators.</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">*cvo_Cluster_Floating_ip*</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">(Optional) für HA FloatingIP, die fließende IP-Adresse für das Cluster-Management.</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">*cvo_Data_Floating_ip*</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">(Optional) für HA FloatingIP, die Daten-FloatingIP-Adresse.</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">*cvo_Data_Floating_ip2*</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">*cvo_svm_Floating_ip*</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">(Optional) für HA FloatingIP, die fließende IP-Adresse für das SVM-Management.</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">*cvo_Route_table_ids*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">Liste</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">(Optional) für HA-FloatingIP, die Liste der Routing-Tabellen-IDs, die mit den fließenden IPs aktualisiert wird.</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">FSX-Implementierung</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Bereitstellung/Konfiguration von NetApp ONTAP FSX auf AWS (Amazon Web Services).</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">Standardausgabeformat [Keine]:</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="15f7e426a035ec7faf6715523364f143" prefix=" " category="inline-code"></block></block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">Terraform-Variablen für die NetApp AWS Connector-Instanz.</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph"><block ref="8fa643108c81bb359c39d110fa732b76" prefix="" category="inline-code"></block></block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">Terraform-Variablen für die NetApp ONTAP FSX-Instanz.</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">*fsx_Name*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">*fsx_Region*</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">*fsx_primary_subnet_id*</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">(Erforderlich) die primäre Subnetz-id, in der die Arbeitsumgebung erstellt wird.</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">*fsx_Secondary_Subnet_id*</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">(Erforderlich) die sekundäre Subnetz-id, in der die Arbeitsumgebung erstellt wird.</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">*fsx_Account_id*</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">(Erforderlich) die NetApp Account-ID, der die FSX-Instanz zugeordnet wird. Falls nicht angegeben, verwendet Cloud Manager das erste Konto. Wenn kein Konto vorhanden ist, erstellt Cloud Manager ein neues Konto. Die Account-ID finden Sie auf der Registerkarte „Account“ in Cloud Manager unter<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">*fsx_Workspace_id*</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">(Erforderlich) die ID des Workspace von Cloud Manager der Arbeitsumgebung.</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">*fsx_admin_password*</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">*fsx_Throughput_Capacity*</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">(Optional) Kapazität des Durchsatzes.</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">*fsx_Storage_Capacity_size*</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">(Optional) EBS Volume-Größe für das erste Daten-Aggregat. Bei GB kann das Gerät Folgendes haben: [100 oder 500]. Für TB kann die Einheit sein: [1,2,4,8,16]. Die Standardeinstellung lautet „1“.</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">*fsx_Storage_Capacity_size_unit*</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">(Optional) ['GB' oder 'TB']. Der Standardwert ist „TB“.</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">*fsx_cloudManager_aws_requency_Name*</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">(Erforderlich) der Name des AWS Credentials-Kontonamens.</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="example-title">Azure</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Bereitstellung/Konfiguration eines ANF (Azure NetApp Files)-Volumes auf Azure.</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Terraform-Dokumentation:<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Melden Sie sich bei Ihrer Azure CLI an (Azure CLI muss installiert sein).</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="8c39601b8ab8961ff411cd5068a67f11" prefix=" " category="inline-code"></block>.</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">Sie können wählen, das ANF-Volume mit einem vorhandenen vnet und Subnetz zu implementieren, indem Sie die Variable „vnet_creation_bool“ und „subnet_creation_bool“ auf false setzen und den Wert „subnet_id_for_anf_vol“ angeben. Sie können diese Werte auch auf true setzen und ein neues vnet und Subnetz erstellen. In diesem Fall wird die Subnetz-ID automatisch aus dem neu erstellten Subnetz übernommen.</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">Terraform-Variablen für ein einzelnes NetApp ANF Volume.</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">*Az_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">(Erforderlich) gibt den unterstützten Azure-Speicherort an, an dem die Ressource vorhanden ist. Wenn Sie diese Änderung ändern, wird eine neue Ressource erstellt.</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">*Az_PREFIX*</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">(Erforderlich) der Name der Ressourcengruppe, in der das NetApp Volume erstellt werden soll. Wenn Sie diese Änderung ändern, wird eine neue Ressource erstellt.</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">*Az_vnet_address_space*</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">(Erforderlich) der Adressraum, der von dem neu erstellten vnet für die Implementierung eines ANF Volume verwendet werden soll.</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">*Az_subnet_address_PREFIX*</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">(Erforderlich) das Subnetz-Adressenpräfix, das vom neu erstellten vnet für die ANF-Volume-Implementierung verwendet werden soll.</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">*Az_Volume_PATH*</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">(Erforderlich) ein eindeutiger Dateipfad für das Volume Wird beim Erstellen von Mount-Zielen verwendet. Wenn Sie diese Änderung ändern, wird eine neue Ressource erstellt.</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">*Az_Capacity_Pool_size*</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">Ganzzahl</block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">(Erforderliche) Kapazität-Pool-Größe in TB angegeben</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">*Az_vnet_creation_bool*</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">Boolesch</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Wenn Sie ein neues vnet erstellen möchten. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes vnet zu verwenden.</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">*Az_subnet_creation_bool*</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Um ein neues Subnetz zu erstellen. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes Subnetz zu verwenden.</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">*Az_subnet_id_for_anf_vol*</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">(Erforderlich) Erzählen Sie die Subnetz-id, falls Sie sich entscheiden, ein vorhandenes Subnetz durch Einstellung zu verwenden<block ref="1cceaecaa3b91a9f1e23ecb4681ce8af" prefix=" " category="inline-code"></block> Um wahr zu sein. Wenn auf false gesetzt, behalten Sie den Standardwert bei.</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">*Az_netapp_Pool_Service_Level*</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">(Erforderlich) die Ziel-Performance des Filesystems. Gültige Werte sind enthalten<block ref="8d5e7e72f12067991186cdf3cb7d5d9d" prefix=" " category="inline-code"></block> ,<block ref="eb6d8ae6f20283755b339c0dc273988b" prefix=" " category="inline-code"></block> , Oder<block ref="7057376a419b3334cc7b8b7a9f064abb" prefix=" " category="inline-code"></block>.</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">*Az_netapp_vol_Service_Level*</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">*Az_netapp_vol_Protocol*</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">(Optional) das als Liste ausgedrückte Ziel-Volume-Protokoll. Unterstützter Einzelwert ist enthalten<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, Oder<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Wenn das Argument nicht definiert ist, wird es standardmäßig auf gesetzt<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Durch diese Änderung wird eine neue Ressource erstellt und Daten gehen verloren.</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">*Az_netapp_vol_Security_Style*</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">(Optional) Volume Security Style, akzeptierte Werte sind<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> Oder<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Wenn dies nicht der Fall ist, wird das Single-Protokoll-Volume standardmäßig auf erstellt<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> Wenn das so ist<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block> Oder<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block> Volume, falls<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>, Wird es standardmäßig auf<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Sofern nicht angegeben, liegt sein Wert in einem Dual-Protokoll-Volume<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>.</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">*Az_netapp_vol_Storage_Quota*</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">(Erforderlich) das maximale Speicherkontingent, das für ein Dateisystem in Gigabyte zulässig ist.</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF Datensicherung</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zum Implementieren/Konfigurieren von ANF- (Azure NetApp Files) Volumes mit Datensicherung auf Azure.</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="7faa6da7e229d163db53602f424f1f82" prefix=" " category="inline-code"></block>.</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph"><block ref="7bc40f4d4f846e8c7177d752ac52b775" prefix="" category="inline-code"></block></block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">Terraform-Variablen für ein einzelnes ANF-Volume mit aktivierter Datensicherung.</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">*Az_alt_Location*</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">(Erforderlich) den Azure-Standort, an dem das sekundäre Volume erstellt wird</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">*Az_vnet_primary_address_space*</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">(Erforderlich) der Adressraum, der von dem neu erstellten vnet für die Implementierung des primären ANF-Volumes verwendet werden soll.</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">*Az_vnet_secondary_address_space*</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">(Erforderlich) der Adressraum, der von dem neu erstellten vnet für die Implementierung eines sekundären ANF-Volumes verwendet werden soll.</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">*Az_subnet_primary_address_PREFIX*</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">(Erforderlich) das Subnetz-Adressenpräfix, das vom neu erstellten vnet für die primäre ANF-Volume-Implementierung verwendet werden soll.</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">*Az_subnet_secondary_address_PREFIX*</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">(Erforderlich) das Subnetz-Adressenpräfix, das vom neu erstellten vnet für die Implementierung eines sekundären ANF-Volumes verwendet werden soll.</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">*Az_Volume_PATH_Primary*</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">(Erforderlich) ein eindeutiger Dateipfad für das primäre Volume Wird beim Erstellen von Mount-Zielen verwendet. Wenn Sie diese Änderung ändern, wird eine neue Ressource erstellt.</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">*Az_Volume_PATH_Secondary*</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">(Erforderlich) ein eindeutiger Dateipfad für das sekundäre Volume. Wird beim Erstellen von Mount-Zielen verwendet. Wenn Sie diese Änderung ändern, wird eine neue Ressource erstellt.</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">*Az_Capacity_Pool_size_primary*</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">*Az_Capacity_Pool_size_secondary*</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">*Az_vnet_primary_creation_bool*</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Wenn Sie ein neues vnet für das primäre Volume erstellen möchten. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes vnet zu verwenden.</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">*Az_vnet_secondary_creation_bool*</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Wenn Sie ein neues vnet für das sekundäre Volumen erstellen möchten. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes vnet zu verwenden.</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">*Az_subnet_primary_creation_bool*</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Um ein neues Subnetz für das primäre Volume zu erstellen. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes Subnetz zu verwenden.</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">*Az_subnet_secondary_creation_bool*</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">(Erforderlich) Dieses boolesche Einstellung auf setzen<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Um ein neues Subnetz für ein sekundäres Volume zu erstellen. Auf einstellen<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> Um ein vorhandenes Subnetz zu verwenden.</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">*Az_primary_subnet_id_for_anf_vol*</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">(Erforderlich) Erzählen Sie die Subnetz-id, falls Sie sich entscheiden, ein vorhandenes Subnetz durch Einstellung zu verwenden<block ref="4480e01b6ddc0f64d89a995dcbd413f6" prefix=" " category="inline-code"></block> Um wahr zu sein. Wenn auf false gesetzt, behalten Sie den Standardwert bei.</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">*Az_secondary_subnet_id_for_anf_vol*</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">(Erforderlich) Erzählen Sie die Subnetz-id, falls Sie sich entscheiden, ein vorhandenes Subnetz durch Einstellung zu verwenden<block ref="963bc6d7f5ebc59003b8ef8f3f92a02c" prefix=" " category="inline-code"></block> Um wahr zu sein. Wenn auf false gesetzt, behalten Sie den Standardwert bei.</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">*Az_netapp_Pool_Service_Level_Primary*</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">*Az_netapp_Pool_Service_Level_Secondary*</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">*Az_netapp_vol_Service_Level_primary*</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">*Az_netapp_vol_Service_Level_Secondary*</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">*Az_netapp_vol_Protocol_primary*</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">*Az_netapp_vol_Protocol_secondary*</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">*Az_netapp_vol_Storage_quota_primary*</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">*Az_netapp_vol_Storage_quota_secondary*</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">*Az_dp_Replication_Frequency*</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">(Erforderlich) Replikationsfrequenz, unterstützte Werte sind<block ref="3602ffca95e52ce3f66ae1c6de108997" prefix=" " category="inline-code"></block>,<block ref="745fd0ea7f576f350a0eed4b8c48a8e2" prefix=" " category="inline-code"></block>,<block ref="bea79186fd7af2da67e59b4b15df5a26" prefix=" " category="inline-code"></block>, Werte beachten die Groß-/Kleinschreibung.</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF Dual-Protokoll</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Bereitstellung/Konfiguration eines ANF (Azure NetApp Files)-Volumes mit aktiviertem Dual-Protokoll für Azure.</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="b81cd75a858f9c9f13b2c366b4254eea" prefix=" " category="inline-code"></block>.</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">Terraform-Variablen für ein einzelnes ANF-Volume mit aktiviertem Dual-Protokoll.</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">*Az_netapp_vol_protocol1*</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">(Erforderlich) das als Liste ausgedrückte Ziel-Volume-Protokoll. Unterstützter Einzelwert ist enthalten<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, Oder<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Wenn das Argument nicht definiert ist, wird es standardmäßig auf gesetzt<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Durch diese Änderung wird eine neue Ressource erstellt und Daten gehen verloren.</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">*Az_netapp_vol_protocol2*</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">*Az_smb_Server_Benutzername*</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">(Erforderlich) Benutzername zum Erstellen von ActiveDirectory-Objekt.</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">*Az_smb_Server_password*</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">(Erforderlich) Benutzerpasswort zum Erstellen des ActiveDirectory-Objekts.</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">*Az_smb_Server_Name*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">(Erforderlich) Servername zum Erstellen von ActiveDirectory-Objekt.</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">*Az_smb_dns_Servers*</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">(Erforderlich) DNS-Server-IP zum Erstellen von ActiveDirectory-Objekten.</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">ANF Volume aus Snapshot</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Bereitstellung/Konfiguration von ANF (Azure NetApp Files) Volumes aus dem Snapshot auf Azure.</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="ef9d672e94eee49d10d74f858a44d14f" prefix=" " category="inline-code"></block>.</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Terraform-Variablen für einzelne ANF-Volumes unter Verwendung des Snapshots.</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">*Az_Snapshot_id*</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">(Erforderlich) Snapshot ID, die verwendet, welches neue ANF Volume erstellt wird.</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Bereitstellung/Konfiguration von Single Node CVO (Cloud Volumes ONTAP) auf Azure.</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">Aktualisieren Sie die Variablen in<block ref="094639eff38e0172690a0fb13cd97348" prefix=" " category="inline-code"></block>.</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">Terraform-Variablen für Single-Node-Cloud Volumes ONTAP (CVO)</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">*Refresh_Token*</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">(Erforderlich) das Aktualisierungsstoken des NetApp Cloud Manager Dies kann aus netapp Cloud Central generiert werden.</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">*Az_Connector_Name*</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">*Az_Connector_location*</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">(Erforderlich) der Speicherort, an dem der Cloud Manager Connector erstellt wird.</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">*Az_Connector_subscription_id*</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">(Erforderlich) die ID des Azure Abonnements</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">*Az_Connector_company*</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">*Az_Connector_Resource_Group*</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">(Erforderlich) die Ressourcengruppe in Azure, wo die Ressourcen erstellt werden.</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">*Az_Connector_subnet_id*</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">(Erforderlich) der Name des Subnetzes für die virtuelle Maschine.</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">*Az_Connector_vnet_id*</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">(Erforderlich) der Name des virtuellen Netzwerks.</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">*Az_Connector_Network_Security_Group_Name*</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">(Erforderlich) der Name der Sicherheitsgruppe für die Instanz.</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">*Az_Connector_Associate_Public_ip_Address*</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">(Erforderlich) gibt an, ob die öffentliche IP-Adresse der virtuellen Maschine zugeordnet werden soll.</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">*Az_Connector_Account_id*</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">(Erforderlich) die NetApp Konto-ID, mit der der Connector verknüpft wird. Falls nicht angegeben, verwendet Cloud Manager das erste Konto. Wenn kein Konto vorhanden ist, erstellt Cloud Manager ein neues Konto. Die Account-ID finden Sie auf der Registerkarte „Account“ in Cloud Manager unter<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">*Az_Connector_admin_password*</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">(Erforderlich) das Kennwort für den Konnektor.</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">*Az_Connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">(Erforderlich) der Benutzername des Connectors.</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">*Az_cvo_Name*</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">*Az_cvo_location*</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">(Erforderlich) der Standort, an dem die Arbeitsumgebung erstellt wird.</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">*Az_cvo_Subnetz_id*</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">(Erforderlich) der Name des Subnetzes des Cloud Volumes ONTAP Systems.</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">*Az_cvo_vnet_id*</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">*Az_cvo_vnet_Resource_Group*</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">(Erforderlich) die dem virtuellen Netzwerk zugeordnete Ressourcengruppe in Azure.</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">*Az_cvo_Data_Encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">(Erforderlich) die Art der Verschlüsselung, die für die Arbeitsumgebung verwendet werden soll: <block ref="71335a48a021ae2aeb7df636ba3d2483" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="71335a48a021ae2aeb7df636ba3d2483" prefix=" " category="inline-code"></block>.</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">*Az_cvo_Storage_TYPE*</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">(Erforderlich) die Art des Storage für das erste Daten-Aggregat: <block ref="31034b38323b8bba82b33017ce6c13ff" prefix="[" category="inline-code"></block>,<block ref="410e42479a4a7cfdbe16e3e285d05598" prefix=" " category="inline-code"></block>,<block ref="2d641bc6cd6c1342dced281e583a3993" prefix=" " category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="31034b38323b8bba82b33017ce6c13ff" prefix=" " category="inline-code"></block></block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">*Az_cvo_svm_password*</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">*Az_cvo_Workspace_id*</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">(Erforderlich) die ID des Workspace von Cloud Manager, in dem Cloud Volumes ONTAP bereitgestellt werden soll. Falls nicht angegeben, verwendet Cloud Manager den ersten Workspace. Die ID finden Sie auf der Registerkarte Arbeitsbereich auf<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">*Az_cvo_Capacity_Tier*</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">(Erforderlich) ob Daten-Tiering für das erste Daten-Aggregat ermöglicht werden: <block ref="e8016c85ada38bdc5fac616ec1318047" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="1649cff06611a6025da3dd511a97fb43" prefix=" " category="inline-code"></block>.</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">*Az_cvo_writing_Speed_State*</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">(Erforderlich) die Schreibgeschwindigkeitseinstellung für Cloud Volumes ONTAP: <block ref="1e23852820b9154316c7c06e2b7ba051" prefix="[" category="inline-code"></block> ,<block ref="b89de3b4b81c4facfac906edf29aec8c" prefix=" " category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="1e23852820b9154316c7c06e2b7ba051" prefix=" " category="inline-code"></block>. Dieses Argument ist für HA-Paare nicht relevant.</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">*Az_cvo_ontap_Version*</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">(Erforderlich) die erforderliche ONTAP-Version. Wird ignoriert, wenn 'use_latest_Version' auf true gesetzt ist. Standardmäßig wird die aktuelle Version verwendet.</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">*Az_cvo_Instance_type*</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">(Erforderlich) die Art der zu verwendenden Instanz, die von dem von Ihnen gewählten Lizenztyp abhängt: Explore:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard:<block ref="3e47288b0119e2f8cd128c5c1feb02e1" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block><block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix="," category="inline-code"></block>], BYOL: Alle für PAYGO definierten Instanztypen. Weitere unterstützte Instanztypen finden Sie in den Versionshinweisen zu Cloud Volumes ONTAP. Die Standardeinstellung lautet<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">*Az_cvo_license_type*</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">(Erforderlich) die Art der zu verwendenden Lizenz. Für Single Node: <block ref="47dfc9e0cae8289642a649a3d4b6f07f" prefix="[" category="inline-code"></block>,<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>,<block ref="fda853806a97d134c59567534d1aabe6" prefix=" " category="inline-code"></block>,<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block>,<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block>]. Für HA: <block ref="18099bc4697504c468dd18adf279ac68" prefix="[" category="inline-code"></block>,<block ref="87d3f1b34e654923bcf9bc3b1b740e47" prefix=" " category="inline-code"></block>,<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block>,<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Nutzung<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> Oder<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Für HA bei der Auswahl bringen Sie Ihre eigenen Lizenztyp kapazitätsbasierte oder Freemium. Nutzung<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> Oder<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Für HA bei der Auswahl von „Bring your own License type Node-based“.</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">*Az_cvo_nss_Account*</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">(Erforderlich) Verwendung des NetApp Support Site Account-ID mit diesem Cloud Volumes ONTAP System Wenn der Lizenztyp BYOL ist und ein NSS-Konto nicht bereitgestellt wird, versucht Cloud Manager, das erste vorhandene NSS-Konto zu verwenden.</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">*Az_Tenant_id*</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">(Erforderlich) Mandanten-ID des in Azure registrierten Anwendungs-/Service-Principal.</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">*Az_Application_id*</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">(Erforderlich) Anwendungs-ID des in Azure registrierten Anwendungs-/Service-Principal.</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">*Az_Application_Key*</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">(Erforderlich) der Anwendungsschlüssel des in Azure registrierten Anwendungs-/Service-Principal.</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Implementierung/Konfiguration von CVO (Cloud Volumes ONTAP) HA (High Availability) auf Azure.</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">Aktualisieren Sie die Variablen in<block ref="3bdb269db9a3f1a5b57521aa62658bf3" prefix=" " category="inline-code"></block>.</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph"><block ref="a82b90469ebb90af122c361dbb754fd8" prefix="" category="inline-code"></block></block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">Terraform-Variablen für HA-Paar-Cloud Volumes ONTAP (CVO).</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">(Erforderlich) die Art der zu verwendenden Instanz, die von dem von Ihnen gewählten Lizenztyp abhängt: Explore:<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard:<block ref="a23549be3ebc980aebe6cb120ab4e310" prefix="[" category="inline-code"></block>], Premium:<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block>,<block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix=" " category="inline-code"></block>], BYOL: Alle für PAYGO definierten Instanztypen. Weitere unterstützte Instanztypen finden Sie in den Versionshinweisen zu Cloud Volumes ONTAP. Die Standardeinstellung lautet<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">(Erforderlich) die Art der zu verwendenden Lizenz. Für Single Node: <block ref="3abe68da9038e8e4aabc1b0e2a6530cc" prefix="[" category="inline-code"></block>]. Für HA: <block ref="86e0c1bceadb9c08ef223996a3e33d86" prefix="[" category="inline-code"></block>]. Die Standardeinstellung lautet<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Nutzung<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> Oder<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Für HA bei der Auswahl bringen Sie Ihre eigenen Lizenztyp kapazitätsbasierte oder Freemium. Nutzung<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> Oder<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Für HA bei der Auswahl von „Bring your own License type Node-based“.</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="example-title">GCP</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien für die Implementierung/Konfiguration von NetApp CVO (Cloud Volumes ONTAP) mit einem einzelnen Node auf GCP (Google Cloud Platform).</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">Speichern Sie die JSON-Datei für den GCP-Authentifizierungsschlüssel im Verzeichnis.</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="0635645653586768460c826b4f319a80" prefix=" " category="inline-code"></block></block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">Sie können den Konnektor bereitstellen, indem Sie die Variable „gcp_Connector_Deploy_Bool“ auf true/false setzen.</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">Terraform-Variablen für die NetApp GCP-Connector-Instanz für die CVO-Implementierung</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">*gcp_Connector_Deploy_Bool*</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">*gcp_Connector_Name*</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">*gcp_Connector_Project_id*</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">(Erforderlich) die GCP Project_id, in der der Connector erstellt wird.</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">*gcp_Connector_Zone*</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">(Erforderlich) die GCP-Zone, in der der Connector erstellt werden soll.</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">*gcp_Connector_company*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">*gcp_Connector_Service_Account_email*</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">(Erforderlich) die E-Mail des Service_Account für die Connector-Instanz. Dieses Servicekonto wird verwendet, um dem Connector das Erstellen von Cloud Volume ONTAP zu ermöglichen.</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">*gcp_Connector_Service_Account_PATH*</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">(Erforderlich) der lokale Pfad der Service_Account JSON-Datei für GCP-Autorisierungszwecke. Mit diesem Service-Konto wird der Connector in GCP erstellt.</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">*gcp_Connector_Account_id*</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">(Optional) die NetApp Account-ID, mit der der Connector verknüpft wird. Falls nicht angegeben, verwendet Cloud Manager das erste Konto. Wenn kein Konto vorhanden ist, erstellt Cloud Manager ein neues Konto. Die Account-ID finden Sie auf der Registerkarte „Account“ in Cloud Manager unter<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">Terraform-Variablen für einzelne NetApp CVO-Instanz auf GCP.</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">*gcp_cvo_Name*</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">*gcp_cvo_Projekt_id*</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">(Erforderlich) ID des GCP-Projekts.</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">*gcp_cvo_Zone*</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">(Erforderlich) die Zone der Region, in der die Arbeitsumgebung geschaffen wird.</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">*gcp_cvo_gcp_Service_Account*</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">(Erforderlich) E-Mail mit dem gcp_Service_Account, um das Tiering von kalten Daten in Google Cloud Storage zu ermöglichen</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">*gcp_cvo_svm_password*</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">*gcp_cvo_Workspace_id*</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">(Optional) die ID des Workspace von Cloud Manager, in dem Cloud Volumes ONTAP bereitgestellt werden soll. Falls nicht angegeben, verwendet Cloud Manager den ersten Workspace. Die ID finden Sie auf der Registerkarte Arbeitsbereich auf<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">*gcp_cvo_license_type*</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">(Optional) der zu verwendende Lizenztyp. Für Single Node: ['Capacity-paygo', 'gcp-COT-explore-paygo', 'gcp-COT-Standard-paygo', 'gcp-COT-Premium-paygo', 'gcp-COT-Premium-byol'], Für Hochverfügbarkeit: ['ha-Capacity-paygo', 'gcp-ha-COT-explore-paygo', 'gcp-ha-COT-Standard-paygo', 'gcp-ha-COT-Premium-paygo', 'gcp-ha-COT-Premium-byol']. Der Standardwert ist „Capacity-paygo“ für Single Node und „ha-Capacity-paygo“ für HA.</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">*gcp_cvo_Capacity_package_Name*</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">(Optional) der Name des Kapazitätspakets: ['Essential', 'Professional', 'Freemium']. Die Standardeinstellung ist „wichtig“.</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien zur Implementierung/Konfiguration von NetApp CVO (Cloud Volumes ONTAP) als Hochverfügbarkeitspaar auf GCP (Google Cloud Platform).</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="aca245204ab77411a71da01b8d6ec7cb" prefix=" " category="inline-code"></block>.</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">Terraform-Variablen für NetApp CVO Instanzen in HA-Paar auf GCP.</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">*gcp_cvo_is_ha*</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">*gcp_cvo_node1_Zone*</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">(Optional) Zone für Node 1.</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">*gcp_cvo_node2_Zone*</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">(Optional) Zone für Node 2.</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">*gcp_cvo_Mediator_Zone*</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">(Optional) Zone für Mediator.</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">*gcp_cvo_vpc_id*</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">(Optional) der Name der VPC.</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">*gcp_cvo_Subnetz_id*</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">(Optional) der Name des Subnetzes für Cloud Volumes ONTAP. Die Standardeinstellung lautet: 'Default'.</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">*gcp_cvo_vpc0_Node_and_Data_Connectivity*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">(Optional) VPC-Pfad für nic1, erforderlich für Node- und Datenkonnektivität. Bei Verwendung von gemeinsam genutztem VPC muss netwrok_project_id angegeben werden.</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">*gcp_cvo_vpc1_Cluster_Connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">(Optional) VPC-Pfad für nic2, erforderlich für Cluster-Konnektivität.</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">*gcp_cvo_vpc2_ha_Connectivity*</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">(Optional) VPC-Pfad für nic3, erforderlich für HA-Konnektivität.</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">*gcp_cvo_vpc3_Data_Replication*</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">(Optional) VPC-Pfad für nic4, erforderlich für Datenreplizierung.</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">*gcp_cvo_subnet0_Node_and_Data_Connectivity*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">(Optional) Subnetz-Pfad für nic1, erforderlich für Node- und Datenkonnektivität. Bei Verwendung von gemeinsam genutztem VPC muss netwrok_project_id angegeben werden.</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">*gcp_cvo_subnet1_Cluster_Connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">(Optional) Subnetz-Pfad für nic2, erforderlich für Cluster-Konnektivität.</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">*gcp_cvo_subnet2_ha_Connectivity*</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">(Optional) Subnetz-Pfad für nic3, erforderlich für HA-Konnektivität.</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">*gcp_cvo_subnet3_Data_Replication*</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">(Optional) Subnetz-Pfad für nic4, erforderlich für Datenreplizierung.</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">*gcp_cvo_gcp_Volume_size*</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">(Optional) die GCP-Volume-Größe für das erste Daten-Aggregat. Bei GB kann das Gerät Folgendes haben: [100 oder 500]. Für TB kann die Einheit: [1,2,4,8] sein. Der Standardwert ist '1' .</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">*gcp_cvo_gcp_Volume_size_unit*</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">CVS Volume</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">Dieser Abschnitt enthält verschiedene Terraform-Konfigurationsdateien für die Implementierung/Konfiguration von NetApp CVS (Cloud Volumes Services) Volume auf GCP (Google Cloud Platform).</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Terraform-Dokumentation:<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">Aktualisieren Sie die Variablenwerte in<block ref="eb1510c0f29be1d144dce2bfa2e8caab" prefix=" " category="inline-code"></block>.</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph"><block ref="944ce323a5a1ffb09543fd409911cc88" prefix="" category="inline-code"></block></block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">Terraform-Variablen für NetApp GCP CVS Volume.</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">*gcp_cvs_Name*</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">(Erforderlich): Der Name des NetApp CVS Volumes</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">*gcp_cvs_Projekt_id*</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">(Erforderlich) das GCP Projekt_id, in dem das CVS Volume erstellt wird.</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">*gcp_cvs_gcp_Service_Account_PATH*</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">(Erforderlich) der lokale Pfad der Service_Account JSON-Datei für GCP-Autorisierungszwecke. Dieses Servicekonto wird verwendet, um das CVS Volume in GCP zu erstellen.</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">*gcp_cvs_Region*</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">(Erforderlich) die GCP-Zone, in der das CVS Volume erstellt wird.</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">*gcp_cvs_Network*</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">(Erforderlich) das Netzwerk-VPC des Volumes.</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">*gcp_cvs_size*</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">(Erforderlich) die Größe des Volumes liegt zwischen 1024 und 102400 einschließlich (in gib).</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">*gcp_cvs_Volume_PATH*</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">(Optional) der Name des Volume-Pfads für das Volume.</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">*gcp_cvs_Protocol_types*</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">(Erforderlich) der Protocol_Typ des Volume. Verwenden Sie für NFS „NFSv3“ oder „NFSv4“ und für SMB „CIFS“ oder „MB“.</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">Mit der Automatisierung von NetApp Lösungen können Kunden die Implementierung, Konfiguration und Ausführung vieler gängiger Infrastrukturaufgaben und Applikationsaufgaben automatisieren.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">Automatisierung der NetApp Lösung</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">Automatisierung vereinfacht die Nutzung von NetApp Lösungen.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">Diese Seite bietet detaillierte Informationen zum Sammeln von erforderlichen Refresh-Tokens und Zugriffs-/Geheimschlüsseln für CVO- und Cloud Manager Connector-Implementierungen über NetApp Cloud Manager.</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">AWS Authentifizierungsanforderungen für CVO und Connector mit NetApp Cloud Manager</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">Zur Konfiguration der automatisierten Implementierungen von CVO und Connectors unter Verwendung von Ansible-Playbooks über AWX/Ansible Tower sind die folgenden Informationen erforderlich:</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">Zugriff/geheime Schlüssel von AWS abrufen</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Für die Implementierung von CVO und Connector in Cloud Manager benötigen wir AWS Access/Secret Key. Erwerben Sie die Schlüssel in der AWS-Konsole, indem Sie IAM--&gt;Users-&gt;your username-&gt;Security redentials-&gt;Create Access key starten.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">Kopieren Sie die Zugriffsschlüssel und halten Sie sie sicher, damit sie in der Konnektor- und CVO-Implementierung verwendet werden können.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">Wenn Sie Ihren Schlüssel verlieren, können Sie einen anderen Zugriffsschlüssel erstellen und den verlorenen löschen</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">Token Aktualisieren</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">Aktualisier Token von NetApp Cloud Central erwerben</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">Melden Sie sich über die Anmeldedaten unter bei Ihrem Cloud-Hauptkonto an<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">Erstellen Sie ein Update Token, und speichern Sie es für Bereitstellungen.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">Client-ID wird erfasst</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">Rufen Sie die API-Seite auf, um die Client-ID zu kopieren unter<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">Klicken Sie rechts oben auf „Lernen wie authentifizieren“.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">Kopieren Sie im daraufhin angezeigten Authentifizierungsfenster die Client-ID aus dem regulären Zugriff, wenn Sie für die Anmeldung einen Benutzernamen bzw. ein Kennwort benötigen. Föderierte Benutzer mit SSO sollten die Client-ID aus der Registerkarte „Token aktualisieren“ kopieren.</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">Client-ID</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">Schlüsselpaar aus AWS übernehmen</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">Suchen Sie in der AWS-Konsole nach „Key Pair“ und erstellen Sie ein Schlüsselpaar mit „Pem“. Denken Sie daran, den Namen Ihres Key_Pair zu verwenden, um den Konnektor bereitzustellen.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">Schlüsselpaar</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">Konto-ID wird erfasst</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Klicken Sie in Cloud Manager auf Account –&gt; Accounts managen und kopieren Sie dann die Konto-id zur Verwendung in Variablen für AWX.</block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">Bei der Bereitstellung von Lösungen, die für die geschäftlichen Herausforderungen von heute eingesetzt werden, bietet NetApp Lösungen mit folgenden Zielen:</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">Validierte Implementierungs- und Konfigurationsschritte</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">Leicht nutzbare Lösungen anbieten,</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">Bereitstellung einer Lösung mit vorhersehbaren Ergebnissen, einfache Wiederholung und Skalierbarkeit im gesamten Unternehmen des Kunden.</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">Um diese Ziele zu erreichen, ist es von entscheidender Bedeutung, dass die Implementierung und Konfiguration von Infrastruktur und/oder Applikationen, die über unsere Lösungen bereitgestellt werden, durch Automatisierung vereinfacht wird. NetApp hat es sich zum Ziel gesetzt, den Lösungsverbrauch durch Automatisierung zu vereinfachen.</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">NetApp Lösungen nutzen Open-Source-Automatisierungs-Tools wie Red hat Ansible, HashiCorp Terraform oder Microsoft PowerShell, und können so die Applikationsbereitstellung, Cloud-Bereitstellung, Konfigurationsmanagement und viele andere gängige IT-Aufgaben automatisieren. Die Lösungen von NetApp nutzen öffentlich verfügbare Automatisierungsartefakte und bieten die von NetApp erstellte Automatisierung, um die allgemeine Implementierung einer Lösung zu vereinfachen.</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">Sofern Automatisierungsfunktionen zur Verfügung stehen, führt das Begleitmaterial zu Lösungen den Benutzer mithilfe der spezifischen Automatisierungstools durch den Prozess der Automatisierung der Lösung oder der Lösungsschritte.</block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">Regionale Verfügbarkeit für zusätzliche NFS-Datastores auf AWS, Azure und GCP</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">Weitere Informationen zur Unterstützung der globalen Region für zusätzliche NFS-Datastores auf AWS, Azure und Google Cloud Platform (GCP).</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">Verfügbarkeit der AWS Region</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">Die Verfügbarkeit von zusätzlichen NFS-Datenspeichern auf AWS/VMC wird durch Amazon festgelegt. Zunächst müssen Sie feststellen, ob VMC und FSxN in einer bestimmten Region verfügbar sind. Als Nächstes müssen Sie feststellen, ob der FSxN zusätzliche NFS-Datastore in dieser Region unterstützt wird.</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">Überprüfen Sie die Verfügbarkeit von VMC <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>.</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">Der Amazon Preisleitfaden enthält Informationen dazu, wo FSxN (FSX ONTAP) verfügbar ist. Diese Informationen finden Sie hier <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">Der zusätzlich zu NFS Datastore für VMC verfügbare FSxN wird demnächst verfügbar sein.</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">Obwohl noch Informationen freigegeben werden, zeigt das folgende Diagramm die aktuelle Unterstützung für VMC, FSxN und FSxN als zusätzliche NFS-Datenspeicher.</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">Nord- Und Südamerika</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">*AWS Region*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">*VMC Verfügbarkeit*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">*FSX ONTAP Verfügbarkeit*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">*Verfügbarkeit von NFS-Datenspeichern*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">US East (Northern Virginia)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">US-Osten (Ohio)</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">USA West (Nordkalifornien)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">US West (Oregon)</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud (USA – Westen)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">Kanada (Zentral)</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">Südamerika (Sao Paulo)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">Zuletzt aktualisiert am: 2. Juni 2022.</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">EMEA</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">Europa (Irland)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">Europa (London)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">Europa (Frankfurt)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">Europa (Paris)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">Europa (Mailand)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">Europa (Stockholm)</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">Asien/Pazifik</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">Asien/Pazifik (Sydney)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">Asien/Pazifik (Tokio)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">Asien/Pazifik (Osaka)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">Asien/Pazifik (Singapur)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">Asien/Pazifik (Seoul)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">Asien/Pazifik (Mumbai)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">Asien/Pazifik (Jakarta)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">Asien/Pazifik (Hongkong)</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">Zuletzt aktualisiert am: 28. September 2022.</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Verfügbarkeit Der Azure Region</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">Die Verfügbarkeit von zusätzlichen NFS-Datenspeichern auf Azure/AVS wird von Microsoft definiert. Zunächst müssen Sie feststellen, ob sowohl AVS als auch ANF in einer bestimmten Region verfügbar sind. Als Nächstes müssen Sie ermitteln, ob der zusätzliche ANF NFS-Datastore in dieser Region unterstützt wird.</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">Überprüfen Sie die Verfügbarkeit von AVS und ANF <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>.</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">Prüfen Sie die Verfügbarkeit des zusätzlichen ANF NFS-Datenspeichers <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>.</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">Verfügbarkeit der GCP-Region</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">Wenn GCP in die öffentliche Verfügbarkeit eintritt, wird GCP verfügbar sein.</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">NetApp Hybrid-Multi-Cloud mit VMware Lösungen sind eine Reihe strategischer und technologischer Funktionen, die die Funktionen von NetApp Storage für die wichtigsten Public-Cloud-Hyperscaler aufzeigen.</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">NetApp Hybrid-Multi-Cloud mit VMware Lösungen</block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">NetApp Hybrid-Multi-Cloud-Lösungen für Azure/AVS</block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Zusätzliche NFS-Datastore-Option in Azure</block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">Die Unterstützung für NFS-Datastore wurde mit ESXi Version 3 in On-Premises-Implementierungen eingeführt, welche die Storage-Funktionen von vSphere erheblich erweitert.</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">VSphere unter NFS ist eine weit verbreitete Option für Virtualisierungsimplementierungen vor Ort, da sie eine hohe Performance und Stabilität bietet. Wenn Sie über einen erheblichen Network-Attached Storage (NAS) in einem On-Premises-Datacenter verfügen, sollten Sie die Implementierung einer Azure VMware Lösung in Azure mit Azure NetApp Dateispeichern in Erwägung ziehen, um Kapazitäts- und Performance-Probleme zu überwinden.</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99 % erzielt</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files basiert auf der führenden, hochverfügbaren Datenmanagement-Software NetApp ONTAP. Die Microsoft Azure Services sind in drei Kategorien unterteilt: Grundlagen, Mainstream und Specialized. Azure NetApp Files gehört zur Spezialienkategorie und wird durch Hardware unterstützt, die bereits in vielen Regionen implementiert ist. Dank der integrierten Hochverfügbarkeit (HA) schützt Azure NetApp Files Ihre Daten vor den meisten Ausfällen und bietet Ihnen ein branchenweit führendes SLA für<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> Verfügbarkeit:</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Vor der Einführung der Azure NetApp Files Datastore-Funktion war für Kunden, die Performance und Storage-intensive Workloads hosten möchten, der Scale-out-Betrieb eine Erweiterung von Computing und Storage erforderlich.</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">Beachten Sie folgende Punkte:</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">In einem SDDC Cluster sind keine unausgeglichenen Cluster-Konfigurationen empfohlen. Daher müssen zusätzliche Hosts hinzugefügt werden, was zu einer höheren TCO führt.</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">Es ist nur eine vSAN Umgebung möglich. Daher steht der gesamte Storage Traffic direkt mit Produktions-Workloads im Wettbewerb.</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">Es besteht keine Möglichkeit, mehrere Performance-Tiers bereitzustellen, um Applikationsanforderungen, Performance und Kosten anzupassen.</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">Es lässt sich leicht an die Grenzen der Storage-Kapazität für vSAN gelangen, das auf Cluster-Hosts aufgebaut ist.durch die Integration von Azure nativen Plattform-als-Service-Angeboten (PaaS) wie Azure NetApp Files als Datastore, Unternehmen haben die Möglichkeit, ihren Storage unabhängig voneinander zu skalieren. Sie können dem SDDC Cluster nur bei Bedarf Compute-Nodes hinzufügen. Dadurch lassen sich die oben genannten Herausforderungen bewältigen.</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">Mit Azure NetApp Files können Sie außerdem mehrere Datastores implementieren. Dies hilft Ihnen, ein On-Premises-Implementierungsmodell zu imitieren, indem Sie Virtual Machines im entsprechenden Datenspeicher platzieren und das erforderliche Service-Level zuweisen, um Workload-Performance-Anforderungen zu erfüllen. Dank der einzigartigen Unterstützung für mehrere Protokolle ist Gastspeicherung eine zusätzliche Option für Datenbank-Workloads wie SQL und Oracle. Zudem wird die zusätzliche NFS-Datastore-Funktion für die verbleibenden VMDKs genutzt. Darüber hinaus können Sie dank der nativen Snapshot-Funktion schnelle Backups und granulare Restores durchführen.</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">Wenden Sie sich an Azure und NetApp Solution Architects, um die Planung und Größe des Storage und die erforderliche Anzahl von Hosts zu bestimmen. NetApp empfiehlt, die Anforderungen an die Storage-Performance zu ermitteln, bevor das Datastore-Layout für Test-, POC- und Produktionsimplementierungen abgeschlossen wird.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">Detaillierte Architektur</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">In dieser Architektur wird auf höchster Ebene beschrieben, wie Hybrid-Cloud-Konnektivität und ApplikationsPortabilität über On-Premises-Umgebungen und Azure hinweg erreicht wird. Zudem wird die Nutzung von Azure NetApp Files als zusätzlicher NFS-Datenspeicher und als Gast-Storage-Option für Virtual Machines beschrieben, die auf der Azure VMware Lösung gehostet werden.</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="section-title">Dimensionierung</block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">Der wichtigste Aspekt bei Migration oder Disaster Recovery ist es, die richtige Größe für die Zielumgebung zu ermitteln. Es ist sehr wichtig zu wissen, wie viele Nodes erforderlich sind, um einen Lift-and-Shift-Ansatz von vor Ort zur Azure VMware Lösung zu bewältigen.</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">Verwenden Sie zur Dimensionierung historische Daten aus der lokalen Umgebung mit RVTools (bevorzugt) oder anderen Tools wie Live Optics oder Azure Migrate. RVTools ist ein ideales Tool für die Erfassung von vCPU, Vmem, vDisk und aller erforderlichen Informationen, einschließlich eingeschaltetem oder ausgeschaltetem VM, um die Zielumgebung zu charakterisieren.</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">Um RVTools auszuführen, führen Sie die folgenden Schritte aus:</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">Laden Sie RVTools herunter und installieren Sie sie.</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">Führen Sie RVTools aus, geben Sie die erforderlichen Informationen ein, um eine Verbindung zu Ihrem lokalen vCenter Server herzustellen, und drücken Sie die Taste Login.</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">Exportieren Sie den Bestand in eine Excel-Tabelle.</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">Bearbeiten Sie die Tabelle und entfernen Sie alle VMs, die keine idealen Kandidaten für die vInfo Registerkarte sind. Dieser Ansatz bietet eine klare Ausgabe zu den Storage-Anforderungen, die zur richtigen Größe des Azure VMware SDDC Clusters mit der erforderlichen Anzahl an Hosts verwendet werden können.</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">Gast-VMs, die mit im Gast-Storage genutzt werden, müssen separat berechnet werden. Azure NetApp Files kann jedoch problemlos die zusätzliche Storage-Kapazität abdecken, wodurch die Gesamtbetriebskosten gering bleiben.</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Implementieren und Konfigurieren der Azure VMware Lösung</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">Wie auch vor Ort ist die Planung einer Azure VMware Lösung entscheidend für eine erfolgreiche produktionsbereite Umgebung zur Erstellung von Virtual Machines und Migrationen.</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie AVS für die Verwendung in Kombination mit Azure NetApp Files als Datastore mit in-Guest Storage einrichten und verwalten können.</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">Der Einrichtungsprozess kann in drei Teile unterteilt werden:</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">Registrieren Sie den Ressourcenanbieter und erstellen Sie eine Private Cloud.</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">Stellen Sie eine Verbindung zu einem neuen oder vorhandenen virtuellen ExpressRoute Netzwerk-Gateway her.</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">Netzwerk-Konnektivität prüfen und auf die Private Cloud zugreifen Weitere Informationen finden Sie hier <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> Für einen Schritt-für-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt-Schritt</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Konfiguration von Azure NetApp Files mit Azure VMware Lösung</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">Die neue Integration von Azure NetApp Files ermöglicht die Erstellung von NFS-Datastores über die Ressourcenprovider APIs/CLI der Azure VMware Lösung mit Azure NetApp Files Volumes und das Mounten der Datastores in einem Private Cloud. Azure NetApp Datei-Volumes können nicht nur VM- und App-VMDKs enthalten, sondern auch von VMs gemountet werden, die in der Azure VMware SDDC-Umgebung erstellt wurden. Die Volumes können auf dem Linux-Client gemountet und auf einem Windows-Client zugeordnet werden, da Azure NetApp Files Server Message Block (SMB)- und Network File System (NFS)-Protokolle unterstützt.</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">Um eine optimale Performance zu erzielen, implementieren Sie die Azure NetApp Files in derselben Verfügbarkeitszone wie die Private Cloud. Die Colocation mit dem Express Route FastPath bietet die beste Performance bei minimaler Netzwerklatenz.</block>
  <block id="2a499560ec410b1e1caeb95f6021ac1e" category="admonition">Diese Funktion befindet sich derzeit in der öffentlichen Vorschau.</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Wenn Sie ein Azure NetApp Datei-Volume als VMware-Datenspeicher einer Private Cloud der Azure VMware Lösung anhängen möchten, müssen Sie die folgenden Voraussetzungen erfüllen.</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">Verwenden Sie die Anmeldung bei az und überprüfen Sie, ob das Abonnement für die CloudSanExperience-Funktion im Namespace von Microsoft.AVS registriert ist.</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">Wenn er nicht registriert ist, registrieren Sie ihn.</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">Die Registrierung kann etwa 15 Minuten dauern.</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">Führen Sie den folgenden Befehl aus, um den Registrierungsstatus zu überprüfen.</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">Wenn die Registrierung länger als 15 Minuten im Zwischenzustand bleibt, melden Sie sich aus und registrieren Sie die Flagge erneut.</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">Vergewissern Sie sich, dass das Abonnement bei der Funktion AnfDatastoreExperience im Namespace von Microsoft.AVS registriert ist.</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">Vergewissern Sie sich, dass die vmware-Erweiterung installiert ist.</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">Wenn die Erweiterung bereits installiert ist, überprüfen Sie, ob die Version 3.0 ist. Wenn eine ältere Version installiert ist, aktualisieren Sie die Erweiterung.</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">Wenn die Erweiterung nicht bereits installiert ist, installieren Sie sie.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="example-title">Azure NetApp Files Volumes erstellen und mounten</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Melden Sie sich im Azure-Portal an und greifen Sie auf Azure NetApp Files zu. Überprüfen Sie den Zugriff auf den Azure NetApp Files-Service und registrieren Sie den Azure NetApp Files Ressourcenanbieter mithilfe von<block ref="37ac6d6acd87f35d4712fb725270d9df" prefix=" " category="inline-code"></block><block ref="d6c188468a5654ff07f3d8da04d06877" prefix=" " category="inline-code"></block> Befehl. Erstellen Sie nach der Registrierung ein NetApp Konto. Weitere Informationen finden Sie hier<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> Für detaillierte Schritte.</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">Nach Erstellung eines NetApp Kontos werden Kapazitäten mit dem erforderlichen Service Level und der erforderlichen Größe eingerichtet. Ausführliche Informationen finden Sie hier<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>.</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="cell">Wichtige Hinweise</block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">NFSv3 wird für Datastores auf Azure NetApp Files unterstützt.</block>
  <block id="62dfd4c1cc43e59ef3c56bb615d3b182" category="list-text">Verwenden Sie die Premium- oder Ultra-Tier für optimale Leistung.</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Konfigurieren Sie ein delegiertes Subnetz für Azure NetApp Files, und geben Sie dieses Subnetz bei der Erstellung von Volumes an. Detaillierte Schritte zum Erstellen eines delegierten Subnetzes finden Sie hier<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>.</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">Fügen Sie ein NFS-Volume für den Datenspeicher hinzu. Verwenden Sie dazu den Volumes Blade unter dem Capacity Pools Blade.</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link">Überlegungen zur Performance von Azure NetApp Files</block>
  <block id="47e7f43ca3ba65dbd1b1edbe26db8cc4" category="paragraph">Informationen zur Azure NetApp Files Volume-Performance nach Größe oder Kontingent finden Sie unter<block ref="bcd13cd67f856c9e615d78327e957b9c" category="inline-link-rx"></block>.</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Fügen Sie einen Azure NetApp Files-Datastore in eine Private Cloud hinzu</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Um einen Azure NetApp Files-Datastore zu einer Private Cloud hinzuzufügen, gehen Sie wie folgt vor:</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">Nachdem die erforderlichen Funktionen registriert sind, schließen Sie einen NFS-Datenspeicher an das Private Cloud Cluster der Azure VMware Lösung an. Führen Sie dazu den entsprechenden Befehl aus.</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Erstellen eines Datastores mit einem vorhandenen ANF Volume im Private Cloud-Cluster der Azure VMware-Lösung</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">C:\Users\niyaz&gt;az vmware Datastore list --Resource-Group anfavsval2 --Cluster-1 --private-Cloud ANFDataClus [ { { Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001" } "diskPoolVolume": Null, "id": "/Abonnements/0efa2s resourfb-917c-4497-b56a-b3fjeadb8111/resourceGroups/anfavs2: "AVs/DSneceval2", "ivaceps/4497-Cluster", "Uve52a52s/fece52s/ivasCluster", "AVs/fece52s/ivasCluster", "AVs-UM/fya52s-UM/fy2", "UM/fy2","UM-UM-Ubara52a52s-Cluster", "Ups: "AVs-Ubara52s-Ups/ivacessy2","UM/ivacessy2","U } { "DiskPoolVolume": Null, "id": "/Subskriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/anfavsval2/Providers/Microsoft.AVS/privateClouds/ANFDataClus/Clusters/Cluster-1/Datastores 4497/ANFATU002", "Favande52C-Gruppen" Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002", "{/Ufande52s52sUfece51s", "rescet2", "rese52s52s", "resefandefande52s52s", "}-Ufype", "rese52s52s", "rescet2", "rese52s52s52s52s52s52s52e-}-Ufecians", "rescetype", "-Ufype", "rese52s52sU</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">Nachdem die erforderliche Konnektivität vorhanden ist, werden die Volumes als Datastore gemountet.</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">Größen- und Performance-Optimierung</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files unterstützt drei Service-Level: Standard (16 Mbit/s pro Terabyte), Premium (64 Mbit/s pro Terabyte) und Ultra (128 Mbit/s pro Terabyte). Die Bereitstellung der passenden Volume-Größe ist für eine optimale Performance des Datenbank-Workloads wichtig. Bei Azure NetApp Files werden die Volume-Performance und das Durchsatzlimit anhand der folgenden Faktoren ermittelt:</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">Der Service Level des Kapazitäts-Pools, zu dem das Volume gehört</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">Der dem Volume zugewiesene Kontingent</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">Die QoS-Art (Quality of Service) (automatisch oder manuell) des Kapazitäts-Pools</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Service-Level für Azure NetApp Files</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">Weitere Informationen finden Sie unter<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="9ce18fddaa7dc898334afc4ab63a163b" category="list-text">Verwenden Sie die Premium oder Ultra Tier für Datastore Volumes, um eine optimale Performance zu erzielen.</block>
  <block id="f681df268b9e05fa5155bbf1f38d672f" category="list-text">Verwenden Sie Standard- oder Premium Tier Volumes, um die Anforderungen an Dateifreigabe für Gast-VMs zu erfüllen.</block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">Überlegungen zur Performance</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">Es ist wichtig, dass bei NFS Version 3 nur eine aktive Leitung für die Verbindung zwischen dem ESXi Host und einem einzelnen Storage-Ziel existiert. Das heißt, obwohl es möglicherweise alternative Verbindungen für Failover gibt, sind die Bandbreite für einen einzelnen Datenspeicher und der zugrunde liegende Storage auf das beschränkt, was eine einzelne Verbindung bieten kann.</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Um mehr verfügbare Bandbreite bei Azure NetApp Files Volumes nutzen zu können, muss ein ESXi Host über mehrere Verbindungen zu den Storage-Zielen verfügen. Um dieses Problem zu beheben, können Sie mehrere Datastores konfigurieren, wobei jeder Datastore separate Verbindungen zwischen dem ESXi Host und dem Storage verwendet.</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">Für eine höhere Bandbreite erstellen Sie als Best Practice mehrere Datastores mit mehreren ANF Volumes, erstellen VMDKs und verteilen die logischen Volumes über VMDKs.</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">Die Azure VMware Lösung lässt standardmäßig acht NFS-Datenspeicher zu. Dies kann über eine Support-Anfrage weiter verbessert werden.</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">Nutzen Sie er FastPath zusammen mit Ultra SKU für eine höhere Bandbreite und niedrigere Latenz. Weitere Informationen</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Mit den „grundlegenden“ Netzwerkfunktionen in Azure NetApp Files wird die Konnektivität über die Azure VMware Lösung durch die Bandbreite der ExpressRoute Verbindung und des ExpressRoute Gateways gebunden.</block>
  <block id="0a8e9b67042320d1a2f3f6155fc3e096" category="list-text">Für Azure NetApp Files Volumes mit „Standard“-Netzwerkfunktionen (derzeit öffentlich Vorschau) wird ExpressRoute FastPath unterstützt. Bei Aktivierung sendet FastPath den Netzwerkdatenverkehr direkt an die Azure NetApp Files Volumes und umgehen das Gateway mit höherer Bandbreite und niedrigerer Latenz.</block>
  <block id="1b75d86136a5cde892b315650fd5ea43" category="section-title">Performance-Optimierung</block>
  <block id="213debd5ccd87a89487239a8460a0f0e" category="paragraph">Obwohl die empfohlene Anzahl an Virtual Machines pro NFS-Datenspeicher subjektiv ist, bestimmen viele Faktoren die optimale Anzahl von VMs, die auf den jeweiligen Datenspeicher platziert werden kann. Obwohl die meisten Administratoren nur die Kapazität berücksichtigen, ist die Menge der gleichzeitigen I/O-Vorgänge, die an die VMDKs gesendet werden, einer der wichtigsten Faktoren für die Gesamt-Performance. Der ESXi Host verfügt über viele Mechanismen, um die Fairness zwischen Virtual Machines zu gewährleisten, die im Wettbewerb um Datastore-Ressourcen stehen. Am einfachsten lässt sich die Performance jedoch durch Regulation der Anzahl der Virtual Machines auf den einzelnen Datenspeichern steuern. Wenn die I/O-Muster paralleler Virtual Machines zu viel Datenverkehr zum Datenspeicher senden, füllen sich die Festplatten-Warteschlangen aus und es wird eine höhere Latenz generiert.</block>
  <block id="f9fd5bbf2764cc5b16e9eeeb8b57ee91" category="section-title">Dimensionierung von Volumes und Datenspeicher</block>
  <block id="01ab7b17836cfa3916b003d7febafe43" category="paragraph">Wenn ein Volume auf Azure NetApp Files für Datenspeicher-Zwecke erstellt wird, empfiehlt es sich, ein Volume zu erstellen, das nicht größer als nötig ist. Obwohl die maximale Volume-Größe bis zu 100 TB beträgt, empfiehlt NetApp, mit einer kleinen Datenspeicherkapazität zu beginnen und diese nach Bedarf zu erhöhen. Mit Datastores mit richtiger Größenbemessung wird verhindert, dass versehentlich zu viele Virtual Machines auf dem Datenspeicher platziert werden, und es wird die Wahrscheinlichkeit von Ressourcenkonflikten verringert. Da Datenspeicher- und VMDK-Größen einfach erhöht werden können, wenn eine Virtual Machine zusätzliche Kapazität benötigt, müssen keine Datenspeicher mehr als erforderlich erstellt werden. Für eine optimale Performance empfiehlt es sich, die Anzahl der Datenspeicher zu erhöhen, statt ihre Größe zu erhöhen.</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">Zeigt auf, wie man sich merken sollte</block>
  <block id="28c7e0cc515aa1271633669cf0e579ad" category="list-text">Eine gute Größe für einen ANF NFS Datastore liegt von 4 TB bis 8 TB.</block>
  <block id="90f9dde25089c324af635a76b75a7509" category="list-text">Platzieren Sie 15-20 VMs auf einem einzelnen Datenspeicher. Je nach VM-Anforderungen kann diese auf 35-40 VMs erhöht werden.</block>
  <block id="3236c97f9f8c9cb7fcbc35b9ff162ab3" category="list-text">Berücksichtigen Sie für die beste Performance und das beste Management Gastsysteme wie NFS/SMB-Filesysteme, die von den Gastsystemen für Applikationen mit hohem I/O-Aufkommen wie Datenbanken verwaltet werden.</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">Vergrößern des Datenspeichers</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">Die Volume-Umgestaltung und die dynamischen Service Level-Änderungen sind für das SDDC vollständig transparent. In Azure NetApp Files bieten diese Funktionen kontinuierliche Performance-, Kapazitäts- und Kostenoptimierungen. Vergrößern Sie die Größe von NFS-Datenspeichern, indem Sie die Größe des Volumes aus dem Azure Portal oder mithilfe der CLI ändern. Greifen Sie anschließend auf vCenter zu, rufen Sie die Registerkarte „Datastore“ auf, klicken Sie mit der rechten Maustaste auf den entsprechenden Datenspeicher, und wählen Sie „Refresh Capacity Information“ (Kapazitätsinformationen aktualisieren) aus. Mit diesem Ansatz kann die Datenspeicherkapazität erhöht und die Performance des Datastores dynamisch und ohne Ausfallzeiten gesteigert werden. Dieser Prozess ist auch für Applikationen völlig transparent.</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">Dank der Volume-Umgestaltung und der dynamischen Service Level-Funktion können Sie die Kosten optimieren, indem Sie für Steady-State Workloads eindimensionieren und so eine Überprovisionierung vermeiden.</block>
  <block id="c38ea7c6c5e1aef9a1df0cebd81737d9" category="list-text">Während der öffentlichen Vorschau ist VAAI nicht aktiviert.</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">Workloads</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="example-title">Migration</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">Einer der häufigsten Anwendungsfälle ist die Migration. On-Premises-VMs mit VMware HCX oder vMotion verschieben Alternativ können Sie mit Riverwiese VMs zu Azure NetApp Files Datastores migrieren.</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="example-title">Datensicherung</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">Zu den größten Stärken der ANF-Datastores zählen das Backup von VMs und die schnelle Wiederherstellung. Mit Snapshot Kopien können Sie ohne Auswirkungen auf die Performance schnell Kopien Ihrer VMs oder Datastores erstellen und diese dann zur längerfristigen Datensicherung oder zu einer sekundären Region an Azure Storage senden. Dabei wird für Disaster Recovery-Zwecke eine regionsübergreifende Replizierung verwendet. Durch diesen Ansatz werden der Storage-Platzbedarf und die Netzwerkbandbreite minimiert, da nur geänderte Informationen gespeichert werden.</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">Verwenden Sie Azure NetApp Files Snapshot Kopien für die allgemeine Sicherheit und Applikations-Tools, um transaktionsorientierte Daten wie SQL Server oder Oracle Daten auf Gast-VMs zu sichern. Diese Snapshot-Kopien unterscheiden sich von VMware (Konsistenz) Snapshots und sind für längerfristigen Schutz geeignet.</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">Mit ANF-Datastores kann die Option „auf neues Volume wiederherstellen“ verwendet werden, um ein gesamtes Datastore Volume zu klonen. Das wiederhergestellte Volume kann als weiterer Datastore für Hosts innerhalb des AVS SDDC gemountet werden. Nachdem ein Datastore gemountet wurde, können die darin enthaltenen VMs registriert, neu konfiguriert und angepasst werden, als wären sie einzeln geklonte VMs.</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">Cloud Backup für Virtual Machines</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">Cloud Backup für Virtual Machines bietet eine vSphere Web-Client-GUI auf vCenter, um Virtual Machines der Azure VMware Lösung und Azure NetApp Files-Datastores über Backup-Richtlinien zu schützen. In diesen Richtlinien können ein Zeitplan, die Aufbewahrung und andere Funktionen definiert werden. Die Funktion Cloud Backup für Virtual Machines kann über den Befehl Ausführen implementiert werden.</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">Die Setup- und Sicherungsrichtlinien können installiert werden, indem folgende Schritte durchgeführt werden:</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">Installieren Sie Cloud Backup für Virtual Machine in der Private Cloud der Azure VMware Lösung mit dem Befehl Ausführen.</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">Fügen Sie Zugangsdaten für das Cloud-Abonnement (Client und Secret Value) hinzu und fügen Sie dann ein Cloud-Abonnementkonto hinzu (NetApp Konto und zugehörige Ressourcengruppe), das die Ressourcen enthält, die Sie schützen möchten.</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">Erstellen Sie mindestens einen Backup-Richtlinien, mit denen die Aufbewahrung, Häufigkeit und andere Einstellungen für Backups von Ressourcengruppen verwaltet werden.</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">Erstellen Sie einen Container, um mindestens einen Container hinzuzufügen, der mit Backup-Richtlinien geschützt werden muss.</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">Bei einem Ausfall werden die gesamte VM oder spezifische einzelne VMDKs an demselben Standort wiederhergestellt.</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Mit der Azure NetApp Files Snapshot Technologie werden Backups und Restores sehr schnell durchgeführt.</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Disaster Recovery mit Azure NetApp Files, JetStream DR und Azure VMware Lösung</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz der Workloads vor Standortausfällen und Datenbeschädigungen (z. B. Ransomware). Mithilfe des VMware VAIO Frameworks können VMware On-Premises-Workloads auf Azure Blob Storage und für die Recovery repliziert werden, was zu minimalen oder fast keinem Datenverlust und nahezu keinem RTO führt. Jetstream DR kann verwendet werden, um die Workloads, die von On-Premises-Systemen auf AVS repliziert wurden, nahtlos wiederherzustellen. Insbesondere können sie auf Azure NetApp Files übertragen werden. Sie ermöglicht eine kostengünstige Disaster Recovery, da minimale Ressourcen am DR-Standort und kostengünstiger Cloud Storage genutzt werden. Jetstream DR automatisiert die Recovery auf ANF-Datastores über Azure Blob Storage. Jetstream DR stellt unabhängige VMs oder Gruppen zugehöriger VMs in der Infrastruktur des Recovery-Standorts entsprechend der Netzwerkzuordnung wieder her und sorgt für zeitpunktgenaue Recovery zur Sicherung von Ransomware.</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">DR-Lösung mit ANF, JetStream und AVS</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>.</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">NetApp Guest Connected Storage Optionen für Azure</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure unterstützt NetApp Storage mit Anbindung an den Gast-Storage über den nativen Azure NetApp Files-Service (ANF) oder über Cloud Volumes ONTAP (CVO).</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp Dateien (ANF)</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files ermöglicht Datenmanagement und Storage der Enterprise-Klasse in Azure, damit Sie Ihre Workloads und Applikationen komfortabel managen. Migrieren Sie Ihre Workloads in die Cloud und führen Sie sie ohne Performance-Einbußen aus.</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files beseitigt Hindernisse, damit Sie alle dateibasierten Applikationen in die Cloud verschieben können. Zum ersten Mal müssen Sie Ihre Applikationen nicht umstrukturieren und Sie erhalten persistenten Storage für Ihre Applikationen ohne Komplexität.</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">Da der Service über das Microsoft Azure-Portal bereitgestellt wird, erhalten Benutzer einen vollständig gemanagten verwalteten Service als Teil ihres Microsoft Enterprise Agreements. Der von Microsoft gemanagte erstklassige Support nimmt Ihnen alle Sorgen. Durch diese einfache Lösung fügen Sie Multiprotokoll-Workloads mit Leichtigkeit schnell hinzu. Dateibasierte Applikationen für Windows und auch für Linux – sogar Applikationen für Legacy-Umgebungen – lassen sich erstellen und implementieren.</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="section-title">Azure NetApp Files (ANF) als Storage mit Gastverbunden</block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="example-title">Konfiguration von Azure NetApp Files mit Azure VMware Lösung (AVS)</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Azure NetApp Files Shares können von VMs gemountet werden, die in der SDDC Umgebung der Azure VMware Lösung erstellt wurden. Die Volumes können auch auf dem Linux-Client eingebunden und auf dem Windows-Client zugeordnet werden, da Azure NetApp Files SMB- und NFS-Protokolle unterstützt. Azure NetApp Files Volumes lassen sich in fünf einfachen Schritten einrichten.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files und Azure VMware müssen sich in derselben Azure Region befinden.</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Führen Sie folgende Schritte aus, um Azure NetApp Files Volumes zu erstellen und zu mounten:</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Melden Sie sich im Azure Portal an und greifen Sie auf Azure NetApp Files zu. Überprüfen Sie den Zugriff auf den Azure NetApp Files-Dienst und registrieren Sie den Azure NetApp Files-Ressourcenanbieter mit dem Befehl _az Provider Register --Namespace Microsoft.NetApp –wait_. Nach Abschluss der Registrierung erstellen Sie einen NetApp Account.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files-Freigaben</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">Ausführliche Schritte finden Sie unter <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. Auf dieser Seite finden Sie einen Schritt-für-Schritt-Prozess.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">Nach der Erstellung des NetApp Accounts werden die Kapazitäts-Pools mit dem erforderlichen Service Level und der erforderlichen Größe eingerichtet.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">Weitere Informationen finden Sie unter <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Delegieren eines Subnetzes an Azure NetApp Files</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Konfigurieren Sie das delegierte Subnetz für Azure NetApp Files, und geben Sie dieses Subnetz an, während Sie die Volumes erstellen. Detaillierte Schritte zum Erstellen eines delegierten Subnetzes finden Sie unter <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Fügen Sie ein SMB-Volume mithilfe des Volumes Blade unter dem Capacity Pools Blade hinzu. Stellen Sie sicher, dass der Active Directory-Konnektor konfiguriert ist, bevor Sie das SMB-Volume erstellen.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">Klicken Sie auf Überprüfen + Erstellen, um das SMB-Volume zu erstellen.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">Wenn es sich bei der Applikation um SQL Server handelt, aktivieren Sie die kontinuierliche Verfügbarkeit von SMB.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">Weitere Informationen zur Azure NetApp Files Volume-Performance nach Größe oder Kontingent finden Sie unter <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">Nach erfolgter Konnektivität kann das Volume gemountet und für Applikationsdaten verwendet werden.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">Dazu klicken Sie im Azure Portal auf das Volumes-Blade und wählen Sie dann das zu montierenden Volume aus und greifen Sie auf die Mount-Anweisungen zu. Kopieren Sie den Pfad und verwenden Sie die Option Map Network Drive, um das Volume auf der VM zu mounten, die auf der Azure VMware Solution SDDC ausgeführt wird.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Um NFS Volumes auf Linux VMs einzubinden, die auf dem Azure VMware Solution SDDC laufen, verwenden Sie denselben Prozess. Erfüllen Sie die Workload-Anforderungen mit Volume-Neustrukturierung oder dynamischen Service-Level-Funktionen.</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">Weitere Informationen finden Sie unter <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP (CVO)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP oder CVO ist die branchenführende Cloud-Datenmanagement-Lösung auf Basis der Storage-Software ONTAP von NetApp. Sie ist nativ auf Amazon Web Services (AWS), Microsoft Azure und Google Cloud Platform (GCP) verfügbar.</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">Es handelt sich um eine softwaredefinierte Version von ONTAP, die Cloud-nativen Storage nutzt, sodass Sie dieselbe Storage-Software in der Cloud und vor Ort nutzen können. Dadurch müssen SIE Ihre IT-Mitarbeiter nicht mehr in komplett neue Methoden zum Datenmanagement Schulen.</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">Mit CVO können Kunden Daten nahtlos vom Edge- zum Datacenter, zur Cloud und zurück verschieben und so Ihre Hybrid Cloud zusammen – all das wird über eine zentrale Managementkonsole, NetApp Cloud Manager, gemanagt.</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">CVO ist von Grund auf für beste Performance und erweiterte Datenmanagementfunktionen konzipiert, um auch die anspruchsvollsten Applikationen in der Cloud zu unterstützen</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="section-title">Cloud Volumes ONTAP (CVO) als Storage mit Gastzugriff</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="example-title">Implementieren Sie neue Cloud Volumes ONTAP in Azure</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Cloud Volumes ONTAP-Freigaben und LUNs können von VMs gemountet werden, die in der SDDC Umgebung der Azure VMware Lösung erstellt wurden. Die Volumes können auch auf dem Linux-Client und auf dem Windows-Client eingebunden werden, da Cloud Volumes ONTAP iSCSI-, SMB- und NFS-Protokolle unterstützt. Cloud Volumes ONTAP Volumes lassen sich in wenigen einfachen Schritten einrichten.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">Datenreplikation zwischen Systemen einrichten</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">Um Volumes aus einer On-Premises-Umgebung zu Disaster-Recovery- oder Migrationszwecken in die Cloud zu replizieren, sollten Sie entweder über ein Site-to-Site-VPN oder ExpressRoute eine Netzwerkverbindung zu Azure herstellen. Die Replizierung von Daten zwischen On-Premises-Systemen und Cloud Volumes ONTAP ist im Rahmen dieses Dokuments nicht enthalten. Informationen zur Replizierung von Daten zwischen On-Premises- und Cloud Volumes ONTAP-Systemen finden Sie unter <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP-Dimensionierungstool</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">Nutzung <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Und die präzise Größe der Cloud Volumes ONTAP-Instanzen. Monitoring der On-Premises-Performance als Eingaben im Cloud Volumes ONTAP Sizer.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">Bei NetApp Cloud Central anmelden – der Bildschirm Fabric View wird angezeigt. Wählen Sie die Registerkarte Cloud Volumes ONTAP aus und wechseln Sie zu Cloud Manager. Nach der Anmeldung wird der Bildschirm Arbeitsfläche angezeigt.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Klicken Sie auf der Cloud Manager-Startseite auf „Arbeitsumgebung hinzufügen“ und wählen Sie dann Microsoft Azure als Cloud und den Typ der Systemkonfiguration aus.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Beim Erstellen der ersten Cloud Volumes ONTAP-Arbeitsumgebung werden Sie von Cloud Manager aufgefordert, einen Connector bereitzustellen.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">Aktualisieren Sie nach der Erstellung des Connectors die Felder Details und Anmeldeinformationen.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">Geben Sie die Details zur zu erstellenden Umgebung an, einschließlich Name der Umgebung und Anmeldedaten des Administrators. Fügen Sie als optionaler Parameter Ressourcengruppen-Tags für die Azure-Umgebung hinzu. Klicken Sie nach dem Abschluss auf Weiter.</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">Wählen Sie die Add-on-Services für die Implementierung von Cloud Volumes ONTAP aus, einschließlich Cloud Data Sense, Cloud Backup und Cloud Insights. Wählen Sie die Dienste aus, und klicken Sie dann auf Weiter.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Konfigurieren Sie den Azure-Speicherort und die Konnektivität. Wählen Sie die Azure Region, Ressourcengruppe, vnet und Subnetz aus, die verwendet werden sollen.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">Wählen Sie die Lizenzoption: Pay-as-you-Go oder BYOL für die Nutzung vorhandener Lizenz. In diesem Beispiel wird die Pay-as-you-Go-Option verwendet.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">Wählen Sie zwischen mehreren vorkonfigurierten Paketen, die für die verschiedenen Workload-Typen verfügbar sind.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Akzeptieren Sie die beiden Vereinbarungen über die Aktivierung von Support und Zuweisung von Azure Ressourcen.zum Erstellen der Cloud Volumes ONTAP Instanz klicken Sie auf Go.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Nach der Bereitstellung von Cloud Volumes ONTAP wird es in den Arbeitsumgebungen auf der Seite Arbeitsfläche aufgelistet.</block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="example-title">Zusätzliche Konfigurationen für SMB Volumes</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">Stellen Sie nach der Arbeitsumgebung sicher, dass der CIFS-Server mit den entsprechenden DNS- und Active Directory-Konfigurationsparametern konfiguriert ist. Dieser Schritt ist erforderlich, bevor Sie das SMB-Volume erstellen können.</block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">Das Erstellen des SMB Volume ist einfach. Wählen Sie die CVO-Instanz aus, um das Volume zu erstellen, und klicken Sie auf die Option Volume erstellen. Wählen Sie die entsprechende Größe und Cloud Manager wählt das Aggregat aus, das Sie enthalten, oder verwenden Sie den erweiterten Zuweisungsmechanismus auf einem bestimmten Aggregat. Für diese Demo wird SMB als Protokoll ausgewählt.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">Nachdem das Volume bereitgestellt wurde, wird es unter dem Fensterbereich Volumes verfügbar sein. Da eine CIFS-Freigabe bereitgestellt wird, geben Sie Ihren Benutzern oder Gruppen Berechtigungen für die Dateien und Ordner und überprüfen Sie, ob diese Benutzer auf die Freigabe zugreifen und eine Datei erstellen können. Dieser Schritt ist nicht erforderlich, wenn das Volume aus einer lokalen Umgebung repliziert wird, da die Datei- und Ordnerberechtigungen im Rahmen der SnapMirror Replizierung beibehalten werden.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">Nachdem das Volume erstellt wurde, verwenden Sie den Mount-Befehl, um eine Verbindung mit dem Share von der VM herzustellen, die auf den Azure VMware SDDC-Lösungen ausgeführt wird.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">Kopieren Sie den folgenden Pfad und verwenden Sie die Option Netzwerklaufwerk zuordnen, um das Volume auf der VM zu mounten, die auf dem Azure VMware SDDC ausgeführt wird.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="example-title">Verbinden Sie die LUN mit einem Host</block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">Gehen Sie wie folgt vor, um die LUN mit einem Host zu verbinden:</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">Doppelklicken Sie auf der Seite Arbeitsfläche von Cloud Volumes ONTAP auf die Arbeitsumgebung, um Volumes zu erstellen und zu verwalten.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Klicken Sie auf Volume hinzufügen &gt; Neues Volume, und wählen Sie iSCSI aus, und klicken Sie auf Initiatorgruppe erstellen. Klicken Sie auf Weiter .</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">Wählen Sie nach der Bereitstellung des Volumes das Volume aus, und klicken Sie dann auf Ziel-IQN. Um den iSCSI-qualifizierten Namen (IQN) zu kopieren, klicken Sie auf Kopieren. Richten Sie eine iSCSI-Verbindung vom Host zur LUN ein.</block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Um dasselbe für den Host, der auf dem Azure VMware Solution SDDC liegt, zu erreichen:</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">RDP auf die VM gehostet auf Azure VMware Solution SDDC.</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">Öffnen Sie das Dialogfeld iSCSI-Initiator-Eigenschaften: Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI-Initiator.</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">Klicken Sie auf der Registerkarte Ermittlung auf Portal erkennen oder Portal hinzufügen, und geben Sie dann die IP-Adresse des iSCSI-Zielports ein.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">Wählen Sie auf der Registerkarte Ziele das erkannte Ziel aus und klicken Sie dann auf Anmelden oder Verbinden.</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">Wählen Sie Multipath aktivieren, und wählen Sie dann automatisch Diese Verbindung wiederherstellen, wenn der Computer startet oder diese Verbindung zur Liste der bevorzugten Ziele hinzufügen. Klicken Sie Auf Erweitert.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">*Hinweis:* der Windows-Host muss eine iSCSI-Verbindung zu jedem Knoten im Cluster haben. Das native DSM wählt die besten Pfade aus.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">LUNs auf Storage Virtual Machine (SVM) werden dem Windows Host als Festplatten angezeigt. Neue hinzugefügte Festplatten werden vom Host nicht automatisch erkannt. Lösen Sie einen manuellen Rescan aus, um die Festplatten zu ermitteln, indem Sie die folgenden Schritte ausführen:</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Öffnen Sie das Dienstprogramm Windows Computer Management: Start &gt; Verwaltung &gt; Computerverwaltung.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">Erweitern Sie den Knoten Speicher in der Navigationsstruktur.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">Klicken Sie Auf Datenträgerverwaltung.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">Klicken Sie Auf Aktion &gt; Datenträger Erneut Scannen.</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Wenn der Windows-Host zum ersten Mal auf eine neue LUN zugreift, hat sie keine Partition oder kein Dateisystem. Initialisieren Sie die LUN; und optional formatieren Sie die LUN mit einem Dateisystem, indem Sie die folgenden Schritte durchführen:</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Starten Sie Windows Disk Management.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">Klicken Sie mit der rechten Maustaste auf die LUN, und wählen Sie dann den erforderlichen Festplatten- oder Partitionstyp aus.</block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">Befolgen Sie die Anweisungen im Assistenten. In diesem Beispiel ist Laufwerk E: Angehängt</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Implementieren und Konfigurieren der Virtualisierungsumgebung auf Azure</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">Wie bei On-Premises-Systemen ist die Planung von Azure VMware Lösungen für eine erfolgreiche produktionsbereite Umgebung für das Erstellen von VMs und die Migration von großer Bedeutung.</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie Azure VMware Lösung einrichten und managen und in Kombination mit den verfügbaren Optionen für die Verbindung von NetApp Storage verwenden.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">Der Einrichtungsvorgang kann in die folgenden Schritte unterteilt werden:</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="example-title">Registrieren Sie den Ressourcenanbieter und erstellen Sie eine Private Cloud</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Für die Nutzung der Azure VMware Lösung müssen Sie zunächst den Ressourcenanbieter im angegebenen Abonnement registrieren:</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Melden Sie sich im Azure Portal an.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Wählen Sie im Menü Azure-Portal die Option Alle Services aus.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">Geben Sie im Dialogfeld „Alle Services“ das Abonnement ein, und wählen Sie anschließend Abonnements aus.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">Wählen Sie das Abonnement aus der Abonnementliste aus, um es anzuzeigen.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">Wählen Sie Ressourcenanbieter aus, und geben Sie Microsoft.AVS in die Suche ein.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">Wenn der Ressourcenanbieter nicht registriert ist, wählen Sie Registrieren.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">Nachdem der Ressourcenanbieter registriert ist, erstellen Sie über das Azure-Portal eine Private Cloud für eine Azure VMware-Lösung.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">Wählen Sie Neue Ressource erstellen.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">Geben Sie im Textfeld „Search the Marketplace“ die Azure VMware Lösung ein und wählen Sie sie aus den Ergebnissen aus.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Wählen Sie auf der Seite Azure VMware Lösung die Option Erstellen.</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">Geben Sie auf der Registerkarte Grundlagen die Werte in die Felder ein, und wählen Sie Überprüfen + Erstellen.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">Hinweise:</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">Für einen schnellen Start müssen Sie die erforderlichen Informationen während der Planungsphase erfassen.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">Wählen Sie eine vorhandene Ressourcengruppe aus oder erstellen Sie eine neue Ressourcengruppe für die private Cloud. Eine Ressourcengruppe ist ein logischer Container, in dem die Azure Ressourcen implementiert und gemanagt werden.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">Stellen Sie sicher, dass die CIDR-Adresse einzigartig ist und nicht mit anderen virtuellen Azure Netzwerken oder On-Premises-Netzwerken überlappt. Das CIDR stellt das private Cloud-Managementnetzwerk dar und wird für Cluster-Managementservices wie vCenter Server und NSX-T Manager verwendet. NetApp empfiehlt die Verwendung eines Adressspeichers unter /22. In diesem Beispiel wird 10.21.0.0/22 verwendet.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">Die Bereitstellung dauert ungefähr 4 bis 5 Stunden. Nach Abschluss des Prozesses muss überprüft werden, ob die Implementierung erfolgreich war. Greifen Sie über das Azure-Portal auf die Private Cloud zu. Nach Abschluss der Bereitstellung wird ein Status von erfolgreich angezeigt.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Eine Private Cloud für eine Azure VMware Lösung erfordert ein virtuelles Azure Netzwerk. Da die Azure VMware Lösung vCenter vor Ort nicht unterstützt, sind für die Integration in eine vorhandene lokale Umgebung zusätzliche Schritte erforderlich. Zudem ist die Einrichtung einer ExpressRoute-Verbindung und eines virtuellen Netzwerk-Gateways erforderlich. Während Sie warten, bis die Cluster-Bereitstellung abgeschlossen ist, erstellen Sie ein neues virtuelles Netzwerk oder verwenden Sie ein vorhandenes für die Verbindung mit Azure VMware Lösung.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="example-title">Stellen Sie eine Verbindung zu einem neuen oder vorhandenen virtuellen ExpressRoute Netzwerk-Gateway her</block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">Um ein neues Azure Virtual Network (vnet) zu erstellen, wählen Sie die Registerkarte Azure vnet Connect aus. Alternativ können Sie aus dem Azure-Portal eine manuell erstellen mit dem Assistenten zum Erstellen von virtuellen Netzwerken:</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Gehen Sie zur Azure VMware Solution Private Cloud und greifen Sie unter Manage auf Konnektivität zu.</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Wählen Sie Azure vnet Connect aus.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">Um ein neues vnet zu erstellen, wählen Sie die Option Neue erstellen.</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">Mit dieser Funktion kann ein vnet mit der Azure VMware-Lösung Private Cloud verbunden werden. Vnet ermöglicht die Kommunikation zwischen Workloads in diesem virtuellen Netzwerk, indem die erforderlichen Komponenten automatisch erstellt werden (z. B. Sprungbox, Shared Services wie Azure NetApp Files und Cloud Volume ONTAP) in der in Azure VMware Lösung erstellten Private Cloud über ExpressRoute.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">*Hinweis:* der vnet-Adressraum sollte sich nicht mit der privaten Cloud CIDR überschneiden.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">Geben Sie die Informationen für die neue vnet ein, oder aktualisieren Sie sie, und wählen Sie OK.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">Das vnet mit dem angegebenen Adressbereich und Gateway Subnetz wird in der designierten Abonnement- und Ressourcengruppe erstellt.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Konfigurieren Sie das Networking für Ihre VMware Private Cloud in Azure</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">Wenn Sie ein vnet manuell erstellen, erstellen Sie ein virtuelles Netzwerk-Gateway mit der entsprechenden SKU und ExpressRoute als Gateway-Typ. Nach Abschluss der Implementierung verbinden Sie die ExpressRoute Verbindung mit dem virtuellen Netzwerk-Gateway mit der Private Cloud der Azure VMware Lösung über den Autorisierungsschlüssel. Weitere Informationen finden Sie unter <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="example-title">Netzwerkverbindung und Zugriff auf Azure VMware Solution Private Cloud validieren</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Mit der Azure VMware Lösung können Sie eine Private Cloud nicht über VMware vCenter vor Ort managen. Stattdessen ist zum Herstellen der Verbindung mit der vCenter Instanz der Azure VMware Lösung ein Sprunglink auf den Host erforderlich. Erstellen Sie einen Sprunghost in der angegebenen Ressourcengruppe und melden Sie sich bei Azure VMware Solution vCenter an. Dieser Jump-Host sollte eine Windows VM in demselben virtuellen Netzwerk sein, das für die Konnektivität erstellt wurde und sowohl vCenter als auch den NSX Manager nutzen sollte.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">Nachdem die virtuelle Maschine bereitgestellt wurde, verwenden Sie die Option Verbinden, um auf RDP zuzugreifen.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">Melden Sie sich von dieser neu erstellten Jump-Host-virtuellen Maschine mit dem Cloud-Admin-Benutzer in vCenter an. Rufen Sie zum Zugreifen auf die Anmeldedaten im Azure-Portal auf und navigieren Sie zu „Identity“ (Identitäts-Management (über die Option „Manage“ in der Private Cloud). Die URLs und Benutzeranmeldeinformationen für die private Cloud vCenter und NSX-T Manager können hier kopiert werden.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Öffnen Sie in der virtuellen Windows-Maschine einen Browser, und navigieren Sie zur vCenter Web-Client-URL <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> Und verwenden Sie den Admin-Benutzernamen als *cloudadmin@vsphere.local* und fügen Sie das kopierte Passwort ein. Auf ähnliche Weise kann auch NSX-T-Manager über die Web-Client-URL zugegriffen werden <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> Und verwenden Sie den Admin-Benutzernamen und fügen Sie das kopierte Passwort ein, um neue Segmente zu erstellen oder die vorhandenen Tier-Gateways zu ändern.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Die Web-Client-URLs sind für jede bereitgestellte SDDC unterschiedlich.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">Erstellen Sie Peer-on-Premises-Umgebungen mit der Azure VMware Lösung</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">Die Azure VMware Lösung SDDC ist jetzt implementiert und konfiguriert. Nutzung von ExpressRoute Global REACH zur Verbindung der lokalen Umgebung mit der Private Cloud der Azure VMware Lösung Weitere Informationen finden Sie unter <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">Disaster Recovery mit ANF und JetStream</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz der Workloads vor Standortausfällen und Datenbeschädigungen (z. B. Ransomware). Mithilfe des VMware VAIO Frameworks können VMware On-Premises-Workloads auf Azure Blob Storage und für die Recovery repliziert werden, was zu minimalen oder fast keinem Datenverlust und nahezu keinem RTO führt.</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">Jetstream DR kann verwendet werden, um die Workloads, die von On-Premises-Systemen auf AVS repliziert wurden, nahtlos wiederherzustellen. Insbesondere können sie auf Azure NetApp Files übertragen werden. Sie ermöglicht eine kostengünstige Disaster Recovery, da minimale Ressourcen am DR-Standort und kostengünstiger Cloud Storage genutzt werden. Jetstream DR automatisiert die Recovery auf ANF-Datastores über Azure Blob Storage. Jetstream DR stellt unabhängige VMs oder Gruppen zugehöriger VMs in der Infrastruktur des Recovery-Standorts entsprechend der Netzwerkzuordnung wieder her und sorgt für zeitpunktgenaue Recovery zur Sicherung von Ransomware.</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">Dieses Dokument vermittelt ein Verständnis der JetStream DR-Prinzipien des Betriebs und seiner Hauptkomponenten.</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">Übersicht über die Lösungsimplementierung</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">Installation der JetStream DR-Software im lokalen Datacenter</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">Laden Sie das JetStream DR-Software-Bundle aus Azure Marketplace (ZIP) herunter, und implementieren Sie das JetStream DR MSA (OVA) im dafür vorgesehenen Cluster.</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">Konfigurieren Sie das Cluster mit dem I/O-Filterpaket (JetStream VIB installieren).</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">Bereitstellen von Azure Blob (Azure Storage-Konto) in derselben Region wie das DR-AVS-Cluster</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">Implementierung von DRVA-Appliances und Zuweisung von Protokoll-Volumes (VMDK aus vorhandenem Datastore oder gemeinsam genutztem iSCSI-Storage)</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">Erstellen Sie geschützte Domänen (Gruppen zugehöriger VMs) und weisen Sie DRVAs und Azure Blob Storage/ANF zu.</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">Schutz starten.</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">Installieren Sie die JetStream DR-Software in der Private Cloud der Azure VMware Lösung.</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">Verwenden Sie den Befehl Ausführen, um JetStream DR zu installieren und zu konfigurieren.</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">Fügen Sie denselben Azure Blob-Container hinzu und entdecken Sie Domänen mithilfe der Option „Scan Domains“.</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">Bereitstellung der erforderlichen DRVA-Appliances</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">Verwenden von verfügbaren vSAN oder ANF-Datastores für Replizierungsprotokolle erstellen</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">Importieren Sie geschützte Domänen und konfigurieren Sie RocVA (Recovery VA), um einen ANF-Datenspeicher für VM-Platzierungen zu verwenden.</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">Wählen Sie die entsprechende Failover-Option aus, und beginnen Sie mit der kontinuierlichen Wiederherstellung nach RTO-Domänen von nahezu null oder VMs.</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">Bei einem Notfall wird ein Failover zu Azure NetApp Files-Datastores am zugewiesenen AVS-DR-Standort ausgelöst.</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">Rufen Sie den geschützten Standort nach der Wiederherstellung des geschützten Standorts auf.bevor Sie beginnen, stellen Sie sicher, dass die Voraussetzungen wie in diesem angegeben erfüllt sind<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> Führen Sie außerdem das von JetStream Software zur Verfügung gestellte Bandwidth Testing Tool (BWT) aus, um die potenzielle Performance des Azure Blob Storage und dessen Replikationsbandbreite in Verbindung mit der JetStream DR-Software zu bewerten. Nachdem die Voraussetzungen, einschließlich Konnektivität, vorhanden sind, richten Sie JetStream DR für AVS von der ein und abonnieren Sie sie<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>. Nachdem das Software Bundle heruntergeladen wurde, fahren Sie mit dem oben beschriebenen Installationsvorgang fort.</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">Verwenden Sie beim Planen und Starten des Schutzes für eine große Anzahl von VMs (z. B. 100+) das Capacity Planning Tool (CPT) aus dem JetStream DR Automation Toolkit. Geben Sie eine Liste der VMs an, die zusammen mit ihren RTO- und Recovery-Gruppeneinstellungen geschützt werden sollen, und führen Sie dann das CPT aus.</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT führt die folgenden Funktionen aus:</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">Die Kombination von VMs in Sicherungsdomänen entsprechend ihrer RTO-Vorgaben.</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">Die optimale Anzahl von DRVAs und deren Ressourcen festlegen.</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">Schätzen der erforderlichen Replikationsbandbreite</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">Ermittlung der Merkmale von Replikationsprotokollvolumes (Kapazität, Bandbreite usw.)</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">Schätzung der erforderlichen Objekt-Storage-Kapazität und mehr</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">Die Anzahl und der Inhalt der Domänen hängen von den verschiedenen VM-Merkmalen ab, wie beispielsweise durchschnittlichen IOPS, Gesamtkapazität, Priorität (die Failover-Reihenfolge definiert), RTO und anderen.</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">Installation der JetStream DR im lokalen Datacenter</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Die Jetstream DR-Software besteht aus drei Hauptkomponenten: Jetstream DR Management Server Virtual Appliance (MSA), DR Virtual Appliance (DRVA) und Host-Komponenten (I/O-Filterpakete). MSA wird verwendet, um Hostkomponenten auf dem Computing-Cluster zu installieren und zu konfigurieren und anschließend JetStream DR-Software zu verwalten. Die folgende Liste enthält eine ausführliche Beschreibung des Installationsprozesses:</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">Installation von JetStream DR für On-Premises</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">Voraussetzungen prüfen.</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">Führen Sie das Capacity Planning Tool für Ressourcen- und Konfigurationsempfehlungen aus (optional, jedoch für Proof-of-Concept-Tests empfohlen).</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">Implementieren Sie JetStream DR MSA auf einem vSphere-Host im zugewiesenen Cluster.</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">Starten Sie das MSA-Produkt mit dem DNS-Namen in einem Browser.</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">Registrieren Sie den vCenter-Server mit dem MSA.um die Installation durchzuführen, führen Sie die folgenden detaillierten Schritte aus:</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">Nachdem JetStream DR MSA implementiert und der vCenter Server registriert wurde, greifen Sie über den vSphere Web Client auf das JetStream DR Plug-in zu. Dazu können Sie im Datacenter &gt; Configure &gt; JetStream DR navigieren.</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">Wählen Sie über die JetStream DR-Schnittstelle den entsprechenden Cluster aus.</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">Konfigurieren Sie das Cluster mit dem I/O-Filterpaket.</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">Fügen Sie Azure Blob Storage am Recovery-Standort hinzu.</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">Stellen Sie eine DR Virtual Appliance (DRVA) über die Registerkarte Appliances bereit.</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">DRVAs können automatisch durch CPT erstellt werden. Für POC-Tests wird jedoch empfohlen, den DR-Zyklus manuell zu konfigurieren und auszuführen (Schutz starten &gt; Failover &gt; Failback).</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">JetStream DRVA ist eine virtuelle Appliance, die wichtige Funktionen bei der Datenreplizierung unterstützt. Ein geschützter Cluster muss mindestens eine DRVA enthalten, und normalerweise ist pro Host ein DRVA konfiguriert. Jeder DRVA kann mehrere geschützte Domänen verwalten.</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">In diesem Beispiel wurden vier DRVA's für 80 virtuelle Maschinen erstellt.</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">Erstellen Sie Protokoll-Volumes für jedes DRVA unter Verwendung von VMDK aus den verfügbaren Datastores oder unabhängigen, gemeinsam genutzten iSCSI-Speicherpools.</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">Erstellen Sie auf der Registerkarte geschützte Domänen die erforderliche Anzahl geschützter Domänen mithilfe von Informationen über die Azure Blob Storage-Site, die DRVA-Instanz und das Replikationsprotokoll. Eine geschützte Domäne definiert eine bestimmte VM oder einen Satz von VMs innerhalb des Clusters, die gemeinsam geschützt werden, und weist eine Prioritätsreihenfolge für Failover-/Failback-Vorgänge zu.</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">Wählen Sie VMs aus, die Sie sichern möchten, und starten Sie den VM-Schutz der geschützten Domäne. Dies beginnt mit der Datenreplizierung zum zugewiesenen Blob-Store.</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">Vergewissern Sie sich, dass derselbe Sicherungsmodus für alle VMs in einer geschützten Domäne verwendet wird.</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">Write Back(VMDK)-Modus kann eine höhere Performance bieten.</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">Vergewissern Sie sich, dass die Protokoll-Volumes für die Replizierung auf hochperformanten Storage platziert sind.</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">Failover Run Books können so konfiguriert werden, dass sie die VMs (namens Recovery Group) gruppieren, die Boot-Reihenfolge festlegen und die CPU-/Speichereinstellungen sowie die IP-Konfigurationen ändern.</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">Installieren Sie JetStream DR für AVS mit dem Befehl Run in einer Private Cloud der Azure VMware Lösung</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">Eine Best Practice für einen Recovery-Standort (AVS) ist die Erstellung eines Pilotlichtclusters mit drei Knoten im Voraus. Dadurch kann die Infrastruktur am Recovery-Standort vorkonfiguriert werden, einschließlich der folgenden Elemente:</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">Netzwerkzielsegmente, Firewalls, Services wie DHCP und DNS usw.</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">Installation von JetStream DR für AVS</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">Konfiguration von ANF Volumes als Datastores und mehrJetStream DR unterstützt RTO-Modus von nahezu null für geschäftskritische Domänen. In diesen Domänen sollte der Ziel-Storage vorinstalliert sein. ANF ist in diesem Fall ein empfohlener Speichertyp.</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">Die Netzwerkkonfiguration einschließlich der Segmenterstellung sollte auf dem AVS-Cluster entsprechend den Anforderungen vor Ort konfiguriert werden.</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">Je nach SLA- und RTO-Anforderungen kann für einen kontinuierlichen Failover oder einen normalen (Standard-) Failover-Modus verwendet werden. Für eine RTO von nahezu null sollte am Recovery-Standort eine kontinuierliche Rehydrierung gestartet werden.</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">So installieren Sie JetStream DR für AVS in einer Private Cloud</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">So installieren Sie JetStream DR für AVS auf einer privaten Cloud der Azure VMware-Lösung:</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">Wählen Sie im Azure-Portal die Azure VMware-Lösung aus, wählen Sie die Private Cloud aus und wählen Sie Ausführen Command &gt; Packages &gt; JSDR.Configuration.</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">Der CloudAdmin-Standardbenutzer in Azure VMware verfügt nicht über ausreichende Berechtigungen, um JetStream DR für AVS zu installieren. Die Azure VMware Lösung ermöglicht eine vereinfachte und automatisierte Installation von JetStream DR durch Aufrufen des Befehls Azure VMware Solution Run für JetStream DR.</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">Der folgende Screenshot zeigt die Installation mithilfe einer DHCP-basierten IP-Adresse.</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">Nachdem die JetStream DR für AVS-Installation abgeschlossen ist, aktualisieren Sie den Browser. Um auf die JetStream DR-UI zuzugreifen, wechseln Sie zum SDDC Datacenter &gt; Configure &gt; JetStream DR.</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">Fügen Sie über die JetStream DR-Schnittstelle das Azure Blob Storage-Konto hinzu, das zum Schutz des lokalen Clusters als Storage-Standort verwendet wurde, und führen Sie die Option Scan Domains aus.</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">Nachdem die geschützten Domains importiert wurden, sollten DRVA-Appliances bereitgestellt werden. In diesem Beispiel wird mithilfe der JetStream DR-Benutzeroberfläche eine kontinuierliche Rehydrierung manuell vom Wiederherstellungsstandort gestartet.</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">Diese Schritte können auch mithilfe von CPT erstellten Plänen automatisiert werden.</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">Importieren Sie die geschützten Domänen und konfigurieren Sie die Recovery VA, um den ANF-Datenspeicher für VM-Platzierungen zu verwenden.</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">Stellen Sie sicher, dass DHCP für das ausgewählte Segment aktiviert ist und genügend IP-Adressen verfügbar sind. Dynamische IPs werden vorübergehend verwendet, während Domänen sich wiederherstellen. Jede wiederherzuckernde VM (einschließlich kontinuierlicher Rehydrierung) erfordert eine individuelle dynamische IP-Adresse. Nach Abschluss der Wiederherstellung wird die IP freigegeben und kann wiederverwendet werden.</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">Wählen Sie die entsprechende Failover-Option (Continuous Failover oder Failover) aus. In diesem Beispiel wird die kontinuierliche Rehydrierung (kontinuierliches Failover) ausgewählt.</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">Failover/Failback Wird Durchgeführt</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">So führen Sie ein Failover/Failback aus</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">Nachdem im geschützten Cluster der lokalen Umgebung ein Ausfall auftritt (ein teilweiser oder vollständiger Ausfall), lösen Sie den Failover aus.</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT kann verwendet werden, um den Failover-Plan zur Wiederherstellung der VMs von Azure Blob Storage auf dem AVS Cluster Recovery-Standort auszuführen.</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">Nach dem Failover (zur kontinuierlichen oder standardmäßigen Wiederherstellung), wenn die geschützten VMs in AVS gestartet wurden, wird der Schutz automatisch fortgesetzt und JetStream DR repliziert ihre Daten weiterhin in den entsprechenden/Original-Containern im Azure Blob Storage.</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">In der Taskleiste wird der Status von Failover-Aktivitäten angezeigt.</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">Nach Abschluss der Aufgabe greifen Sie auf die wiederhergestellten VMs zu, und der Geschäftsbetrieb läuft normal weiter.</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">Wenn der primäre Standort wieder in Betrieb ist, kann ein Failback durchgeführt werden. Der VM-Schutz wird wieder aufgenommen und die Datenkonsistenz sollte überprüft werden.</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">Wiederherstellung der lokalen Umgebung Je nach Art des Notfalleinfalls sind möglicherweise die Wiederherstellung und/oder Überprüfung der Konfiguration des geschützten Clusters erforderlich. Falls erforderlich, muss die JetStream DR-Software möglicherweise erneut installiert werden.</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">Hinweis: Der<block ref="cad8a6b900ca13dfc8b04dee1f744111" prefix=" " category="inline-code"></block> Das im Automation Toolkit zur Verfügung gestellte Skript kann verwendet werden, um die ursprüngliche geschützte Site von veralteten VMs, Domäneninformationen usw. zu reinigen.</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">Greifen Sie auf die wiederhergestellte On-Premises-Umgebung zu, rufen Sie die Jetstream DR UI auf und wählen Sie die entsprechende geschützte Domäne aus. Nachdem der geschützte Standort für Failback bereit ist, wählen Sie die Failback-Option in der UI aus.</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">Mit dem durch CPT generierten Failback-Plan kann außerdem die Rückgabe der VMs und ihrer Daten aus dem Objektspeicher in die ursprüngliche VMware Umgebung initiiert werden.</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">Geben Sie die maximale Verzögerung an, nachdem Sie die VMs am Recovery-Standort angehalten und am geschützten Standort neu gestartet haben. Diese Zeit umfasst das Abschließen der Replizierung nach dem Stoppen von Failover-VMs, die Zeit für die Bereinigung des Recovery-Standorts und die Zeit zur Wiederherstellung von VMs am geschützten Standort. Der von NetApp empfohlene Wert beträgt 10 Minuten.</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">Schließen Sie den Failback-Prozess ab, und bestätigen Sie anschließend die Wiederaufnahme des VM-Schutzes und der Datenkonsistenz.</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Wiederherstellung Von Lösegeld-Waren</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">Die Wiederherstellung von Ransomware kann eine gewaltige Aufgabe sein. Insbesondere kann es für IT-Abteilungen schwierig sein, den sicheren Rückgabepunkt zu ermitteln und einmal festgestellt zu haben, wie sichergestellt werden kann, dass wiederhergestellte Workloads vor den erneuten Angriffen (vom Schlafen von Malware oder durch anfällige Anwendungen) geschützt sind.</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR für AVS kann zusammen mit Azure NetApp Files Datastores diese Bedenken lösen, da Unternehmen eine Recovery von verfügbaren Zeitpunkten durchführen können, sodass Workloads bei Bedarf in einem funktionsfähigen, isolierten Netzwerk wiederhergestellt werden können. Durch Recovery können Applikationen funktionieren und miteinander kommunizieren, ohne dass sie dem Nord- Süd-Datenverkehr ausgesetzt werden. So erhalten Sicherheitsteams einen sicheren Ort, um forensische und andere notwendige Korrekturmaßnahmen durchzuführen.</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">Regionale Verfügbarkeit – Ergänzender NFS-Datenspeicher für ANF</block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4940: Migration von Workloads auf Azure NetApp Files Datastore mithilfe von VMware HCX - QuickStart Guide</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">Autor(en): NetApp Solutions Engineering</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">Übersicht: Migration von Virtual Machines mit VMware HCX, Azure NetApp Files Datastores und Azure VMware Lösung</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Eine der gängigsten Anwendungsfälle für die Azure VMware Lösung und den Azure NetApp Files Datastore ist die Migration von VMware Workloads. VMware HCX ist eine bevorzugte Option und bietet verschiedene Migrationsmechanismen zum Verschieben von On-Premises-Virtual Machines (VMs) und deren Daten in Azure NetApp Files Datastores.</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX ist primär eine Migrationsplattform, die entwickelt wurde, um die Migration von Applikationen, die Ausbalancierung von Workloads und sogar Business Continuity Cloud-übergreifend zu vereinfachen. Es ist im Rahmen von Azure VMware Solution Private Cloud enthalten und bietet viele Möglichkeiten zum Migrieren von Workloads und kann für Disaster-Recovery-(DR-)Vorgänge genutzt werden.</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">Dieses Dokument enthält eine Schritt-für-Schritt-Anleitung zur Bereitstellung von Azure NetApp Files Datastore. Anschließend werden die Komponenten von VMware HCX heruntergeladen, implementiert und konfiguriert, einschließlich aller Hauptkomponenten vor Ort und der Seite der Azure VMware Lösung, einschließlich Interconnect, Netzwerkerweiterung und WAN-Optimierung, um verschiedene VM-Migrationsmechanismen zu ermöglichen.</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX arbeitet mit jedem Datenspeichertyp zusammen, da die Migration auf VM-Ebene erfolgt. Dieses Dokument eignet sich daher für bestehende NetApp Kunden sowie für Kunden anderer Anbieter, die eine Implementierung der Azure NetApp Files Lösung mit Azure VMware als kostengünstige VMware Cloud-Implementierung planen.</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">Allgemeine Schritte</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">Diese Liste enthält grundlegende Schritte, die für die Installation und Konfiguration von HCX Cloud Manager auf der Azure Cloud-Seite und die Installation von HCX Connector vor Ort erforderlich sind:</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">Installieren Sie HCX über das Azure-Portal.</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">Laden Sie das Installationsprogramm für die HCX Connector Open Virtualization Appliance (OVA) im lokalen VMware vCenter Server herunter und implementieren Sie es.</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">HCX mit dem Lizenzschlüssel aktivieren.</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">Verbinden Sie den lokalen VMware HCX Connector mit der Azure VMware-Lösung HCX Cloud Manager.</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">Sie konfigurieren das Netzwerkprofil, das Computing-Profil und das Service-Mesh.</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(Optional) Sie können eine Netzwerkerweiterung vornehmen, um bei Migrationen eine erneute IP-Adresse zu vermeiden.</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">Validieren des Appliance-Status und Sicherstellen der Möglichkeit der Migration</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">Migration der VM-Workloads</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">Bevor Sie beginnen, stellen Sie sicher, dass die folgenden Voraussetzungen erfüllt sind. Weitere Informationen finden Sie unter<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>. Nachdem die Voraussetzungen, einschließlich der Konnektivität, vorhanden sind, konfigurieren und aktivieren Sie HCX, indem Sie den Lizenzschlüssel aus dem Azure VMware-Lösungsportal generieren. Nach dem Herunterladen des OVA-Installationsprogramms gehen Sie wie unten beschrieben mit der Installation vor.</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCX Advanced ist die Standardoption und die VMware HCX Enterprise Edition ist auch über ein Support-Ticket erhältlich und wird ohne zusätzliche Kosten unterstützt.</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">Link von NetApp</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Microsoft-Link</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">Nutzen Sie ein bereits softwaredefiniertes Datacenter (SDDC) einer Azure VMware Lösung oder erstellen Sie mithilfe dieses Modells eine Private Cloud<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> Oder hier<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>.</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">Richten Sie eine Site-to-Site-VPN- oder Express-Route-globale REACH-Verbindung ein</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">Die Migration von VMs und zugehörigen Daten vom lokalen Datacenter mit VMware vSphere erfordert Netzwerkkonnektivität vom Datacenter zur SDDC-Umgebung. Vor der Migration von Workloads<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> Zwischen der lokalen Umgebung und der jeweiligen Private Cloud verschieben.</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">Der Netzwerkpfad von der lokalen VMware vCenter Server Umgebung zur Private Cloud der Azure VMware Lösung muss die Migration von VMs mithilfe von vMotion unterstützen.</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">Firewall-Regeln und -Ports</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">Stellen Sie sicher, dass die erforderlichen<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sind für vMotion Traffic zwischen dem lokalen vCenter Server und SDDC vCenter zulässig. In der Private Cloud ist das Routing im vMotion Netzwerk standardmäßig konfiguriert.</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Das Azure NetApp Files NFS-Volume sollte als Datastore in der Azure VMware-Lösung eingebunden werden. Befolgen Sie die in diesem Schritt beschriebenen Schritte<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Um Azure NetApp Files-Datenspeicher an Azure VMware Solutions Hosts anzuschließen.</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">Übergeordnete Architektur</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">Die für diese Validierung verwendete Lab-Umgebung wurde zu Testzwecken über ein Site-to-Site-VPN verbunden, das On-Premises-Konnektivität mit der Azure VMware Lösung ermöglicht.</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">Dieses Bild zeigt die in dieser Lösung verwendete allgemeine Architektur.</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">Lösungsimplementierung</block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">Führen Sie die folgenden Schritte aus, um die Implementierung dieser Lösung abzuschließen:</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">Schritt 1: Installieren Sie HCX über Azure Portal mit der Option Add-ons</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">Gehen Sie wie folgt vor, um die Installation durchzuführen:</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Melden Sie sich im Azure-Portal an und greifen Sie auf die Private Cloud der Azure VMware Lösung zu.</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">Wählen Sie die entsprechende private Cloud aus, und greifen Sie auf Add-ons zu. Dazu navigieren Sie zu *Verwalten &gt; Add-ons*.</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">Klicken Sie im Bereich HCX Workload Mobility auf *Get Started*.</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">Screenshot des Abschnitts HCX Workload Mobility.</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">Wählen Sie die Option *Ich stimme den Allgemeinen Geschäftsbedingungen* zu und klicken Sie auf *Aktivieren und Bereitstellen*.</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">Die Standardbereitstellung ist HCX Advanced. Öffnen Sie eine Support-Anfrage, um die Enterprise Edition zu aktivieren.</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">Die Implementierung dauert etwa 25 bis 30 Minuten.</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">Screenshot der Fertigstellung des Abschnitts HCX Workload Mobility.</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">Schritt 2: Stellen Sie das Installationsprogramm OVA im lokalen vCenter Server bereit</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">Damit der On-Premises Connector eine Verbindung zum HCX Manager in Azure VMware herstellen kann, müssen in der On-Premises-Umgebung die entsprechenden Firewall-Ports geöffnet sein.</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">So laden Sie den HCX Connector auf dem lokalen vCenter Server herunter und installieren ihn:</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">Wählen Sie im Azure-Portal die Azure-VMware-Lösung aus, wählen Sie die Private Cloud aus, und wählen Sie *Verwalten &gt; Add-ons &gt; Migration* mit HCX aus. Kopieren Sie das HCX-Cloud-Manager-Portal, um die OVA-Datei herunterzuladen.</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">Verwenden Sie die standardmäßigen CloudAdmin-Benutzeranmeldeinformationen für den Zugriff auf das HCX-Portal.</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">Screenshot des Azure-Portals zum Herunterladen der HCX OVA-Datei.</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">Nachdem Sie über den Jumphost auf das HCX-Portal mit mailto:cloudadmin@vsphere.local[cloudadmin@vsphere.local^] zugegriffen haben, navigieren Sie zu *Administration &gt; Systemaktualisierungen* und klicken Sie auf *Download anfordern Link*.</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">Laden Sie entweder den Link zur OVA herunter oder kopieren Sie ihn in einen Browser, um den Download-Prozess der OVA-Datei von VMware HCX Connector zu starten, um sie auf dem lokalen vCenter Server bereitzustellen.</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">Fehler: Screenshot des OVA Download-Links.</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">Nachdem die OVA heruntergeladen wurde, stellen Sie sie in der lokalen VMware vSphere Umgebung mithilfe der Option *Deploy OVF Template* bereit.</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">Fehler: Screenshot zur Auswahl der richtigen OVA-Vorlage.</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">Geben Sie alle erforderlichen Informationen für die OVA-Bereitstellung ein, klicken Sie auf *Weiter* und klicken Sie dann auf *Fertig stellen*, um die OVA des VMware HCX-Connectors bereitzustellen.</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">Schalten Sie die virtuelle Appliance manuell ein.</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">VMware HCX-Benutzerhandbuch</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">Eine Schritt-für-Schritt-Anleitung finden Sie im<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">Schritt 3: HCX Connector mit dem Lizenzschlüssel aktivieren</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">Nachdem Sie den VMware HCX Connector OVA vor Ort bereitgestellt und das Gerät gestartet haben, führen Sie die folgenden Schritte aus, um den HCX Connector zu aktivieren. Generieren Sie den Lizenzschlüssel aus dem Azure VMware Lösungs-Portal und aktivieren Sie ihn in VMware HCX Manager.</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">Wählen Sie im Azure-Portal die Azure VMware-Lösung, wählen Sie die Private Cloud aus und wählen Sie *Verwalten &gt; Add-ons &gt; Migration Using HCX* aus.</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">Klicken Sie unter *Verbindung mit On-Premise mit HCX-Tasten* auf *Hinzufügen* und kopieren Sie den Aktivierungsschlüssel.</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">Screenshot zum Hinzufügen von HCX-Tasten.</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">Für jeden bereitgestellten HCX-Connector vor Ort ist ein separater Schlüssel erforderlich.</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">Melden Sie sich beim lokalen VMware HCX Manager unter an<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> Administratordaten werden verwendet.</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">Verwenden Sie das während der OVA-Bereitstellung definierte Passwort.</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">Geben Sie in der Lizenzierung den aus Schritt 3 kopierten Schlüssel ein und klicken Sie auf *Aktivieren*.</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">Der HCX-Connector sollte über einen Internetzugang verfügen.</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">Geben Sie unter *Datacenter Location* den nächstgelegenen Standort für die Installation des VMware HCX Managers vor Ort an. Klicken Sie Auf *Weiter*.</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">Aktualisieren Sie unter *Systemname* den Namen und klicken Sie auf *Weiter*.</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">Klicken Sie Auf *Ja, Weiter*.</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">Geben Sie unter *Connect Your vCenter* den vollständig qualifizierten Domänennamen (FQDN) oder die IP-Adresse des vCenter Servers und die entsprechenden Anmeldeinformationen an und klicken Sie auf *Continue*.</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">Verwenden Sie den FQDN, um Verbindungsprobleme später zu vermeiden.</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">Geben Sie unter * SSO/PSC konfigurieren* den FQDN oder die IP-Adresse des Plattform-Services-Controllers an und klicken Sie auf *Weiter*.</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">Geben Sie den VMware vCenter Server FQDN oder die IP-Adresse ein.</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">Überprüfen Sie, ob die eingegebenen Informationen korrekt sind, und klicken Sie auf *Neustart*.</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">Nach dem Neustart der Dienste wird vCenter Server auf der angezeigten Seite grün angezeigt. Sowohl vCenter Server als auch SSO müssen über die entsprechenden Konfigurationsparameter verfügen, die mit der vorherigen Seite übereinstimmen sollten.</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">Dieser Vorgang dauert etwa 10 bis 20 Minuten, und das Plug-in wird dem vCenter Server hinzugefügt.</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">Screenshot mit dem abgeschlossenen Prozess</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">Schritt 4: Verbinden Sie den lokalen VMware HCX Connector mit der Azure VMware-Lösung HCX Cloud Manager</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">Nachdem HCX Connector sowohl in der lokalen als auch in der Azure VMware-Lösung installiert wurde, konfigurieren Sie die private Cloud der lokalen VMware HCX Connector for Azure VMware-Lösung, indem Sie die Paarung hinzufügen. Gehen Sie wie folgt vor, um die Standortpaarung zu konfigurieren:</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">Um ein Standortpaar zwischen der lokalen vCenter Umgebung und der Azure VMware Solution SDDC zu erstellen, melden Sie sich beim lokalen vCenter Server an und greifen Sie auf das neue HCX vSphere Web Client Plug-in zu.</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">Screenshot des HCX vSphere Web Client Plug-ins.</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">Klicken Sie unter Infrastruktur auf *Site Pairing hinzufügen*.</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">Geben Sie die URL oder IP-Adresse der Azure VMware Solution HCX Cloud Manager und die Anmeldedaten für CloudAdmin-Rolle für den Zugriff auf die private Cloud ein.</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">Screenshot-URL oder IP-Adresse und Anmeldeinformationen für die CloudAdmin-Rolle.</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">Klicken Sie Auf *Verbinden*.</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">VMware HCX Connector muss über Port 443 zu HCX Cloud Manager IP weiterleiten können.</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">Nach der Erstellung der Kopplung steht die neu konfigurierte Standortpairing auf dem HCX Dashboard zur Verfügung.</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">Screenshot des abgeschlossenen Prozesses auf dem HCX-Dashboard.</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">Schritt 5: Netzwerkprofil, Computing-Profil und Service-Mesh konfigurieren</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">Die VMware HCX Interconnect Service Appliance bietet Replizierungs- und vMotion-basierte Migrationsfunktionen über das Internet und private Verbindungen zum Zielstandort. Das Interconnect bietet Verschlüsselung, Traffic Engineering und VM-Mobilität. Um eine Interconnect Service Appliance zu erstellen, gehen Sie wie folgt vor:</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">Wählen Sie unter Infrastruktur die Option *Interconnect &gt; Multi-Site Service Mesh &gt; Compute Profiles &gt; Create Compute Profile* aus.</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">Die Computing-Profile definieren die Implementierungsparameter einschließlich der Appliances, die bereitgestellt werden und welche Teile des VMware Datacenters für den HCX-Service verfügbar sind.</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">Screenshot der Seite mit den vSphere Client Interconnects</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">Erstellen Sie nach dem Erstellen des Rechenprofils die Netzwerkprofile, indem Sie *Multi-Site Service Mesh &gt; Netzwerkprofile &gt; Netzwerkprofil erstellen* auswählen.</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">Das Netzwerkprofil definiert einen Bereich von IP-Adressen und Netzwerken, die von HCX für seine virtuellen Appliances verwendet werden.</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">Für diesen Schritt werden mindestens zwei IP-Adressen benötigt. Diese IP-Adressen werden den Interconnect Appliances vom Managementnetzwerk zugewiesen.</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">Screenshot des Hinzufügens von IP-Adressen zur Seite vSphere Client Interconnect.</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">Derzeit wurden die Computing- und Netzwerkprofile erfolgreich erstellt.</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">Erstellen Sie das Service Mesh, indem Sie in der Option *Interconnect* die Registerkarte *Service Mesh* auswählen und die On-Premises- und Azure SDDC-Sites auswählen.</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">Das Service Mesh gibt ein lokales und entferntes Compute- und Netzwerkprofilpaar an.</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">Im Rahmen dieses Prozesses werden die HCX-Appliances sowohl an den Quell- als auch an den Zielstandorten bereitgestellt und automatisch konfiguriert, um eine sichere Transportstruktur zu erstellen.</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">Screenshot der Registerkarte Service Mesh auf der Seite vSphere Client Interconnect.</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">Dies ist der letzte Konfigurationsschritt. Die Implementierung sollte also fast 30 Minuten dauern. Nach der Konfiguration des Service-Mesh ist die Umgebung bereit, wobei die IPsec-Tunnel erfolgreich erstellt wurden, um die Workload-VMs zu migrieren.</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">Screenshot aus dem abgeschlossenen Prozess auf der Seite vSphere Client Interconnect</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">Schritt 6: Migration von Workloads</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">Workloads können mithilfe verschiedener VMware HCX Migrationstechnologien bidirektional zwischen lokalen und Azure SDDCs migriert werden. VMs können mithilfe von mehreren Migrationstechnologien wie HCX Bulk Migration, HCX vMotion, HCX Cold Migration, HCX Replication Assisted vMotion (erhältlich mit HCX Enterprise Edition) und HCX OS Assisted Migration (erhältlich mit der HCX Enterprise Edition) in und von VMware HCX Enterprise Edition verschoben werden.</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">Migrationstypen von VMware HCX</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">Weitere Informationen zu verschiedenen HCX-Migrationsmechanismen finden Sie unter<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>.</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*Massenmigration*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">In diesem Abschnitt wird der Migrationsmechanismus für große Datenmengen beschrieben. Während einer Massenmigration nutzt die Funktion zur Massenmigration von HCX vSphere Replication, um Festplattendateien zu migrieren und die VM auf der vSphere HCX-Zielinstanz neu zu erstellen.</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">Um VM-Massenmigrationen zu initiieren, führen Sie die folgenden Schritte aus:</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">Öffnen Sie die Registerkarte * Migrate* unter *Services &gt; Migration*.</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">Screenshot aus dem Abschnitt Migration im vSphere Client</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">Wählen Sie unter *Remote-Standortverbindung* die Verbindung mit dem Remote-Standort aus und wählen Sie die Quelle und das Ziel aus. In diesem Beispiel wird als Ziel der SDDC HCX-Endpunkt der Azure VMware-Lösung verwendet.</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">Klicken Sie auf *Select VMs for Migration*. Hier wird eine Liste aller lokalen VMs angezeigt. Wählen Sie die VMs basierend auf dem Ausdruck Match:value aus und klicken Sie auf *Add*.</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">Aktualisieren Sie im Abschnitt *Transfer und Platzierung* die Pflichtfelder (*Cluster*, *Storage*, *Ziel* und *Netzwerk*), einschließlich des Migrationsprofils, und klicken Sie auf *Validieren*.</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">Screenshot aus dem Abschnitt „Übertragung und Platzierung“ des vSphere Clients</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">Nachdem die Validierungsprüfungen abgeschlossen sind, klicken Sie auf *Go*, um die Migration zu starten.</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">Screenshot der Migrationsbeginn.</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">Während dieser Migration wird auf dem angegebenen Azure NetApp Files Datastore im Ziel-vCenter eine Platzhalterfestplatte erstellt, um die Daten der Quell-VM-Festplatte auf die Platzhalterfestplatten replizieren zu können. HBR wird ausgelöst, um eine vollständige Synchronisierung zum Ziel zu ermöglichen. Nach Abschluss der Baseline wird basierend auf dem RPO-Zyklus (Recovery Point Objective) eine inkrementelle Synchronisierung durchgeführt. Nach Abschluss der vollständigen/inkrementellen Synchronisierung wird die Umschaltung automatisch ausgelöst, es sei denn, ein bestimmter Zeitplan ist festgelegt.</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">Nach Abschluss der Migration können Sie dies durch Zugriff auf das SDDC Ziel-vCenter validieren.</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">Weitere und detaillierte Informationen zu verschiedenen Migrationsoptionen und zur Migration von Workloads von On-Premises-Systemen zur Azure VMware Lösung mithilfe von HCX finden Sie unter<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="73e6478a04a38e6c1af3fd112abd351f" category="paragraph">Wenn Sie mehr über diesen Prozess erfahren möchten, folgen Sie bitte dem detaillierten Video:</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">Hier sehen Sie einen Screenshot der HCX vMotion Option.</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">Stellen Sie sicher, dass für die Migration ausreichend Bandbreite zur Verfügung steht.</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">Der Ziel-ANF-Datastore sollte über genügend Speicherplatz für die Migration verfügen.</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">Ganz gleich, ob Sie nur auf All-Cloud- oder Hybrid Cloud-Umgebungen abzielen und Daten in On-Premises-Storage eines beliebigen Typs oder Anbieters speichern – Azure NetApp Files und HCX bieten hervorragende Optionen für die Implementierung und Migration der Applikations-Workloads und senken gleichzeitig die TCO, da die Datenanforderungen nahtlos auf die Applikationsebene integriert sind. Wie auch immer der Anwendungsfall ist: Wählen Sie Azure VMware Lösung zusammen mit Azure NetApp Files, um schnell von den Vorteilen der Cloud zu profitieren, eine konsistente Infrastruktur und Abläufe vor Ort und in mehreren Clouds, bidirektionale Portabilität von Workloads und Kapazität und Performance der Enterprise-Klasse. Es handelt sich dabei um denselben bekannten Prozess und dieselben Verfahren, die zum Verbinden des Storage und zur Migration von VMs mithilfe von VMware vSphere Replication, VMware vMotion oder sogar NFS (Network File Copy) verwendet werden.</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">Erkenntnisse Aus</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">Zu den wichtigsten Punkten dieses Dokuments gehören:</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">Sie können Azure NetApp Files nun als Datastore auf dem Azure VMware Solution SDDC verwenden.</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">Daten lassen sich problemlos von lokalen Systemen zu Azure NetApp Files Datastores migrieren.</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">Erweitern und verkleinern Sie den Azure NetApp Files-Datastore einfach, um die Kapazitäts- und Performance-Anforderungen während der Migration zu erfüllen.</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Daten finden Sie unter den folgenden Links:</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Dokumentation der Azure VMware Lösung</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Azure NetApp Files-Dokumentation</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">NetApp Funktionen für Azure AVS</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">Erfahren Sie mehr über die Funktionen, die NetApp in die Azure VMware Lösung (AVS) bietet: Von NetApp als Storage-Gerät mit Anbindung an den Gast oder über einen zusätzlichen NFS Datastore für die Migration von Workflows, über Erweiterung/Bursting in die Cloud, Backup/Wiederherstellung und Disaster Recovery.</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">Springen Sie zum Abschnitt zum gewünschten Inhalt, indem Sie eine der folgenden Optionen auswählen:</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="inline-link-macro">AVS wird in Azure konfiguriert</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="inline-link-macro">NetApp Storage-Optionen für AVS</block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">NetApp/VMware Cloud-Lösungen</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">Wie bei lokalen Systemen ist die Planung einer Cloud-basierten Virtualisierungsumgebung eine entscheidende Voraussetzung für eine erfolgreiche, sofort einsatzbereite Umgebung zum Erstellen von VMs und Migrationen.</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">Der in-Guest-Speicher ist die einzige unterstützte Methode zur Verbindung von Cloud Volumes ONTAP mit Azure VMware-Lösung.</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="list-text">Netzwerkverbindung validieren und auf Private Cloud zugreifen</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">Konfigurationsschritte für AVS</block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">Details anzeigen <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>.</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">NetApp Storage kann innerhalb von Azure AVS auf verschiedene Arten genutzt werden – entweder als angebundenen oder als zusätzlicher NFS-Datenspeicher.</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">Unterstützte NetApp Storage-Optionen</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">Besuchen Sie <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure unterstützt NetApp Storage in den folgenden Konfigurationen:</block>
  <block id="119d7589ae9a38050e960d08d321b275" category="list-text">Azure NetApp Files (ANF) als zusätzlicher NFS-Datastore^1^</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">Gastanbindung Speicheroptionen für AVS</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">Zusätzliche NFS-Datastore-Optionen für AVS</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">Details anzeigen <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>. Details anzeigen <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>.</block>
  <block id="0f9904cf8a560b1c4309e4cf7750b7b9" category="admonition">1 - ANF als zusätzlicher NFS-Datastore für AVS befindet sich derzeit in der öffentlichen Vorschau. Lesen Sie mehr darüber<block ref="5b3a31b4442bd8ea3aebfc18fe8411e5" category="inline-link-rx"></block>.</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">Anwendungsfälle Für Lösungen</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">Mit Cloud-Lösungen von NetApp und VMware können viele Anwendungsfälle problemlos in Azure AVS implementiert werden. se-Fälle werden für jeden der von VMware definierten Cloud-Bereiche definiert:</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">Schutz (sowohl Disaster Recovery als auch Backup/Restore)</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">Erweitern</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="list-text">Migrieren</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Die NetApp Lösungen für Azure AVS</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">NetApp Lösungen für Azure VMware (AVS)</block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">Erfahren Sie mehr über die Lösungen von NetApp für Azure.</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware definiert Cloud-Workloads in eine von drei Kategorien:</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">Schutz (sowohl Disaster Recovery als auch Backup/Restore)</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">Durchsuchen Sie die verfügbaren Lösungen in den folgenden Abschnitten.</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">Sichern</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">Disaster Recovery mit ANF und JetStream (zusätzlicher NFS-Datastore)</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">Disaster Recovery mit ANF und CVO (über Gast verbundener Storage)</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">Migrieren Sie Workloads mithilfe von VMware HCX zum Azure NetApp Files Datastore</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">IN KÜRZE:</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">Überblick über ANF Datastore Solutions</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">Alle erfolgreichen Unternehmen befinden sich auf dem Weg der Transformation und Modernisierung. In diesem Prozess verwenden Unternehmen in der Regel ihre vorhandenen VMware-Investitionen, während sie gleichzeitig die Vorteile der Cloud nutzen und untersuchen, wie sich Migrations-, Burst-, Extend- und Disaster Recovery-Prozesse so nahtlos wie möglich gestalten lassen. Kunden, die zur Cloud migrieren, müssen die Aspekte Flexibilität und Burst, Datacenter-Ausstieg, Datacenter-Konsolidierung, End-of-Life-Szenarien, Fusionen, Übernahmen usw. bewerten. Der von den einzelnen Unternehmen angenommene Ansatz kann je nach Geschäftsprioritäten variieren. Bei der Auswahl der Cloud-basierten Prozesse ist die Auswahl eines kostengünstigen Modells mit angemessener Performance und minimaler Behinderung ein entscheidendes Ziel. Dabei ist es besonders wichtig, dass Sie die richtige Plattform auswählen, sowie die Storage- und Workflow-Orchestrierung, um das Potenzial der Cloud-Implementierung und -Flexibilität auszuschöpfen.</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Obwohl die Azure VMware Lösung Kunden einzigartige Hybrid-Funktionen bietet, haben begrenzte native Storage-Optionen jedoch ihre Nützlichkeit in Unternehmen mit speicherlastigen Workloads eingeschränkt. Da Storage direkt an Hosts gebunden ist, besteht die einzige Möglichkeit zur Skalierung des Storage darin, weitere Hosts hinzuzufügen. Dadurch lassen sich die Kosten bei Storage-intensiven Workloads um 35 bis 40 % oder mehr senken. Diese Workloads erfordern zusätzlichen Storage und keine zusätzliche Leistung, sondern die Kosten für zusätzliche Hosts.</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">Betrachten wir einmal das folgende Szenario: Ein Kunde benötigt sechs Hosts für mehr Performance (vCPU/Vmem), hat aber auch einen erheblichen Storage-Bedarf. Basierend auf ihrem Assessment benötigen sie 12 Hosts, um die Storage-Anforderungen zu erfüllen. Dies erhöht die Gesamtbetriebskosten, da diese zusätzliche Leistung anschaffen müssen, wenn überhaupt mehr Storage benötigt wird. Dies gilt für alle Anwendungsfälle, einschließlich Migration, Disaster Recovery, Bursting, Entwicklung/Test, Und so weiter.</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Ein weiterer häufiger Anwendungsfall für Azure VMware Lösung ist Disaster Recovery (DR). Die meisten Unternehmen verfügen nicht über eine zukunftssichere DR-Strategie. Oder sie tun sich schwer damit, einen Geist nur für DR zu rechtfertigen. Administratoren prüfen möglicherweise in Verbindung mit einem Pilot-Light-Cluster oder On-Demand-Cluster DR-Optionen, die für keinerlei Stellfläche benötigen. Anschließend konnte der Storage ohne zusätzliche Hosts skaliert werden, was potenziell eine attraktive Option wäre.</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">Zusammengefasst können die Anwendungsfälle auf zwei Arten klassifiziert werden:</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">Skalierung der Storage-Kapazität mithilfe von ANF Datastores</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">Nutzung von ANF-Datastores als Disaster-Recovery-Ziel für einen kostenoptimierten Recovery-Workflow von lokalen oder Azure-Regionen zwischen den softwaredefinierten Datacentern (SDDC).dieser Leitfaden bietet Einblicke in die Verwendung von Azure NetApp Files für die Bereitstellung von optimiertem Storage für Datastores (derzeit in öffentlicher Vorschau). Neben erstklassigen Datensicherungs- und DR-Funktionen in einer Azure VMware Lösung können Sie Storage-Kapazität von vSAN Storage verlagern.</block>
  <block id="301964836d84fb491fca23f51f902cd0" category="admonition">Die Azure NetApp Files-Datastore-Funktion ist derzeit in öffentlicher Vorschau verfügbar. Weitere Informationen erhalten Sie von NetApp oder Microsoft Solution Architects in Ihrer Region.</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">VMware Cloud Optionen in Azure</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware Lösung</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Die Azure VMware Lösung (AVS) ist ein Hybrid-Cloud-Service, der VMware Datacenters in einer Public Cloud von Microsoft Azure vollständig nutzt. AVS ist eine Lösung eines Erstanbieters, die vollständig von Microsoft verwaltet und unterstützt wird und von VMware überprüft wurde, die eine Azure-Infrastruktur nutzt. Kunden entscheiden sich daher für VMware ESXi für Computing-Virtualisierung, vSAN für hyperkonvergenten Storage und NSX für Netzwerk und Sicherheit. Sie profitieren gleichzeitig von der globalen Präsenz von Microsoft Azure, den erstklassigen Datacenter-Einrichtungen und der Nähe zum umfassenden Ecosystem aus nativen Azure Services und Lösungen. Eine Kombination aus Azure VMware Solution SDDC und Azure NetApp Files bietet die beste Performance bei minimaler Netzwerklatenz.</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">Unabhängig vom verwendeten Cloud-Einsatz umfasst der anfängliche Cluster bei der Implementierung eines VMware SDDC die folgenden Komponenten:</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">VMware ESXi Hosts für die Computing-Virtualisierung mit einer vCenter Server Appliance zum Management</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">VMware vSAN hyperkonvergenter Storage mit den physischen Storage-Ressourcen des jeweiligen ESXi Hosts.</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">VMware NSX für virtuelles Networking und Sicherheit mit einem NSX Manager Cluster für Management.</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">Egal, ob Sie auf eine All-Cloud oder eine Hybrid Cloud abzielen – Azure NetApp Files bietet exzellente Optionen zur Implementierung und zum Management von Applikations-Workloads zusammen mit Fileservices und senkt gleichzeitig die TCO, da die Datenanforderungen nahtlos auf die Applikationsebene integriert werden. Wie auch immer der Anwendungsfall ist: Wählen Sie die Azure VMware Lösung zusammen mit Azure NetApp Files, um Cloud-Vorteile schnell zu realisieren, eine konsistente Infrastruktur und Abläufe vor Ort und in mehreren Clouds, bidirektionale Workload-Portabilität und Kapazität und Performance der Enterprise-Klasse. Es handelt sich dabei um denselben bekannten Prozess und dieselben Verfahren, mit denen der Speicher verbunden wird. Denken Sie daran: Es ist nur die Position der geänderten Daten, die Tools und Prozesse bleiben dieselben, und Azure NetApp Files hilft bei der Optimierung der generellen Implementierung.</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">Sie können Azure NetApp Files nun als Datastore auf dem AVS SDDC verwenden.</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">Kürzere Reaktionszeiten von Applikationen und höhere Verfügbarkeit für den Zugriff auf Workload-Daten nach Bedarf</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">Mit einfachen und sofortigen Funktionen zur Anpassung vereinfachen Sie die allgemeine Komplexität des vSAN-Storage.</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">Garantierte Performance für geschäftskritische Workloads durch dynamische Umformungsfunktionen</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Wenn Azure VMware Solution Cloud Ziel ist, ist Azure NetApp Files die richtige Storage-Lösung für eine optimierte Implementierung.</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Azure NetApp Files-Datenspeicher an Hosts der Azure VMware Lösung anhängen (Vorschau)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz von Workloads vor Standortausfällen und Datenbeschädigungen wie Ransomware. Mit NetApp SnapMirror können lokale VMware Workloads, die einen mit dem Gast verbundenen Storage verwenden, auf NetApp Cloud Volumes ONTAP in Azure repliziert werden.</block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">Disaster Recovery mit CVO und AVS (Storage mit Anbindung an den Gast)</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">Autoren: Ravi BCB und Niyaz Mohamed, NetApp</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz von Workloads vor Standortausfällen und Datenbeschädigungen wie Ransomware. Mit NetApp SnapMirror können lokale VMware Workloads, die einen mit dem Gast verbundenen Storage verwenden, auf NetApp Cloud Volumes ONTAP in Azure repliziert werden. Dies bezieht sich auf Applikationsdaten, doch was ist mit den eigentlichen VMs selbst. Disaster Recovery sollte alle abhängigen Komponenten, einschließlich Virtual Machines, VMDKs, Applikationsdaten und mehr, abdecken. Zu diesem Zweck kann SnapMirror zusammen mit Jetstream verwendet werden, um Workloads, die von On-Premises zu Cloud Volumes ONTAP repliziert wurden, nahtlos wiederherzustellen und gleichzeitig vSAN Storage für VM-VMDKs zu verwenden.</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">Dieses Dokument bietet einen Schritt-für-Schritt-Ansatz zur Einrichtung und Durchführung von Disaster Recovery mit NetApp SnapMirror, JetStream und der Azure VMware Lösung (AVS).</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">Voraussetzungen</block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">Dieses Dokument konzentriert sich auf den Gast-Storage für Applikationsdaten (auch als Gastsystem bekannt) und wir gehen davon aus, dass die On-Premises-Umgebung SnapCenter für applikationskonsistente Backups verwendet.</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">Dieses Dokument bezieht sich auf jede Backup- oder Recovery-Lösung eines Drittanbieters. Je nach der in der Umgebung verwendeten Lösung befolgen Sie Best Practices, um Backup-Richtlinien zu erstellen, die die SLAs des Unternehmens erfüllen.</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">Für die Konnektivität zwischen der On-Premises-Umgebung und dem virtuellen Azure-Netzwerk nutzen Sie die globale Express Route oder ein virtuelles WAN mit einem VPN-Gateway. Segmente sollten basierend auf dem lokalen VLAN-Design erstellt werden.</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">Es gibt mehrere Optionen, um On-Premises-Datacenter mit Azure zu verbinden, sodass wir nicht einen bestimmten Workflow in diesem Dokument beschreiben können. Die entsprechende On-Premises-zu-Azure-Konnektivitätsmethode finden Sie in der Azure-Dokumentation.</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">Implementieren der DR-Lösung</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">Übersicht Zur Lösungsimplementierung</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">Stellen Sie sicher, dass die Applikationsdaten mit SnapCenter zusammen mit den erforderlichen RPO-Anforderungen gesichert werden.</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">Stellen Sie mithilfe von Cloud Manager Cloud Volumes ONTAP mit der richtigen Instanzgröße innerhalb des entsprechenden Abonnements und des virtuellen Netzwerks bereit.</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">Konfiguration von SnapMirror für die entsprechenden Applikations-Volumes</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">Aktualisieren Sie die Backup-Richtlinien in SnapCenter, um SnapMirror Updates nach den geplanten Aufgaben auszulösen.</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">Installieren Sie die JetStream DR-Software im lokalen Datacenter, und beginnen Sie mit dem Schutz für Virtual Machines.</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">Bei einem Notfall können Sie die SnapMirror Beziehung mithilfe von Cloud Manager unterbrechen und das Failover von Virtual Machines zu Azure NetApp Files oder zu vSAN Datastores im vorgesehenen AVS-DR-Standort auslösen.</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">Schließen Sie die ISCSI-LUNs und NFS-Mounts für die Applikations-VMs wieder an.</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">Rufen Sie Failback auf den geschützten Standort auf, indem Sie SnapMirror nach der Wiederherstellung des primären Standorts erneut resynchronisieren.</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">Einzelheiten Zur Bereitstellung</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">Konfiguration von CVO auf Azure und Replizierung von Volumes zu CVO</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">Verlinken</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">Als ersten Schritt müssen Sie Cloud Volumes ONTAP auf Azure konfigurieren <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>) Und replizieren Sie die gewünschten Volumen zu Cloud Volumes ONTAP mit den gewünschten Frequenzen und Snapshot-Aufbewahrung.</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">Konfigurieren Sie AVS-Hosts und CVO-Datenzugriff</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">Zwei wichtige Faktoren, die bei der Implementierung des SDDC berücksichtigt werden müssen, sind die Größe des SDDC-Clusters in der Azure VMware Lösung und die Dauer des SDDC im Service. Diese beiden wichtigen Überlegungen für eine Disaster-Recovery-Lösung tragen zur Senkung der Gesamtbetriebskosten bei. Das SDDC kann mit nur drei Hosts eingerichtet sein und bis hin zu einem Cluster mit mehreren Hosts in einer umfassenden Implementierung.</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">Die Entscheidung für die Implementierung eines AVS-Clusters hängt in erster Linie von den RPO/RTO-Anforderungen ab. Mit der Azure VMware Lösung kann das SDDC bereits rechtzeitig zur Verfügung gestellt werden, um entweder für das Testen oder für ein tatsächliches Notfallereignis zu sorgen. Ein durch die Just-in-time-Implementierung implementierter SDDC spart ESXi Hostkosten, wenn Sie keine Katastrophe mehr haben. Diese Form der Implementierung wirkt sich jedoch auf das RTO um einige Stunden aus, während das SDDC bereitgestellt wird.</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">Am häufigsten implementiert wird die SDDC-Option in einem Pilot-Light-Modus, der immer aktiviert ist. Diese Option bietet einen kleinen Platzbedarf von drei Hosts, die immer verfügbar sind. Außerdem werden Recovery-Vorgänge durch eine Basis für Simulationsaktivitäten und Compliance-Prüfungen beschleunigt, sodass das Risiko einer operativen Abweichungen zwischen dem Produktions- und dem DR-Standort vermieden wird. Der Pilot-Light-Cluster kann bei Bedarf schnell auf das gewünschte Niveau skaliert werden, um tatsächliche DR-Ereignisse zu bewältigen.</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">Informationen zur Konfiguration des AVS SDDC (ob On-Demand oder im Pilot-Light-Modus) finden Sie unter<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>. Überprüfen Sie als Voraussetzung, ob die Gast-VMs auf den AVS-Hosts nach dem Einrichten der Konnektivität Daten von Cloud Volumes ONTAP nutzen können.</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Nach der ordnungsgemäßen Konfiguration von Cloud Volumes ONTAP und AVS beginnen Sie mit der Konfiguration des Jetstream zur Automatisierung der Wiederherstellung lokaler Workloads auf AVS (VMs mit Applikations-VMDKs und VMs mit in-Guest-Storage) mithilfe des VAIO Mechanismus und durch Nutzung von SnapMirror für Applikations-Volumes-Kopien auf Cloud Volumes ONTAP.</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">Installieren Sie JetStream DR im lokalen Datacenter</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Die Jetstream DR-Software besteht aus drei Hauptkomponenten: Der JetStream DR Management Server Virtual Appliance (MSA), der DR Virtual Appliance (DRVA) und den Host-Komponenten (I/O-Filterpakete). Mit dem MSA-System werden Hostkomponenten auf dem Compute-Cluster installiert und konfiguriert und JetStream DR-Software verwaltet. Die Installation erfolgt wie folgt:</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">Voraussetzungen prüfen.</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">Nutzen Sie das Kapazitätsplanungs-Tool für Ressourcen- und Konfigurationsempfehlungen.</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">Implementieren Sie JetStream DR MSA auf jedem vSphere-Host im zugewiesenen Cluster.</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">Registrieren Sie den vCenter-Server mit dem MSA.</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">Nachdem JetStream DR MSA implementiert und der vCenter Server registriert wurde, navigieren Sie zum JetStream DR Plug-in mit dem vSphere Web Client. Dazu können Sie im Datacenter &gt; Configure &gt; JetStream DR navigieren.</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">Führen Sie über die JetStream DR-Schnittstelle die folgenden Aufgaben aus:</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">Fügen Sie den Azure Blob-Storage am Recovery-Standort hinzu.</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">Stellen Sie die erforderliche Anzahl an DR Virtual Appliances (DRVAs) über die Registerkarte Appliances bereit.</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">Verwenden Sie das Kapazitätsplanungs-Tool, um die Anzahl der benötigten DRVAs zu ermitteln.</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">Erstellen Sie Protokoll-Volumes für jedes DRVA unter Verwendung der VMDK aus den verfügbaren Datenspeichern oder dem unabhängigen gemeinsamen iSCSI-Speicherpool.</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">Erstellen Sie auf der Registerkarte geschützte Domänen die erforderliche Anzahl geschützter Domänen mithilfe von Informationen über die Azure Blob Storage-Site, die DRVA-Instanz und das Replikationsprotokoll. Eine geschützte Domäne definiert eine bestimmte VM oder einen Satz von Applikations-VMs innerhalb des Clusters, die gemeinsam gesichert werden und einer Prioritätsreihenfolge für Failover-/Failback-Vorgänge zugewiesen ist.</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">Wählen Sie die zu sichernden VMs aus und gruppieren Sie die VMs je nach Abhängigkeit in Applikationsgruppen. Anhand von Applikationsdefinitionen können Gruppen von VMs zu logischen Gruppen gruppiert werden, die ihre Boot-Aufträge, Boot-Verzögerungen und optionale Applikationsvalidierungen enthalten, die nach der Recovery ausgeführt werden können.</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">Vergewissern Sie sich, dass derselbe Sicherungsmodus für alle VMs in einer geschützten Domäne verwendet wird.</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">Write Back(VMDK)-Modus bietet eine höhere Performance.</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">Stellen Sie sicher, dass Replizierungs-Protokoll-Volumes auf hochperformanten Storage platziert werden.</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">Klicken Sie nach dem Abschluss auf Schutz für die geschützte Domäne starten. Damit wird die Datenreplizierung für die ausgewählten VMs auf den zugewiesenen Blob-Speicher gestartet.</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">Nach Abschluss der Replizierung wird der Sicherungsstatus der VM als wiederherstellbar markiert.</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">Failover-Runbooks können so konfiguriert werden, dass sie die VMs gruppieren (so genannte Recovery-Gruppe), die Boot-Reihenfolge festlegen und die CPU-/Speichereinstellungen zusammen mit den IP-Konfigurationen ändern.</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">Klicken Sie auf Einstellungen und dann auf den Link Runbook Configure, um die Runbook-Gruppe zu konfigurieren.</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">Klicken Sie auf die Schaltfläche Gruppe erstellen, um mit der Erstellung einer neuen Runbook-Gruppe zu beginnen.</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">Falls erforderlich, wenden Sie im unteren Teil des Bildschirms benutzerdefinierte Pre-scripts und Post-scripts an, um automatisch vor und nach dem Betrieb der Runbook-Gruppe auszuführen. Stellen Sie sicher, dass die Runbook-Skripte auf dem Management-Server residieren.</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">Bearbeiten Sie die VM-Einstellungen nach Bedarf. Geben Sie die Parameter für die Wiederherstellung der VMs an, einschließlich der Boot-Sequenz, der Boot-Verzögerung (angegeben in Sekunden), der Anzahl der CPUs und der zuzuzuzuzuzuzuzuzuzuzuzuzuzuweist. Ändern Sie die Boot-Sequenz der VMs, indem Sie auf die Pfeile nach oben oder unten klicken. Zur Aufbewahrung von MAC stehen auch Optionen zur Verfügung.</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">Statische IP-Adressen können manuell für die einzelnen VMs der Gruppe konfiguriert werden. Klicken Sie auf den Link „NIC-Ansicht“ einer VM, um die IP-Adresseinstellungen manuell zu konfigurieren.</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">Klicken Sie auf die Schaltfläche Konfigurieren, um die NIC-Einstellungen für die jeweiligen VMs zu speichern.</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">Der Status der Failover- und Failback-Runbooks wird nun als konfiguriert aufgeführt. Failover- und Failback-Runbook-Gruppen werden paarweise erstellt, wobei dieselbe erste Gruppe von VMs und Einstellungen verwendet wird. Bei Bedarf können die Einstellungen einer Runbook-Gruppe individuell angepasst werden, indem Sie auf den entsprechenden Link Details klicken und Änderungen vornehmen.</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">Installieren Sie JetStream DR für AVS in der Private Cloud</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">Eine Best Practice für einen Recovery-Standort (AVS) ist die Erstellung eines Pilotlichtclusters mit drei Knoten im Voraus. Dadurch kann die Infrastruktur am Recovery-Standort vorkonfiguriert werden, einschließlich:</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">Netzwerkzielsegmente, Firewalls, Services wie DHCP und DNS usw.</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">Konfiguration von ANF-Volumes als Datastores und mehr</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR unterstützt einen RTO-Modus von nahezu null für geschäftskritische Domänen. In diesen Domänen sollte der Ziel-Storage vorinstalliert sein. ANF ist in diesem Fall ein empfohlener Speichertyp.</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">Je nach SLA- und RTO-Anforderungen können Sie einen kontinuierlichen Failover oder einen normalen (Standard-) Failover-Modus verwenden. Bei einer RTO von nahezu null sollten Sie am Recovery-Standort mit der kontinuierlichen Rehydrierung beginnen.</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Verwenden Sie den Befehl Ausführen, um JetStream DR für AVS auf einer privaten Cloud der Azure VMware-Lösung zu installieren. Wählen Sie im Azure-Portal zur Azure VMware-Lösung die Private Cloud aus und wählen Sie Ausführen Command &gt; Packages &gt; JSDR.Configuration.</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">Der CloudAdmin-Standardbenutzer der Azure VMware-Lösung verfügt nicht über ausreichende Berechtigungen, um JetStream DR für AVS zu installieren. Die Azure VMware Lösung ermöglicht eine vereinfachte und automatisierte Installation von JetStream DR durch Aufrufen des Befehls Azure VMware Solution Run für JetStream DR.</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">Fügen Sie das Azure Blob Storage-Konto hinzu, das zur Sicherung des lokalen Clusters als Storage-Standort verwendet wurde, und starten Sie dann die Option Scan Domains.</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">Wählen Sie im angezeigten Popup-Dialogfeld die zu importierende geschützte Domäne aus, und klicken Sie anschließend auf den Link Importieren.</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">Die Domäne wird zur Wiederherstellung importiert. Gehen Sie auf die Registerkarte geschützte Domänen und überprüfen Sie, ob die vorgesehene Domäne ausgewählt wurde, oder wählen Sie die gewünschte aus dem Menü geschützte Domäne auswählen aus. Eine Liste der wiederherstellbaren VMs in der geschützten Domäne wird angezeigt.</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">Nachdem die geschützten Domains importiert wurden, sollten DRVA-Appliances bereitgestellt werden.</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">Diese Schritte können auch mithilfe von CPT- erstellten Plänen automatisiert werden.</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">Importieren Sie die geschützten Domänen und konfigurieren Sie die Recovery-VA, um einen ANF-Datenspeicher für VM-Platzierungen zu verwenden.</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">Stellen Sie sicher, dass DHCP für das ausgewählte Segment aktiviert ist und genügend IP-Adressen verfügbar sind. Dynamische IPs werden vorübergehend verwendet, während Domänen sich wiederherstellen. Jede wiederherzuckernde VM (einschließlich kontinuierlicher Rehydrierung) erfordert eine individuelle dynamische IP-Adresse. Nach Abschluss der Wiederherstellung wird die IP freigegeben und kann wiederverwendet werden.</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">Obwohl sich der kontinuierliche Failover- und Failover-Modus bei der Konfiguration unterscheiden, werden beide Failover-Modi mit den gleichen Schritten konfiguriert. Failover-Schritte werden als Reaktion auf ein Notfall konfiguriert und durchgeführt. Ein kontinuierlicher Failover kann jederzeit konfiguriert werden und dann im Hintergrund während des normalen Systembetriebs ausgeführt werden. Nach einem Zwischenfall wird der fortlaufende Failover abgeschlossen, sodass die Eigentümerschaft der geschützten VMs direkt auf den Recovery-Standort übertragen wird (RTO von nahezu null).</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">Der kontinuierliche Failover-Prozess beginnt und der Fortschritt kann über die UI überwacht werden. Durch Klicken auf das blaue Symbol im Abschnitt „Aktueller Schritt“ wird ein Popup-Fenster angezeigt, in dem Details zum aktuellen Schritt des Failover-Prozesses angezeigt werden.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">Failover und Failback</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">Nach einem Ausfall im geschützten Cluster der lokalen Umgebung (teilweiser oder kompletter Ausfall) können Sie das Failover für VMs auslösen. Dazu verwenden Sie Jetstream, nachdem die SnapMirror Beziehung für die jeweiligen Applikations-Volumes unterbrochen wurde.</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">Dieser Schritt kann zur Erleichterung des Recovery-Prozesses einfach automatisiert werden.</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">Greifen Sie auf die Jetstream UI auf dem AVS SDDC (Zielseite) zu und lösen Sie die Failover-Option aus, um den Failover abzuschließen. Die Taskleiste zeigt den Fortschritt für Failover-Aktivitäten an.</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">Im Dialogfeld, das beim Abschluss des Failover angezeigt wird, kann die Failover-Aufgabe als geplant oder als erzwungen angegeben werden.</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">Erzwungenes Failover geht davon aus, dass auf den primären Standort nicht mehr zugegriffen werden kann und die Eigentümerschaft der geschützten Domäne direkt vom Recovery-Standort übernommen werden muss.</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">Nachdem der kontinuierliche Failover abgeschlossen ist, wird eine Meldung angezeigt, die den Abschluss der Aufgabe bestätigt. Nach Abschluss der Aufgabe greifen Sie auf die wiederhergestellten VMs zu, um ISCSI- oder NFS-Sitzungen zu konfigurieren.</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">Der Failover-Modus wird in Failover ausgeführt, und der Status der VM ist wiederherstellbar. Alle VMs der geschützten Domäne werden jetzt am Recovery-Standort in dem von den Failover-Runbook-Einstellungen angegebenen Zustand ausgeführt.</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">Um die Failover-Konfiguration und die Infrastruktur zu überprüfen, kann JetStream DR im Testmodus (Option Test Failover) betrieben werden, um die Wiederherstellung von Virtual Machines und deren Daten vom Objektspeicher in einer Test-Recovery-Umgebung zu beobachten. Wenn ein Failover-Verfahren im Testmodus ausgeführt wird, ähnelt sein Vorgang einem tatsächlichen Failover-Prozess.</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">Sobald die Virtual Machines wiederhergestellt sind, wird Disaster Recovery für Storage auf dem Gast-Storage eingesetzt. Um diesen Prozess zu demonstrieren, wird SQL-Server in diesem Beispiel verwendet.</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">Melden Sie sich bei der wiederhergestellten SnapCenter-VM auf dem AVS SDDC an und aktivieren Sie den DR-Modus.</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">Greifen Sie über Browsern auf die SnapCenter-Benutzeroberfläche zu.</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">Navigieren Sie auf der Seite Einstellungen zu Einstellungen &gt; Globale Einstellungen &gt; Disaster Recovery.</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">Wählen Sie Disaster Recovery Aktivieren.</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">Klicken Sie Auf Anwenden.</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">Überprüfen Sie, ob der DR-Job aktiviert ist, indem Sie auf Überwachen &gt; Jobs klicken.</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">Für das Storage Disaster Recovery sollte NetApp SnapCenter 4.6 oder höher verwendet werden. Frühere Versionen sollten applikationskonsistente Snapshots (replizierte mit SnapMirror) verwenden und ein manuelles Recovery ausführen, falls frühere Backups am Disaster Recovery-Standort wiederhergestellt werden müssen.</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">Stellen Sie sicher, dass die SnapMirror Beziehung beschädigt ist.</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Verbinden Sie die LUN aus Cloud Volumes ONTAP mit der wiederhergestellten SQL Gast-VM mit gleichen Laufwerksbuchstaben.</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">Öffnen Sie den iSCSI-Initiator, löschen Sie die vorherige getrennte Sitzung und fügen Sie das neue Ziel zusammen mit Multipath für die replizierten Cloud Volumes ONTAP Volumes hinzu.</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">Stellen Sie sicher, dass alle Laufwerke mit denselben Laufwerksbuchstaben verbunden sind, die vor DR verwendet wurden.</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">Starten Sie den MSSQL-Serverdienst neu.</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">Stellen Sie sicher, dass die SQL-Ressourcen wieder online sind.</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">Hängen Sie im Fall von NFS die Volumes mit dem Mount-Befehl an, und aktualisieren Sie die<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Einträge.</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">An diesem Punkt können Betriebsabläufe ausgeführt werden und der Geschäftsbetrieb normal weiterläuft.</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">Am NSX-T-Ende kann ein separates, dediziertes Tier-1 Gateway zur Simulation von Failover-Szenarien erstellt werden. So ist sichergestellt, dass alle Workloads miteinander kommunizieren können, dass jedoch kein Traffic in die bzw. aus der Umgebung geleitet werden kann. So können alle Triage-, Containment- oder Härteaufgaben ohne das Risiko einer Kreuzkontamination durchgeführt werden. Dieser Vorgang ist außerhalb des Anwendungsbereichs dieses Dokuments, kann aber problemlos zur Simulation der Isolation durchgeführt werden.</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">Wenn der primäre Standort wieder in Betrieb ist, können Sie ein Failback durchführen. Die VM-Sicherung wird durch Jetstream fortgesetzt, und die SnapMirror Beziehung muss umgekehrt werden.</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">Wiederherstellung der lokalen Umgebung Je nach Art des Notfalleinfalls sind möglicherweise die Wiederherstellung und/oder Überprüfung der Konfiguration des geschützten Clusters erforderlich. Falls erforderlich, muss die JetStream DR-Software möglicherweise erneut installiert werden.</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">Mit dem CPT-generierten Failback-Plan kann außerdem die Rückgabe der VMs und ihrer Daten aus dem Objektspeicher in die ursprüngliche VMware Umgebung initiiert werden.</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">Geben Sie die maximale Verzögerung an, nachdem Sie die VMs am Recovery-Standort angehalten und am geschützten Standort neu gestartet haben. Die zum Abschluss dieses Prozesses erforderliche Zeit umfasst das Abschließen der Replizierung nach dem Stoppen von Failover-VMs, die zum Reinigen des Recovery-Standorts benötigte Zeit und die Zeit zur Wiederherstellung von VMs am geschützten Standort. NetApp empfiehlt 10 Minuten.</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">Schließen Sie den Failback-Prozess ab, und bestätigen Sie anschließend die Wiederaufnahme des VM-Schutzes und der Datenkonsistenz.</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">Nachdem die VMs wiederhergestellt wurden, trennen Sie den sekundären Storage vom Host und stellen eine Verbindung zum primären Storage her.</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">Vergewissern Sie sich, dass die SQL-Ressourcen wieder online sind.</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">Für ein Failback auf den primären Storage sollten Sie sicherstellen, dass die Beziehungsrichtung vor dem Failover unverändert bleibt, indem Sie einen umgekehrten Resynchronisierungsvorgang durchführen.</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">Um die Rollen des primären und sekundären Storage nach der umgekehrten Resynchronisierung beizubehalten, führen Sie den umgekehrten Resync-Vorgang erneut aus.</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">Dieser Prozess gilt für andere Applikationen wie Oracle, ähnliche Datenbankumgebungen und andere Applikationen, die mit Gast-vernetztem Storage verwenden.</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">Testen Sie wie immer die Schritte zur Wiederherstellung der kritischen Workloads, bevor Sie sie in die Produktionsumgebung portieren.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">Vorteile dieser Lösung</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">Nutzt die effiziente und ausfallsichere Replizierung von SnapMirror</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">Wiederherstellung zu beliebigen verfügbaren Zeitpunkten mit ONTAP Snapshot Aufbewahrung</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">Eine vollständige Automatisierung steht für alle erforderlichen Schritte zur Wiederherstellung von Hunderten bis Tausenden von VMs zur Verfügung – von den Schritten für Storage, Computing, Netzwerk und Applikationen.</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter nutzt Klonmechanismen, die das replizierte Volume nicht ändern.</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">So wird das Risiko einer Beschädigung von Daten von Volumes und Snapshots vermieden.</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">Keine Replizierungsunterbrechungen während der DR-Test-Workflows</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">Nutzung der DR-Daten für Workflows über DR hinaus, wie Entwicklung/Test, Sicherheitstests, Patch- und Upgrade-Tests und Korrekturtests</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">CPU- und RAM-Optimierung können die Cloud-Kosten senken, indem Recovery auf kleinere Computing-Cluster ermöglicht wird.</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">NetApp Storage-Optionen für Public-Cloud-Provider</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">Entdecken Sie die Optionen für NetApp als Storage in den drei wichtigsten Hyperscalern.</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS unterstützt NetApp Storage in den folgenden Konfigurationen:</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="list-text">FSX ONTAP als Storage mit Gastverbunden</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP als zusätzlichen NFS-Datastore</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">Storage-Optionen für VMC für Gastverbindung</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">Zusätzliche NFS-Datastore-Optionen für VMC</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">Details anzeigen <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>. Details anzeigen <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>.</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure/AVS</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">Details anzeigen <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>. Details anzeigen <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud unterstützt NetApp Storage in den folgenden Konfigurationen:</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="list-text">Cloud Volumes Service (CVS) als Storage mit Gastverbunden</block>
  <block id="efe20646a1138596f4f7b7f387cae230" category="list-text">Cloud Volumes Service (CVS) als zusätzlicher NFS-Datastore^1^</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">Speicheroptionen für die Gastverbindung für GCVE</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">Details anzeigen <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>.</block>
  <block id="e7e05ca1857ad4b0e930d0672e7657c4" category="inline-link-macro">Cloud Volumes Service (CVS) als zusätzlicher NFS-Datastore^1</block>
  <block id="8bde1a7decedb03d4e5ae4c5b6c9f5d3" category="paragraph">Weitere Informationen <block ref="d54e964e36cd6cf7ab87b4b420d12109" category="inline-link-macro-rx"></block>.</block>
  <block id="c567300e15e9f9b873771e56c72c938b" category="admonition">1 - Zurzeit in der privaten Vorschau</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">Überblick über NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">Die meisten IT-Abteilungen verfolgen den Hybrid-Cloud-First-Ansatz. Diese Unternehmen befinden sich in einer Transformationsphase, und Kunden bewerten ihre aktuelle IT-Umgebung und migrieren ihre Workloads anschließend anhand des Assessments und der Bestandsaufnahme in die Cloud.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">Zu den Faktoren für Kunden, die eine Migration zur Cloud durchführen, gehören Flexibilität und Burst, der Ausstieg aus dem Datacenter, die Datacenter-Konsolidierung, End-of-Life-Szenarien, Fusionen, Firmenübernahmen usw. Der Grund für diese Migration kann je nach Unternehmen und ihren jeweiligen Geschäftsprioritäten variieren. Beim Wechsel in die Hybrid Cloud ist die Wahl des richtigen Storage in der Cloud sehr wichtig, um die Vorteile der Cloud-Implementierung und -Flexibilität auszuschöpfen.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">VMware Cloud-Optionen in der Public Cloud</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">avs</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware Lösung ist ein Hybrid-Cloud-Service, der VMware SDDC innerhalb der Public Cloud Microsoft Azure vollständig nutzt. Azure VMware Solution ist eine Komplettlösung, die vollständig von Microsoft gemanagt und unterstützt wird und die von VMware unter Verwendung der Azure Infrastruktur verifiziert wurde. Das heißt, Unternehmen können bei der Implementierung der Azure VMware Lösung ESXi für Computing-Virtualisierung nutzen, vSAN für hyperkonvergenten Storage. NSX für Networking und Sicherheit, gleichzeitig aber auch die globale Präsenz von Microsoft Azure, erstklassige Datacenter-Einrichtungen und die Nähe zum umfassenden Ecosystem aus nativen Azure-Services und -Lösungen.</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="section-title">VMware Cloud auf AWS</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">vmc</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud auf AWS ermöglicht die Software SDDC der Enterprise-Klasse von VMware in der AWS Cloud mit optimiertem Zugriff auf native AWS Services. VMware Cloud auf AWS basiert auf VMware Cloud Foundation und integriert die Computing-, Storage- und Netzwerkvirtualisierungsprodukte von VMware (VMware vSphere, VMware vSAN und VMware NSX) in Kombination mit dem VMware vCenter Server-Management, das für die Ausführung auf einer dedizierten, flexiblen Bare-Metal-Infrastruktur von AWS optimiert ist.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware Engine</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">Gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine ist ein IaaS-Angebot (Infrastruktur als Service), das auf der enorm performanten skalierbaren Infrastruktur von Google Cloud und dem VMware Cloud Foundation Stack – VMware vSphere, vCenter, vSAN und NSX-T. – basiert Dieser Service ermöglicht einen schnellen Pfad zur Cloud und eine nahtlose Migration oder Erweiterung vorhandener VMware Workloads von On-Premises-Umgebungen auf die Google Cloud Platform – ohne die Kosten, den Aufwand oder das Risiko einer Umstrukturierung von Applikationen oder Neuwerkzeugen. Es handelt sich um einen Service, der von Google vertrieben und unterstützt wird und eng mit VMware zusammenarbeitet.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">Die Private Cloud SDDC und NetApp Cloud Volumes Colocation bieten optimale Performance bei minimaler Netzwerklatenz.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">Wussten Sie schon?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">Unabhängig von der verwendeten Cloud umfasst der erste Cluster bei Implementierung eines VMware SDDC die folgenden Produkte:</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">VMware ESXi Hosts für die Computing-Virtualisierung mit einer vCenter Server Appliance zum Management</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">VMware vSAN hyperkonvergenter Storage mit den physischen Storage-Ressourcen des jeweiligen ESXi Hosts</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">VMware NSX für virtuelles Networking und Sicherheit mit einem NSX Manager Cluster für Management</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Storage-Konfiguration</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">Wenn Kunden planen, Storage-intensive Workloads zu hosten und horizontal auf jeder Cloud-gehosteten VMware Lösung zu skalieren, schreibt die hyperkonvergente Standardinfrastruktur vor, dass die Erweiterung sowohl auf die Computing- als auch auf die Storage-Ressourcen erfolgen sollte.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Durch die Integration mit NetApp Cloud Volumes, z. B. Azure NetApp Files, Amazon FSX für NetApp ONTAP, Cloud Volumes ONTAP (verfügbar für alle drei gängigen Hyperscaler) und Cloud Volumes Service für Google Cloud, haben Kunden nun die Möglichkeit, ihren Storage unabhängig voneinander zu skalieren. Sie fügen dann nach Bedarf nur noch Computing-Nodes zum SDDC-Cluster hinzu.</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware empfiehlt keine unausgeglichenen Cluster-Konfigurationen, daher bedeutet Erweiterung des Storage das Hinzufügen weiterer Hosts, was zu höheren TCO führt.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">Es ist nur eine vSAN Umgebung möglich. Der gesamte Storage Traffic steht somit direkt mit den Produktions-Workloads im Wettbewerb.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">Es besteht keine Option, mehrere Performance-Tiers bereitzustellen, um Applikationsanforderungen, Performance und Kosten anzupassen.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">Es ist sehr einfach, die Storage-Kapazitäten von vSAN, das auf den Cluster-Hosts aufgebaut ist, zu erreichen. Verwenden Sie NetApp Cloud Volumes, um Storage zu skalieren, um entweder aktive Datensätze zu hosten oder kühlere Daten auf persistenten Storage zu verschieben.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSX für NetApp ONTAP, Cloud Volumes ONTAP (verfügbar für alle drei gängigen Hyperscaler) und Cloud Volumes Service für Google Cloud können zusammen mit Gast-VMs verwendet werden. Diese Hybrid-Storage-Architektur besteht aus einem vSAN Datastore, der das Gastbetriebssystem und Binärdaten der Applikationen enthält. Die Applikationsdaten sind über einen Gast-basierten iSCSI-Initiator oder die NFS/SMB-Mounts mit der VM verbunden, die direkt mit Amazon FSX für NetApp ONTAP, Cloud Volume ONTAP, Azure NetApp Files und Cloud Volumes Service für Google Cloud kommunizieren. Mit dieser Konfiguration lassen sich Herausforderungen mit Storage-Kapazität wie mit vSAN bewältigen. Der verfügbare freie Speicherplatz hängt von den eingesetzten Rack-Flächen und Storage-Richtlinien ab.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">Betrachten wir ein SDDC-Cluster mit drei Nodes auf VMware Cloud auf AWS:</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">Die gesamte Rohkapazität eines SDDC mit drei Nodes = 31,1 TB (ca. 10 TB pro Node).</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">Der zu pflegende Slack-Platz bevor zusätzliche Hosts hinzugefügt werden = 25% = (0,25 x 31,1 TB) = 7,7 TB.</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">Die nutzbare Bruttokapazität nach Abzug des Speicherplatzes = 22,4 TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">Der verfügbare effektive freie Speicherplatz hängt von der angewandten Storage-Richtlinie ab.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Beispiel:</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = effektiver freier Speicherplatz = 22,4 TB (nutzbare Bruttokapazität/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = effektiver freier Speicherplatz = 11,7 TB (nutzbare Rohkapazität/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = effektiver freier Speicherplatz = 17,5 TB (nutzbare Bruttokapazität/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">Daher würde eine Nutzung von NetApp Cloud Volumes als Storage mit Gastverbunden helfen, den Storage zu erweitern und die TCO zu optimieren, während gleichzeitig die Anforderungen an Performance und Datensicherung erfüllt werden.</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">Die Option in-Guest Storage war zum Zeitpunkt der Erstellung dieses Dokuments die einzige verfügbare. Sobald eine zusätzliche Unterstützung für einen NFS-Datastore verfügbar wird, wird eine zusätzliche Dokumentation verfügbar sein <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>.</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">Platzieren Sie in Hybrid-Storage-Modellen Tier-1- oder Workloads mit hoher Priorität auf vSAN Datastore, um alle spezifischen Latenzanforderungen abzudecken, da diese Teil des Hosts selbst und in der Nähe sind. Nutzung von in-Guest-Mechanismen für alle Workload-VMs, für die transaktionsorientierte Latenzen akzeptabel sind</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">NetApp SnapMirror Technologie ermöglicht die Replizierung der Workload-Daten vom lokalen ONTAP System auf Cloud Volumes ONTAP oder Amazon FSX für NetApp ONTAP, um die Migration mithilfe von Mechanismen auf Blockebene zu vereinfachen. Dies gilt nicht für Azure NetApp Files und Cloud Volumes Services. Für die Migration von Daten zu Azure NetApp Files oder Cloud Volumes Services verwenden Sie je nach verwendetem Dateiprotokoll NetApp XCP, Cloud Sync, rysnc oder robocopy.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">Bei den Tests wird eine zusätzliche Latenz von 2 bis 4 ms angezeigt, während der Zugriff auf Storage von den jeweiligen SDDCs erfolgt. Berücksichtigen Sie diese zusätzliche Latenz bei der Zuordnung des Storage in die Applikationsanforderungen.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">Um mit dem Gast verbundenen Storage während des Test Failover und des tatsächlichen Failover zu mounten, stellen Sie sicher, dass iSCSI-Initiatoren neu konfiguriert sind, DNS für SMB-Freigaben aktualisiert wird und die NFS-Mount-Punkte in fstab aktualisiert werden.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">Vergewissern Sie sich, dass die Registry-Einstellungen für Microsoft Multipath I/O (MPIO), Firewall und Festplatten-Timeout innerhalb der VM ordnungsgemäß konfiguriert sind.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">Dies bezieht sich ausschließlich auf den zu Gast verbundenen Speicher.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">Vorteile von NetApp Cloud Storage</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">NetApp Cloud Storage bietet folgende Vorteile:</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">Verbessert die Dichte von Computing zu Storage durch Skalierung des Storage unabhängig vom Computing.</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">Ermöglicht Ihnen eine Verringerung der Host-Anzahl und somit eine Reduzierung der TCO insgesamt.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">Ein Ausfall des Computing-Nodes hat keine Auswirkungen auf die Storage-Performance.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">Mit der Volume-Umgestaltung und den dynamischen Service Level-Funktionen von Azure NetApp Files können Sie die Kosten optimieren, indem Sie die Größe für stabilen Workloads dimensionieren und so die Überprovisionierung verhindern.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Die Cloud Volumes ONTAP Funktionen für Storage-Effizienz, Cloud-Tiering und Instanztypen erlauben das optimale Hinzufügen und Skalieren von Storage.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">Verhindert, dass überprovisioniert wird, dass Storage-Ressourcen nur bei Bedarf hinzugefügt werden.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">Mit effizienten Snapshot-Kopien und Klonen können Sie schnell und ohne Performance-Einbußen Kopien erstellen.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Ransomware-Angriffe werden mit einer schnellen Recovery aus Snapshot-Kopien beheben.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">Effizientes, inkrementelles, blockbasiertes regionales Disaster Recovery und integrierte Backup-Blockebene über Regionen hinweg sorgen für bessere RPO und RTOs.</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">SnapMirror Technologie oder andere relevante Datenmigrationsmechanismen werden aktiviert. Es gibt viele Konnektivitätsoptionen – vor Ort und in beliebigen Hyperscaler-Clouds. Verwenden Sie den entsprechenden Pfad, und arbeiten Sie mit den entsprechenden Netzwerkteams zusammen.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">Wenden Sie sich an NetApp Solution Architects und zugehörige Hyperscaler-Cloud-Architekten, um Storage und die erforderliche Anzahl von Hosts zu planen und zu dimensionieren. NetApp empfiehlt die Ermittlung der Anforderungen an die Storage-Performance, bevor das Cloud Volumes ONTAP-Sizer verwendet wird, um den Instanztyp oder das entsprechende Service Level mit dem richtigen Durchsatz abzuschließen.</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">Im allgemeinen wird mit dieser Architektur (in der Abbildung unten dargestellt) erläutert, wie sich Hybrid-Multi-Cloud-Konnektivität und App-Portabilität über diverse Cloud-Provider hinweg erreichen lässt, die NetApp Cloud Volumes ONTAP, Cloud Volumes Service für Google Cloud und Azure NetApp Files als zusätzliche Option für Gast-Storage verwenden.</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">Hybrid Cloud-Architektur Der Enterprise-Klasse</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">NetApp Hybrid-Multi-Cloud-Lösungen für GCP/GCVE</block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">NetApp Funktionen für die Google Cloud Platform GSCVE</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">Erfahren Sie mehr über die Funktionen, die NetApp für die Google Cloud Platform (GCP) bietet Google Cloud Virtualization Engine (GCVE) – von NetApp als Storage-Gerät mit Gastverbunden oder als zusätzlicher NFS Datastore für die Migration von Workflows, Erweiterung/Bursting in die Cloud, Backup/Restore und Disaster Recovery.</block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="inline-link-macro">GCVE wird in GCP konfiguriert</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="inline-link-macro">NetApp Storage-Optionen für GCVE</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie GCVE einrichten und managen und in Kombination mit den verfügbaren Optionen zum Verbinden von NetApp Storage verwenden.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">Der in-Guest-Speicher ist die einzige unterstützte Methode zum Verbinden von Cloud Volumes ONTAP und Cloud Volumes Services mit GCVE.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="list-text">Bereitstellen und Konfigurieren von GCVE</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="list-text">Aktivieren Sie den privaten Zugriff auf GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">Konfigurationsschritte für GCVE</block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">Details anzeigen <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>.</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">NetApp Storage kann in GCP GCVE auf verschiedene Weise genutzt werden – entweder als „Raten“ verbunden oder als zusätzlicher NFS-Datenspeicher.</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">Details anzeigen <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>.</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">Informieren Sie sich über die NetApp Lösungen für Google Cloud GCVE</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">NetApp Lösungen für die Google Cloud Virtualization Engine (GCVE)</block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">Erfahren Sie mehr über die Lösungen von NetApp für GCP.</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="inline-link-macro">Disaster Recovery für Applikationen mit SnapCenter, Cloud Volumes ONTAP und Veeam Replication</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">Regionale Verfügbarkeit – ergänzender NFS-Datastore für Google Cloud Platform (GCP)</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">Die Verfügbarkeit von zusätzlichen NFS-Datenspeichern auf GCP / GCVE ist durch Google festgelegt. Zunächst müssen Sie feststellen, ob GCVE und CVS in einer bestimmten Region verfügbar sind. Als Nächstes müssen Sie feststellen, ob der CVS zusätzliche NFS-Datastore in dieser Region unterstützt wird.</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">Prüfen Sie die Verfügbarkeit von GCVE und CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">Prüfen Sie die Verfügbarkeit des zusätzlichen CVS NFS Datastore <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">NetApp zusätzliche NFS-Datastore-Optionen für GCP</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Implementieren und Konfigurieren der Virtualisierungsumgebung auf der Google Cloud Platform (GCP)</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">Wie bei vor Ort ist die Planung der Google Cloud VMware Engine (GCVE) entscheidend für eine erfolgreiche produktionsbereite Umgebung für das Erstellen von VMs und die Migration.</block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">GCVE bereitstellen und konfigurieren</block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">Um eine GCVE-Umgebung auf GCP zu konfigurieren, melden Sie sich bei der GCP-Konsole an und greifen Sie auf das VMware Engine-Portal zu.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">Klicken Sie auf die Schaltfläche „Neue private Cloud“ und geben Sie die gewünschte Konfiguration für die GCVE Private Cloud ein. Achten Sie beim „Standort“ darauf, die Private Cloud in derselben Region/Zone, in der CVS/CVO implementiert wird, zu implementieren, um die beste Performance und die niedrigste Latenz zu gewährleisten.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">Voraussetzungen:</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">Einrichtung der IAM-Rolle des VMware Engine Service Admin</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">VMware Engine-API-Zugriff und Node-Kontingent aktivieren</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">Stellen Sie sicher, dass der CIDR-Bereich nicht mit Ihren lokalen oder Cloud-Subnetzen überlappt. Der CIDR-Bereich muss /27 oder höher sein.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">Hinweis: Die Erstellung einer privaten Cloud kann zwischen 30 Minuten und 2 Stunden dauern.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">Konfigurieren Sie nach der Bereitstellung der Private Cloud den privaten Zugriff auf die Private Cloud für eine Verbindung mit hohem Durchsatz und niedriger Latenz.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP-Dokumentation</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">Dadurch wird sichergestellt, dass das VPC-Netzwerk, auf dem Cloud Volumes ONTAP-Instanzen ausgeführt werden, mit der GCVE Private Cloud kommunizieren kann. Folgen Sie dazu dem <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. Richten Sie für den Cloud Volume Service eine Verbindung zwischen VMware Engine und Cloud Volumes Service ein, indem Sie einmalig zwischen den Mandanten-Host-Projekten Peering durchführen. Gehen Sie wie folgt vor, um ausführliche Schritte zu erhalten <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">Melden Sie sich mit dem CloudOwner@gve.local-Benutzer bei vcenter an. Rufen Sie das VMware Engine Portal auf, rufen Sie zu Ressourcen auf und wählen Sie die entsprechende Private Cloud aus. Klicken Sie im Abschnitt grundlegende Informationen auf den Link Anzeigen, um die vCenter-Anmeldedaten (vCenter Server, HCX Manager) oder NSX-T-Anmeldeinformationen (NSX Manager) anzuzeigen.</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Öffnen Sie in einer virtuellen Windows-Maschine einen Browser, und navigieren Sie zur vCenter Web-Client-URL <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> Verwenden Sie dann den Admin-Benutzernamen als CloudOwner@gve.local, und fügen Sie das kopierte Passwort ein. Auf ähnliche Weise kann auch NSX-T-Manager über die Web-Client-URL zugegriffen werden <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> Und verwenden Sie den Admin-Benutzernamen und fügen Sie das kopierte Passwort ein, um neue Segmente zu erstellen oder die vorhandenen Tier-Gateways zu ändern.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">Wenn Sie ein lokales Netzwerk zur Private Cloud der VMware Engine verbinden möchten, nutzen Sie Cloud-VPN oder Cloud Interconnect, um entsprechende Konnektivität zu erhalten und stellen sicher, dass die erforderlichen Ports geöffnet sind. Gehen Sie wie folgt vor, um ausführliche Schritte zu erhalten <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="doc">NetApp Storage-Optionen für GCP</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">Die GCP unterstützt NetApp Storage mit Anbindung an den Gast-Storage über Cloud Volumes ONTAP (CVO) oder Cloud Volumes Service (CVS).</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="example-title">Implementierung von Cloud Volumes ONTAP in der Google Cloud (Do IT Yourself)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Cloud Volumes ONTAP-Freigaben und LUNs können von VMs gemountet werden, die in der GCVE Private Cloud-Umgebung erstellt wurden. Die Volumes können auch auf dem Linux-Client und auf dem Windows-Client eingebunden werden, wobei auf LUNS unter Linux- oder Windows-Clients als Blockgeräte zugegriffen werden kann, wenn sie über iSCSI gemountet werden, da Cloud Volumes ONTAP iSCSI-, SMB- und NFS-Protokolle unterstützt. Cloud Volumes ONTAP Volumes lassen sich in wenigen einfachen Schritten einrichten.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">Wenn Sie Volumes aus einer lokalen Umgebung für Disaster Recovery- oder Migrationszwecke in die Cloud replizieren möchten, richten Sie Netzwerkkonnektivität mit Google Cloud ein, entweder über ein Site-to-Site VPN oder ein Cloud Interconnect. Die Replizierung von Daten zwischen On-Premises-Systemen und Cloud Volumes ONTAP ist im Rahmen dieses Dokuments nicht enthalten. Informationen zur Replizierung von Daten zwischen On-Premises- und Cloud Volumes ONTAP-Systemen finden Sie unter <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Klicken Sie auf der Registerkarte „Canvas“ auf „Arbeitsumgebung hinzufügen“ und wählen Sie dann Google Cloud Platform als Cloud und den Typ der Systemkonfiguration aus. Klicken Sie anschließend auf Weiter.</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">Geben Sie die Details zur zu erstellenden Umgebung an, einschließlich Name der Umgebung und Anmeldedaten des Administrators. Klicken Sie nach dem Abschluss auf Weiter.</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">Wählen Sie die Add-on-Services für die Cloud Volumes ONTAP-Bereitstellung aus, einschließlich Data Sense &amp; Compliance oder Backup in der Cloud. Klicken Sie anschließend auf Weiter.</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">HINWEIS: Beim Deaktivieren von Add-On-Diensten wird eine Pop-up-Meldung zur Überprüfung angezeigt. Add-on-Services können nach der CVO-Implementierung hinzugefügt/entfernt werden. Ziehen Sie in Erwägung, diese Services von Anfang an zu deaktivieren, wenn sie nicht benötigt werden, um Kosten zu vermeiden.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">Wählen Sie einen Speicherort aus, wählen Sie eine Firewallrichtlinie aus und aktivieren Sie das Kontrollkästchen, um die Netzwerkverbindung zu Google Cloud Storage zu bestätigen.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">Wählen Sie die Lizenzoption: Pay-as-you-Go oder BYOL für die Nutzung vorhandener Lizenz. In diesem Beispiel wird die Freimium-Option verwendet. Klicken Sie anschließend auf Weiter.</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">Wählen Sie zwischen mehreren vorkonfigurierten Paketen, die auf Grundlage des Workload-Typs verfügbar sind, die auf den VMs implementiert werden, die auf der VMware Cloud auf dem AWS SDDC ausgeführt werden.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">HINWEIS: Ziehen Sie Ihre Maus über die Kacheln, um Details zu erhalten, oder passen Sie die CVO-Komponenten und die ONTAP-Version an, indem Sie auf Konfiguration ändern klicken.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">Prüfen und bestätigen Sie die Auswahl auf der Seite Prüfen &amp; Genehmigen.zum Erstellen der Cloud Volumes ONTAP-Instanz klicken Sie auf Los.</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">HINWEIS: Klicken Sie auf das Menü-Symbol (º), wählen Sie Erweitert, um weitere Optionen anzuzeigen, und wählen Sie CIFS-Setup.</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">Das Erstellen des SMB Volume ist einfach. Doppelklicken Sie auf Canvas auf die Cloud Volumes ONTAP-Arbeitsumgebung, um Volumes zu erstellen und zu verwalten, und klicken Sie auf die Option „Volume erstellen“. Wählen Sie die entsprechende Größe und Cloud Manager wählt das Aggregat aus, das Sie enthalten, oder verwenden Sie den erweiterten Zuweisungsmechanismus auf einem bestimmten Aggregat. Für diese Demo wird CIFS/SMB als Protokoll ausgewählt.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">TIPP: Klicken Sie auf das Menü Volume (º), um seine Optionen anzuzeigen.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">Nach der Erstellung des Volumes zeigen Sie mit dem Befehl Mount die Anweisungen zur Volume-Verbindung an und stellen dann eine Verbindung mit der Freigabe von den VMs auf der Google Cloud VMware Engine her.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">Kopieren Sie den folgenden Pfad und verwenden Sie die Option Netzlaufwerk zuordnen, um das Volume auf der VM zu mounten, die auf der Google Cloud VMware Engine ausgeführt wird.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">Nach dem Mapping kann man leicht darauf zugreifen, und die NTFS-Berechtigungen können entsprechend eingestellt werden.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="example-title">Verbinden Sie die LUN auf Cloud Volumes ONTAP mit einem Host</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Führen Sie die folgenden Schritte aus, um die Cloud Volumes ONTAP-LUN mit einem Host zu verbinden:</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">Nachdem das Volume bereitgestellt wurde, wählen Sie das Menü Volume (º) aus, und klicken Sie dann auf Ziel-IQN. Um den iSCSI-qualifizierten Namen (IQN) zu kopieren, klicken Sie auf Kopieren. Richten Sie eine iSCSI-Verbindung vom Host zur LUN ein.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Für den Host, der sich auf der Google Cloud VMware Engine befindet, gilt dasselbe:</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">RDP auf die VM gehostet auf Google Cloud VMware Engine.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Der Windows-Host muss über eine iSCSI-Verbindung zu jedem Knoten im Cluster verfügen. Das native DSM wählt die besten Pfade aus.</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">Befolgen Sie die Anweisungen im Assistenten. In diesem Beispiel ist Laufwerk F: Angehängt.</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Stellen Sie auf den Linux-Clients sicher, dass der iSCSI-Daemon ausgeführt wird. Sobald die LUNs bereitgestellt sind, lesen Sie als Beispiel hier die detaillierte Anleitung zur iSCSI-Konfiguration mit Ubuntu. Führen Sie zur Überprüfung lsblk cmd aus der Shell aus.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="example-title">Mounten Sie das Cloud Volumes ONTAP NFS Volume auf dem Linux Client</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">So mounten Sie das Cloud Volumes ONTAP-Dateisystem (DIY) von VMs in der Google Cloud VMware Engine:</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">Stellen Sie das Volume gemäß den nachstehenden Schritten bereit</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">Klicken Sie auf der Registerkarte Volumes auf Neues Volume erstellen .</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">Wählen Sie auf der Seite Neues Volume erstellen einen Volume-Typ aus:</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">Legen Sie auf der Registerkarte Volumes den Mauszeiger über die Lautstärke, wählen Sie das Menüsymbol (º) und klicken Sie dann auf Mount Command.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">Klicken Sie auf Kopieren .</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">Stellen Sie eine Verbindung mit der angegebenen Linux-Instanz her.</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Öffnen Sie ein Terminal auf der Instanz mithilfe von Secure Shell (SSH), und melden Sie sich mit den entsprechenden Anmeldedaten an.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">Erstellen Sie mit dem folgenden Befehl ein Verzeichnis für den Mount-Punkt des Volumes.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">Mounten Sie das Cloud Volumes ONTAP-NFS-Volume in das Verzeichnis, das im vorherigen Schritt erstellt wurde.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service (CVS)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud Volumes Services (CVS) ist ein umfassendes Portfolio von Datenservices für erweiterte Cloud-Lösungen. Cloud Volumes Services unterstützt diverse Dateizugriffsprotokolle für wichtige Cloud-Provider (NFS- und SMB-Unterstützung).</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">Weitere Vorteile und Funktionen sind Datensicherung und -Wiederherstellung mit Snapshot, besondere Features für Replizierung, Synchronisierung und Migration von Datenzielen auf On-Premises- oder Cloud-Basis sowie eine konsistent hohe Performance auf dem Niveau eines dedizierten Flash-Storage-Systems.</block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="example-title">Konfiguration von Cloud Volumes Service mit der VMware Engine</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Cloud Volumes Service Shares können von VMs gemountet werden, die in der VMware Engine Umgebung erstellt wurden. Die Volumes können auch auf dem Linux-Client eingebunden und auf dem Windows-Client zugeordnet werden, da Cloud Volumes Service SMB- und NFS-Protokolle unterstützt. Cloud Volumes Service Volumes lassen sich in einfachen Schritten einrichten.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service und Google Cloud VMware Engine Private Cloud müssen sich in derselben Region befinden.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">Begleiten</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Im folgenden Dokument können Sie NetApp Cloud Volumes Service für Google Cloud über den Google Cloud Marketplace erwerben, aktivieren und konfigurieren <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="example-title">Erstellen eines CVS NFS-Volumes in die GCVE Private Cloud</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">Führen Sie folgende Schritte aus, um NFS-Volumes zu erstellen und einzubinden:</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Zugriff auf Cloud Volumes über Partnerlösungen finden Sie über die Google Cloud-Konsole.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Rufen Sie in der Cloud Volumes Console die Seite Volumes auf und klicken Sie auf Erstellen.</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">Geben Sie auf der Seite Create File System den Namen des Volumes und die Rechnungs-Labels an, die für Chargeback-Mechanismen erforderlich sind.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">Wählen Sie den entsprechenden Service aus. Wählen Sie für GCVE CVS-Performance und das gewünschte Service-Level aus, um basierend auf den Applikations-Workload-Anforderungen die Latenz und eine höhere Performance zu verbessern.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">Legen Sie die Google Cloud-Region für den Volume- und Volume-Pfad fest (der Volume-Pfad muss für alle Cloud Volumes im Projekt eindeutig sein).</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">Wählen Sie das Performance-Level für das Volume aus.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">Geben Sie die Größe des Volume und den Protokolltyp an. In diesem Test wird NFSv3 verwendet.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">In diesem Schritt wählen Sie das VPC-Netzwerk aus, auf das das Volume zugegriffen werden soll. VPC-Peering sicherstellen.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">HINWEIS: Falls VPC-Peering nicht durchgeführt wurde, wird ein Pop-up-Button angezeigt, der Sie durch die Peering-Befehle leitet. Öffnen Sie eine Cloud-Shell-Sitzung und führen Sie die entsprechenden Befehle aus, um mit Cloud Volumes Service Producer Ihre VPC zu tauschen. Falls Sie sich dazu entschließen, das VPC-Peering vorab vorzubereiten, lesen Sie diese Anweisungen.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">Managen Sie die Exportrichtlinien, indem Sie die entsprechenden Regeln hinzufügen, und aktivieren Sie das Kontrollkästchen für die entsprechende NFS-Version.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">Hinweis: Der Zugriff auf NFS-Volumes ist erst möglich, wenn eine Exportrichtlinie hinzugefügt wird.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Klicken Sie auf Speichern, um das Volume zu erstellen.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="example-title">Mounten von NFS-Exporten auf VMs, die auf der VMware Engine ausgeführt werden</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">Stellen Sie vor dem Bereitstellen des NFS-Volumes sicher, dass der Peering-Status der privaten Verbindung als aktiv aufgeführt ist. Sobald der Status „aktiv“ lautet, verwenden Sie den Befehl „Mount“.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">Gehen Sie zum Mounten eines NFS-Volumes wie folgt vor:</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">Wechseln Sie in der Cloud Console zu Cloud Volumes &gt; Volumes.</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Wechseln Sie zur Seite Volumes</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">Klicken Sie auf das NFS-Volumen, für das Sie NFS-Exporte mounten möchten.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">Scrollen Sie nach rechts unter Mehr anzeigen auf Mount Instructions.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">So führen Sie den Montageprozess innerhalb des Gastbetriebssystems der VMware VM aus:</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">Verwenden Sie SSH Client und SSH für die virtuelle Maschine.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">installieren Sie den nfs-Client auf der Instanz.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Auf Red hat Enterprise Linux oder SUSE Linux-Instanz:</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Auf einer Ubuntu oder Debian-Instanz:</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">Erstellen Sie ein neues Verzeichnis auf der Instanz, z. B. „/nimCVSNFSol01“:</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">Mounten Sie den Volume mit dem entsprechenden Befehl. Beispiel-Befehl aus dem Labor ist unten:</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="example-title">Erstellen und Mounten von SMB-Share an VMs, die auf VMware Engine ausgeführt werden</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">Vergewissern Sie sich bei SMB-Volumes, dass die Active Directory-Verbindungen vor dem Erstellen des SMB-Volume konfiguriert sind.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">Sobald die AD-Verbindung hergestellt ist, erstellen Sie das Volume mit dem gewünschten Service-Level. Die Schritte sind wie die Erstellung eines NFS-Volume, außer Auswahl des entsprechenden Protokolls.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">Wählen Sie den entsprechenden Service aus. Wählen Sie für GCVE CVS-Performance und den gewünschten Service Level aus, um basierend auf den Workload-Anforderungen die Latenz und eine höhere Performance zu verbessern.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">Geben Sie die Größe des Volume und den Protokolltyp an. In diesem Test wird SMB verwendet.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">Anweisungen</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">HINWEIS: Falls VPC-Peering nicht durchgeführt wurde, wird ein Pop-up-Button angezeigt, der Sie durch die Peering-Befehle leitet. Öffnen Sie eine Cloud-Shell-Sitzung und führen Sie die entsprechenden Befehle aus, um mit Cloud Volumes Service Producer Ihre VPC zu tauschen. Falls Sie sich dazu entschließen, VPC Peering vorab vorzubereiten, lesen Sie diese <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">Gehen Sie zum Mounten des SMB-Volumes wie folgt vor:</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">Klicken Sie auf das SMB-Volume, für das eine SMB-Freigabe zugeordnet werden soll.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">So führen Sie den Einmounten innerhalb des Windows Gastbetriebssystems der VMware VM durch:</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">Klicken Sie auf die Schaltfläche Start und dann auf Computer.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">Klicken Sie Auf Netzlaufwerk Zuordnen.</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">Klicken Sie in der Liste Laufwerk auf einen beliebigen verfügbaren Laufwerksbuchstaben.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">Geben Sie im Feld Ordner Folgendes ein:</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">Aktivieren Sie das Kontrollkästchen bei der Anmeldung erneut verbinden, um jedes Mal eine Verbindung herzustellen.</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">Klicken Sie Auf Fertig Stellen.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz von Workloads vor Standortausfällen und Datenbeschädigungen wie Ransomware. Mit NetApp SnapMirror können lokale VMware Workloads, die Storage mit Anbindung des Gastspeichers verwenden, auf NetApp Cloud Volumes ONTAP repliziert werden, die in Google Cloud ausgeführt werden.</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">Autoren: Suresh ThopPay, NetApp</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">Disaster Recovery in die Cloud ist eine stabile und kostengünstige Möglichkeit zum Schutz von Workloads vor Standortausfällen und Datenbeschädigungen wie Ransomware. Mit NetApp SnapMirror können lokale VMware Workloads, die Storage mit Anbindung des Gastspeichers verwenden, auf NetApp Cloud Volumes ONTAP repliziert werden, die in Google Cloud ausgeführt werden. Dies bezieht sich auf Applikationsdaten, doch was ist mit den eigentlichen VMs selbst. Disaster Recovery sollte alle abhängigen Komponenten, einschließlich Virtual Machines, VMDKs, Applikationsdaten und mehr, abdecken. Dazu kann SnapMirror zusammen mit Veeam verwendet werden, um Workloads, die von On-Premises zu Cloud Volumes ONTAP repliziert wurden, nahtlos wiederherzustellen und gleichzeitig mit vSAN Storage für VM-VMDKs zu verwenden.</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">Dieses Dokument bietet eine Schritt-für-Schritt-Methode zum Einrichten und Durchführen von Disaster-Recovery mit NetApp SnapMirror, Veeam und der Google Cloud VMware Engine (GCVE).</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">Für die Verbindung zwischen der lokalen Umgebung und dem Google Cloud-Netzwerk können Sie die Konnektivitätsoptionen wie dediziertes Interconnect oder Cloud VPN verwenden. Segmente sollten basierend auf dem lokalen VLAN-Design erstellt werden.</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">Es gibt mehrere Optionen, um On-Premises-Datacenter mit Google Cloud zu verbinden, was uns daran hindert, einen bestimmten Workflow in diesem Dokument zu beschreiben. Die entsprechende On-Premises-zu-Google-Verbindungsmethode finden Sie in der Google Cloud-Dokumentation.</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Installieren Sie die Veeam Software und beginnen Sie mit der Replizierung von Virtual Machines zu Google Cloud VMware Engine Instanz.</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">Brechen Sie während eines Notfallereignisses die SnapMirror Beziehung mithilfe von Cloud Manager auf und lösen Sie das Failover von Virtual Machines mit Veeam aus.</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">Anwendungen online schalten.</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Konfiguration von CVO auf Google Cloud und Replizierung von Volumes zu CVO</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">cvo</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">Als ersten Schritt müssen Sie Cloud Volumes ONTAP auf Google Cloud konfigurieren <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>) Und replizieren Sie die gewünschten Volumen zu Cloud Volumes ONTAP mit den gewünschten Frequenzen und Snapshot-Aufbewahrung.</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">Einrichtung der Replikation mit SnapCenter</block>
  <block id="8064e6b40ef12da2c44763dcfe735ae8" category="paragraph">Eine Schritt-für-Schritt-Anleitung zum Einrichten von SnapCenter und Replizieren der Daten finden Sie unter<block ref="68793c30d3c5e8a024de6c79bc478fe1" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">Konfigurieren Sie GCVE-Hosts und CVO-Datenzugriff</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">Zwei wichtige Faktoren, die bei der Implementierung des SDDC berücksichtigt werden müssen, sind die Größe des SDDC-Clusters in der GCVE-Lösung und die Dauer, bis das SDDC den Betrieb aufrecht erhalten hat. Diese beiden wichtigen Überlegungen für eine Disaster-Recovery-Lösung tragen zur Senkung der Gesamtbetriebskosten bei. Das SDDC kann mit nur drei Hosts eingerichtet sein und bis hin zu einem Cluster mit mehreren Hosts in einer umfassenden Implementierung.</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">Cloud Volumes ONTAP kann in jede VPC implementiert werden und GCVE sollte über eine private Verbindung zu dieser VPC verfügen, damit VM-Verbindung mit iSCSI-LUNs hergestellt werden kann.</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">Informationen zum Konfigurieren von GCVE SDDC finden Sie unter<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>. Überprüfen Sie als Voraussetzung, ob die Gast-VMs auf den GCVE-Hosts nach dem Einrichten der Konnektivität Daten von Cloud Volumes ONTAP nutzen können.</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Nachdem Cloud Volumes ONTAP und GCVE ordnungsgemäß konfiguriert wurden, beginnen Sie mit der Konfiguration von Veeam, um die Wiederherstellung lokaler Workloads auf GCVE (VMs mit Applikations-VMDKs und VMs mit in-Guest-Storage) zu automatisieren. Dazu nutzen Sie die Veeam Replication-Funktion und können SnapMirror für Applikations-Volumes-Kopien in Cloud Volumes ONTAP nutzen.</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Veeam Komponenten Installieren</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">Das Installationsverfahren finden Sie in der Veeam-Dokumentation</block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">VM Replication mit Veeam einrichten</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">VSphere VM Replication Job einrichten</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">VCenter vor Ort und GCVE vCenter müssen bei Veeam registriert werden.<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> Wählen Sie im Assistenten zur Gastverarbeitung die Option Anwendungsverarbeitung deaktivieren, da wir SnapCenter für applikationsgerechtes Backup und Recovery verwenden werden.</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Failover von Microsoft SQL Server VM</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">Veeam Replication ermöglicht das Ändern der VM-IP-Adressen am DR-Standort.</block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">Unterstütze Konfigurationen für NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">Verstehen der Kombinationen für den Support von NetApp Storage in den wichtigsten Hyperscalern.</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*Gast Verbunden*</block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">*Ergänzende NFS-Datastore*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">*AWS*</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">CVO FSX-ONTAP<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">FSX ONTAP<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">*Azure*</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">CVO ANF<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="7ddf4642a2bfdc9a45847e5d375a1ddb" category="inline-link-macro">Details^2</block>
  <block id="9b5e2f812e05038b9b432b2e47e60e83" category="cell">ANF<block ref="982de57bbd4b4909ca13b7582da5a7cb" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">*GCP*</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVO CVS<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="1d2f8b078a75242901e868e7bd66ab6b" category="inline-link-macro">Details^3</block>
  <block id="ef1c4ae5f356b44ca460e3aaf7bf2a32" category="cell">CVS<block ref="3317ea58799e6c9da952335ff4000296" category="inline-link-macro-rx"></block></block>
  <block id="6830947ed88b541bd76da4fcd40e36de" category="paragraph">HINWEIS: 1 - zur Zeit in erster Verfügbarkeit (IA) 2 - zur Zeit in der öffentlichen Vorschau 3 - zur Zeit in der privaten Vorschau</block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">Zusammenfassung und Schlussfolgerung: Warum NetApp Hybrid Multicloud mit VMware</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">NetApp Cloud Volumes bietet zusammen mit VMware Lösungen für die wichtigsten Hyperscaler ein großes Potenzial für Unternehmen, die Hybrid Cloud nutzen möchten. Der Rest dieses Abschnitts enthält die Nutzungsfälle, in denen die Integration von NetApp Cloud Volumes echte Hybrid-Multi-Cloud-Funktionen ermöglicht.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">Anwendungsfall #1: Storage-Optimierung</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">Bei einer Größenbemessung mit RVTools-Ausgabe ist es immer offensichtlich, dass die leistungsstarke Skalierung (vCPU/Vmem) parallel zum Storage erfolgt. Viele Unternehmen stellen sich in einer Situation wieder fest, dass durch den Storage-Platzbedarf die Größe des Clusters deutlich größer ist als für jede Leistung nötig.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">Durch die Integration von NetApp Cloud Volumes können Unternehmen eine auf vSphere basierende Cloud-Lösung mit einem einfachen Migrationsansatz realisieren, ohne dass eine neue Plattform erforderlich ist oder IP-Änderungen vorgenommen werden müssen. Zudem ermöglicht diese Optimierung eine Skalierung des Storage-Platzbedarfs, während die Host-Anzahl auf die geringste Menge in vSphere beschränkt wird, jedoch keine Änderung der Storage-Hierarchie, der Sicherheit oder der verfügbaren Dateien vorgenommen werden muss. Somit können Sie die Implementierung optimieren und die Gesamtbetriebskosten um 35 bis 45 % senken. Dank dieser Integration ist außerdem die Möglichkeit möglich, in Sekundenschnelle Storage von warmen Storage-Ressourcen auf Produktionsebene zu skalieren.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">Anwendungsfall #2: Cloud-Migration</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">Unternehmen stehen unter dem Druck, Applikationen aus verschiedenen Gründen von lokalen Datacentern in die Public Cloud zu migrieren: Zu einem bevorstehenden Ablauf des Leasing-Vertrags, zu einer Finanzrichtlinie zur Ausgabenübernahme (Investitions-) in Betriebskosten oder einfach zu einem Top-down-Auftrag, um alles in die Cloud zu verschieben.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">Wenn Geschwindigkeit entscheidend ist, ist nur ein optimierter Migrationsansatz möglich, da die Rekonfiguration und Refakturierung von Anwendungen zur Anpassung an die spezielle IaaS-Plattform der Cloud langsam und teuer ist und oft Monate in Anspruch nimmt. Durch die Kombination von NetApp Cloud Volumes mit der bandbreiteneffizienten SnapMirror Replizierung für Storage mit Anbindung an den Gast-Storage (einschließlich RDMs in Verbindung mit applikationskonsistenten Snapshot Kopien und HCX, Cloud-spezifische Migration (z. B. Azure Migrate) oder Produkte von Drittanbietern zur Replizierung von VMs) ist dieser Wechsel noch einfacher, als auf zeitaufwändige I/O-Filtermechanismen zurückgreifen zu müssen.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">Anwendungsfall #3: Datacenter-Erweiterung</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">Wenn in einem Datacenter aufgrund von saisonalen Bedarfsspitzen oder einem stabilen organischen Wachstum Kapazitätsgrenzen erreicht werden, ist der Wechsel zu VMware in Cloud-Umgebungen zusammen mit NetApp Cloud Volumes eine einfache Lösung. Der Einsatz von NetApp Cloud Volumes ermöglicht das sehr einfache Erstellen, Replizieren und erweitern von Storage, da über Verfügbarkeitszonen hinweg Hochverfügbarkeit und dynamische Skalierungsfunktionen sichergestellt sind. Mithilfe von NetApp Cloud Volumes minimieren Sie die Host-Cluster-Kapazität, da es dafür keine Stretch-Cluster mehr braucht.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">Anwendungsfall #4: Disaster Recovery in der Cloud</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">Bei einem herkömmlichen Ansatz würden im Falle eines Ausfalls die in die Cloud replizierten VMs vor der Wiederherstellung auf die Cloud eigene Hypervisor-Plattform umgewandelt werden müssen – und das in einer Krise nicht.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">Durch den Einsatz von NetApp Cloud Volumes für miteinander verbundenen Storage mit SnapCenter und SnapMirror Replizierung aus lokalen Systemen sowie mit Public-Cloud-Virtualisierungslösungen lässt sich ein besserer Disaster-Recovery-Ansatz entwickeln, der die Wiederherstellung von VM-Replikaten in einer vollständig konsistenten VMware SDDC-Infrastruktur sowie Cloud-spezifischen Recovery-Tools (z. B. Azure Site Recovery) oder vergleichbare Tools anderer Hersteller wie Veeam Dieser Ansatz unterstützt Sie auch bei der schnellen Durchführung von Disaster-Recovery-Prozessen und Recovery von Ransomware. Außerdem lassen sich dank bedarfsorientierter Hosts die gesamte Produktion zu Testzwecken oder bei einem Ausfall skalieren.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">Anwendungsfall #5: Applikationsmodernisierung</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">Sobald Applikationen in der Public Cloud bereitgestellt wurden, möchten Unternehmen die zahlreichen leistungsstarken Cloud-Services nutzen, um sie zu modernisieren und zu erweitern. Mit NetApp Cloud Volumes ist eine Modernisierung ein einfacher Prozess, da die Applikationsdaten nicht in vSAN geschützt sind. Außerdem ermöglicht sie Datenmobilität für zahlreiche Anwendungsfälle, einschließlich Kubernetes.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">Egal, ob Sie eine All-Cloud oder eine Hybrid Cloud abzielen – NetApp Cloud Volumes bietet Ihnen hervorragende Optionen für die Implementierung und das Management von Applikations-Workloads zusammen mit Fileservices und Blockprotokollen. Gleichzeitig reduziert es die TCO, indem die Datenanforderungen nahtlos auf die Applikationsebene übertragen werden.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">Welche Anwendungsfälle auch immer sind: Wählen Sie Ihre bevorzugten Cloud/Hyperscaler zusammen mit NetApp Cloud Volumes, um schnell von den Vorteilen der Cloud zu profitieren, konsistente Infrastruktur und Abläufe zwischen On-Premises- und diversen Clouds, bidirektionaler Portabilität von Workloads sowie Kapazität und Performance der Enterprise-Klasse zu profitieren.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">Es handelt sich dabei um denselben bekannten Prozess und dieselben Verfahren, mit denen der Speicher verbunden wird. Denken Sie daran, es ist nur die Position der Daten, die sich mit neuen Namen geändert haben. NetApp Cloud Volumes bleiben dieselben Tools und Prozesse, und NetApp Cloud Volumes helfen bei der Optimierung der generellen Implementierung.</block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">Anwendungsfälle für NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">Ein Überblick über die Anwendungsfälle, die für DIE IT-Abteilung bei der Planung von Hybrid-Cloud- oder Cloud-First-Implementierungen von Bedeutung sind</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">Gängige Anwendungsfälle</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">Anwendungsfälle:</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">Disaster Recovery,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">Hosting von Workloads während der Rechenzentrumswartung, * schneller Burst, in dem zusätzliche Ressourcen über die im lokalen Rechenzentrum bereitgestellten Ressourcen erforderlich sind,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware-Site-Erweiterung,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">Schnelle Migration in die Cloud,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">Entwicklung/Test und</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">Modernisierung von Applikationen mithilfe von zusätzlichen Cloud-Technologien</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">In der gesamten Dokumentation werden die Referenzen für Cloud-Workloads anhand der VMware Anwendungsfälle detailliert beschrieben. Anwendungsfälle sind:</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">In DER IT-Entwicklung</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">Die meisten Unternehmen befinden sich auf dem Weg zur Transformation und Modernisierung. Im Rahmen dieses Prozesses versuchen Unternehmen, ihre vorhandenen VMware Investitionen zu nutzen und gleichzeitig von den Vorteilen der Cloud zu profitieren und Möglichkeiten für eine nahtlose Migration zu entdecken. Durch diesen Ansatz würde sich ihre Modernisierungsbemühungen sehr vereinfachen, da sich die Daten bereits in der Cloud befinden.</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">Die einfachste Antwort auf dieses Szenario sind die Angebote von VMware in jedem Hyperscaler. Wie bei NetApp Cloud Volumes bietet VMware eine Möglichkeit, lokale VMware Umgebungen in jede Cloud zu verschieben oder zu erweitern. So können Sie vorhandene Ressourcen, Fachkenntnisse und Tools weiterhin nutzen, während Sie Workloads nativ in der Cloud ausführen. Das verringert die Risiken, da keine Serviceunterbrechungen oder IP-Änderungen erforderlich sind. Das IT-Team kann so unter Verwendung vorhandener Fachkenntnisse und Tools vor Ort Verfahren. Dies ermöglicht beschleunigte Cloud-Migrationen und einen viel reibungsloseren Übergang zu einer Hybrid Multi Cloud Architektur.</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">Bedeutung von zusätzlichen NFS-Storage-Optionen</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">Während VMware in jeder Cloud seinen Kunden einzigartige Hybrid-Funktionen bietet, haben begrenzte zusätzliche NFS-Storage-Optionen den Nutzen für Unternehmen mit Storage-lastigen Workloads eingeschränkt. Da Storage direkt an Hosts gebunden ist, besteht die einzige Möglichkeit zur Skalierung von Storage darin, weitere Hosts hinzuzufügen. Die Kosten können bei Storage-intensiven Workloads um 35 bis 40 % oder mehr gesenkt werden. Diese Workloads erfordern nur zusätzlichen Storage und keine zusätzliche Leistung. Aber das bedeutet, dass zusätzliche Hosts bezahlt werden.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">Betrachten wir das folgende Szenario:</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">Ein Kunde benötigt nur fünf Hosts für CPU und Arbeitsspeicher, hat aber hohe Storage-Anforderungen und benötigt 12 Hosts, um die Storage-Anforderungen zu erfüllen. Diese Anforderung kippt letztlich in Richtung Finanzskalierung, indem sie zusätzliche Leistung kaufen müssen, wenn sie nur den Storage erhöhen müssen.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">Wenn Sie Cloud-Einführung und -Migrationen planen, ist es immer wichtig, den besten Ansatz zu bewerten und den einfachsten Weg zu gehen, der die Gesamtinvestitionen reduziert. Der gängigste und einfachste Ansatz für jede Applikationsmigration besteht in Rehosting (auch bekannt als „Lift and Shift“), in dem keine Virtual Machine (VM) oder Datenkonvertierung vorhanden ist. NetApp Cloud Volumes mit dem softwaredefinierten Datacenter (SDDC) von VMware und ergänzen vSAN und bieten eine einfache „Lift-and-Shift“-Option.</block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">Konfiguration der Virtualisierungsumgebung beim Cloud-Provider</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">Im Folgenden werden Details zur Konfiguration der Virtualisierungsumgebung für jeden der unterstützten Hyperscaler erläutert.</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie VMware Cloud auf AWS SDDC einrichten und managen und es in Kombination mit den verfügbaren Optionen zur Verbindung von NetApp Storage nutzen.</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">Der in-Guest Storage ist die einzige unterstützte Methode zur Verbindung von Cloud Volumes ONTAP mit AWS VMC.</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">Implementieren und Konfigurieren von VMware Cloud für AWS</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="list-text">Verbinden Sie VMware Cloud mit FSX ONTAP</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">Konfigurationsschritte für VMC</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">Details anzeigen <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>.</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">Details anzeigen <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>.</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">Details anzeigen <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>.</block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS ist ein Distributed File System-Protokoll. Es handelt sich um einen offenen IETF-Standard, der in Request for Comments (RFC) definiert ist und unter dem jeder dieses Protokoll implementieren kann.</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">Früher: Grundlagen von NAS-Protokollen_overview.</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">Volumes in Cloud Volumes Service werden für NFS-Clients freigegeben, indem ein Pfad exportiert wird, der für einen Client oder eine Gruppe von Clients zugänglich ist. Die Berechtigungen zum Mounten dieser Exporte werden durch Richtlinien und Regeln für den Export definiert, die von Cloud Volumes Service-Administratoren konfiguriert werden können.</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">Die NetApp NFS-Implementierung gilt als Gold-Standard für das Protokoll und wird in unzähligen Enterprise-NAS-Umgebungen eingesetzt. In den folgenden Abschnitten werden NFS, spezifische Sicherheitsfunktionen in Cloud Volumes Service sowie deren Implementierung behandelt.</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">Lokale UNIX-Standardbenutzer und -Gruppen</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service enthält mehrere UNIX Standard-Benutzer und -Gruppen für verschiedene grundlegende Funktionen. Diese Benutzer und Gruppen können derzeit nicht geändert oder gelöscht werden. Neue lokale Benutzer und Gruppen können derzeit nicht zu Cloud Volumes Service hinzugefügt werden. UNIX-Benutzer und -Gruppen außerhalb der Standardbenutzer und -Gruppen müssen von einem externen LDAP-Namensdienst bereitgestellt werden.</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">Die folgende Tabelle zeigt die Standardbenutzer und -Gruppen sowie die zugehörigen numerischen IDs. NetApp empfiehlt, keine neuen Benutzer oder Gruppen in LDAP oder auf den lokalen Clients zu erstellen, die diese numerischen IDs erneut verwenden.</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">Standardbenutzer: Numerische IDs</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">Standardgruppen: Numerische IDs</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">Stammverzeichnis:0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">Pcuser:65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">Niemand:65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">Daemon: 1</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">Bei der Verwendung von NFSv4.1 wird der Root-Benutzer möglicherweise als niemand angezeigt, wenn er Verzeichnislisting-Befehle auf NFS-Clients ausführt. Dies liegt an der Konfiguration der ID-Domänenzuordnung des Clients. Siehe Abschnitt genannt <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> Finden Sie weitere Informationen zu diesem Problem und wie Sie es lösen können.</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">Der Root-Benutzer</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">In Linux hat das Root-Konto Zugriff auf alle Befehle, Dateien und Ordner in einem Linux-basierten Dateisystem. Aufgrund der Leistungsfähigkeit dieses Kontos müssen Benutzer häufig aufgrund von Best Practices für die Sicherheit deaktiviert oder auf irgendeine Weise eingeschränkt werden. Bei NFS-Exporten kann die Leistung, die ein Root-Benutzer über die Dateien und Ordner hat, im Cloud Volumes Service über Exportrichtlinien und -Regeln gesteuert werden. Auch das Konzept wird als Root Squash bezeichnet.</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">Setuid/setgid-Befehle (das klebrige Bit)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">Root-Squashing sorgt dafür, dass der Root-Benutzer, der auf eine NFS-Bereitstellung zugreift, auf den anonymen numerischen Benutzer 65534 (siehe Abschnitt „<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>“) und ist derzeit nur verfügbar, wenn CVS-Performance verwendet wird, indem Sie bei der Erstellung von Regeln für Exportrichtlinien aus für Root-Zugriff auswählen. Wenn der Root-Benutzer auf den anonymen Benutzer zerquetscht wird, hat er keinen Zugriff mehr auf das Ausführen von Chown oder<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> In Dateien oder Ordnern im NFS-Mount und Dateien oder Ordnern, die vom Root-Benutzer erstellt wurden, zeigen die Anon-UID als Eigentümer/Gruppe an. Darüber hinaus können NFSv4 ACLs nicht vom Root-Benutzer geändert werden. Der Root-Benutzer hat jedoch weiterhin Zugriff auf chmod und gelöschte Dateien, für die er keine expliziten Berechtigungen besitzt. Wenn Sie den Zugriff auf die Datei- und Ordnerberechtigungen eines Root-Benutzers beschränken möchten, ziehen Sie in Betracht, ein Volume mit NTFS ACLs zu verwenden und einen Windows-Benutzer mit dem Namen zu erstellen<block ref="63a9f0ea7bb98050796b649e85481845" prefix=" " category="inline-code"></block>, Und die gewünschten Berechtigungen auf die Dateien oder Ordner anwenden.</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">Der anonyme Benutzer</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">Die anonyme (anon) Benutzer-ID gibt eine UNIX-Benutzer-ID oder einen UNIX-Benutzernamen an, der Client-Anforderungen ohne gültige NFS-Anmeldeinformationen zugeordnet ist. Dies kann den Root-Benutzer einschließen, wenn Root-Squashing verwendet wird. Der anon-Benutzer in Cloud Volumes Service ist 65534.</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">Diese UID ist normalerweise dem Benutzernamen zugeordnet<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Oder<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> In Linux Umgebungen zu managen. Cloud Volumes Service verwendet auch 65534 als den lokalen UNIX-Benutzer` pcuser` (siehe Abschnitt “<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>“), der auch der Standard-Fallback-Benutzer für Windows auf UNIX-Namenszuordnungen ist, wenn kein gültiger übereinstimmender UNIX-Benutzer in LDAP gefunden werden kann.</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">Aufgrund der Unterschiede bei Benutzernamen in Linux und Cloud Volumes Service für UID 65534, konnte die Namenszeichenfolge für Benutzer, die 65534 zugeordnet sind, bei der Verwendung von NFSv4.1 nicht übereinstimmen. Dies könnte zu sehen sein<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Als Benutzer auf einigen Dateien und Ordnern. Siehe Abschnitt „<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>“ Für Informationen zu diesem Problem und zur Lösung dieses Problems.</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">Zugriffssteuerung/Exporte</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">Der erste Export-/Freigabzugriff für NFS-Mounts wird über hostbasierte Exportrichtlinien gesteuert, die in einer Exportrichtlinie enthalten sind. Eine Host-IP, ein Hostname, ein Subnetz, eine Netzwerkgruppe oder eine Domäne sind definiert, um den Zugriff auf die Bereitstellung der NFS-Freigabe und die Zugriffsebene zu ermöglichen, die dem Host erlaubt ist. Die Konfigurationsoptionen für die Exportrichtlinie hängen von der Cloud Volumes Service-Ebene ab.</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">Für CVS-SW stehen die folgenden Optionen für die Konfiguration von Exportrichtlinien zur Verfügung:</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*Client-Match.* kommagetrennte Liste von IP-Adressen, kommagetrennte Liste von Hostnamen, Subnetzen, Netzgruppen, Domain-Namen.</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">*RO/RW-Zugriffsregeln.* Wählen Sie Lese-/Schreibschutz oder Schreibschutz, um den Zugriff auf den Export zu steuern.CVS-Performance bietet die folgenden Optionen:</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">*RO/RW-Zugriffsregeln.* Wählen Sie Lese-/Schreibschutz oder Schreibschutz, um den Zugriff auf den Export zu steuern.</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*Root-Zugriff (ein/aus).* konfiguriert Root Squash (siehe Abschnitt „<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>„ Weitere Informationen).</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*Protokolltyp.* Dies beschränkt den Zugriff auf die NFS-Bereitstellung auf eine bestimmte Protokollversion. Wenn Sie sowohl NFSv3 als auch NFSv4.1 für das Volume angeben, lassen Sie entweder beide Felder leer oder aktivieren Sie beide Kontrollkästchen.</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">*Kerberos-Sicherheitsstufe (wenn Kerberos aktivieren ausgewählt ist).* bietet die Optionen von krb5, krb5i und/oder krb5p für schreibgeschützten oder schreibgeschützten Zugriff.</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">Eigentümerschaft (chown) und Change Group (chgrp) ändern</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">NFS auf Cloud Volumes Service ermöglicht es dem Root-Benutzer nur chown/chgrp auf Dateien und Ordnern auszuführen. Andere Benutzer sehen ein<block ref="7627e13d3e1910d7f604aa77914613da" prefix=" " category="inline-code"></block> Fehler – auch bei den eigenen Dateien. Wenn Sie Root Squash verwenden (wie im Abschnitt “ beschrieben<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>“), wird die Root zu einem nicht-Root-Benutzer gequetscht und darf keinen Zugriff auf Chown und chgrp haben. Derzeit gibt es in Cloud Volumes Service keine Problemumgehungen, um chown und chgrp für nicht-Root-Benutzer zu ermöglichen. Wenn Eigentumsänderungen erforderlich sind, ziehen Sie die Verwendung von doppelten Protokoll-Volumes in Erwägung und legen Sie den Sicherheitsstil auf NTFS fest, um die Berechtigungen von Windows-Seite aus zu steuern.</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">Berechtigungsmanagement</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service unterstützt beide Mode-Bits (z. B. 644, 777 usw. für rwx) und NFSv4.1 ACLs, um die Berechtigungen auf NFS-Clients für Volumes zu steuern, die den UNIX-Sicherheitsstil nutzen. Hierfür wird das standardmäßige Berechtigungsmanagement verwendet (z. B. chmod, chown oder nfs4_setfacl) und arbeitet mit jedem Linux-Client zusammen, der diese unterstützt.</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">Wenn Sie außerdem Dual-Protokoll-Volumes auf NTFS setzen, können NFS-Clients die Cloud Volumes Service-Namenszuweisung für Windows-Benutzer nutzen, die dann zur Behebung der NTFS-Berechtigungen verwendet werden. Dazu ist eine LDAP-Verbindung zu Cloud Volumes Service erforderlich, um numerische ID-zu-Benutzernamen-Übersetzungen bereitzustellen, da Cloud Volumes Service einen gültigen UNIX-Benutzernamen benötigt, um einen Windows-Benutzernamen korrekt zuzuordnen.</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">Bereitstellung granularer ACLs für NFSv3</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">Mode-Bit-Berechtigungen decken nur Besitzer, Gruppe und alle anderen in der Semantik ab. Dies bedeutet, dass für Basic NFSv3 keine granularen Benutzerzugriffskontrollen vorhanden sind. Cloud Volumes Service unterstützt weder POSIX ACLs noch erweiterte Attribute (wie z. B. Chattr), sodass granulare ACLs nur in den folgenden Szenarien mit NFSv3 möglich sind:</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">NTFS Security Style Volumes (CIFS Server erforderlich) mit gültigen Zuordnungen von UNIX zu Windows-Benutzern.</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">NFSv4.1 ACLs werden mithilfe eines Administrator-Clients unter Verwendung von NFSv4.1 angewendet.</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">„LDAP“</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">Beide Methoden erfordern eine LDAP-Verbindung für das UNIX-Identitätsmanagement und eine gültige UNIX-Benutzer- und Gruppeninformationen (siehe Abschnitt <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>) Und sind nur mit CVS-Performance Instanzen verfügbar. Um Volumes im NTFS-Sicherheitsstil mit NFS zu verwenden, müssen Sie Dual-Protokoll (SMB und NFSv3) oder Dual-Protokoll (SMB und NFSv4.1) verwenden, auch wenn keine SMB-Verbindungen hergestellt werden. Um NFSv4.1 ACLs für NFSv3-Mounts zu verwenden, müssen Sie auswählen<block ref="3e8ec25076adc34554202fd2df86b9b4" prefix=" " category="inline-code"></block> Als Protokolltyp.</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">nfs4_acl – NFSv4 Access Control-Listen</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">Normale UNIX Modus Bits bieten nicht die gleiche Granularitätsebene in Berechtigungen, die NTFS oder NFSv4.x ACLs bieten. In der folgenden Tabelle wird die Berechtigungsgranularität zwischen NFSv3-Modus-Bits und NFSv4.1 ACLs verglichen. Informationen zu NFSv4.1 ACLs finden Sie unter<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>.</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">Bits im NFSv3 Modus</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">NFSv4.1 ACLs</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">Legen Sie bei der Ausführung die Benutzer-ID fest</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">Legen Sie bei der Ausführung die Gruppen-ID fest</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">Getauschtes Text speichern (nicht in POSIX definiert)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">Leseberechtigung für Eigentümer</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">Schreibberechtigung für Eigentümer</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">Berechtigung für Eigentümer einer Datei ausführen oder die Berechtigung für Eigentümer im Verzeichnis suchen (suchen)</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">Berechtigung für Gruppe lesen</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">Schreibberechtigung für Gruppe</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">Berechtigung für eine Gruppe in einer Datei ausführen oder die Berechtigung für die Gruppe im Verzeichnis suchen (suchen)</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">Lesen Sie die Erlaubnis für andere</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">Schreibberechtigung für andere</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">Berechtigung für andere in einer Datei ausführen oder die Berechtigung für andere Personen im Verzeichnis suchen (suchen)</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">ACE-Typen (Access Control Entry) (allow/Deny/Audit) * Vererbung-Flags * Verzeichnis-Erben * Datei-Erben * No-propate-Erben * Erben-only</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">Berechtigungen * Read-Data (Files) / list-Directory (Verzeichnisse) * Write-Data (Files) / create-file (Directories) * append-Data (files) / create-Unterverzeichnis (Directories) * execute (files) / change-Directory (Directories) * delete * delete-child * read-attributes * write-named-aCLL * write-awned-attributes * read-ACL Synchronize-awner</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">Schließlich ist die NFS-Gruppenmitgliedschaft (sowohl in NFSv3 als AUCH NFSV4.x) auf ein Standardlimit von 16 für AUTH_SYS begrenzt, gemäß den RPC-Paketlimits. NFS Kerberos bietet bis zu 32 Gruppen und NFSv4 ACLs entfernen die Beschränkung durch granulare Benutzer- und Gruppen-ACLs (bis zu 1024 Einträge pro ACE).</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">Erstellen und Managen von NFS-Volumes</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">Darüber hinaus bietet Cloud Volumes Service erweiterte Gruppen-Support, um die maximal unterstützten Gruppen auf 32 zu erweitern. Dazu ist eine LDAP-Verbindung zu einem LDAP-Server erforderlich, der gültige UNIX-Benutzer- und Gruppenidentitäten enthält. Weitere Informationen zur Konfiguration finden Sie unter<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> In der Google-Dokumentation.</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">NFSv3-Benutzer- und Gruppen-IDs</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">NFSv3-Benutzer- und Gruppen-IDs kommen über das Netzwerk als numerische IDs und nicht als Namen. Cloud Volumes Service bietet keine Nutzername-Auflösung für diese numerischen IDs mit NFSv3, mit UNIX-Sicherheitsstil-Volumes mit Just-Mode-Bits. Wenn NFSv4.1 ACLs vorhanden sind, ist eine numerische ID-Suche und/oder Suche nach Namespace erforderlich, um die ACL ordnungsgemäß zu lösen – sogar bei Verwendung von NFSv3. Bei NTFS-Volumes im Sicherheitsstil muss Cloud Volumes Service eine numerische ID einem gültigen UNIX-Benutzer auflösen und dann einem gültigen Windows-Benutzer zuordnen, um Zugriffsrechte auszuhandeln.</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">Sicherheitseinschränkungen von NFSv3 Benutzer- und Gruppen-IDs</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">Bei NFSv3 müssen Client und Server niemals bestätigen, dass der Benutzer, der einen Lese- oder Schreibversuch mit einer numerischen ID versucht, ein gültiger Benutzer ist; er ist einfach implizit vertrauenswürdig. Das öffnet das Dateisystem bis zu potenziellen Verstößen, indem es einfach eine numerische ID vortäuscht. Um Sicherheitslücken wie diese zu verhindern, gibt es einige Optionen für Cloud Volumes Service.</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">Die Implementierung von Kerberos für NFS zwingt Benutzer, sich mit einem Benutzernamen und einem Kennwort oder einer Keytab-Datei zu authentifizieren, um ein Kerberos-Ticket für den Zugriff in einem Mount zu erhalten. Kerberos ist mit CVS-Performance-Instanzen und nur mit NFSv4.1 verfügbar.</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">Die Einschränkung der Liste der Hosts in Ihren Exportrichtlinien beschränkt die Grenzen, die NFSv3-Clients auf das Cloud Volumes Service-Volume zugreifen können.</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">Durch die Verwendung von Dual-Protokoll-Volumes und die Anwendung von NTFS-ACLs auf das Volume sind NFSv3-Clients gezwungen, numerische IDs auf gültige UNIX-Benutzernamen zu lösen, um sich für den ordnungsgemäßen Zugriff auf Mounts zu authentifizieren. Dazu muss LDAP aktiviert und UNIX-Benutzer- und Gruppenidentitäten konfiguriert werden.</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">Das Squashing des Root-Benutzers begrenzt den Schaden, den ein Root-Benutzer auf einen NFS-Mount tun kann, aber das Risiko wird nicht vollständig beseitigt. Weitere Informationen finden Sie im Abschnitt „<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>.“</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">Letztendlich ist die NFS-Sicherheit auf das beschränkt, was die Protokollversion verwendet, die Sie Angebote verwenden. NFSv3, obwohl mehr Performance im Allgemeinen als NFSv4.1, nicht dasselbe Maß an Sicherheit bietet.</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1 bietet im Vergleich zu NFSv3 eine höhere Sicherheit und Zuverlässigkeit. Dies hat folgende Gründe:</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">Integrierte Sperrung über einen Leasingbasierten Mechanismus</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">Statusorientierte Sessions</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">Alle NFS-Funktionen über einen einzelnen Port (2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">Nur TCP</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">ID-Domain-Zuordnung</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Kerberos Integration (NFSv3 kann Kerberos verwenden, aber nur für NFS, nicht für zusätzliche Protokolle wie NLM)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">NFSv4.1-Abhängigkeiten</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">Aufgrund der zusätzlichen Sicherheitsfunktionen in NFSv4.1 sind einige externe Abhängigkeiten beteiligt, die nicht für die Verwendung von NFSv3 benötigt wurden (ähnlich wie SMB Abhängigkeiten wie Active Directory erfordert).</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service bietet Unterstützung für NFSv4.x ACLs, die bestimmte Vorteile gegenüber normalen POSIX-Berechtigungen bieten, wie z. B.:</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">Granulare Steuerung des Benutzerzugriffs auf Dateien und Verzeichnisse</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">Bessere NFS-Sicherheit</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">Bessere Interoperabilität mit CIFS/SMB</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">Entfernung der NFS-Beschränkung von 16 Gruppen pro Benutzer mit AUTH_SYS-Sicherheit</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">ACLs umgehen die Notwendigkeit einer Gruppen-ID-Lösung (GID), die effektiv das GID limitNFSv4.1 ACLs werden von NFS-Clients gesteuert, nicht von Cloud Volumes Service. Um NFSv4.1 ACLs zu verwenden, stellen Sie sicher, dass die Softwareversion Ihres Clients sie unterstützt und die richtigen NFS-Dienstprogramme installiert sind.</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">Kompatibilität zwischen NFSv4.1 ACLs und SMB-Clients</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">NFSv4 ACLs unterscheiden sich von Windows ACLs auf Dateiebene (NTFS ACLs), haben aber ähnliche Funktionen. In NAS-Umgebungen mit mehreren Protokollen, wenn NFSv4.1 ACLs vorhanden sind und Sie Dual-Protokoll-Zugriff verwenden (NFS und SMB auf den gleichen Datensätzen), werden Clients mit SMB2.0 und später nicht in der Lage sein, ACLs von Windows-Sicherheitregisterkarten anzuzeigen oder zu verwalten.</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">Funktionsweise von NFSv4.1 ACLs</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">Als Referenz sind folgende Begriffe definiert:</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*Access control list (ACL).* eine Liste der Berechtigungs Einträge.</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*Zugangskontrolleintrag (ACE).* Ein Berechtigungseintrag in der Liste.</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">Wenn ein Client während einer SETATTR-Operation eine NFSv4.1-ACL für eine Datei setzt, setzt Cloud Volumes Service diese ACL für das Objekt und ersetzt eine vorhandene ACL. Wenn es keine ACL für eine Datei gibt, werden die Modus-Berechtigungen für die Datei von EIGENTÜMER@, GROUP@ und EVERYONE@ berechnet. Wenn SUID/SGID/STICKY Bits in der Datei vorhanden sind, sind diese nicht betroffen.</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">Wenn ein Client während einer GETATTR Operation eine NFSv4.1 ACL für eine Datei erhält, liest Cloud Volumes Service die mit dem Objekt verknüpfte NFSv4.1 ACL, erstellt eine Liste von Aces und gibt die Liste an den Client zurück. Wenn die Datei über eine NT ACL oder Mode Bits verfügt, wird eine ACL aus Modus-Bits erstellt und an den Client zurückgegeben.</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">Der Zugriff wird verweigert, wenn in der ACL ein ACE VERWEIGERN vorhanden ist; der Zugriff wird gewährt, wenn ACE ZULASSEN vorhanden ist. Der Zugang wird jedoch auch verweigert, wenn keines der Asse in der ACL vorhanden ist.</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">Ein Sicherheitsdeskriptor besteht aus einer Sicherheits-ACL (SACL) und einer Ermessensdatei (Discretionary ACL, DACL). Bei der Ausführung von NFSv4.1 mit CIFS/SMB ist die DACL 1-to-One-Zuordnung mit NFSv4 und CIFS. Die DACL besteht aus DEM ERLAUBEN und DEN LEUGNEN Assen.</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">Wenn ein einfaches<block ref="417e248f80c35ca0d471575a5fb951f5" prefix=" " category="inline-code"></block> Wird auf einer Datei oder einem Ordner mit NFSv4.1 ACLs gesetzt ausgeführt, bestehende Benutzer- und Gruppen-ACLs bleiben erhalten, aber der STANDARDEIGENTÜMER@, GROUP@, EVERYONE@ ACLs werden geändert.</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">Ervererbungsflaggen</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">Ein Client, der NFSv4.1 ACLs verwendet, kann ACLs für Dateien und Verzeichnisse auf dem System festlegen und anzeigen. Wenn eine neue Datei oder ein Unterverzeichnis in einem Verzeichnis erstellt wird, das über eine ACL verfügt, erbt dieses Objekt alle Asse in der ACL, die mit dem entsprechenden gekennzeichnet wurden<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>.</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">Wenn eine Datei oder ein Verzeichnis über eine NFSv4.1-ACL verfügt, wird diese ACL verwendet, um den Zugriff zu steuern, unabhängig davon, welches Protokoll für den Zugriff auf die Datei oder das Verzeichnis verwendet wird.</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">Dateien und Verzeichnisse erben Asse von NFSv4 ACLs auf übergeordneten Verzeichnissen (möglicherweise mit entsprechenden Änderungen), solange die Asse mit den korrekten Vererbung-Flags markiert wurden.</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">Wenn eine Datei oder ein Verzeichnis als Ergebnis einer NFSv4-Anforderung erstellt wird, hängt die ACL für die resultierende Datei oder das Verzeichnis davon ab, ob die Dateierstellungsanforderung eine ACL oder nur standardmäßige UNIX-Dateizugriffsberechtigungen enthält. Die ACL hängt auch davon ab, ob das übergeordnete Verzeichnis über eine ACL verfügt.</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">Wenn die Anforderung eine ACL enthält, wird diese ACL verwendet.</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">Wenn die Anforderung nur standardmäßige UNIX-Dateizugriffsberechtigungen enthält und das übergeordnete Verzeichnis keine ACL besitzt, wird der Client-Dateimodus verwendet, um standardmäßige UNIX-Dateizugriffsberechtigungen festzulegen.</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">Wenn die Anforderung nur Standardberechtigungen für den Zugriff auf UNIX-Dateien enthält und das übergeordnete Verzeichnis über eine nicht vererbbare ACL verfügt, wird eine Standard-ACL auf Basis der Mode-Bits, die an die Anforderung übergeben wurden, auf dem neuen Objekt festgelegt.</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">Wenn die Anforderung nur Standardzugriffsberechtigungen für UNIX-Dateien enthält, aber das übergeordnete Verzeichnis über eine ACL verfügt, werden die Asse in der ACL des übergeordneten Verzeichnisses von der neuen Datei oder dem neuen Verzeichnis geerbt, solange die Aces mit den entsprechenden Vererbung-Flags gekennzeichnet wurden.</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">ACE-Berechtigungen</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">WIE: Verwenden Sie NFSv4 ACL</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">Die Berechtigungen für NFSv4.1 ACLs verwenden eine Reihe von Groß- und Kleinbuchstaben (z. B.<block ref="a0331a73af55fd5fda99201f776e847c" prefix=" " category="inline-code"></block>) Um den Zugriff zu steuern. Weitere Informationen zu diesen Buchstabenwerten finden Sie unter<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>.</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">NFSv4.1 ACL-Verhalten mit Umask und ACL-Vererbung</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">NFSv4 ACLs bieten die Möglichkeit, eine ACL-Vererbung anzubieten</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">ACL-Vererbungskennzeichnung</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>. ACL-Vererbung bedeutet, dass Dateien oder Ordner, die unter Objekten mit NFSv4.1 ACLs-Satz erstellt wurden, die ACLs basierend auf der Konfiguration des erben können<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>.</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">Umfragen</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> Wird verwendet, um die Berechtigungsstufe zu steuern, auf der Dateien und Ordner in einem Verzeichnis ohne Administratorinteraktion erstellt werden. Standardmäßig können mit Cloud Volumes Service übernommene ACLs überschrieben werden. Dies ist ein erwartetes Verhalten wie per<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>.</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">ACL-Formatierung</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">NFSv4.1 ACLs haben bestimmte Formatierung. Das folgende Beispiel ist ein ACE-Satz für eine Datei:</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">Das vorangegangene Beispiel folgt den Richtlinien im ACL-Format von:</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">Einen Typ von<block ref="7fc56270e7a70fa81a5935b72eacbe29" prefix=" " category="inline-code"></block> Bedeutet „Zulassen“. Die Erben-Flags werden in diesem Fall nicht festgelegt, da der Principal keine Gruppe ist und keine Vererbung beinhaltet. Da es sich bei ACE nicht um EINEN AUDIT-Eintrag handelt, müssen die Audit-Flags nicht festgelegt werden. Weitere Informationen zu NFSv4.1 ACLs finden Sie unter<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>.</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">Wenn die NFSv4.1 ACL nicht richtig eingestellt ist (oder eine Namenszeichenfolge nicht vom Client und Server aufgelöst werden kann), verhält sich die ACL möglicherweise nicht wie erwartet. Andernfalls kann die ACL-Änderung nicht angewendet werden und einen Fehler verursacht.</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">Beispielfehler sind:</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">Explizites ABLEHNEN</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">Die Berechtigungen in NFSv4.1 können explizite DENY-Attribute für EIGENTÜMER, GRUPPE und ALLE enthalten. Das liegt daran, dass NFSv4.1 ACLs Standard-Deny sind. Dies bedeutet, dass, wenn eine ACL nicht ausdrücklich von einem ACE gewährt wird, sie verweigert wird. Explizite DENY-Attribute überschreiben alle ZUGRIFFSOPTIONEN, explizit oder nicht.</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">DENY Aces werden mit einem Attribut-Tag von festgelegt<block ref="f623e75af30e62bbd73d6df5b50bb7b5" prefix=" " category="inline-code"></block>.</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">Im folgenden Beispiel ist DER GRUPPE@ alle Lese- und Ausführungsberechtigungen erlaubt, aber der gesamte Schreibzugriff wird verweigert.</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">DENY Aces sollten möglichst vermieden werden, da sie verwirrend und kompliziert sein können; ACLS, die nicht explizit definiert sind, WERDEN implizit verweigert. Wenn Asse VERWEIGERN festgelegt sind, wird Benutzern möglicherweise der Zugriff verweigert, wenn sie erwarten, dass ihnen Zugriff gewährt wird.</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">Der vorhergehende Satz von Assen entspricht 755 im Modus Bits, was bedeutet:</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">Der Eigentümer hat volle Rechte.</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">Gruppen haben schreibgeschützt.</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">Andere haben nur gelesen.</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">Selbst wenn die Berechtigungen auf das Äquivalent von 775 angepasst werden, kann der Zugriff aufgrund der expliziten DENY-Einstellung für ALLE verweigert werden.</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">Abhängigkeiten für die Zuordnung der NFSv4.1 ID-Domäne</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1 nutzt die ID-Domain-Mapping-Logik als Sicherheitsschicht, um zu überprüfen, ob ein Benutzer, der auf einen NFSv4.1-Mount zugreifen möchte, tatsächlich derjenige ist, der behauptet. In diesen Fällen hängt der vom NFSv4.1-Client stammende Benutzername und Gruppenname eine Namenszeichenfolge an und sendet sie an die Cloud Volumes Service-Instanz. Wenn diese Kombination aus Benutzername/Gruppenname und ID-Zeichenfolge nicht übereinstimmt, dann wird der Benutzer und/oder die Gruppe auf den Standard-niemand-Benutzer gesetzt, der im angegeben wurde<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block> Datei auf dem Client.</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">Diese ID-Zeichenfolge ist eine Voraussetzung für die ordnungsgemäße Einhaltung von Berechtigungen, insbesondere wenn NFSv4.1 ACLs und/oder Kerberos verwendet werden. Daher sind Serverabhängigkeiten des Nameservice wie LDAP-Server erforderlich, um die Konsistenz zwischen Clients und Cloud Volumes Service für eine ordnungsgemäße Identitätsauflösung von Benutzer und Gruppennamen zu gewährleisten.</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service verwendet einen statischen Standard-ID-Domänennamen von<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block>. NFS-Clients verwenden standardmäßig den DNS-Domain-Namen für seine ID-Domain-Namen-Einstellungen. Sie können den ID-Domain-Namen in jedoch manuell anpassen<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block>.</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Wenn LDAP in Cloud Volumes Service aktiviert ist, dann Cloud Volumes Service automatisiert die NFS ID Domain zu ändern, was für die Suche Domain in DNS konfiguriert ist und Clients nicht geändert werden müssen, es sei denn sie verwenden unterschiedliche DNS Domain Suchnamen.</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Wenn Cloud Volumes Service einen Benutzernamen oder Gruppennamen in lokalen Dateien oder LDAP auflösen kann, wird die Domänenzeichenfolge verwendet und nicht übereinstimmende Domänen-IDs Squash an niemand. Wenn Cloud Volumes Service einen Benutzernamen oder Gruppennamen nicht in lokalen Dateien oder LDAP finden kann, wird der numerische ID-Wert verwendet, und der NFS-Client löst den Namen richtig aus (dies entspricht dem NFSv3-Verhalten).</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">Ohne die NFSv4.1 ID-Domäne des Clients zu ändern, um mit dem zu übereinstimmen, was der Cloud Volumes Service-Datenträger verwendet, sehen Sie folgendes Verhalten:</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">UNIX-Benutzer und -Gruppen mit lokalen Einträgen in Cloud Volumes Service (wie root, wie in lokalen UNIX-Benutzern und -Gruppen definiert) werden auf den nobody-Wert gequetscht.</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">UNIX-Benutzer und -Gruppen mit Einträgen in LDAP (wenn Cloud Volumes Service so konfiguriert ist, dass sie LDAP verwenden), nehmen keine Wimpern auf, wenn sich DNS-Domänen zwischen NFS-Clients und Cloud Volumes Service unterscheiden.</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">UNIX-Benutzer und -Gruppen ohne lokale Einträge oder LDAP-Einträge verwenden den numerischen ID-Wert und lösen den auf dem NFS-Client angegebenen Namen. Wenn auf dem Client kein Name vorhanden ist, wird nur die numerische ID angezeigt.</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">Die Ergebnisse des vorhergehenden Szenarios:</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">Wenn die Client- und Server-ID-Domänen übereinstimmen, wird die gleiche Dateiliste angezeigt:</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">Weitere Informationen zu diesem Thema und wie man es löst, finden Sie im Abschnitt „<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>.“</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Kerberos Abhängigkeiten</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">Wenn Sie Kerberos mit NFS verwenden möchten, müssen Sie für Cloud Volumes Service Folgendes haben:</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Active Directory-Domäne für Kerberos-Verteilzentrum-Dienste (KDC)</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">Active Directory-Domäne mit Benutzer- und Gruppenattributen, die mit UNIX-Informationen für LDAP-Funktionalität gefüllt sind (NFS-Kerberos im Cloud Volumes Service benötigt für die ordnungsgemäße Funktion einen Benutzer-SPN für UNIX-Benutzerzuordnung).</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">LDAP auf der Cloud Volumes Service-Instanz aktiviert</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">Active Directory-Domäne für DNS-Services</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1 und der niemand-Benutzer/Gruppe</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">Eines der häufigsten Probleme bei einer NFSv4.1-Konfiguration ist, wenn eine Datei oder ein Ordner in einer Auflistung mit angezeigt wird<block ref="44ba5ca65651b4f36f1927576dd35436" prefix=" " category="inline-code"></block> Als im Besitz des<block ref="aa22bf558e0fe9237af37223aa4eecbb" prefix=" " category="inline-code"></block> Kombination von<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>.</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">Und die numerische ID lautet<block ref="ac627ab1ccbdb62ec96e702f07f6425b" prefix=" " category="inline-code"></block>.</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">In manchen Fällen wird die Datei möglicherweise den korrekten Eigentümer, aber angezeigt<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Als Gruppe.</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">Wer ist niemand?</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">Der<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Benutzer in NFSv4.1 unterscheidet sich von dem<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> Benutzer: Sie können anzeigen, wie ein NFS Client jeden Benutzer sieht, indem Sie die ausführen<block ref="b80bb7740288fda1f201890375a60c8f" prefix=" " category="inline-code"></block> Befehl:</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">Mit NFSv4.1, das<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Der von definierte Standardbenutzer ist der Benutzer<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> Datei und kann als jeder Benutzer definiert werden, den Sie verwenden möchten.</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">Warum passiert das?</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">Da Sicherheit durch Namenszeichenzuordnung ein Schlüsseltenet von NFSv4.1-Operationen ist, ist das Standardverhalten, wenn eine Namenszeichenfolge nicht richtig übereinstimmt, dass der Benutzer zu einem Squash, der normalerweise keinen Zugriff auf Dateien und Ordner hat, die Benutzer und Gruppen gehören.</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">Wenn Sie sehen<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Für den Benutzer und/oder die Gruppe in Dateilisten bedeutet dies im Allgemeinen, dass etwas in NFSv4.1 falsch konfiguriert ist. Hier kann die Empfindlichkeit des Falles ins Spiel kommen.</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">Wenn z. B. user1@CVSDEMO.LOCAL (uid 1234, gid 1234) auf einen Export zugreift, muss Cloud Volumes Service user1@CVSDEMO.LOCAL (uid 1234, gid 1234) finden können. Wenn der Benutzer in Cloud Volumes Service ist USER1@CVSDEMO.LOCAL, dann wird es nicht übereinstimmen (GROSSUSER1 vs. Kleinbuchstaben user1). In vielen Fällen können Sie Folgendes in der Meldungsdatei auf dem Client sehen:</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">Der Client und Server müssen beide zustimmen, dass ein Benutzer tatsächlich der Meinung ist, dass er sein soll. Sie müssen daher Folgendes überprüfen, um sicherzustellen, dass der Benutzer, der den Client sieht, dieselben Informationen hat wie der Benutzer, den Cloud Volumes Service sieht.</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">*NFSv4.x ID Domain.* Client:<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> Datei; Cloud Volumes Service verwendet<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block> Und kann nicht manuell geändert werden. Bei Verwendung von LDAP mit NFSv4.1 ändert Cloud Volumes Service die ID-Domäne in das, was die DNS-Suchdomäne verwendet, was mit der AD-Domäne identisch ist.</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*Benutzername und numerische IDs.* Dies legt fest, wo der Client nach Benutzernamen sucht und die Namensdienstschalter-Konfiguration nutzt – Client:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Und/oder lokale Passwd- und Gruppendateien; Cloud Volumes Service erlaubt keine Änderungen, sondern fügt der Konfiguration automatisch LDAP hinzu, wenn sie aktiviert ist.</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*Gruppenname und numerische IDs.* Dies legt fest, wo der Client nach Gruppennamen sucht und nutzt die Namensdienst-Switch-Konfiguration – Client:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Und/oder lokale Passwd- und Gruppendateien; Cloud Volumes Service erlaubt keine Änderungen, sondern fügt der Konfiguration automatisch LDAP hinzu, wenn sie aktiviert ist.</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">In fast allen Fällen, wenn Sie sehen<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Bei Benutzer- und Gruppenlisten von Clients handelt es sich um das Problem der Übersetzung von Benutzer- oder Gruppennamen-Domänen-ID zwischen Cloud Volumes Service und dem NFS-Client. Um dieses Szenario zu vermeiden, verwenden Sie LDAP, um Benutzer- und Gruppeninformationen zwischen Clients und Cloud Volumes Service aufzulösen.</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">Anzeigen von Name-ID-Strings für NFSv4.1 auf Clients</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">Wenn Sie NFSv4.1 verwenden, gibt es ein Name-String-Mapping, das während NFS-Vorgängen stattfindet, wie zuvor beschrieben.</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">Nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">Zusätzlich zu verwenden<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block> Um ein Problem mit NFSv4-IDs zu finden, können Sie das verwenden<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> Befehl auf dem NFS Client, um anzuzeigen, welche Benutzernamen der NFSv4-Domäne ordnungsgemäß zugeordnet haben.</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">Dies wird beispielsweise nach einem Benutzer ausgegeben, der vom Client gefunden werden kann und Cloud Volumes Service auf einen NFSv4.x Mount zugreift:</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">Wenn ein Benutzer, der der NFSv4.1 ID-Domäne nicht ordnungsgemäß zugeordnet ist (in diesem Fall<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>) Versucht, auf denselben Mount zuzugreifen und berührt eine Datei, sie sind zugewiesen<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>, Wie erwartet.</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">Der<block ref="600a8e1223f644dfc8fc6d9eaf7c6585" prefix=" " category="inline-code"></block> Ausgabe zeigt den Benutzer an<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Im Display, aber nicht<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>; Dies ist der anonyme Benutzer in unserer Export-Policy Regel <block ref="f9df942af967185fc775031b3c286856" prefix="(" category="inline-code"></block>).</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">Weiter: SMB.</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Alle Management-Aktionen an Cloud Volumes Service werden über die API ausgeführt. Das in die GCP Cloud Console integrierte Cloud Volumes Service-Management verwendet auch die Cloud Volumes Service-API.</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">Kontrollebene Architektur</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">Früher: Cloud Volumes Service Architektur.</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">Identitäts- und Zugriffsmanagement</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">Identitäts- und Zugriffsmanagement <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>) Ist ein Standardservice, mit dem Sie Authentifizierung (Logins) und Berechtigungen (Berechtigungen) für Google Cloud-Projektinstanzen steuern können. Google IAM bietet ein vollständiges Audit-Protokoll über Berechtigungen zum Berechtigungs- und Entfernen. Derzeit bietet Cloud Volumes Service keine Prüfung auf Kontrollebenen.</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">Autorisierungs-/Berechtigungs-Übersicht</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">Vollständige Liste mit granularen Berechtigungen hier</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM bietet integrierte, granulare Berechtigungen für Cloud Volumes Service. Hier finden Sie ein<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>.</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM bietet außerdem zwei vordefinierte Rollen, die als Namen bezeichnet werden<block ref="4a5395c87dd91b3242056f83b7cedb9b" prefix=" " category="inline-code"></block> Und<block ref="d8cd72eb52281636a72e12ef877b62f8" prefix=" " category="inline-code"></block>. Diese Rollen können bestimmten Benutzern oder Servicekonten zugewiesen werden.</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">Weisen Sie geeignete Rollen und Berechtigungen zu, um IAM-Benutzern das Management von Cloud Volumes Service zu ermöglichen.</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">Beispiele für die Verwendung granularer Berechtigungen sind:</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">Erstellen Sie eine benutzerdefinierte Rolle nur mit Berechtigungen zum Abrufen/Auflisten/Erstellen/Aktualisieren, damit Benutzer Volumes nicht löschen können.</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">Verwenden Sie eine benutzerdefinierte Rolle nur mit<block ref="984f6a68d5cd59b0b62580124dedfd98" prefix=" " category="inline-code"></block> Berechtigungen zum Erstellen eines Servicekontos, das zum Aufbau einer applikationskonsistenten Snapshot Integration verwendet wird.</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">Erstellen Sie eine benutzerdefinierte Rolle zum Delegieren<block ref="49fb6de34b20a50950c47f0a75513736" prefix=" " category="inline-code"></block> An bestimmte Benutzer.</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">Servicekonten</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">Um Cloud Volumes Service-API-Aufrufe über Skripte oder durchzuführen<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>, Sie müssen ein Dienstkonto mit dem erstellen<block ref="5e467dce18f46b1803b06097fae60b82" prefix=" " category="inline-code"></block> Rolle: Sie können dieses Dienstkonto verwenden, um die JWT-Token zu generieren, die zur Authentifizierung von Cloud Volumes Service-API-Anforderungen erforderlich sind:</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">Generieren Sie einen JSON-Schlüssel und verwenden Sie Google APIs, um daraus ein JWT-Token abzuleiten. Dies ist der einfachste Ansatz, aber es beinhaltet manuelle Geheimnisse (den JSON-Schlüssel) Management.</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">Imitation von Servicekonten</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">Standardanmeldedaten Für Anwendungen</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">Nutzung<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> Mit<block ref="4d4344aa5ad9d43d63ab2f068115cadb" prefix=" " category="inline-code"></block>. Der Code (Skript, Terraform usw.) läuft mit<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> Und personifiziert das Servicekonto, um seine Berechtigungen zu erhalten. Dieser Ansatz spiegelt die Best Practices für die Sicherheit von Google wider.</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">Erstellen Ihres Servicekontos und privaten Schlüssels</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">Siehe<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> In der Google Cloud Dokumentation finden Sie weitere Informationen.</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">Cloud Volumes Service API</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">Cloud Volumes APIs in der Google Cloud-Dokumentation</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">Die Cloud Volumes Service API verwendet eine REST-basierte API mithilfe von HTTPS (TLSv1.2) als zugrunde liegenden Netzwerktransport. Hier finden Sie die neueste API-Definition<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> Und Informationen zur Verwendung der API unter<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>.</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">Der API-Endpunkt wird durch NetApp mit Standard-HTTPS-Funktionalität (TLSv1.2) betrieben und gesichert.</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">JWT-Token</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">Die Authentifizierung an der API erfolgt mit JWT-Inhabertoken <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>). Gültige JWT-Token müssen über die Google Cloud IAM-Authentifizierung abgerufen werden. Dazu muss ein Token vom IAM abgerufen werden, indem ein JSON-Schlüssel für ein Servicekonto bereitgestellt wird.</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">Audit-Protokollierung</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">Derzeit sind keine vom Benutzer zugänglichen Prüfprotokolle für Kontrollebenen verfügbar.</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">Als Nächstes: Datenebene-Architektur</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">Cloud Volumes Service verwendet für die Bereitstellung des Service Google PSA in einer Weise, die mit anderen nativen Google Cloud-Services wie CloudSQL, Google Cloud VMware Engine (GCVE) und FileStore ähnlich ist.</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Architektur von Cloud Volumes Service</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">VPC-Netzwerk-Peering</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">Cloud Volumes Service verwendet in ähnlicher Weise wie andere Cloud-native Dienste von Google wie CloudSQL, Google Cloud VMware Engine (GCVE) und FileStore<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> Für die Bereitstellung des Service. In PSA werden Dienste innerhalb eines Service-Producer-Projekts aufgebaut, das verwendet wird<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> So stellen Sie eine Verbindung zum Serviceverbraucher her. Der Hersteller des Service wird von NetApp bereitgestellt und betrieben. Der Serviceverbraucher ist eine VPC in einem Kundenprojekt und hostet die Clients, die auf Cloud Volumes Service Dateifreigaben zugreifen möchten.</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">Abschnitt zur Architektur</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">Die folgende Abbildung, auf die im Bezug genommen wird<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> In der Cloud Volumes Service-Dokumentation wird eine allgemeine Ansicht angezeigt.</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">Der Teil über der gepunkteten Linie zeigt die Kontrollebene des Services an, der den Volumenlebenszyklus steuert. Der Teil unterhalb der gepunkteten Linie zeigt die Datenebene. Das linke blaue Feld zeigt die Benutzer-VPC (Service-Verbraucher), das rechte blaue Feld ist der von NetApp bereitgestellte Service-Hersteller. Beide sind über VPC-Peering verbunden.</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">Tenancy-Modell</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">In Cloud Volumes Service gelten einzelne Projekte als eigenständige Mandanten. Das bedeutet, dass Manipulationen von Volumes, Snapshot Kopien usw. pro Projekt durchgeführt werden. Das heißt, alle Volumes sind im Besitz des Projekts, in dem sie erstellt wurden. Nur das Projekt kann standardmäßig die darin enthaltenen Daten managen und darauf zugreifen. Dies wird als Ansicht der Kontrollebene des Services betrachtet.</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">Gemeinsam genutzte VPCs</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">In der Ansicht „Datenebene“ kann Cloud Volumes Service eine Verbindung zu einer gemeinsamen VPC herstellen. Sie können Volumes im Hosting-Projekt oder in einem der Service-Projekte erstellen, die mit der gemeinsam genutzten VPC verbunden sind. Alle mit dieser gemeinsamen VPC verbundenen Projekte (Host oder Service) sind in der Lage, die Volumes auf der Netzwerkebene (TCP/IP) zu erreichen. Da alle Clients mit Netzwerkkonnektivität auf der gemeinsam genutzten VPC potenziell über NAS-Protokolle auf die Daten zugreifen können, muss die Zugriffssteuerung für das individuelle Volume (z. B. User-/Group-Zugriffssteuerungslisten (ACLs) und Hostnamen/IP-Adressen für NFS-Exporte) verwendet werden, um zu kontrollieren, wer auf die Daten zugreifen kann.</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">Sie können Cloud Volumes Service mit bis zu fünf VPCs pro Kundenprojekt verbinden. In der Kontrollebene können Sie mit dem Projekt alle erstellten Volumes managen – unabhängig von der VPC, mit der sie verbunden sind. Auf der Datenebene sind VPCs voneinander isoliert, wobei jedes Volume nur mit einer VPC verbunden werden kann.</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">Der Zugriff auf einzelne Volumes wird über protokollspezifische Zugriffskontrollmechanismen (NFS/SMB) gesteuert.</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">Das bedeutet, dass auf der Netzwerkebene alle mit der gemeinsam genutzten VPC verbundenen Projekte in der Lage sind, das Volume zu sehen, während auf der Managementseite nur die Kontrollebene es dem Owner-Projekt erlaubt, das Volume zu sehen.</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">VPC-Service-Kontrollen</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">VPC-Service-Kontrollen einrichten eine Zugriffskontrollumgebung um Google Cloud Services herum, die mit dem Internet verbunden sind und weltweit zugänglich sind. Diese Dienste bieten Zugriffskontrolle über Benutzeridentitäten, können aber nicht einschränken, aus welchen Netzwerkstandortanforderungen stammen. Die VPC-Service-Kontrollen schließen diese Lücke, indem sie Funktionen zur Einschränkung des Zugriffs auf definierte Netzwerke einführen.</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Die Cloud Volumes Service-Datenebene ist nicht mit dem externen Internet verbunden, sondern mit privaten VPCs mit klar definierten Netzwerkgrenzen (Perimeter). Innerhalb dieses Netzwerks verwendet jedes Volume eine protokollspezifische Zugriffssteuerung. Jegliche externe Netzwerkverbindung wird explizit von Google Cloud-Projektadministratoren erstellt. Die Kontrollebene bietet jedoch nicht denselben Schutz wie die Datenebene und kann von jedem beliebigen Ort mit gültigen Zugangsdaten aufgerufen werden (<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>).</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">Kurz gesagt, die Cloud Volumes Service Datenebene bietet die Möglichkeit der Netzwerk-Zugriffssteuerung, ohne dass die VPC-Service-Kontrollen unterstützt werden müssen. Außerdem werden nicht explizit VPC-Service-Controls verwendet.</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">Überlegungen zu Packet Sniffing/Trace</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">Paketerfassungen können für die Behebung von Netzwerkproblemen oder anderen Problemen (z. B. NAS-Berechtigungen, LDAP-Konnektivität usw.) nützlich sein, können aber auch missverständlich verwendet werden, um Informationen über Netzwerk-IP-Adressen, MAC-Adressen, Benutzer- und Gruppennamen und die Sicherheitsstufe für Endpunkte zu erhalten. Aufgrund der Art und Weise, wie Google Cloud-Netzwerke, VPCs und Firewall-Regeln konfiguriert werden, sollte ein unerwünschter Zugriff auf Netzwerkpakete ohne Benutzeranmeldung oder nur schwer zu erhalten sein <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> In Cloud-Instanzen integriert. Paketerfassungen sind nur auf Endpunkten (z. B. Virtual Machines (VMs) möglich und nur in Endpunkten innerhalb der VPC möglich, es sei denn, ein Shared VPC und/oder ein externer Netzwerktunnel/IP-Weiterleitung wird verwendet, um explizit externen Traffic zu Endpunkten zu erlauben. Es gibt keine Möglichkeit, den Verkehr außerhalb der Kunden zu schnuppern.</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="inline-link-macro">SMB-Verschlüsselung</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="inline-link-macro">DNS</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="inline-link-macro">LDAP-Abfragen</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">Bei gemeinsamen VPCs wird die Verschlüsselung auf der Übertragungsstrecke mit NFS Kerberos und/oder genutzt <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> Kann einen Großteil der Informationen aus Spuren verbergen. Allerdings wird noch etwas Verkehr in Klartext gesendet, wie <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> Und <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>. Die folgende Abbildung zeigt eine Paketerfassung aus einer Klartext-LDAP-Abfrage, die aus Cloud Volumes Service stammt, und die potenziellen identifizierenden Informationen, die freigelegt wurden. LDAP-Abfragen in Cloud Volumes Service unterstützen derzeit keine Verschlüsselung oder LDAP über SSL. CVS-Performance unterstützt LDAP-Signatur, falls durch Active Directory angefordert. CVS-SW unterstützt LDAP-Signatur nicht.</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">UnixUserPassword wird von LDAP abgefragt und nicht im Klartext, sondern in einem gesalzenem Hash gesendet. Standardmäßig füllt Windows LDAP die Felder unixUserPassword nicht aus. Dieses Feld ist nur erforderlich, wenn Sie Windows LDAP für interaktive Anmeldungen über LDAP für Clients verwenden müssen. Cloud Volumes Service unterstützt keine interaktiven LDAP-Anmeldungen bei den Instanzen.</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">Die folgende Abbildung zeigt eine Paketerfassung aus einem NFS-Kerberos-Gespräch neben einer NFS-Erfassung über AUTH_SYS. Beachten Sie, wie sich die Informationen in einer Kurve zwischen den beiden unterscheiden und wie die Aktivierung der Verschlüsselung während der Übertragung eine größere Gesamtsicherheit für den NAS-Datenverkehr bietet.</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">VM-Netzwerkschnittstellen</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">Promiskuous Modus</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">Angreifer können versuchen, eine neue Netzwerkschnittstellenkarte (NIC) zu einer VM in hinzuzufügen<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> (Port-Spiegelung) oder aktivieren Sie den Promiskuus-Modus auf einer vorhandenen NIC, um den gesamten Datenverkehr zu entschnüffeln. Beim Hinzufügen einer neuen NIC muss in Google Cloud eine VM vollständig heruntergefahren werden, was zu Warnmeldungen führt. So können Angreifer nicht unbemerkt das tun.</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">Darüber hinaus können NICs überhaupt nicht auf den promiskuitiven Modus eingestellt werden und erzeugen in Google Cloud Warnmeldungen.</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">Als Nächstes: Kontrollebene Architektur.</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service bietet die Möglichkeit, Ihre Cloud Volumes Service Instanz mit einem externen Active Directory Server zu verbinden, um Identitäts-Management für SMB- und UNIX-Benutzer zu ermöglichen. Für die Verwendung von SMB in Cloud Volumes Service ist das Erstellen einer Active Directory-Verbindung erforderlich.</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Überlegungen zum Erstellen von Active Directory-Verbindungen</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">Früher: Dual-Protokoll/Multiprotokoll.</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">Privater Zugriff Auf Google</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Best Practices Using Active Directory in Google Cloud</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">Bei der Konfiguration hierfür stehen verschiedene Optionen zur Verfügung, bei denen die Sicherheit berücksichtigt werden muss. Der externe Active Directory Server kann eine lokale oder Cloud-native Instanz sein. Wenn Sie einen lokalen Active Directory-Server verwenden, setzen Sie die Domäne nicht dem externen Netzwerk (z. B. mit einer DMZ oder einer externen IP-Adresse) aus. Verwenden Sie stattdessen sichere private Tunnel oder VPNs, One-Way-Forest-Trusts oder dedizierte Netzwerkverbindungen zu den On-Premises-Netzwerken mit<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>. In der Google Cloud-Dokumentation finden Sie weitere Informationen zu<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>.</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW erfordert, dass sich Active Directory-Server in derselben Region befinden. Wenn eine DC-Verbindung in CVS-SW zu einer anderen Region versucht wird, schlägt der Versuch fehl. Wenn Sie CVS-SW verwenden, erstellen Sie Active Directory-Sites, die die Active Directory-Datacenter enthalten, und geben Sie dann Standorte in Cloud Volumes Service an, um regionale DC-Verbindungsversuche zu vermeiden.</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Active Directory-Anmeldeinformationen</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">Wenn SMB oder LDAP für NFS aktiviert ist, interagiert Cloud Volumes Service mit den Active Directory Controllern, um ein Computerkonto-Objekt zu erstellen, das für die Authentifizierung verwendet werden soll. Dies unterscheidet sich nicht von der Verbindung eines Windows SMB-Clients zu einer Domäne und erfordert dieselben Zugriffsrechte für Organisationseinheiten (OUs) in Active Directory.</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">In vielen Fällen ist die Verwendung eines Windows-Administratorkontos auf externen Servern wie Cloud Volumes Service nicht gestattet. In einigen Fällen ist der Windows Administrator-Benutzer vollständig als bewährte Sicherheitsübung deaktiviert.</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">Zum Erstellen von SMB-Computerkonten erforderliche Berechtigungen</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">Delegierte Berechtigungen zum Erstellen und Ändern von Computerkontontobjekten</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Um einem Active Directory Cloud Volumes Service-Maschinenobjekte hinzuzufügen, ein Konto, das entweder über Administratorrechte für die Domäne verfügt oder über<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> Für eine angegebene Organisationseinheit ist erforderlich. Dazu können Sie den Assistenten zur Delegierung von Computerobjekten in Active Directory verwenden, indem Sie eine benutzerdefinierte Aufgabe erstellen, die einem Benutzer den Zugriff auf das Erstellen/Löschen von Computerobjekten mit den folgenden Zugriffsberechtigungen bietet:</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">Lese-/Schreibzugriff</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">Alle Untergeordneten Objekte Erstellen/Löschen</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">Lesen/Schreiben Aller Eigenschaften</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">Passwort Ändern/Zurücksetzen</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">Dadurch wird der OU in Active Directory automatisch eine Sicherheits-ACL für den definierten Benutzer hinzugefügt und der Zugriff auf die Active Directory-Umgebung wird minimiert. Nachdem ein Benutzer delegiert wurde, können dieser Benutzername und dieses Passwort in diesem Fenster als Active Directory-Anmeldeinformationen angegeben werden.</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">Der Benutzername und das Passwort, das an die Active Directory-Domäne übergeben wird, nutzen die Kerberos-Verschlüsselung während der Abfrage des Computerkontos und der Erstellung für zusätzliche Sicherheit.</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Details zur Active Directory-Verbindung</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Active Directory-Verbindungsdetails</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">Der<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> Bereitstellen von Feldern für Administratoren, um bestimmte Active Directory-Schemainformationen für die Platzierung von Computerkonten bereitzustellen, z. B.:</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">*Active Directory-Verbindungstyp.* zur Angabe, ob die Active Directory-Verbindung in einer Region für Volumes von entweder Cloud Volumes Service oder CVS-Performance-Diensttypen verwendet wird. Wenn diese Funktion bei einer vorhandenen Verbindung falsch eingestellt ist, funktioniert sie möglicherweise nicht richtig, wenn sie verwendet oder bearbeitet wird.</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*Domain.* der Active Directory-Domänenname.</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">Überlegungen</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*Site.* beschränkt Active Directory-Server auf einen bestimmten Standort für Sicherheit und Leistung<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>. Dies ist erforderlich, wenn mehrere Active Directory-Server Regionen umfassen, da Cloud Volumes Service derzeit keine Unterstützung bietet, um Active Directory-Authentifizierungsanforderungen an Active Directory-Server in einer anderen Region als der Cloud Volumes Service-Instanz zu erlauben. (Beispielsweise ist der Active Directory Domain Controller in einer Region, die nur CVS-Performance unterstützt, aber einen SMB-Share in einer CVS-SW-Instanz wünschen.)</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">*DNS-Server.* DNS-Server zur Verwendung bei der Namensaufsuchen.</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Wie Cloud Volumes Service in Active Directory angezeigt wird</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">*NetBIOS-Name (optional).* auf Wunsch der NetBIOS-Name für den Server. Dies wird verwendet, wenn neue Computerkonten mithilfe der Active Directory-Verbindung erstellt werden. Wenn beispielsweise der NetBIOS-Name auf CVS-EAST gesetzt ist, dann sind die Namen des Computerkontos CVS-EAST-{1234}. Siehe Abschnitt <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*Organisationseinheit (Organisationseinheit).* die spezifische Organisationseinheit, die das Computerkonto erstellt. Dies ist nützlich, wenn Sie die Kontrolle an einen Benutzer für Maschinenkonten an eine bestimmte OU delegieren.</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">*AES-Verschlüsselung.* Sie können auch das Kontrollkästchen AES-Verschlüsselung für AD-Authentifizierung aktivieren oder deaktivieren. Das Aktivieren der AES-Verschlüsselung für die Active Directory-Authentifizierung bietet zusätzliche Sicherheit für die Kommunikation zwischen Cloud Volumes Service und Active Directory bei Benutzer- und Gruppensuchen. Bevor Sie diese Option aktivieren, fragen Sie Ihren Domänenadministrator, ob die Active Directory-Domänencontroller die AES-Authentifizierung unterstützen.</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">Standardmäßig deaktivieren die meisten Windows-Server schwächere Chiffren (wie DES oder RC4-HMAC) nicht, aber wenn Sie schwächere Chiffren deaktivieren möchten, bestätigen Sie, dass die Cloud Volumes Service Active Directory-Verbindung für die Aktivierung von AES konfiguriert wurde. Andernfalls treten Authentifizierungsfehler auf. Die Aktivierung der AES-Verschlüsselung deaktiviert nicht schwächere Chiffren, sondern fügt dem Cloud Volumes Service SMB-Maschinenkonto Unterstützung für AES-Chiffren hinzu.</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Kerberos-Bereich – Details</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">Diese Option gilt nicht für SMB-Server. Es wird vielmehr verwendet, wenn NFS Kerberos für das Cloud Volumes Service System konfiguriert wird. Wenn diese Details ausgefüllt werden, wird der NFS-Kerberos-Bereich konfiguriert (ähnlich einer krb5.conf-Datei unter Linux) und wird verwendet, wenn NFS-Kerberos bei der Erstellung des Cloud Volumes Service-Volumes angegeben wird, da die Active Directory-Verbindung als NFS Kerberos-Verteilzentrum (KDC) fungiert.</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">Nicht-Windows-Rechenzentren werden derzeit nicht für die Verwendung mit Cloud Volumes Service unterstützt.</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">Region</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">In einer Region können Sie den Speicherort der Active Directory-Verbindung angeben. Diese Region muss dieselbe Region wie das Cloud Volumes Service-Volumen aufweisen.</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*Lokale NFS-Benutzer mit LDAP.* in diesem Abschnitt gibt es auch eine Option, lokale NFS-Benutzer mit LDAP zu erlauben. Diese Option muss nicht ausgewählt werden, wenn Sie Ihre UNIX-Benutzergruppenmitgliedschaft über die 16-Gruppen-Beschränkung von NFS hinaus erweitern möchten (erweiterte Gruppen). Die Verwendung erweiterter Gruppen erfordert jedoch einen konfigurierten LDAP-Server für UNIX-Identitäten. Wenn Sie keinen LDAP-Server haben, lassen Sie diese Option nicht ausgewählt. Wenn Sie über einen LDAP-Server verfügen und auch lokale UNIX-Benutzer verwenden möchten (z. B. Root), wählen Sie diese Option aus.</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">Backup-Benutzer</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">Aktivieren der Prüfung dieses Benutzerzugriffs</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">Mit dieser Option können Sie Windows-Benutzer angeben, die Sicherungsberechtigungen auf dem Cloud Volumes Service-Volume besitzen. Backup-Berechtigungen (SeBackupPrivilege) sind für einige Anwendungen erforderlich, um Daten in NAS-Volumes ordnungsgemäß zu sichern und wiederherzustellen. Dieser Benutzer hat einen hohen Zugriff auf die Daten des Volumes, daher sollten Sie es in Betracht ziehen<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>. Nach Aktivierung werden Audit-Ereignisse in der Ereignisanzeige &gt; Windows-Protokolle &gt; Sicherheit angezeigt.</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">Benutzer mit Sicherheitsberechtigungen</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">Z. B. SQL Server</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">Prüfung des Benutzerzugriffs von Benutzern</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">Mit dieser Option können Sie Windows-Benutzer angeben, die über Sicherheitsberechtigungen für das Cloud Volumes Service-Volume verfügen. Für einige Anwendungen sind Sicherheitsberechtigungen (SeSecurityPrivilege) erforderlich <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>) Die Berechtigungen während der Installation richtig einstellen. Diese Berechtigung ist zur Verwaltung des Sicherheitsprotokolls erforderlich. Obwohl dieses Privilege nicht so mächtig ist wie SeBackupPrivilege, empfiehlt NetApp Folgendes<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> Bei Bedarf mit dieser Berechtigungsebene verfügbar.</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">Neue Anmeldung zugewiesene Sonderberechtigungen</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">Weitere Informationen finden Sie unter<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>.</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service wird in Active Directory als normales Konto-Objekt angezeigt. Die Namenskonventionen lauten wie folgt.</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB und NFS Kerberos erstellen separate Computerkontoobjekte.</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">NFS mit aktiviertem LDAP erstellt ein Maschinenkonto in Active Directory für Kerberos LDAP bindet.</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">Duale Protokoll-Volumes mit LDAP nutzen das CIFS/SMB-Maschinenkonto für LDAP und SMB.</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">CIFS/SMB-Maschinenkonten verwenden eine Namensgebungskonvention von NAME-1234 (zufällige vierstellige ID mit Bindestrich angefügt an &lt;10 Zeichen Name) für das Maschinenkonto. SIE können DEN NAMEN durch die Einstellung des NetBIOS-Namens auf der Active Directory-Verbindung definieren (siehe Abschnitt „<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>„).</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos verwendet NFS-NAME-1234 als Namenskonvention (bis zu 15 Zeichen). Wenn mehr als 15 Zeichen verwendet werden, lautet der Name NFS-CAM-NAME-1234.</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">Nur NFS CVS-Performance-Instanzen mit aktiviertem LDAP erstellen ein SMB-Maschinenkonto, um es an den LDAP-Server zu binden, und zwar mit derselben Namenskonvention wie CIFS/SMB-Instanzen.</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">„Standard versteckte Freigaben“</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">Wenn ein SMB-Computerkonto erstellt wird, werden standardmäßig ausgeblendete Admin-Freigaben verwendet (siehe Abschnitt <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Werden auch erstellt (c€, Admin-Dollar, ipc-Dollar), aber diese Aktien haben keine ACLs zugewiesen und sind unzugänglich.</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">Die Rechnungsobjekte werden standardmäßig in CN=Computer platziert, aber eine können Sie bei Bedarf eine andere OU festlegen. Siehe Abschnitt „<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>“ Informationen darüber, welche Zugriffsrechte zum Hinzufügen/Entfernen von Gerätekontonobjekten für Cloud Volumes Service erforderlich sind.</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Wenn Cloud Volumes Service das SMB-Maschinenkonto zu Active Directory hinzufügt, werden die folgenden Felder ausgefüllt:</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">cn (mit dem angegebenen SMB-Servernamen)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">DNSHostName (mit SMBserver.domain.com)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">MSDS-SupportedVerschlüsselungTypes (allows DES_CBC_MD5, RC4_HMAC_MD5, wenn die AES-Verschlüsselung nicht aktiviert ist; WENN die AES-Verschlüsselung aktiviert ist, SIND DES_CBC_MD5, RC4_HMAC_MD5, AES128_CTS_HMAC_SHA1_96, AES256_CTS_HMAC_SHA1_96 für den Kerberos-Account zugelassen)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">Name (mit SMB-Servername)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">SAMAccountName (mit SMBserver-Kosten)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">ServicePrincipalName (mit Host/smbserver.domain.com und Host/smbserver-SPNs für Kerberos)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">Wenn Sie schwächere Kerberos-Verschlüsselungstypen (Enctype) auf dem Maschinenkonto deaktivieren möchten, können Sie den Wert MSDS-SupportedVerschlüsselungTypes auf dem Maschinenkonto auf einen der Werte in der folgenden Tabelle ändern, um nur AES zu ermöglichen.</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">MSDS-SupportVerschlüsselungTypes Wert</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">Zuctype aktiviert</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">NUR AES128_CTS_HMAC_SHA1_96</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">NUR AES256_CTS_HMAC_SHA1_96</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96 UND AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5, RC4_HMAC, AES128_CTS_HMAC_SHA1_96 UND AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">Um die AES-Verschlüsselung für SMB-Computerkonten zu aktivieren, klicken Sie beim Erstellen der Active Directory-Verbindung auf AES-Verschlüsselung für AD-Authentifizierung aktivieren.</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Weitere Informationen finden Sie in der Cloud Volumes Service-Dokumentation</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">Um die AES-Verschlüsselung für NFS-Kerberos zu aktivieren,<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>.</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">Als Nächstes: Andere NAS-Infrastruktur-Serviceabhängigkeiten (KDC, LDAP, DNS).</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">Weitere Informationen, Versionsverlauf und Kontaktinformationen</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">Zurück: Service Operation.</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Google Cloud-Dokumentation für Cloud Volumes Service</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Google Private Service-Zugriff</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp Produktdokumentation</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">Kryptografisches Validierungsmodul-Programm – NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="list-text">NetApp Lösung gegen Ransomware</block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616: NFS Kerberos im ONTAP</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">Lassen Sie uns wissen, wie wir diesen technischen Bericht verbessern können.</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">Kontaktieren Sie uns unter mailto:doccomments@netapp.com[doccomments@netapp.com^]. Nehmen SIE den TECHNISCHEN BERICHT 4918 in die Betreffzeile auf.</block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB ist ein von Microsoft entwickeltes Netzwerkdateiprotokoll, das eine zentralisierte Benutzer-/Gruppenauthentifizierung, Berechtigungen, Sperrung und Dateifreigabe für mehrere SMB-Clients über ein Ethernet-Netzwerk ermöglicht.</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">SMB</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">Früher: NFS.</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> Das von Microsoft entwickelte Netzwerk-File-Sharing-Protokoll bietet zentralisierte Benutzer-/Gruppenauthentifizierung, Berechtigungen, Sperren und Dateifreigabe für mehrere SMB-Clients über ein Ethernet-Netzwerk. Dateien und Ordner werden Clients über Freigaben angezeigt, die mit einer Vielzahl von Freigabeeigenschaften konfiguriert werden können und die Zugriffskontrolle über Berechtigungen auf Share-Ebene bietet. SMB kann jedem Client angezeigt werden, der Protokolle unterstützt, einschließlich Windows-, Apple- und Linux-Clients.</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service unterstützt die Protokollversionen SMB 2.1 und 3.x.</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">Zugriffssteuerung/SMB-Freigaben</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Wenn ein Windows-Benutzername Zugriff auf das Cloud Volumes Service-Volume anfordert, sucht Cloud Volumes Service nach einem UNIX-Benutzernamen mit den von Cloud Volumes Service-Administratoren konfigurierten Methoden.</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">Wenn ein externer UNIX Identity Provider (LDAP) konfiguriert ist und Windows/UNIX Nutzernamen identisch sind, werden Windows-Benutzernamen ohne zusätzliche Konfiguration 1:1 zu UNIX Benutzernamen mappen. Wenn LDAP aktiviert ist, wird Active Directory verwendet, um die UNIX-Attribute für Benutzer- und Gruppenobjekte zu hosten.</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">„LDAP für asymmetrisches Namenszuordnungen verwenden“</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Wenn Windows-Namen und UNIX-Namen nicht identisch sind, muss LDAP konfiguriert werden, damit Cloud Volumes Service die LDAP-Namenszuordnungskonfiguration verwenden kann (siehe Abschnitt <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>).</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">Wenn LDAP nicht verwendet wird, werden Windows SMB-Benutzer einem lokalen UNIX-Standardbenutzer zugeordnet<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Im Cloud Volumes Service. Das bedeutet Dateien, die von Benutzern in Windows geschrieben wurden, die dem zugeordnet sind<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Zeigen Sie die UNIX-Eigentümerschaft als<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> In NAS-Umgebungen mit mehreren Protokollen.<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Hier ist effektiv das<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Benutzer in Linux-Umgebungen (UID 65534).</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">Bei Implementierungen nur mit SMB gilt das<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Mapping tritt immer noch auf, aber es wird keine Rolle spielen, weil Windows-Benutzer und Gruppen-Eigentum korrekt angezeigt wird und NFS-Zugriff auf das SMB-only Volumen ist nicht erlaubt. Außerdem unterstützen SMB-only Volumes nach der Erstellung keine Konvertierung in NFS- oder Dual-Protokoll-Volumes.</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows nutzt Kerberos für die Benutzerauthentifizierung mit den Active Directory-Domänencontrollern, die einen Austausch von Benutzername/Passwort mit den AD-DCs erfordern, die sich außerhalb der Cloud Volumes Service-Instanz befinden. Kerberos-Authentifizierung wird verwendet, wenn das verwendet wird<block ref="cd2eba6db07c5178e47368d41d7c8ecb" prefix=" " category="inline-code"></block> UNC-Pfad wird von den SMB-Clients verwendet, und folgende lautet „true“:</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">DNS A/AAAA-Eintrag für SERVERNAME vorhanden</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">Für SERVERNAME ist ein gültiger SPN für SMB/CIFS-Zugriff vorhanden</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">„Wie Cloud Volumes Service in Active Directory erscheint.“</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Wenn ein Cloud Volumes Service SMB Volume erstellt wird, wird der Name des Maschinenkontos wie in Abschnitt definiert erstellt <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Der Name des Computerkontos wird auch zum SMB-Freigabepfad, da Cloud Volumes Service dynamische DNS (DDNS) verwendet, um die erforderlichen A/AAAA- und PTR-Einträge im DNS und die erforderlichen SPN-Einträge auf dem Computerkonto-Principal zu erstellen.</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">Damit PTR-Einträge erstellt werden können, muss auf dem DNS-Server die Reverse-Lookup-Zone für die IP-Adresse der Cloud Volumes Service-Instanz vorhanden sein.</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">Beispielsweise verwendet dieses Cloud Volumes Service Volume den folgenden UNC-Freigabepfad:<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>.</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">Im Active Directory sind dies die von Cloud Volumes Service generierten SPN-Einträge:</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">Dies ist das Ergebnis des DNS-Vorwärts-/Reverse-Lookups:</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">Optional kann eine bessere Zugriffssteuerung durch Aktivieren/Aktivieren der SMB-Verschlüsselung für SMB-Freigaben in Cloud Volumes Service angewendet werden. Wenn die SMB-Verschlüsselung von einem der Endpunkte nicht unterstützt wird, ist der Zugriff nicht zulässig.</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">Verwenden von SMB-Namenaliasen</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">In einigen Fällen kann es ein Sicherheitsbedenken für Endbenutzer sein, den Namen des für Cloud Volumes Service verwendeten Computerkontos zu kennen. In anderen Fällen möchten Sie Ihren Endbenutzern möglicherweise lediglich einen einfacheren Zugriffspfad bieten. In diesen Fällen können Sie SMB-Aliase erstellen.</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">Wenn Sie Aliase für den SMB-Freigabepfad erstellen möchten, können Sie den Namen CNAME-Datensatz in DNS verwenden. Beispiel: Wenn Sie den Namen verwenden möchten<block ref="87154d57e8c4e5c93755c1e158cd3257" prefix=" " category="inline-code"></block> Auf Freigaben statt auf<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>, Aber Sie möchten immer noch Kerberos-Authentifizierung verwenden, ein CNAME in DNS, der auf den vorhandenen A/AAAA-Datensatz verweist, und ein zusätzlicher SPN, der dem bestehenden Computerkonto hinzugefügt wurde, bietet Kerberos-Zugriff.</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">Dies ist das resultierende DNS-Weitersuchergebnis nach dem Hinzufügen eines CNAME:</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">Dies ist die resultierende SPN-Abfrage nach dem Hinzufügen neuer SPNs:</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">In einer Paketerfassung können wir die Session-Setup-Anforderung mit dem SPN sehen, der an den CNAME gebunden ist.</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">SMB-Authentifizierungsdialekte</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">Dialekte</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service unterstützt Folgendes<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> Für SMB-Authentifizierung:</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">Kerberos-Authentifizierung für SMB-Freigabe-Zugriff ist die sicherste Authentifizierungsstufe, die Sie verwenden können. Mit AES- und SMB-Verschlüsselung wird die Sicherheit weiter erhöht.</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service unterstützt außerdem die Rückwärtskompatibilität für die LM- und NTLM-Authentifizierung. Wenn Kerberos falsch konfiguriert ist (z. B. beim Erstellen von SMB-Aliasen), geht der Zugriff auf Shares auf schwächere Authentifizierungsmethoden zurück (z. B. NTLMv2). Da diese Mechanismen weniger sicher sind, sind sie in einigen Active Directory-Umgebungen deaktiviert. Wenn schwächere Authentifizierungsmethoden deaktiviert sind und Kerberos nicht richtig konfiguriert ist, schlägt der Zugriff auf die Freigabe fehl, da keine gültige Authentifizierungsmethode vorhanden ist, auf die Sie zurückgreifen können.</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">Netzwerksicherheit: Authentifizierungsebene des LAN Managers</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Informationen zum Konfigurieren/Anzeigen der unterstützten Authentifizierungsstufen in Active Directory finden Sie unter<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>.</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">Berechtigungsmodelle</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">NTFS/Dateiberechtigungen</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">NTFS-Berechtigungen sind die Berechtigungen, die auf Dateien und Ordner in Dateisystemen angewendet werden, die der NTFS-Logik entsprechen. Sie können NTFS-Berechtigungen in anwenden<block ref="972e73b7a882d0802a4e3a16946a2f94" prefix=" " category="inline-code"></block> Oder<block ref="9b6545e4cea9b4ad4979d41bb9170e2b" prefix=" " category="inline-code"></block> Und kann auf festgelegt werden<block ref="45f0fb72a0defdfdb01de4b5a5a6876b" prefix=" " category="inline-code"></block> Oder<block ref="3682d1665cf331373000c20680732d3a" prefix=" " category="inline-code"></block> Für die Zugriffssteuerung.</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">Grundlegende Berechtigungen beinhalten Folgendes:</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">Volle Kontrolle</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">Ändern</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">Lesen Und Ausführen</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">Lesen</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">Schreiben</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">Wenn Sie Berechtigungen für einen Benutzer oder eine Gruppe festlegen, die als ACE bezeichnet wird, befindet sie sich in einer ACL. NTFS-Berechtigungen verwenden die gleichen Grundlagen zum Lesen/Schreiben/Ausführen wie UNIX-Mode-Bits, können aber auch auf granularere und erweiterte Zugriffskontrollen (auch bekannt als Spezialberechtigungen), wie zum Beispiel Besitzrechte übernehmen, Ordner erstellen/Daten anhängen, Attribute schreiben usw. erweitern.</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">Bits des Standard-UNIX-Modus bieten nicht dieselbe Granularität wie NTFS-Berechtigungen (beispielsweise die Möglichkeit, Berechtigungen für einzelne Benutzer und Gruppenobjekte in einer ACL festzulegen oder erweiterte Attribute festzulegen). NFSv4.1 ACLs bieten jedoch dieselben Funktionen wie NTFS ACLs.</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">NTFS-Berechtigungen sind spezifischer als Freigabeberechtigungen und können in Verbindung mit Freigabeberechtigungen verwendet werden. Bei NTFS-Berechtigungsstrukturen gilt die restriktivere Vorgehensweise. Als solche überschreibt explizite Denals für einen Benutzer oder eine Gruppe sogar die volle Kontrolle, wenn die Zugriffsrechte definiert werden.</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">NTFS-Berechtigungen werden von Windows SMB Clients gesteuert.</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">Freigabeberechtigungen</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">Freigabeberechtigungen sind allgemeiner als NTFS-Berechtigungen (nur Lesen/Ändern/Vollzugriff) und steuern den anfänglichen Eintrag in eine SMB-Freigabe – ähnlich wie die NFS-Exportrichtlinien funktionieren.</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">Obwohl die NFS-Exportrichtlinien den Zugriff über hostbasierte Informationen wie IP-Adressen oder Hostnamen steuern, können SMB-Freigabe-Berechtigungen den Zugriff über Benutzer- und Gruppennamen in einer Share-ACL steuern. Sie können die Share ACLs entweder über den Windows Client oder über die Cloud Volumes Service Management UI festlegen.</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">Standardmäßig enthalten alle ACLs und Initial Volume ACLs mit vollständiger Kontrolle. Die Datei ACLs sollten geändert werden, aber Freigabeberechtigungen werden durch die Dateiberechtigungen für Objekte in der Freigabe überbeherrscht.</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">Wenn ein Benutzer beispielsweise nur Lesezugriff auf die Cloud Volumes Service Volume-Datei-ACL hat, wird ihm der Zugriff auf die Erstellung von Dateien und Ordnern verweigert, obwohl die share ACL für alle mit Full Control eingestellt ist, wie in der folgenden Abbildung dargestellt.</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">Gehen Sie wie folgt vor, um die besten Sicherheitsergebnisse zu erzielen:</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">Entfernen Sie alle aus den Freigabe- und Datei-ACLs und legen Sie stattdessen den Freigaberzugriff für Benutzer oder Gruppen fest.</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">Verwenden Sie Gruppen zur Zugriffssteuerung anstelle einzelner Benutzer, um das Management zu vereinfachen und das Entfernen bzw. Hinzufügen von Benutzern zu beschleunigen, um ACLs über das Gruppenmanagement zu teilen.</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">Weniger restriktiver, allgemeiner Zugriff auf die Asse auf den Freigabeberechtigungen und Sperrung des Zugriffs auf Benutzer und Gruppen mit Dateiberechtigungen für eine granularere Zugriffskontrolle.</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">Die allgemeine Verwendung von expliziten Ablehnen von ACLs vermeiden, da sie ACLs außer Kraft setzen. Beschränken Sie die Verwendung expliziter Ablehnen von ACLs für Benutzer oder Gruppen, die schnell vom Zugriff auf ein Dateisystem eingeschränkt werden müssen.</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">ACL-Vererbung</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">Achten Sie darauf, dass Sie auf die achten<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> Einstellungen beim Ändern von Berechtigungen; das Festlegen des Vererbungsfahs auf der obersten Ebene eines Verzeichnisses oder Volumes mit hoher Dateianzahl bedeutet, dass jede Datei unter diesem Verzeichnis oder Volume über geerbte Berechtigungen verfügt, die ihr hinzugefügt wurden. Dies kann unerwünschte Verhaltensweisen wie unbeabsichtigten Zugriff/Denial-of-DoS und lange Abgänge von Berechtigungsänderungen verursachen, wenn jede Datei angepasst wird.</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">Sicherheitsfunktionen für die SMB-Freigabe</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">Wenn Sie zum ersten Mal ein Volume mit SMB-Zugriff in Cloud Volumes Service erstellen, erhalten Sie eine Reihe von Optionen zum Sichern des Volumes.</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">Einige dieser Optionen hängen von der Cloud Volumes Service-Ebene (Leistung oder Software) ab und stehen zur Auswahl:</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*Snapshot-Verzeichnis sichtbar machen (sowohl für CVS-Performance als auch für CVS-SW verfügbar).* mit dieser Option lässt sich kontrollieren, ob SMB-Clients in einem SMB-Share auf das Snapshot-Verzeichnis zugreifen können <block ref="f9f8c4c52f58b30f374525080a180c65" prefix="(" category="inline-code"></block> Und/oder Registerkarte frühere Versionen). Die Standardeinstellung ist nicht aktiviert, was bedeutet, dass das Volume standardmäßig den Zugriff auf das ausgeblendet und deaktiviert<block ref="26bef40a7b3e14ad93e80f8f4be79090" prefix=" " category="inline-code"></block> Verzeichnis, und es werden keine Snapshot-Kopien auf der Registerkarte Vorherige Versionen des Volumes angezeigt.</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">Das Ausblenden von Snapshot Kopien vor Endbenutzern kann aus Sicherheitsgründen oder aus Performance-Gründen (Ausblenden dieser Ordner vor AV-Scans) oder unter Voreinstellung gewünscht werden. Cloud Volumes Service Snapshots sind schreibgeschützt, d. h. selbst wenn diese Snapshots sichtbar sind, können Endanwender Dateien im Snapshot Verzeichnis nicht löschen oder ändern. Dateiberechtigungen auf die Dateien oder Ordner beim Erstellen der Snapshot Kopie. Wenn sich die Berechtigungen einer Datei oder eines Ordners zwischen Snapshot Kopien ändern, gelten die Änderungen auch für die Dateien oder Ordner im Snapshot Verzeichnis. Benutzer und Gruppen können auf Basis von Berechtigungen auf diese Dateien oder Ordner zugreifen. Das Löschen oder Modifizierungen von Dateien im Snapshot Verzeichnis ist zwar nicht möglich, aber es ist möglich, Dateien oder Ordner aus dem Snapshot Verzeichnis zu kopieren.</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">*SMB-Verschlüsselung aktivieren (sowohl für CVS-Performance als auch für CVS-SW verfügbar).* SMB-Verschlüsselung ist auf der SMB-Freigabe standardmäßig deaktiviert (deaktiviert). Wenn Sie das Kontrollkästchen aktiviert SMB-Verschlüsselung aktivieren, bedeutet dies, dass der Datenverkehr zwischen dem SMB-Client und dem -Server im laufenden Vorgang verschlüsselt wird, wobei die am höchsten unterstützten Verschlüsselungsstufen ausgehandelt werden. Cloud Volumes Service unterstützt bis zu AES-256-Verschlüsselung für SMB. Durch die Aktivierung der SMB-Verschlüsselung kommen Performance-Einbußen mit sich, die für Ihre SMB-Clients möglicherweise nicht spürbar sind – in etwa im Bereich von 10 bis 20 %. NetApp empfiehlt Tests nachdrücklich, um zu prüfen, ob diese Performance-Einbußen akzeptabel sind.</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">*SMB-Share ausblenden (verfügbar sowohl für CVS-Performance als auch CVS-SW).* durch diese Option wird der SMB-Share-Pfad vom normalen Browsing ausgeblendet. Das bedeutet, dass Clients, die den Freigabepfad nicht kennen, die Freigaben beim Zugriff auf den Standard-UNC-Pfad nicht sehen können (z. B.<block ref="eaf10dd9986e1d76c577b974d994e349" prefix=" " category="inline-code"></block>). Wenn das Kontrollkästchen aktiviert ist, können nur Clients darauf zugreifen, die den SMB-Freigabepfad explizit kennen oder über den von einem Gruppenrichtlinienobjekt definierten Freigabepfad verfügen (Sicherheit durch Obfuscation).</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">Wie funktioniert Access Based Enumeration (ABE)?</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*Access-Based Enumeration (ABE) aktivieren (nur CVS-SW).* Dies ähnelt dem Ausblenden der SMB-Freigabe, außer die Freigaben oder Dateien sind nur Benutzern oder Gruppen verborgen, die keine Berechtigung zum Zugriff auf die Objekte haben. Beispiel: Wenn Windows-Benutzer<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Ist mindestens nicht erlaubt Lese-Zugriff durch die Berechtigungen, dann der Windows-Benutzer<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> SMB-Freigabe oder Dateien können überhaupt nicht angezeigt werden. Dies ist standardmäßig deaktiviert und Sie können sie durch Aktivieren des Kästchens aktivieren. Weitere Informationen zu ABE finden Sie im NetApp Knowledge Base-Artikel<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">Kontinuierlich verfügbare SMB-Freigaben</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*Kontinuierliche verfügbare (CA) Freigabesupport aktivieren (nur CVS-Performance).*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Bietet eine Möglichkeit, Applikationsunterbrechungen bei Failover-Ereignissen zu minimieren, indem Sperrstatus über Nodes im Cloud Volumes Service-Back-End-System hinweg repliziert werden. Dies ist keine Sicherheitsfunktion, bietet aber insgesamt eine höhere Ausfallsicherheit. Derzeit werden nur SQL Server- und FSLogix-Anwendungen unterstützt.</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">Ausgeblendete Standardfreigaben</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">Versteckte administrative Freigaben</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">Wenn in Cloud Volumes Service ein SMB Server erstellt wird, gibt es diese<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> (Unter Verwendung der Namenskonvention für USD), die zusätzlich zum SMB-Share des Daten-Volumes erstellt werden. Dazu gehören C€ (Namespace Access) und IPC€ (gemeinsame Nutzung von benannten Rohren für die Kommunikation zwischen Programmen, wie z. B. die Remote Procedure Calls (RPC), die für den Zugriff auf die Microsoft Management Console (MMC) verwendet werden).</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Windows deaktiviert standardmäßig den anonymen Zugriff auf diese Freigaben</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">Die IPC-USD-Freigabe enthält keine Share-ACLs und kann nicht geändert werden – sie wird streng für RPC-Aufrufe und verwendet<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>.</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">Der Wert-Anteil ermöglicht standardmäßig den Zugriff von BUILTIN/Administratoren, aber die Cloud Volumes Service-Automatisierung entfernt das Share-ACL und erlaubt keinen Zugriff auf jemanden, da der Zugriff auf die C€-Aktie eine Übersicht über alle gemounteten Volumes in den Cloud Volumes Service-Dateisystemen ermöglicht. Daher wird versucht, zu navigieren<block ref="33f61bb25149c01e06f9ef66d462e5a2" prefix=" " category="inline-code"></block> Fehler.</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">Konten mit lokalen/BUILTIN-Administrator/Backup-Rechten</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Cloud Volumes Service SMB-Server verfügen über ähnliche Funktionen wie normale Windows SMB-Server, da lokale Gruppen (z. B. BUILTIN\-Administratoren) Zugriffsrechte für ausgewählte Domänenbenutzer und -Gruppen anwenden.</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege und SeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">Wenn Sie einen Benutzer angeben, der zu Backup-Benutzern hinzugefügt werden soll, wird der Benutzer der Gruppe BUILTIN\Backup Operators in der Cloud Volumes Service-Instanz hinzugefügt, die diese Active Directory-Verbindung verwendet, die dann den ruft<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>.</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SQL Server auf SMB-Freigaben</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">Wenn Sie Benutzern von Sicherheitsberechtigungen einen Benutzer hinzufügen, erhält der Benutzer die SeSecurityPrivilege, die in einigen Anwendungsanwendungsfällen, wie z. B., nützlich ist<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>.</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">Sie können die Mitgliedschaften der lokalen Cloud Volumes Service-Gruppen über das MMC mit den entsprechenden Berechtigungen anzeigen. Die folgende Abbildung zeigt Benutzer, die mit der Cloud Volumes Service Konsole hinzugefügt wurden.</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">Die folgende Tabelle zeigt die Liste der Standard-BUILTIN-Gruppen und welche Benutzer/Gruppen standardmäßig hinzugefügt werden.</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">Lokale/BUILTIN-Gruppe</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">Standardmitglieder</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">BUILTIN\Administratoren*</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">DOMAIN\Domänen-Administratoren</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">BUILTIN\Backup Operators*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">BAUEN Sie\Gäste</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">DOMAIN\Domain-Gäste</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">BUILTIN\Power-User</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">BUILTIN\Domain-Benutzer</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">DOMAIN\Domain-Benutzer</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*Gruppenmitgliedschaft in Cloud Volumes Service Active Directory Verbindungskonfiguration gesteuert.</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">Sie können lokale Benutzer und Gruppen (und Gruppenmitglieder) im MMC-Fenster anzeigen, aber Sie können keine Objekte hinzufügen oder löschen oder Gruppenmitgliedschaften von dieser Konsole aus ändern. Standardmäßig werden nur die Gruppe Domänenadministratoren und der Administrator der BUILTIN\Administrators in Cloud Volumes Service hinzugefügt. Derzeit können Sie dies nicht ändern.</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">MMC-/Computermanagement-Zugriff</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">SMB-Zugriff in Cloud Volumes Service bietet Konnektivität zum Computer Management MMC, mit dem Sie Freigaben anzeigen, ACLs gemeinsam nutzen, SMB-Sessions anzeigen/managen und Dateien öffnen können.</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">Damit Sie die MMC verwenden können, um SMB-Freigaben und -Sitzungen in Cloud Volumes Service anzuzeigen, muss der aktuell angemeldete Benutzer ein Domänenadministrator sein. Andere Benutzer haben Zugriff auf das Anzeigen oder Verwalten des SMB-Servers von MMC aus und erhalten ein Dialogfeld ohne Berechtigungen, wenn Sie versuchen, Freigaben oder Sitzungen in der Cloud Volumes Service SMB-Instanz anzuzeigen.</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">Um eine Verbindung zum SMB-Server herzustellen, öffnen Sie Computerverwaltung, klicken Sie mit der rechten Maustaste auf Computerverwaltung, und wählen Sie dann Verbindung zu einem anderen Computer herstellen. Daraufhin wird das Dialogfeld „Computer auswählen“ geöffnet, in dem Sie den SMB-Servernamen eingeben können (zu finden in den Cloud Volumes Service-Volume-Informationen).</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">Wenn Sie SMB-Freigaben mit den entsprechenden Berechtigungen anzeigen, sehen Sie alle verfügbaren Freigaben in der Cloud Volumes Service-Instanz, die die Active Directory-Verbindung nutzen. Um dieses Verhalten zu steuern, legen Sie die Option SMB-Freigaben ausblenden auf der Cloud Volumes Service-Volume-Instanz fest.</block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">Denken Sie daran, dass pro Region nur eine Active Directory-Verbindung zulässig ist.</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">Die folgende Tabelle zeigt eine Liste der unterstützten/nicht unterstützten Funktionen für MMC.</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">Unterstützte Funktionen</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">Nicht unterstützte Funktionen</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">Freigaben anzeigen</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">Anzeigen von aktiven SMB-Sitzungen</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">Öffnen Sie Dateien anzeigen</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">Zeigen Sie lokale Benutzer und Gruppen an</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">Zeigen Sie lokale Gruppenmitgliedschaften an</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">Listen Sie die Liste der Sitzungen, Dateien und Baumverbindungen im System auf</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">Schließen Sie offene Dateien im System</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">Offene Sitzungen schließen</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">Freigaben erstellen/managen</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">Erstellen neuer lokaler Benutzer/Gruppen</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">Verwalten/Anzeigen vorhandener lokaler Benutzer/Gruppen</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">Zeigt Ereignisse oder Performance-Protokolle an</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">Storage-Management</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">Management von Services und Applikationen</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">Sicherheitsinformationen für SMB-Server</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Der SMB-Server in Cloud Volumes Service verwendet eine Reihe von Optionen, die Sicherheitsrichtlinien für SMB-Verbindungen definieren, einschließlich Kerberos-Clock-Skew, Ticketalter, Verschlüsselung und mehr.</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">Die folgende Tabelle enthält eine Liste dieser Optionen, was sie tun, der Standardkonfigurationen und, ob sie mit Cloud Volumes Service geändert werden können. Einige Optionen gelten nicht für Cloud Volumes Service.</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">Sicherheitsoption</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">Das macht es</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">Standardwert</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">Können Sie Veränderungen vornehmen?</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">Maximale Kerberos-Uhr-Skew (Minuten)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Maximale Zeitabweichung zwischen Cloud Volumes Service und Domain Controllern Wenn die Zeitskew 5 Minuten überschreitet, schlägt die Kerberos-Authentifizierung fehl. Dieser Wert ist auf den Standardwert von Active Directory gesetzt.</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Lebensdauer von Kerberos-Tickets (Stunden)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">Maximale Zeit, bis ein Kerberos-Ticket gültig bleibt, bevor eine Erneuerung erforderlich ist. Wenn keine Verlängerung vor 10 Stunden erfolgt, müssen Sie ein neues Ticket einholen. Cloud Volumes Service führt diese Verlängerungen automatisch durch. 10 Stunden ist der Standardwert von Active Directory.</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Maximale Kerberos-Ticketverlängerung (Tage)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">Maximale Anzahl der Tage, an denen ein Kerberos-Ticket erneuert werden kann, bevor eine neue Autorisierungsanforderung erforderlich ist. Cloud Volumes Service verlängert automatisch die Tickets für SMB-Verbindungen. Sieben Tage ist der Standardwert von Active Directory.</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Kerberos KDC-Verbindungszeitlimit (Sek.)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">Die Anzahl der Sekunden, bevor eine KDC-Verbindung ausgeht.</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">Für eingehenden SMB-Datenverkehr müssen signiert werden</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">Für SMB-Datenverkehr muss eine Signatur erforderlich sein. Wenn auf „true“ gesetzt ist, unterstützen Clients, die keine Verbindung zum Signieren von Fehlschlagen unterstützen.</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">Komplexität des Kennworts für lokale Benutzerkonten erforderlich</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">Wird für Passwörter für lokale SMB-Benutzer verwendet. Cloud Volumes Service unterstützt die Erstellung lokaler Benutzer nicht, daher gilt diese Option nicht für Cloud Volumes Service.</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">Richtig</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Verwenden Sie Start_tls für Active Directory-LDAP-Verbindungen</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Wird zum Starten von TLS-Verbindungen für Active Directory LDAP verwendet. Cloud Volumes Service unterstützt derzeit die Aktivierung dieses Systems nicht.</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">AES-128- und AES-256-Verschlüsselung für Kerberos aktiviert</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">Dies steuert, ob AES-Verschlüsselung für Active Directory-Verbindungen verwendet wird und wird über die Option AES-Verschlüsselung für Active Directory-Authentifizierung aktivieren bei der Erstellung/Änderung der Active Directory-Verbindung gesteuert.</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">LM-Kompatibilitätsstufe</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Ebene der unterstützten Authentifizierungsdialekte für Active Directory-Verbindungen. Siehe Abschnitt „<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>„ Weitere Informationen.</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">ntlmv2-krb</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">SMB-Verschlüsselung für eingehenden CIFS-Datenverkehr erforderlich</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">SMB-Verschlüsselung für alle Freigaben erforderlich Dies wird nicht von Cloud Volumes Service verwendet; stattdessen setzen Sie Verschlüsselung auf Volume-Basis (siehe Abschnitt „<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>„).</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">Sicherheit Der Client-Sitzung</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">„LDAP-Kanalbindung.“</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">Legt das Signing und/oder Sealing für die LDAP-Kommunikation fest. Dies ist derzeit nicht in Cloud Volumes Service eingestellt, kann aber in zukünftigen Versionen zur Adresse benötigt werden. Die Behebung von Problemen mit der LDAP-Authentifizierung aufgrund des Windows-Patches wird im Abschnitt behandelt <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>.</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">SMB2 aktivieren für Gleichstromverbindungen</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">Verwendet SMB2 für DC-Verbindungen. Standardmäßig aktiviert.</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">Systemstandard</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">LDAP Referral Chasing</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">Bei der Verwendung mehrerer LDAP-Server ermöglicht die Verweisungsjagd dem Client, auf andere LDAP-Server in der Liste zu verweisen, wenn ein Eintrag nicht im ersten Server gefunden wird. Dies wird derzeit nicht von Cloud Volumes Service unterstützt.</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">Verwenden Sie LDAPS für sichere Active Directory-Verbindungen</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">Aktiviert die Verwendung von LDAP über SSL. Derzeit nicht unterstützt von Cloud Volumes Service.</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">Für DC-Verbindung ist eine Verschlüsselung erforderlich</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">Verschlüsselung für erfolgreiche DC-Verbindungen erforderlich. In Cloud Volumes Service standardmäßig deaktiviert.</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">Weiter: Dual-Protokoll/Multiprotokoll.</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Cloud Volumes Service in Google Cloud bietet zahlreiche Möglichkeiten zur nativen Sicherung Ihrer Daten.</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Wie Cloud Volumes Service in Google Cloud Ihre Daten sichert</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">Sichere Architektur und Mandantenmodell</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">„Cloud Volumes Service Architecture“</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">Zugang zu privaten Services</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service bietet eine sichere Architektur in Google Cloud, indem das Service-Management (Kontrollebene) und der Datenzugriff (Datenebene) über verschiedene Endpunkte segmentiert werden, sodass keine Auswirkung auf den anderen Endpunkte besteht (siehe Abschnitt <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>). Sie verwendet Googles<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA) Framework zur Bereitstellung des Service. In diesem Rahmen wird zwischen dem von NetApp bereitgestellten und betriebenen Service-Produzenten unterschieden. Dabei handelt es sich um eine Virtual Private Cloud (VPC) in einem Kundenprojekt, in dem die Clients gehostet werden, die auf Cloud Volumes Service-Dateifreigaben zugreifen möchten.</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">„Tenancy model“</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">„Gemeinsame VPCs“</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">In dieser Architektur finden Mandanten (siehe Abschnitt <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>) Sind als Google Cloud-Projekte definiert, die vollständig voneinander getrennt sind, es sei denn, der Benutzer hat ausdrücklich eine Verbindung. Mandanten ermöglichen durch die Cloud Volumes Service Volume-Plattform die vollständige Isolierung von Daten-Volumes, externen Name Services und anderen wichtigen Lösungselementen von anderen Mandanten. Da die Cloud Volumes Service Plattform über VPC Peering verbunden ist, gilt diese Isolierung auch für die IT. Sie können die Freigabe von Cloud Volumes Service Volumes zwischen mehreren Projekten mithilfe einer gemeinsam genutzten VPC aktivieren (siehe Abschnitt <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>). Zugriffssteuerung kann auf SMB-Freigaben und NFS-Exporte angewendet werden, um zu beschränken, wer bzw. welche Datensätze angezeigt oder geändert werden können.</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">Starkes Identitätsmanagement für die Kontrollebene</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">Identitäts-Zugriffsmanagement (Identity Access Management, IAM)</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">In der Kontrollebene, auf der die Cloud Volumes Service-Konfiguration stattfindet, wird das Identitätsmanagement mit verwaltet<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>. IAM ist ein Standardservice, mit dem die Authentifizierung (Logins) und Autorisierung (Berechtigungen) für Google Cloud-Projektinstanzen gesteuert werden kann. Die gesamte Konfiguration erfolgt über Cloud Volumes Service APIs über einen sicheren HTTPS-Transport mithilfe der TLS 1.2-Verschlüsselung. Die Authentifizierung erfolgt über JWT-Token für zusätzliche Sicherheit. Die Google-Konsole-Benutzeroberfläche für Cloud Volumes Service übersetzt Benutzereingaben in Cloud Volumes Service-API-Aufrufe.</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">Sicherheitshärtung – Begrenzung von Angriffsflächen</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">Ein Teil der effektiven Sicherheit ist die Begrenzung der Anzahl der Angriffsflächen, die in einem Service verfügbar sind. Angriffsflächen können eine Vielzahl von Dingen umfassen, beispielsweise Daten im Ruhezustand, Übertragungs- und Logins während der Übertragung und die Datensätze selbst.</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">„Service-Betrieb“,</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">Ein Managed Service entfernt einige Angriffsflächen inhärent in seinem Design. Infrastruktur-Management, wie im Abschnitt beschrieben <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> Wird von einem dedizierten Team durchgeführt und verringert automatisch die Anzahl der Male, die ein Mensch tatsächlich bei Konfigurationen berührt, wodurch die Anzahl vorsätzlicher und unbeabsichtigter Fehler reduziert wird. Die Netzwerkumgebung ist abgezäunt, sodass nur erforderliche Services aufeinander zugreifen können. Die Verschlüsselung wird in den Datenspeicher integriert. Cloud Volumes Service Administratoren benötigen lediglich die Datenebene Sicherheitsaspekte. Wenn Sie den Großteil der Verwaltung hinter einer API-Schnittstelle verbergen, wird die Sicherheit durch Begrenzung der Angriffsflächen erreicht.</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">Zero-Trust-Modell</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">In der Vergangenheit BESTAND DIE IT-Sicherheitsphilosophie darin, Vertrauen zu geben, zu verifizieren und zu manifestieren, dass sie sich ausschließlich auf externe Mechanismen (wie Firewalls und Intrusion Detection Systems) zur Minderung von Bedrohungen verlassen. Angriffe und Verstöße wurden jedoch entwickelt, um die Verifizierung in Umgebungen durch Phishing, Social Engineering, Bedrohungen von innen und andere Methoden zu umgehen, die die Verifizierung in Netzwerke und Verwüstung ermöglichen.</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">Zero Trust hat sich zu einer neuen Sicherheitsmethode entwickelt, wobei das aktuelle Mantra „Vertrauen Sie nichts, während Sie noch alles überprüfen“ ist. Daher ist standardmäßig kein Zugriff zulässig. Dieses Mantra wird auf verschiedene Arten durchgesetzt, darunter Standard-Firewalls und Intrusion Detection-Systeme (IDS) sowie folgende Methoden:</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">Starke Authentifizierungsmethoden (z. B. AES-verschlüsselte Kerberos- oder JWT-Token)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">Einzelne, starke Identifikationsquellen (z. B. Windows Active Directory, Lightweight Directory Access Protocol (LDAP) und Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">Netzwerksegmentierung und sichere Mandantenfähigkeit (standardmäßig sind nur Mandanten Zugriff erlaubt)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">Granulare Zugriffssteuerung mit den geringsten Zugriffsrichtlinien</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">Kleine exklusive Listen von engagierten, vertrauenswürdigen Administratoren mit digitalen Audit- und Papiertrails</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">Cloud Volumes Service läuft in Google Cloud hält sich an das Zero-Trust-Modell durch die Umsetzung der "Vertrauen nichts, alles überprüfen" Haltung.</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">Verschlüsselung</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">„Datenverschlüsselung im Ruhezustand“</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">„SMB-Verschlüsselung“</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">„Regionenübergreifende Replikation“</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">„Datenverschlüsselung während der Übertragung“</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">„Google Cloud-Netzwerk“</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">Verschlüsselung von Daten im Ruhezustand (siehe Abschnitt <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) Mit XTS-AES-256-Chiffren mit NetApp Volume Encryption (NVE) und im Flight mit <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> Oder NFS Kerberos 5p-Support. Gut zu wissen, dass regionsübergreifende Replikationstransfers durch TLS 1.2-Verschlüsselung geschützt sind (siehe Abschnitt <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>). Darüber hinaus bietet Google Networking auch verschlüsselte Kommunikation (siehe Abschnitt <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>) Für eine zusätzliche Schutzschicht gegen Angriffe. Weitere Informationen zur Transportverschlüsselung finden Sie im Abschnitt <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>.</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">Datensicherung und Backups</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="inline-link-macro">Cloud Volumes Service-Backup</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">Bei der Sicherheit geht es nicht nur um die Verhinderung von Angriffen. Es geht auch darum, wie wir nach Angriffen eine Wiederherstellung durchführen, wenn sie auftreten. Diese Strategie umfasst Datenschutz und -Backups. Cloud Volumes Service bietet Methoden zur Replizierung in andere Regionen bei Ausfällen (siehe Abschnitt <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>) Oder wenn ein Datensatz von einem Ransomware-Angriff betroffen ist. Sie kann auch asynchrone Daten-Backups von Standorten außerhalb der Cloud Volumes Service Instanz mithilfe von durchführen <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>. Mit regelmäßigen Backups kann das Abmildern von Sicherheitsereignissen Zeit in Anspruch nehmen, Geld und Aufwand für Administratoren einsparen.</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">Schnelle Abwehr von Ransomware mit branchenführenden Snapshot Kopien</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">„Unveränderliche Snapshot Kopien“</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">„Service-Betrieb“</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Zusätzlich zu Datensicherung und Backups unterstützt Cloud Volumes Service auch unveränderliche Snapshot Kopien (siehe Abschnitt <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>) Von Volumes, die eine Wiederherstellung nach Ransomware-Angriffen ermöglichen (siehe Abschnitt <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>Innerhalb von Sekunden nach der Entdeckung des Problems und mit minimaler Unterbrechung. Die Recovery-Zeit und -Auswirkungen hängen vom Snapshot Zeitplan ab. Allerdings können Snapshot-Kopien erstellt werden, die bei Ransomware-Angriffen nur eine Stunde Deltawerte liefern. Snapshot Kopien haben nahezu unmerkliche Auswirkungen auf die Performance und Kapazitätsauslastung und stellen einen Ansatz mit niedrigem Risiko und hoher Rendite zum Schutz Ihrer Datensätze dar.</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">Als Nächstes: Sicherheitsüberlegungen und Angriffsflächen.</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">Bei der Verwendung von Cloud Volumes Service für NAS-Freigaben sind möglicherweise externe Abhängigkeiten erforderlich, um ordnungsgemäße Funktion sicherzustellen. Diese Abhängigkeiten spielen unter bestimmten Umständen eine Rolle.</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">Andere NAS-Infrastruktur-Serviceabhängigkeiten (KDC, LDAP und DNS)</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">Zurück: Überlegungen zum Erstellen von Active Directory-Verbindungen.</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">Bei der Verwendung von Cloud Volumes Service für NAS-Freigaben sind möglicherweise externe Abhängigkeiten erforderlich, um ordnungsgemäße Funktion sicherzustellen. Diese Abhängigkeiten spielen unter bestimmten Umständen eine Rolle. Die folgende Tabelle zeigt verschiedene Konfigurationsoptionen und ggf. erforderliche Abhängigkeiten.</block>
  <block id="254f642527b45bc260048e30704edb39" category="cell">Konfiguration</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">Erforderliche Abhängigkeiten</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">Nur NFSv3</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">Nur NFSv3 Kerberos</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Windows Active Directory: * KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">Nur NFSv4.1</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">Konfiguration der Client-ID-Zuordnung (/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">Nur Kerberos</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Windows Active Directory: KDC-DNS-LDAP</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">Nur SMB</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory: * KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">Multi-Protokoll-NAS (NFS und SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">Konfiguration der Client-ID-Zuordnung (nur NFSv4.1; /etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">Kerberos Keytab-Rotation/Passwort-Reset für Computerkontoobjekte</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">Bei SMB-Computerkonten plant Cloud Volumes Service regelmäßige Passwortrücksetzungen für das SMB-Maschinenkonto. Diese Kennwortrücksetzung erfolgt mit Kerberos-Verschlüsselung und wird nach einem Zeitplan jeden vierten Sonntag zu einer zufälligen Zeit zwischen 23:00 und 1:00 UHR ausgeführt. Mit diesem Kennwort werden die Kerberos-Schlüsselversionen geändert, die Keytabs, die auf dem Cloud Volumes Service-System gespeichert sind, gedreht und die Sicherheit von SMB-Servern, die in Cloud Volumes Service ausgeführt werden, erhöht. Passwörter für Computerkonten sind randomisiert und Administratoren nicht bekannt.</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">Bei NFS-Kerberos-Computerkonten erfolgt ein Zurücksetzen des Passworts nur dann, wenn ein neuer Keytab mit dem KDC erstellt/ausgetauscht wird. Derzeit ist dies in Cloud Volumes Service nicht möglich.</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">Netzwerkports zur Verwendung mit LDAP und Kerberos</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">Cloud Volumes Service Dokumentation zu Sicherheitsüberlegungen</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">Wenn Sie LDAP und Kerberos verwenden, sollten Sie die von diesen Diensten verwendeten Netzwerkports ermitteln. Eine vollständige Liste der von Cloud Volumes Service verwendeten Ports finden Sie im<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>.</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service fungiert als LDAP-Client und verwendet Standard-LDAP-Suchanfragen für Benutzer- und Gruppensuchen nach UNIX-Identitäten. LDAP ist erforderlich, wenn Sie Benutzer und Gruppen außerhalb der von Cloud Volumes Service bereitgestellten Standardbenutzer verwenden möchten. LDAP ist auch erforderlich, wenn Sie die Verwendung von NFS Kerberos mit Benutzerprinzipals (z. B. user1@domain.com) planen. Derzeit wird nur LDAP unterstützt, die Microsoft Active Directory verwenden.</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Wenn Sie Active Directory als UNIX LDAP-Server verwenden möchten, müssen Sie die erforderlichen UNIX-Attribute für Benutzer und Gruppen ausfüllen, die Sie für UNIX-Identitäten verwenden möchten. Cloud Volumes Service verwendet eine Standard-LDAP-Schemavorlage, die Attribute basierend auf abfragt<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>. Die folgende Tabelle zeigt die für Benutzer und Gruppen erforderlichen Mindestattribute für Active Directory und deren Verwendung für die einzelnen Attribute.</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">Management des Dual-Protokoll-Zugriffs:</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Weitere Informationen zum Festlegen von LDAP-Attributen in Active Directory finden Sie unter<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">Attribut</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">uid*</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">Gibt den UNIX-Benutzernamen an</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">UidNummer*</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">Gibt die numerische ID des UNIX-Benutzers an</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">GidNumber*</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">Gibt die numerische ID der primären Gruppe des UNIX-Benutzers an</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">ObjectClass*</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">Gibt an, welcher Objekttyp verwendet wird; Cloud Volumes Service erfordert, dass „Benutzer“ in die Liste der Objektklassen aufgenommen werden muss (ist standardmäßig in den meisten Active Directory-Bereitstellungen enthalten).</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">Allgemeine Informationen zum Konto (echter Name, Telefonnummer usw.)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">UnixUserpasswort</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">Kein Grund zur Festlegung; nicht in UNIX-Identitätssuchten für die NAS-Authentifizierung verwendet. Durch diese Einstellung wird der konfigurierte Wert unixUserPassword in Klartext gesetzt.</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">UnixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">Definiert den Pfad zu UNIX-Home-Verzeichnissen, wenn ein Benutzer sich von einem Linux-Client aus mit LDAP authentifiziert. Legen Sie diesen Wert fest, wenn Sie die Home-Directory-Funktion LDAP für UNIX verwenden möchten.</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">LoginShell</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">Definiert den Pfad zur Bash/Profile Shell für Linux-Clients, wenn ein Benutzer sich mit LDAP authentifiziert.</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*Bezeichnet das Attribut, das für die ordnungsgemäße Funktion mit Cloud Volumes Service erforderlich ist. Die übrigen Attribute gelten nur für die Client-seitige Verwendung.</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">kn*</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">Gibt den Namen der UNIX-Gruppe an. Bei der Verwendung von Active Directory für LDAP wird dieser Wert bei der ersten Erstellung des Objekts festgelegt, kann aber später geändert werden. Dieser Name darf nicht mit anderen Objekten identisch sein. Zum Beispiel, wenn Ihr UNIX-Benutzer namens user1 gehört zu einer Gruppe namens user1 auf Ihrem Linux-Client, Windows erlaubt nicht zwei Objekte mit dem gleichen cn-Attribut. Um dies zu umgehen, benennen Sie den Windows-Benutzer in einen eindeutigen Namen um (z. B. user1-UNIX); LDAP in Cloud Volumes Service verwendet das Attribut uid für UNIX-Benutzernamen.</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">Gibt die numerische ID der UNIX-Gruppe an.</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">Gibt an, welcher Objekttyp verwendet wird; Cloud Volumes Service erfordert eine Gruppe, die in die Liste der Objektklassen aufgenommen werden soll (dieses Attribut ist standardmäßig in den meisten Active Directory-Bereitstellungen enthalten).</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">MitgliedschaftenUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">Gibt an, welche UNIX-Benutzer Mitglieder der UNIX-Gruppe sind. Bei Active Directory LDAP in Cloud Volumes Service ist dieses Feld nicht erforderlich. Das Cloud Volumes Service-LDAP-Schema verwendet das Mitgliedfeld für Gruppenmitgliedschaften.</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">Mitglied*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">Erforderlich für Gruppenmitgliedschaften/sekundäre UNIX-Gruppen Dieses Feld wird ausgefüllt, indem Windows-Benutzer zu Windows-Gruppen hinzugefügt werden. Allerdings, wenn die Windows-Gruppen nicht über UNIX-Attribute gefüllt haben, sind sie nicht in der UNIX-Benutzer-Gruppenmitgliedliste enthalten. Alle Gruppen, die in NFS verfügbar sein müssen, müssen die in dieser Tabelle aufgeführten erforderlichen UNIX-Gruppenattribute ausfüllen.</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">LDAP-Bindeinformationen</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">Um Benutzer in LDAP abfragen zu können, muss Cloud Volumes Service den LDAP-Dienst binden (anmelden). Diese Anmeldung hat schreibgeschützte Berechtigungen und wird verwendet, um LDAP-UNIX-Attribute für Verzeichnissuchen abzufragen. Derzeit ist LDAP-Bindungen nur über die Verwendung eines SMB-Maschinenkontos möglich.</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">LDAP kann nur für aktiviert werden<block ref="439d7969e09b4b31626fcf209b8fdcb7" prefix=" " category="inline-code"></block> Instanzen können für NFSv3, NFSv4.1 oder Dual-Protocol Volumes verwendet werden. Für die erfolgreiche Bereitstellung des LDAP-fähigen Volumes muss eine Active Directory-Verbindung in derselben Region wie das Cloud Volumes Service-Volume hergestellt werden.</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">Wenn LDAP aktiviert ist, tritt in bestimmten Szenarien Folgendes auf.</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Wenn nur NFSv3 oder NFSv4.1 für das Cloud Volumes Service-Projekt verwendet wird, wird im Active Directory-Domänencontroller ein neues Maschinenkonto erstellt, und der LDAP-Client in Cloud Volumes Service bindet sich mithilfe der Anmeldeinformationen für das Computerkonto an Active Directory. Für das NFS Volume und die verborgenen administrativen Standardfreigaben werden keine SMB-Freigaben erstellt (siehe Abschnitt <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Haben Freigabe-ACLs entfernt.</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Wenn Dual-Protokoll-Volumes für das Cloud Volumes Service-Projekt genutzt werden, wird nur das für SMB-Zugriff erstellte Maschinenkonto verwendet, um den LDAP-Client in Cloud Volumes Service an Active Directory zu binden. Es werden keine weiteren Computerkonten erstellt.</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">Wenn dedizierte SMB-Volumes separat erstellt werden (entweder vor oder nach Aktivierung von NFS-Volumes mit LDAP), wird das Computerkonto für LDAP-Bindungen mit dem SMB-Computerkonto gemeinsam genutzt.</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">Wenn NFS Kerberos ebenfalls aktiviert ist, werden zwei Computerkonten erstellt: Eins für SMB-Freigaben und/oder LDAP bindet und eins für die NFS-Kerberos-Authentifizierung.</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">Obwohl LDAP-Bindungen verschlüsselt sind, werden LDAP-Abfragen über das Netzwerk im Klartext über den gemeinsamen LDAP-Port 389 übergeben. Dieser bekannte Port kann derzeit nicht in Cloud Volumes Service geändert werden. Infolgedessen kann ein Benutzer- und Gruppennamen, numerische IDs und Gruppenmitgliedschaften mit Zugriff auf Packet Sniffing im Netzwerk angezeigt werden.</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">„Packet Sniffing/Trace Betrachtungen.“</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">Allerdings können Google Cloud VMs nicht schnuppern andere VM Unicast-Verkehr. Nur VMs, die aktiv am LDAP-Datenverkehr beteiligt sind (das heißt, binden zu können), können Datenverkehr vom LDAP-Server sehen. Weitere Informationen zum Packet Sniffing in Cloud Volumes Service finden Sie im Abschnitt <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">Standard für die LDAP-Client-Konfiguration</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Wenn LDAP in einer Cloud Volumes Service-Instanz aktiviert ist, wird standardmäßig eine LDAP-Client-Konfiguration mit spezifischen Konfigurationsdetails erstellt. In einigen Fällen gelten Optionen entweder nicht für Cloud Volumes Service (nicht unterstützt) oder können nicht konfiguriert werden.</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">LDAP-Client-Option</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">LDAP-Serverliste</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">Legt LDAP-Servernamen oder IP-Adressen für Abfragen fest. Dies wird für Cloud Volumes Service nicht verwendet. Stattdessen wird Active Directory Domain zum Definieren von LDAP-Servern verwendet.</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">Nicht festgelegt</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Active Directory-Domäne</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">Legt die Active Directory-Domäne für LDAP-Abfragen fest. Cloud Volumes Service nutzt SRV-Datensätze für LDAP in DNS, um LDAP-Server in der Domäne zu finden.</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Legen Sie die Active Directory-Domäne fest, die in der Active Directory-Verbindung angegeben ist.</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">Bevorzugte Active Directory-Server</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">Legt die bevorzugten Active Directory-Server fest, die für LDAP verwendet werden sollen. Nicht unterstützt durch Cloud Volumes Service. Verwenden Sie stattdessen Active Directory-Sites, um die LDAP-Serverauswahl zu steuern.</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">Nicht festgelegt.</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">Binden mit SMB Server Credentials</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">Bindet an LDAP über das SMB-Maschinenkonto. Derzeit ist die einzige unterstützte LDAP-Bindemethode in Cloud Volumes Service.</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">Schemavorlage</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">Die Schemavorlage, die für LDAP-Abfragen verwendet wird.</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">LDAP-Serverport</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">Die für LDAP-Abfragen verwendete Portnummer. Cloud Volumes Service verwendet derzeit nur den Standard-LDAP-Port 389. LDAPS/Port 636 wird derzeit nicht unterstützt.</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">Ist LDAPS aktiviert</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">Steuert, ob LDAP over Secure Sockets Layer (SSL) für Abfragen und Bindungen verwendet wird. Derzeit nicht unterstützt von Cloud Volumes Service.</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">Zeitüberschreitung bei Abfrage (Sek.)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">Timeout für Abfragen. Wenn Abfragen länger als der angegebene Wert dauern, schlagen Abfragen fehl.</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">Minimale Stufe Der Bind-Authentifizierung</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">Die minimal unterstützte Bindestufe. Da Cloud Volumes Service Computerkonten für LDAP-Bindungen verwendet und Active Directory standardmäßig keine anonymen Bindungen unterstützt, kommt diese Option aus Sicherheitsgründen nicht zum Spiel.</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">Anonym</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">DN binden</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">Der für Bindungen verwendete Benutzer/Distinguished Name (DN) wird verwendet, wenn einfache Bindung verwendet wird. Cloud Volumes Service verwendet Computerkonten für LDAP-Verbindungen und unterstützt derzeit keine einfache Bindeauthentifizierung.</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">Basis-DN</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">Der Basis-DN, der für LDAP-Suchen verwendet wird.</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">Die Windows-Domäne, die für die Active Directory-Verbindung im DN-Format verwendet wird (d. h. DC=Domain, DC=local).</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">Umfang der Basissuche</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">Der Suchbereich für Basis-DN-Suchvorgänge. Werte können Basis, Onelevel oder Unterbaum umfassen. Cloud Volumes Service unterstützt nur Unterbaumsuchen.</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">Unterbaum</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">Benutzer-DN</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">Definiert den DN, in dem der Benutzer nach LDAP-Abfragen startet. Derzeit wird Cloud Volumes Service nicht unterstützt, sodass alle Benutzersuchen am Basis-DN beginnen.</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">Umfang der Benutzersuche</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">Der Suchbereich für Benutzer-DN sucht. Werte können Basis, Onelevel oder Unterbaum umfassen. Cloud Volumes Service unterstützt das Festlegen des Anwendungsbereichs für die Benutzersuche nicht.</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">Gruppen-DN</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">Definiert den DN, in dem die Gruppensuche nach LDAP-Abfragen beginnen soll. Derzeit wird Cloud Volumes Service nicht unterstützt, daher beginnen alle Gruppensuchen am Basis-DN.</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">Bereich der Gruppensuche</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">Der Suchbereich für Gruppen-DN sucht. Werte können Basis, Onelevel oder Unterbaum umfassen. Cloud Volumes Service unterstützt das Festlegen des Umfangs der Gruppensuche nicht.</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">Netzgruppe DN</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">Definiert den DN, in dem Netzgruppe nach LDAP-Abfragen startet. Derzeit wird Cloud Volumes Service nicht unterstützt, daher beginnen alle Netzgruppensuchvorgänge am Basis-DN.</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">Suchumfang für Netzgruppe</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">Der Suchbereich für Netzgruppe DN sucht. Werte können Basis, Onelevel oder Unterbaum umfassen. Cloud Volumes Service unterstützt nicht das Festlegen des Suchbereichs für Netzgruppen.</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">Verwenden Sie Start_tls über LDAP</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">Nutzt Start TLS für zertifikatbasierte LDAP-Verbindungen über Port 389. Derzeit nicht unterstützt von Cloud Volumes Service.</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">Aktivieren Sie die Suche in netgroup-by-Host</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">Ermöglicht die Suche in einer Netzwerkgruppe nach Hostnamen und nicht die Erweiterung von Netgroups, um alle Mitglieder aufzulisten. Derzeit nicht unterstützt von Cloud Volumes Service.</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">Netgroup-by-Host DN</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">Definiert den DN, in dem netgroup-by-Host nach LDAP-Abfragen startet. Netgroup-by-Host wird derzeit für Cloud Volumes Service nicht unterstützt.</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">Suchumfang für Netzgruppe nach Host</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">Der Suchbereich für netgroup-by-Host DN sucht. Werte können Basis, Onelevel oder Unterbaum enthalten. Netgroup-by-Host wird derzeit für Cloud Volumes Service nicht unterstützt.</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">Sicherheit der Client-Session</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">Definiert, in welchem Maß die Sitzungssicherheit von LDAP verwendet wird (Zeichen, Siegel oder keine). Das LDAP-Signieren wird von CVS-Performance unterstützt, sofern dies von Active Directory angefordert wird. CVS-SW unterstützt LDAP-Signatur nicht. Für beide Servicetypen wird die Dichtung derzeit nicht unterstützt.</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">LDAP-Verweisungsjagd</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">Filter für Gruppenmitgliedschaft</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">Bietet einen benutzerdefinierten LDAP-Suchfilter, der verwendet werden kann, wenn eine Gruppenmitgliedschaft von einem LDAP-Server aus gesucht wird. Derzeit nicht unterstützt mit Cloud Volumes Service.</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">LDAP für asymmetrische Namenszuweisung verwenden</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">Cloud Volumes Service ordnet Windows-Benutzern und UNIX-Benutzern standardmäßig ohne spezielle Konfiguration bidirektional identische Benutzernamen zu. Solange Cloud Volumes Service einen gültigen UNIX-Benutzer (mit LDAP) finden kann, erfolgt die 1:1-Namenszuweisung. Beispiel: Wenn Windows-Benutzer<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Wird verwendet, dann, wenn Cloud Volumes Service einen UNIX-Benutzer namens finden kann<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> In LDAP ist die Namenszuordnung für diesen Benutzer erfolgreich, alle Dateien/Ordner, die von erstellt wurden<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Zeigen Sie den korrekten Benutzerbesitz und alle ACLs an, die davon betroffen sind<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Unabhängig vom verwendeten NAS-Protokoll honoriert werden. Dies wird als symmetrisches Namenszuordnungen bezeichnet.</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">Asymmetrisches Namenszuordnungen ist, wenn die Windows-Benutzer- und UNIX-Benutzeridentität nicht übereinstimmt. Beispiel: Wenn Windows-Benutzer<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Hat eine UNIX-Identität von<block ref="39ce7e2a8573b41ce73b5ba41617f8f7" prefix=" " category="inline-code"></block>, Cloud Volumes Service braucht einen Weg, um über die Variation zu erzählen. Da Cloud Volumes Service derzeit nicht die Erstellung von statischen Name Mapping Regeln unterstützt, muss LDAP verwendet werden, um die Identität der Benutzer für Windows und UNIX Identitäten zu suchen, um die ordnungsgemäße Eigentum von Dateien und Ordnern und erwarteten Berechtigungen zu gewährleisten.</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">Standardmäßig enthält Cloud Volumes Service Folgendes<block ref="2363dee608bcd9f6ce7f980bfdad5789" prefix=" " category="inline-code"></block> Im ns-Switch der Instanz für die Name-Map-Datenbank, sodass Sie die Namenszuordnungsfunktion durch die Verwendung von LDAP für asymmetrische Namen bereitstellen können, müssen Sie nur einige der Benutzer-/Gruppenattribute ändern, um das zu reflektieren, was Cloud Volumes Service sucht.</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">In der folgenden Tabelle wird gezeigt, welche Attribute für die asymmetrische Namenszuordnungsfunktion in LDAP ausgefüllt werden müssen. In den meisten Fällen ist Active Directory bereits dafür konfiguriert.</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Cloud Volumes Service Attribut</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Von Cloud Volumes Service für die Namenszuweisung verwendeter Wert</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">Windows auf UNIX objectClass</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">Gibt den Typ des verwendeten Objekts an. (D. h. Benutzer, Gruppe, PosixAccount usw.)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">Muss Benutzer enthalten (kann mehrere andere Werte enthalten, falls gewünscht.)</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Attribut Windows zu UNIX</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">Dies definiert den Windows-Benutzernamen bei der Erstellung. Cloud Volumes Service verwendet dies für Windows-to-UNIX-Lookups.</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">Hier ist keine Änderung erforderlich; sAMAccountName ist der gleiche wie der Windows-Anmeldename.</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">Definiert den UNIX-Benutzernamen.</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">Gewünschter UNIX-Benutzername.</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service verwendet derzeit keine Domänenpräfixe in LDAP-Lookups, so dass mehrere Domänen-LDAP-Umgebungen nicht richtig funktionieren mit LDAP-Namemap-Lookups.</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">Im folgenden Beispiel wird ein Benutzer mit dem Windows-Namen angezeigt<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block>, Der UNIX-Name<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Und das Verhalten folgt es beim Schreiben von Dateien sowohl aus SMB und NFS.</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">Die folgende Abbildung zeigt, wie LDAP-Attribute vom Windows-Server aussehen.</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">Von einem NFS-Client aus können Sie den UNIX-Namen, nicht jedoch den Windows-Namen abfragen:</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">Wenn eine Datei aus NFS als geschrieben wird<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Das folgende Ergebnis ist von dem NFS Client:</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">Von einem Windows-Client aus sehen Sie, dass der Eigentümer der Datei auf den richtigen Windows-Benutzer eingestellt ist:</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">Umgekehrt werden Dateien vom Windows-Benutzer erstellt<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block> Von einem SMB-Client wird der richtige UNIX-Eigentümer angezeigt, wie im folgenden Text dargestellt.</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB:</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">LDAP-Kanalbindung</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Microsoft Security Advisory ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">Aufgrund einer Schwachstelle bei Windows Active Directory-Domänencontrollern<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> Ändert die Art und Weise, wie DCs LDAP-Bindungen zulassen.</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">Die Auswirkungen von Cloud Volumes Service sind dieselben wie für alle LDAP-Clients. Cloud Volumes Service unterstützt derzeit keine Channel-Bindung. Da Cloud Volumes Service standardmäßig LDAP-Signatur durch Aushandlung unterstützt, sollte die LDAP-Channel-Bindung kein Problem darstellen. Wenn Sie Probleme mit der Bindung an LDAP bei aktivierter Kanalbindung haben, befolgen Sie die Schritte zur Problembehebung in ADV190023, damit LDAP-Bindungen von Cloud Volumes Service erfolgreich durchgeführt werden können.</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">Dynamisches DNS</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory und Kerberos haben beide Abhängigkeiten von DNS für den Hostnamen zu IP/IP bis zur Auflösung des Hostnamens. DNS erfordert, dass Port 53 offen ist. Cloud Volumes Service nimmt keine Änderungen an DNS-Einträgen vor und unterstützt derzeit nicht die Verwendung von<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> An Netzwerkschnittstellen.</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">Sicheres Windows DNS</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">Sie können Active Directory DNS so konfigurieren, dass Sie festlegen können, welche Server DNS-Einträge aktualisieren können. Weitere Informationen finden Sie unter<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>.</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Beachten Sie, dass Ressourcen innerhalb eines Google-Projekts standardmäßig mit Google Cloud DNS, die nicht mit Active Directory DNS verbunden ist. Clients, die Cloud DNS verwenden, können keine UNC-Pfade auflösen, die von Cloud Volumes Service zurückgegeben werden. Windows-Clients, die mit der Active Directory-Domäne verbunden sind, sind für die Verwendung von Active Directory DNS konfiguriert und können solche UNC-Pfade auflösen.</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">Warum kann mein Client den SMB NetBIOS-Namen nicht lösen?</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">Um einem Client zu Active Directory beizutreten, müssen Sie seine DNS-Konfiguration so konfigurieren, dass Active Directory DNS verwendet wird. Optional können Sie Cloud DNS konfigurieren, um Anfragen an Active Directory DNS weiterzuleiten. Siehe<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>Finden Sie weitere Informationen.</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service unterstützt derzeit keine DNSSEC- und DNS-Abfragen werden im Klartext ausgeführt.</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">Prüfung von Dateizugriffen</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">Derzeit nicht unterstützt für Cloud Volumes Service.</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">Virenschutz</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">Sie müssen in Cloud Volumes Service am Client auf eine NAS-Freigabe Antivirenprüfungen durchführen. Derzeit ist keine native Virenschutz-Integration in Cloud Volumes Service möglich.</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">Weiter: Service-Betrieb.</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">NAS-Protokolle sind Möglichkeiten für mehrere Clients im Netzwerk, um auf dieselben Daten in einem Storage-System zuzugreifen, beispielsweise auf Cloud Volumes Service in GCP. NFS und SMB sind die definierten NAS-Protokolle und werden auf Client-/Server-Basis ausgeführt, wobei Cloud Volumes Service als Server fungiert.</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">Grundlagen der NAS-Protokolle</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">Früher: NAS-Protokolle – Übersicht</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">NAS-Protokolle sind Möglichkeiten für mehrere Clients im Netzwerk, um auf dieselben Daten in einem Storage-System zuzugreifen, beispielsweise auf Cloud Volumes Service in GCP. NFS und SMB sind die definierten NAS-Protokolle und werden auf Client-/Server-Basis ausgeführt, wobei Cloud Volumes Service als Server fungiert. Clients senden Zugriffs-, Lese- und Schreibanfragen an den Server, und der Server ist für die Koordinierung der Sperrmechanismen für Dateien, die Speicherung von Berechtigungen und die Bearbeitung von Identitäts- und Authentifizierungsanforderungen zuständig.</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">Der folgende allgemeine Prozess wird beispielsweise verfolgt, wenn ein NAS-Client eine neue Datei in einem Ordner erstellen möchte.</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">Der Client fragt den Server nach Informationen zum Verzeichnis (Berechtigungen, Eigentümer, Gruppe, Datei-ID, verfügbarer Speicherplatz, Und so weiter); der Server antwortet mit den Informationen, wenn der anfragende Client und der Benutzer die erforderlichen Berechtigungen für den übergeordneten Ordner haben.</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">Wenn die Berechtigungen im Verzeichnis den Zugriff zulassen, fragt der Client den Server, ob der erstellte Dateiname bereits im Dateisystem vorhanden ist. Wenn der Dateiname bereits verwendet wird, schlägt die Erstellung fehl. Wenn der Dateiname nicht vorhanden ist, lässt der Server dem Client wissen, dass er fortgesetzt werden kann.</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">Der Client ruft den Server aus, um die Datei mit dem Verzeichnis-Handle und dem Dateinamen zu erstellen, und legt die Zugriffszeiten und die geänderten Zeiten fest. Der Server gibt eine eindeutige Datei-ID für die Datei aus, um sicherzustellen, dass keine anderen Dateien mit derselben Datei-ID erstellt werden.</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">Der Client sendet einen Anruf, um Dateiattribute vor DEM SCHREIBVORGANG zu überprüfen. Falls dies durch Berechtigungen möglich ist, schreibt der Client die neue Datei. Falls das Protokoll oder die Applikation gesperrt wird, fordert der Client den Server zur Sperrung auf, um zu verhindern, dass andere Clients auf die Datei zugreifen können, während diese gesperrt ist, um Datenbeschädigungen zu verhindern.</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">Weiter: NFS.</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">Das Cloud Volumes Service-Team verwaltet die Backend-Services in Google Cloud und nutzt verschiedene Strategien, um die Plattform zu sichern und unerwünschte Zugriffe zu vermeiden.</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">Service-Betrieb</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">Früher: Andere NAS-Infrastruktur-Service-Abhängigkeiten (KDC, LDAP, DNS).</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">Jeder Kunde erhält sein eigenes Subnetz, mit dem standardmäßig Zugriff von anderen Kunden isoliert ist. Jeder Mandant in Cloud Volumes Service erhält seinen eigenen Namespace und VLAN für eine vollständige Datenisolierung. Nachdem ein Benutzer authentifiziert wurde, kann die Service Delivery Engine (SDE) nur noch Konfigurationsdaten für diesen Mandanten lesen.</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">Physische Sicherheit</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">Mit entsprechender Vorabgenehmigung haben nur Techniker vor Ort und NetApp Außendiensttechniker (Field Support Engineers, FSEs) Zugriff auf den Käfig und die Racks für physische Arbeiten. Storage- und Netzwerk-Management ist nicht zulässig. Nur diese Ressourcen vor Ort sind in der Lage, Hardware-Wartungsarbeiten durchzuführen.</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">Für Techniker vor Ort wird ein Ticket für die Leistungsbeschreibung (Statement of Work, SOW) angehoben, das die Rack-ID und den Standort des Geräts (RU) enthält. Alle weiteren Details sind im Ticket enthalten. Bei NetApp FSEs muss ein Besuchsticket vor Ort mit COLO GELEGT werden, und das Ticket enthält die Daten, das Datum und die Zeit der Besucher zu Audit-Zwecken. Das SOW für den FSE wird intern an NetApp kommuniziert.</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">Operations Team</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">Das Betriebsteam für Cloud Volumes Service setzt sich aus Produktionstechnik und einem Site Reliability Engineer (SRE) für Cloud Volume Services sowie NetApp Field Support Engineers und Hardware-Partnern zusammen. Alle Mitglieder des Betriebsteams sind für die Arbeit in Google Cloud akkreditiert und für jedes angehobene Ticket werden detaillierte Arbeitsunterlagen aufbewahrt. Darüber hinaus gibt es einen strengen Änderungskontroll- und Genehmigungsprozess, um sicherzustellen, dass jede Entscheidung angemessen überprüft wird.</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">Das SRE-Team verwaltet die Kontrollebene und wie die Daten von UI-Anfragen an Back-End-Hardware und -Software in Cloud Volumes Service weitergeleitet werden. Das SRE-Team verwaltet außerdem Systemressourcen, wie z. B. die maximale Anzahl von Volumes und Inode. SRES dürfen nicht mit Kundendaten interagieren oder Zugriff haben. Darüber hinaus koordiniert SRES mit Return Material Authorizations (RMAs), wie z. B. neue Festplatten- oder Speicherersatzanfragen für die Backend-Hardware.</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">Mitwirkungspflichten des Kunden</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Kunden von Cloud Volumes Service verwalten das Active Directory und die Benutzerrollenverwaltung sowie die Menge und die Datenvorgänge ihrer Organisation. Kunden können über Administratorrollen verfügen und Berechtigungen an andere Endbenutzer innerhalb desselben Google Cloud-Projekts delegieren. Dabei werden die beiden vordefinierten Rollen verwendet, die NetApp und Google Cloud (Administrator und Viewer) bereitstellen.</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">Der Administrator kann eine beliebige VPC im Kundenprojekt an Cloud Volumes Service Peer, die der Kunde für angemessen entscheidet. Der Kunde ist selbst dafür verantwortlich, den Zugriff auf sein Google Cloud Marketplace Abonnement zu managen und die VPCs zu managen, die Zugriff auf die Datenebene haben.</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">Bösartiger SRE-Schutz</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">Ein Problem, das entstehen könnte, ist, wie schützt Cloud Volumes Service vor Szenarien, in denen es einen bösartigen SRE gibt oder wenn die SRE-Anmeldeinformationen kompromittiert wurden?</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">Der Zugang zur Produktionsumgebung ist nur mit einer begrenzten Anzahl von SRE-Einzelpersonen möglich. Darüber hinaus sind Administratorrechte auf eine Handvoll erfahrener Administratoren beschränkt. Alle Aktionen, die von jedem Mitarbeiter der Cloud Volumes Service Produktionsumgebung ausgeführt werden, werden protokolliert. Anomalien an der Basis- oder verdächtigen Aktivitäten werden durch unsere SIEM-Plattform (Security Information and Event Management) Threat Intelligence (Threat Intelligence Platform) erkannt. Dadurch können böswillige Aktionen nachverfolgt und abgemildert werden, bevor das Cloud Volumes Service-Backend zu einem zu großen Schaden angerichtet wird.</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">Volumenlebenszyklus</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service managt nur die Objekte innerhalb des Service, nicht die Daten innerhalb der Volumes. Nur Clients, die auf die Volumes zugreifen, können die Daten, ACLs, Dateieigentümer usw. managen. Die Daten in diesen Volumes sind im Ruhezustand verschlüsselt und der Zugriff ist auf Mandanten der Cloud Volumes Service Instanz beschränkt.</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Der Lebenszyklus eines Volumes für Cloud Volumes Service ist create-Update-delete. Volumes behalten Snapshot Kopien von Volumes, bis die Volumes gelöscht werden. Nur validierte Cloud Volumes Service Administratoren können Volumes in Cloud Volumes Service löschen. Wenn ein Administrator eine Volume-Löschung angefordert hat, muss ein zusätzlicher Schritt zur Eingabe des Volume-Namens erforderlich sein, um die Löschung zu überprüfen. Nachdem ein Volume gelöscht wurde, ist das Volume verschwunden und kann nicht wiederhergestellt werden.</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">Falls ein Cloud Volumes Service-Vertrag beendet wird, kennzeichnet NetApp Volumes nach einem bestimmten Zeitraum zum Löschen. Bevor dieser Zeitraum abläuft, können Sie Volumes auf Kundenwunsch wiederherstellen.</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">Zertifizierungen</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">Compliance: Datensicherheit und Datenschutz</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Cloud Volumes Services für Google Cloud sind derzeit nach den Standards ISO/IEC 27001:2013 und ISO/IEC 27018:2019 zertifiziert. Der Service erhielt kürzlich auch seinen SOC2 Type I Attestation Report. Weitere Informationen über die Verpflichtung von NetApp zur Datensicherheit und zum Datenschutz finden Sie unter<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>.</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">DSGVO</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">Kundenverträge</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">Ergänzung Zur Kundendatenverarbeitung</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">Standardvertragsklauseln</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">Unsere Verpflichtung zu Datenschutz und Einhaltung der DSGVO steht in mehreren unserer zahlreichen verfügbar <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>, Wie unsere<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>, Das beinhaltet die <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> Von der Europäischen Kommission bereitgestellt. Diese Verpflichtungen stellen wir auch in unserer Datenschutzrichtlinie ein, die durch die zentralen Werte unseres Unternehmenskodex eingehalten wird.</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">Weiter: Zusätzliche Informationen, Versionsverlauf und Kontaktinformationen.</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service bietet die Möglichkeit, dieselben Datensätze sowohl für SMB- als auch für NFS-Clients zu nutzen, während das Dual-Protokoll für ordnungsgemäße Zugriffsberechtigungen besteht. Dies geschieht durch die Koordinierung der Identitätszuordnung zwischen Protokollen und die Verwendung eines zentralen Backend-LDAP-Servers zur Bereitstellung der UNIX-Identitäten an Cloud Volumes Service. Sie können Windows Active Directory verwenden, um sowohl Windows- als auch UNIX-Benutzer zur Benutzerfreundlichkeit bereitzustellen.</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">Dual-Protokoll/Multiprotokoll</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">Früher: SMB.</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">Dual-Protokoll</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service bietet die Möglichkeit, dieselben Datensätze sowohl für SMB- als auch für NFS-Clients zu nutzen, ohne dass die Zugriffsberechtigungen dafür unterbrochen werden <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>). Dies geschieht durch die Koordinierung der Identitätszuordnung zwischen Protokollen und die Verwendung eines zentralen Backend-LDAP-Servers zur Bereitstellung der UNIX-Identitäten an Cloud Volumes Service. Sie können Windows Active Directory verwenden, um sowohl Windows- als auch UNIX-Benutzer zur Benutzerfreundlichkeit bereitzustellen.</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">Zugriffssteuerung</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">„Konten mit lokalen/BUILTIN-Administrator/Backup-Rechten.“</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">MMC/Computer-Management</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*Zugriffskontrollen freigeben.* Bestimmen Sie, welche Clients und/oder Benutzer und Gruppen auf eine NAS-Freigabe zugreifen können. Für NFS kontrollieren Exportrichtlinien und Regeln den Client-Zugriff auf Exporte. NFS-Exporte werden von der Cloud Volumes Service Instanz gemanagt. SMB nutzt CIFS/SMB-Freigaben und ACLs für die Freigabe von ACLs und ermöglicht eine granularere Kontrolle auf Benutzer- und Gruppenebene. Sie können ACLs auf Share-Ebene nur über SMB-Clients konfigurieren<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Mit einem Konto, das über Administratorrechte auf der Cloud Volumes Service-Instanz verfügt (siehe Abschnitt <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>).</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*Dateizugriffssteuerung.* Kontrollieren Sie Berechtigungen auf Datei- oder Ordnerebene und werden immer vom NAS-Client verwaltet. NFS Clients können die traditionellen Modus-Bits (rwx) oder NFSv4 ACLs nutzen. SMB-Clients nutzen NTFS-Berechtigungen.</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">Die Zugriffssteuerung für Volumes, die Daten sowohl für NFS als auch für SMB bereitstellen, hängt vom verwendeten Protokoll ab. Informationen zu Berechtigungen mit Dual-Protokoll finden Sie im Abschnitt „<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>.“</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">Benutzerzuordnung</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">Wenn ein Client auf ein Volume zugreift, versucht Cloud Volumes Service, den eingehenden Benutzer in die entgegengesetzte Richtung einem gültigen Benutzer zuzuordnen. Dies ist notwendig, damit ein ordnungsgemäßer Zugriff über verschiedene Protokolle hinweg festgestellt werden kann und sicherzustellen ist, dass der Benutzer, der Zugriff beantragt, tatsächlich derjenige ist, der von ihm behauptet wird.</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">Beispiel: Wenn ein Windows-Benutzer mit dem Namen<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Versucht über SMB den Zugriff auf ein Volume mit UNIX-Berechtigungen, dann führt Cloud Volumes Service eine Suche durch, um einen entsprechenden UNIX-Benutzer zu finden<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block>. Ist eine vorhanden, so werden Dateien, die als Windows Benutzer in eine SMB-Freigabe geschrieben werden<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Wird als UNIX-Benutzer angezeigt<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Von NFS-Clients.</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">Alternativ können Sie auch festlegen, ob ein UNIX-Benutzer den Namen hat<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Versucht, auf ein Cloud Volumes Service-Volume mit Windows-Berechtigungen zuzugreifen, dann muss der UNIX-Benutzer in der Lage sein, einem gültigen Windows-Benutzer zuzuordnen. Andernfalls wird der Zugriff auf das Volume verweigert.</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">Erstellen einer AD-Verbindung</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">Derzeit wird nur Active Directory für das externe UNIX-Identitätsmanagement mit LDAP unterstützt. Weitere Informationen zum Konfigurieren des Zugriffs auf diesen Dienst finden Sie unter<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>.</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">Berechtigungsmodell</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">Bei der Verwendung von Dual-Protokoll-Setups verwendet Cloud Volumes Service Sicherheitsformate für Volumes, um den Typ der ACL zu bestimmen. Diese Sicherheitsstile werden basierend auf bestimmten NAS-Protokollen oder bei einem dualen Protokoll festgelegt. Sie sollten zur Zeit der Cloud Volumes Service Volume-Erstellung gewählt werden.</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">Wenn Sie nur NFS verwenden, verwenden Cloud Volumes Service-Volumes UNIX-Berechtigungen.</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">Wenn Sie nur SMB verwenden, verwenden Cloud Volumes Service Volumes NTFS-Berechtigungen.</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">Wenn Sie ein Dual-Protokoll-Volume erstellen, können Sie bei der Volume-Erstellung den ACL-Stil wählen. Diese Entscheidung sollte auf der Grundlage der gewünschten Berechtigungsverwaltung getroffen werden. Wenn Ihre Benutzer Berechtigungen von Windows-/SMB-Clients verwalten, wählen Sie NTFS. Wenn Ihre Benutzer NFS-Clients und chmod/chown verwenden möchten, verwenden Sie UNIX-Sicherheitsmethoden.</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">Weiter: Überlegungen zum Erstellen von Active Directory-Verbindungen.</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Alle Volumes in Cloud Volumes Service werden im Ruhezustand mit AES-256-Verschlüsselung verschlüsselt, d. h. alle auf das Medium geschriebenen Benutzerdaten werden verschlüsselt und können nur mit einem Schlüssel pro Volume entschlüsselt werden.</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">Verschlüsselung von Daten im Ruhezustand</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">Früher: Datenverschlüsselung während der Übertragung.</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">Für CVS-SW werden von Google generierte Schlüssel verwendet.</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">Die Schlüssel für CVS-Performance werden in einem im Cloud Volumes Service integrierten Schlüsselmanager gespeichert, der die Schlüssel pro Volume enthält.</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google Key Management Service (KMS):</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">Ab November 2021 wurde eine Vorschau auf die Funktionalität der vom Kunden gemanagten Verschlüsselungsschlüssel (CMEK) bereitgestellt. So können Sie die Schlüssel pro Volume mit einem in einzelnen Projekten und Regionen gehosteten Master-Schlüssel verschlüsseln<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> KMS ermöglicht es Ihnen, externe Schlüsselmanager anzubinden.</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">Einrichten von vom Kunden gemanagten Verschlüsselungsschlüsseln</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">Informationen zur Konfiguration von KMS für CVS-Performance finden Sie unter<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>.</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">Als Nächstes: Firewall.</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service legt mehrere TCP Ports für NFS- und SMB-Freigaben bereit.</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">Firewall</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">Früher: Verschlüsselung von Daten im Ruhezustand.</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service legt mehrere TCP Ports für NFS- und SMB-Freigaben bereit:</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">Für NFS-Zugriff erforderliche Ports</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">Für SMB-Zugriff erforderliche Ports</block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">Konfiguriert</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">DNS-basierte DC-Erkennung</block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">Außerdem erfordern SMB, NFS mit LDAP, einschließlich Kerberos und Dual-Protokoll-Konfigurationen den Zugriff auf eine Windows Active Directory Domain. Active Directory-Verbindungen müssen sein<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> Pro Region. Active Directory-Domänencontroller (DC) werden mithilfe identifiziert<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> Verwenden der angegebenen DNS-Server. Alle zurückgegebenen Datacenter werden genutzt. Die Liste der geeigneten DCs kann durch Angabe einer Active Directory-Site beschränkt werden.</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">On-Boarding the Cloud Volumes Service</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service erreicht mit IP-Adressen aus dem CIDR-Bereich, der dem zugewiesen ist<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> Befehl während<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>. Sie können dieses CIDR als Quelladressen verwenden, um eingehende Firewalls für Ihre Active Directory-Domänencontroller zu konfigurieren.</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">Legen Sie wie hier erwähnt Ports den Cloud Volumes Service-CIDRs offen</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Active Directory-Domänencontroller müssen<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>.</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">Weiter: Übersicht über NAS-Protokolle</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">Als Teil des Vertrauens einer Cloud-Lösung müssen Sie die Architektur und die Art und Weise der Sicherheit kennen. In diesem Abschnitt werden verschiedene Aspekte der Cloud Volumes Service-Architektur in Google erläutert, um mögliche Bedenken hinsichtlich der Datensicherheit zu zerstreuen und Bereiche herauszurufen, in denen zusätzliche Konfigurationsschritte erforderlich sind, um die sichere Implementierung zu erhalten.</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">Früher: Sicherheitsüberlegungen und Angriffsflächen.</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">Die allgemeine Architektur von Cloud Volumes Service kann in zwei Hauptkomponenten aufgeteilt werden: Die Kontrollebene und die Datenebene.</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">Kontrollebene</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Die Kontrollebene in Cloud Volumes Service ist die von Cloud Volumes Service-Administratoren und der nativen Automatisierungssoftware von NetApp gemanagte Back-End-Infrastruktur. Diese Ebene ist für Endbenutzer vollständig transparent und beinhaltet Netzwerk, Storage-Hardware, Software-Updates usw., um einen Mehrwert für eine Cloud-residente Lösung wie Cloud Volumes Service bereitzustellen.</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">Datenebene</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Die Datenebene in Cloud Volumes Service umfasst die tatsächlichen Daten-Volumes und die gesamte Cloud Volumes Service-Konfiguration (wie Zugriffssteuerung, Kerberos Authentifizierung usw.). Die Datenebene unterliegt vollständig der Kontrolle von Endbenutzern und Nutzern der Cloud Volumes Service Plattform.</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">Es gibt unterschiedliche Arten, wie jede Ebene gesichert und verwaltet wird. In den folgenden Abschnitten werden diese Unterschiede näher beschrieben. Zunächst wird die Cloud Volumes Service Architektur im Überblick angezeigt.</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">Als Nächstes: Cloud Volumes Service Architektur</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service für Google Cloud nutzt das Google Cloud Private Services ZugriffsFramework. In diesem Framework können sich Benutzer mit dem Cloud Volumes Service verbinden. Dieses Framework verwendet Service Networking und VPC Peering so wie andere Google Cloud-Services, dass die vollständige Isolierung zwischen Mandanten gewährleistet ist.</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">Datenplanarchitektur</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">Früher: Kontrollebene Architektur.</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service für Google Cloud nutzt die Google Cloud<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> Framework: In diesem Framework können sich Benutzer mit dem Cloud Volumes Service verbinden. Dieses Framework verwendet Service Networking und VPC Peering so wie andere Google Cloud-Services, dass die vollständige Isolierung zwischen Mandanten gewährleistet ist.</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Architektur für Cloud Volumes Service</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Eine Übersicht über die Architektur von Cloud Volumes Service für Google Cloud finden Sie unter<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>.</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">Benutzer-VPCs (Standalone oder Shared) werden an VPCs innerhalb von Cloud Volumes Service gemanagten Mandantenprojekten weitergegeben, die die Volumes hostet.</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">Die obige Abbildung zeigt ein Projekt (das CVS Verbraucherprojekt in der Mitte) mit drei VPC-Netzwerken, die mit Cloud Volumes Service verbunden sind, und mehreren Compute Engine VMs (GCE1-7), die Volumes gemeinsam nutzen:</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1 ermöglicht GCE1 auf Volumes A und B. zuzugreifen</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2 ermöglicht GCE2 und GCE4 den Zugriff auf Lautstärke C.</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">Das dritte VPC-Netzwerk ist eine gemeinsame VPC, von der zwei Service-Projekte gemeinsam genutzt werden. GCE3, GCE4, GCE5 und GCE6 können auf Volumes D und E. zugreifen Shared VPC-Netzwerke werden nur für Volumes des Servicetyps „CVS-Performance“ unterstützt.</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7 kann auf keine Volumes zugreifen.</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">Die Daten können sowohl bei der Übertragung (mit Kerberos- und/oder SMB-Verschlüsselung) als auch im Ruhezustand in Cloud Volumes Service verschlüsselt werden.</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">Im nächsten Schritt: Datenverschlüsselung während der Übertragung.</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="doc">NAS-Protokolle</block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">Die NAS-Protokolle umfassen NFS (v3 und v4.1) und SMB/CIFS (2.x und 3.x). Mit diesen Protokollen ermöglicht CVS gemeinsamen Zugriff auf Daten über mehrere NAS Clients hinweg. Darüber hinaus ermöglicht Cloud Volumes Service den gleichzeitigen Zugriff auf NFS- und SMB/CIFS-Clients (Dual-Protokoll), während sämtliche Identitäts- und Berechtigungseinstellungen auf Dateien und Ordnern in den NAS-Freigaben berücksichtigt werden.</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">Übersicht über NAS-Protokolle</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">Früher: Firewall.</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">Die NAS-Protokolle umfassen NFS (v3 und v4.1) und SMB/CIFS (2.x und 3.x). Mit diesen Protokollen ermöglicht CVS gemeinsamen Zugriff auf Daten über mehrere NAS Clients hinweg. Darüber hinaus ermöglicht Cloud Volumes Service den gleichzeitigen Zugriff auf NFS- und SMB/CIFS-Clients (Dual-Protokoll), während sämtliche Identitäts- und Berechtigungseinstellungen auf Dateien und Ordnern in den NAS-Freigaben berücksichtigt werden. Cloud Volumes Service unterstützt die Protokollverschlüsselung im laufenden Betrieb mit SMB-Verschlüsselung und NFS Kerberos 5p, um die höchstmögliche Sicherheit bei Datentransfers zu gewährleisten.</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">Das Dual-Protokoll ist nur mit CVS-Performance verfügbar.</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">Weiter: Grundlagen der NAS-Protokolle.</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">Der erste Schritt zum Verständnis der Datensicherung besteht darin, die Risiken und potenziellen Angriffsflächen zu identifizieren.</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">Sicherheitsüberlegungen und Angriffsflächen</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">Wie Cloud Volumes Service in Google Cloud Ihre Daten sichert.</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">Der erste Schritt zum Verständnis der Datensicherung besteht darin, die Risiken und potenziellen Angriffsflächen zu identifizieren. Dazu gehören (aber nicht beschränkt auf) die folgenden:</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">Administration und Anmeldung</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">Daten im Ruhezustand</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">Genutzte Daten</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">Netzwerk und Firewalls</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">Ransomware, Malware und Viren</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">Das Verständnis von Angriffsflächen kann Ihnen helfen, Ihre Umgebungen besser zu schützen. Cloud Volumes Service in Google Cloud berücksichtigt bereits viele dieser Themen und implementiert Sicherheitsfunktionen standardmäßig ohne administrative Eingriffe.</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">Sichere Anmeldungen sicherstellen</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">Bei der Sicherung Ihrer kritischen Infrastrukturkomponenten ist es von größter Wichtigkeit, sicherzustellen, dass nur genehmigte Benutzer sich einloggen und Ihre Umgebungen managen können. Wenn fehlerhafte Akteure die Anmeldedaten in Ihrem System verletzen, haben sie die Schlüssel zum Schloss und können alles tun, was sie wollen: Konfigurationen ändern, Volumes und Backups löschen, Backdoors erstellen oder Snapshot-Zeitpläne deaktivieren.</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service für Google Cloud bietet Schutz vor unautorisierten administrativen Anmeldungen durch den Ausfall von Storage als Service (StaaS). Cloud Volumes Service wird vom Cloud-Provider komplett gewartet, ohne dass eine externe Anmeldung verfügbar ist. Alle Setup- und Konfigurationsvorgänge sind vollautomatisiert, sodass ein Administrator in seltenen Fällen nie mit den Systemen interagieren muss.</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">„Cloud Volumes Service Architecture“.</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">Wenn Anmeldung erforderlich ist, sichert Cloud Volumes Service in Google Cloud Anmeldungen, indem eine sehr kurze Liste vertrauenswürdiger Administratoren geführt wird, die Zugriff haben, um sich bei den Systemen anzumelden. Diese Gatekeeping hilft, die Anzahl potenzieller schlechter Akteure mit Zugriff zu reduzieren. Darüber hinaus verbirgt das Google Cloud-Netzwerk die Systeme hinter Schichten der Netzwerksicherheit und legt nur das, was für die Außenwelt benötigt wird, offen. Weitere Informationen zur Google Cloud- und Cloud Volumes Service-Architektur finden Sie im Abschnitt <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">Cluster-Administration und Upgrades</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">Zu den zwei Bereichen mit potenziellen Sicherheitsrisiken zählen die Clusterverwaltung (was passiert, wenn ein schlechter Akteur Administratorzugriff hat) und Upgrades (was passiert, wenn ein Software-Image beeinträchtigt wird).</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">Sicherung der Storage-Administration</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">„Service-Betrieb“.</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">Der als Service bereitgestellte Storage beseitigt das zusätzliche Risiko, dass Administratoren diesem Zugriff nicht mehr an Anwender außerhalb des Cloud-Datacenters ausgesetzt sind. Stattdessen gilt die einzige Konfiguration für die Datenzugriffsebene durch Kunden. Jeder Mandant managt seine eigenen Volumes, und ein Mandant kann andere Cloud Volumes Service Instanzen nicht erreichen. Der Service wird durch Automatisierung gemanagt, wobei in einer sehr kleinen Liste vertrauenswürdiger Administratoren über die im Abschnitt behandelten Prozesse Zugriff auf die Systeme gewährt wird <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">Der Servicetyp CVS-Performance bietet regionenübergreifende Replizierung als Option zur Sicherung von Daten für eine andere Region bei Ausfall. In diesen Fällen kann ein Failover der Cloud Volumes Service in die nicht betroffene Region durchgeführt werden, um den Datenzugriff zu gewährleisten.</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">Service-Upgrades</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">Updates helfen, gefährdete Systeme zu schützen. Jedes Update bietet Verbesserungen der Sicherheit und Fehlerbehebungen zur Minimierung von Angriffsflächen. Software-Updates werden aus zentralen Repositorys heruntergeladen und validiert, bevor die Updates überprüft werden, ob offizielle Bilder verwendet werden und dass die Upgrades nicht durch fehlerhafte Akteure beeinträchtigt werden.</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Mit Cloud Volumes Service werden Updates von den Cloud-Provider-Teams durchgeführt, die Risiken für Administratoren abschaffen, indem Experten versiert in Konfiguration und Upgrades sind, die den Prozess automatisiert und vollständig getestet haben. Upgrades werden unterbrechungsfrei durchgeführt und Cloud Volumes Service behält die neuesten Updates bei, um optimale Ergebnisse zu erzielen.</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">Informationen über das Administrator-Team, das diese Service-Upgrades durchführt, finden Sie im Abschnitt <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">Sicherheit von Daten im Ruhezustand</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">Die Verschlüsselung ruhender Daten ist wichtig, um sensible Daten bei Diebstahl, Rückgabe oder neuer Verwendung einer Festplatte zu schützen. Daten in Cloud Volumes Service werden mithilfe von softwarebasierter Verschlüsselung im Ruhezustand gesichert.</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Google-generierte Schlüssel werden für CVS-SW verwendet.</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2 Zertifikat #4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">Für die CVS-Performance werden die Schlüssel pro Volume in einem in Cloud Volumes Service integrierten Schlüsselmanager gespeichert, der mit NetApp ONTAP CryptoMod die AES-256-Verschlüsselung generiert. CryptoMod ist in der nach FIPS 140-2 validierten CMVP-Modulliste aufgeführt. Siehe<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>.</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">Im November 2021 wurde eine Vorschau auf die Funktionalität Customer-Managed Encryption (CMEK) für CVS-Performance bereitgestellt. Diese Funktionalität ermöglicht Ihnen die Verschlüsselung der Schlüssel pro Volume mit Master-Schlüsseln für einzelne Projekte und Regionen, die im Google Key Management Service (KMS) gehostet werden. KMS ermöglicht es Ihnen, externe Schlüsselmanager anzubinden.</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">Details zur Konfiguration von KMS für CVS-Performance finden Sie unter<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>.</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">Weitere Informationen zur Architektur finden Sie im Abschnitt <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">Sicherheit der aktiven Daten</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">Sie müssen nicht nur Daten im Ruhezustand sichern, sondern auch bei laufender Übertragung zwischen der Cloud Volumes Service Instanz und einem Client oder Replizierungsziel sichern können. Cloud Volumes Service bietet Verschlüsselung von Daten auf der Übertragungsstrecke über NAS-Protokolle. Dabei kommen Verschlüsselungsmethoden wie SMB-Verschlüsselung mit Kerberos, das Signing/Sealing von Paketen und NFS Kerberos 5p für die End-to-End-Verschlüsselung von Datentransfers zum Einsatz.</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">Die Replizierung von Cloud Volumes Service Volumes verwendet TLS 1.2, die von AES-GCM-Verschlüsselungsmethoden profitiert.</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">Die unsicheres in-Flight-Protokolle wie Telnet, NDMP usw. sind standardmäßig deaktiviert. DNS ist jedoch nicht durch Cloud Volumes Service verschlüsselt (keine DNS-sec-Unterstützung) und sollte, wenn möglich, mit externer Netzwerkverschlüsselung verschlüsselt werden. Siehe Abschnitt <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen über die Sicherung Ihrer aktiven Daten.</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">„NAS-Protokolle“.</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">Informationen zur Verschlüsselung von NAS-Protokollen finden Sie im Abschnitt <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">Benutzer und Gruppen für NAS-Berechtigungen</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">Bei der Sicherung Ihrer Daten in der Cloud ist eine ordnungsgemäße Benutzer- und Gruppenauthentifizierung erforderlich, wobei die Benutzer, die auf die Daten zugreifen, als echte Benutzer in der Umgebung überprüft werden und die Gruppen gültige Benutzer enthalten. Diese Benutzer und Gruppen bieten ersten Zugriff auf Freigabe und Export sowie Berechtigungsvalidierung für Dateien und Ordner im Speichersystem.</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service verwendet die standardmäßige, auf Active Directory basierende Windows-Benutzer- und Gruppenauthentifizierung für SMB-Freigaben und Windows-artige Berechtigungen. Der Service kann auch UNIX Identitätsanbieter wie LDAP für UNIX Benutzer und Gruppen für NFS-Exporte, NFSv4 ID-Validierung, Kerberos-Authentifizierung und NFSv4 ACLs nutzen.</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">Derzeit wird mit Cloud Volumes Service nur Active Directory LDAP zur LDAP-Funktionalität unterstützt.</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">Erkennung, Verhinderung und Minimierung von Ransomware, Malware und Viren</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">Ransomware, Malware und Viren sind für Administratoren eine persistente Bedrohung. Die Erkennung, das Vorbeugen und die Minimierung dieser Bedrohungen steht für Unternehmen immer im Mittelpunkt. Ein einzelnes Ransomware-Ereignis auf einem kritischen Datensatz kann potenziell Millionen US-Dollar kosten. Daher ist es vorteilhaft, alles zu tun, um das Risiko zu minimieren.</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">Automatische Ransomware-Erkennung</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Obwohl Cloud Volumes Service derzeit nicht schließt native Detection oder Prävention Maßnahmen, wie Virenschutz oder<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>, Es gibt Möglichkeiten, nach einem Ransomware-Ereignis schnell wiederherzustellen, indem es regelmäßige Snapshot-Zeitpläne ermöglicht. Snapshot-Kopien sind unveränderliche und schreibgeschützte Verweise auf geänderte Blöcke im Filesystem, werden praktisch sofort erzeugt, haben minimale Auswirkungen auf die Performance und verbrauchen nur Speicherplatz, wenn Daten geändert oder gelöscht werden. Sie können Zeitpläne für Snapshot Kopien einrichten, die auf Ihre gewünschte akzeptable Recovery Point Objective (RPO)/Recovery Time Objective (RTO) abgestimmt sind und bis zu 1,024 Snapshot Kopien pro Volume aufbewahren.</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">Snapshot Support ist ohne zusätzliche Kosten enthalten (Storage-Kosten für veränderte Blöcke/Daten, die von Snapshot Kopien aufbewahrt Cloud Volumes Service werden) und kann bei einem Ransomware-Angriff genutzt werden, um ein Rollback auf eine Snapshot Kopie vor dem Angriff durchzuführen. Snapshot Wiederherstellungen dauern nur wenige Sekunden und Daten können wieder wie gewohnt bereit sein. Weitere Informationen finden Sie unter<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>.</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">Die Auswirkungen von Ransomware auf Ihr Unternehmen zu verhindern, ist ein mehrschichtiger Ansatz erforderlich, der einen oder mehrere der folgenden Elemente umfasst:</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">Endpoint-Schutz</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">Schutz vor externen Bedrohungen durch Netzwerk-Firewalls</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">Erkennung von Datenanomalien</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">Mehrere Backups (vor Ort und extern) kritischer Datensätze</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">Regelmäßige Restore-Tests von Backups</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">Unveränderliche schreibgeschützte NetApp Snapshot Kopien</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">Multi-Faktor-Authentifizierung für kritische Infrastrukturen</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">Sicherheitsprüfungen von Systemanmeldungen</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">Diese Liste ist bei weitem nicht erschöpfend, aber ist eine gute Blaupause, wenn man mit dem Potential der Ransomware-Angriffe zu folgen. Cloud Volumes Service in Google Cloud bietet verschiedene Möglichkeiten zum Schutz vor Ransomware-Ereignissen und zur Reduzierung der Auswirkungen.</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">Unveränderliche Snapshot Kopien</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service bietet native unveränderliche, schreibgeschützte Snapshot Kopien, die in einem anpassbaren Zeitplan erstellt werden, um schnelle zeitpunktgenaue Recovery beim Löschen von Daten zu ermöglichen oder wenn ein gesamtes Volume durch einen Ransomware-Angriff zu Opfer gebracht wurde. Snapshots können zu vorherigen guten Snapshot Kopien schnell wiederhergestellt werden und minimieren Datenverluste aufgrund der Aufbewahrungsdauer Ihrer Snapshot-Zeitpläne und RTO/RPO. Der Performance-Effekt mit der Snapshot Technologie ist zu vernachlässigen.</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Da Snapshot Kopien in Cloud Volumes Service schreibgeschützt sind, können diese nicht durch Ransomware infiziert werden, wenn die Ransomware nicht in den Datensatz „unbemerkt“ und Snapshot-Kopien der von Ransomware infizierten Daten erstellt wurde. Deshalb ist es notwendig, auf der Basis von Datenanomalien auch Ransomware-Erkennung in Betracht zu ziehen. Cloud Volumes Service bietet derzeit keine native Erkennung, Sie können jedoch externe Überwachungssoftware verwenden.</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">Backups und Restores</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service bietet standardmäßige NAS-Client-Backup-Funktionen (z. B. Backups über NFS oder SMB).</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">Volume-Replizierung</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS-Performance bietet regionenübergreifende Volume-Replizierung zu anderen CVS-Performance Volumes. Weitere Informationen finden Sie unter<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> In der Cloud Volumes Service-Dokumentation.</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">Cloud-Backup</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW bietet Service-native Backup-/Restore-Funktionen für Volumes. Weitere Informationen finden Sie unter<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> In der Cloud Volumes Service-Dokumentation.</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">Die Volume-Replizierung liefert eine exakte Kopie des Quell-Volumes für schnelles Failover im Falle eines Ausfalls, einschließlich Ransomware-Ereignissen.</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">Regionsübergreifende Replizierung</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS-Performance ermöglicht die sichere Replizierung von Volumes über Google Cloud Regionen hinweg zur Datensicherung und Archivierung von Anwendungsfällen. Dazu wird mit TLS1.2 AES 256 GCM-Verschlüsselung auf einem von NetApp gesteuerten Backend-Service-Netzwerk über spezifische Schnittstellen verwendet, die für die Replizierung im Google-Netzwerk verwendet werden. Ein primäres Volume (Quell-Volume) enthält die aktiven Produktionsdaten und repliziert auf ein sekundäres Volume (Ziel-Volume), um ein exaktes Replikat des primären Datensatzes zu erstellen.</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">Bei der anfänglichen Replizierung werden alle Blöcke übertragen, jedoch werden nur die geänderten Blöcke in einem primären Volume übertragen. Wird beispielsweise eine Datenbank mit 1 TB auf einem primären Volume auf das sekundäre Volume repliziert, so werden bei der ersten Replizierung 1 TB Speicherplatz übertragen. Wenn diese Datenbank einige hundert Zeilen (hypothetisch einige MB) hat, die zwischen der Initialisierung und dem nächsten Update wechseln, werden nur die Blöcke mit den geänderten Zeilen auf das sekundäre (wenige MB) repliziert. So wird sichergestellt, dass die Übertragungszeiten niedrig bleiben und die Replizierungskosten sinken.</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">Alle Berechtigungen für Dateien und Ordner werden auf das sekundäre Volume repliziert, aber die Zugriffsberechtigungen für die Freigabe (wie Exportrichtlinien und Regeln oder SMB-Freigaben und ACLs für die Freigabe) müssen separat gehandhabt werden. Bei einem Site-Failover sollte der Zielstandort dieselben Namensdienste und Active Directory-Domänenverbindungen nutzen, um eine konsistente Handhabung von Benutzer- und Gruppenidentitäten und -Berechtigungen zu ermöglichen. Sie können ein sekundäres Volume im Notfall als Failover-Ziel verwenden, indem Sie die Replizierungsbeziehung unterbrechen, die das sekundäre Volume in Lese- und Schreibvorgänge konvertiert.</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">Volume-Replikate sind schreibgeschützt, d. h. eine unveränderliche Kopie der Daten an einem externen Standort zur schnellen Recovery von Daten in Instanzen, in denen ein Virus infizierte Daten hat oder Ransomware den primären Datensatz verschlüsselt hat. Nur-Lese-Daten werden nicht verschlüsselt, aber, wenn das primäre Volume betroffen ist und Replikation auftritt, die infizierten Blöcke replizieren auch. Zur Wiederherstellung können Sie ältere, nicht betroffene Snapshot Kopien verwenden. Je nachdem, wie schnell ein Angriff erkannt wird, fallen jedoch unter Umständen die versprochenen RTO/RPO-Vorgaben aus.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">Überlegungen Zur Sicherheit</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">Darüber hinaus können Sie mit dem Management der regionsübergreifenden Replizierung (CRR) in Google Cloud böswillige Administratoraktionen, wie z. B. Volume-Löschungen, Snapshot-Löschungen oder Änderungen bei Snapshot-Planungen, verhindern. Dazu werden benutzerdefinierte Rollen erstellt, die Volume-Administratoren trennen, die Quell-Volumes löschen, aber keine Spiegelungen unterbrechen und daher keine Ziel-Volumes von CRR-Administratoren löschen können, die keine Volume-Vorgänge ausführen können. Siehe<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> In der Cloud Volumes Service-Dokumentation finden Sie Berechtigungen, die von den einzelnen Administratorgruppen zulässig sind.</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Cloud Volumes Service bietet zwar eine hohe Datenaufbewahrung, externe Ereignisse können jedoch zu Datenverlusten führen. Falls es zu Sicherheitsereignisse wie Viren oder Ransomware kommt, werden Backups und Restores so wichtig, dass der Datenzugriff rechtzeitig wiederaufgenommen werden kann. Ein Administrator kann ein Cloud Volumes Service Volume versehentlich löschen. Oder Benutzer möchten einfach noch viele Monate Backup-Versionen ihrer Daten aufbewahren und den zusätzlichen Speicherplatz für Snapshot-Kopien innerhalb des Volumes zu einer Kostenanforderung machen. Snapshot-Kopien sollten die bevorzugte Methode sein, Backup-Versionen für die letzten Wochen zu behalten, um verlorene Daten von ihnen wiederherzustellen, sie befinden sich jedoch im Volume und gehen verloren, wenn das Volume entfernt wird.</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">Aus allen diesen Gründen bietet NetApp Cloud Volumes Service Backup-Services über an<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>.</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">Cloud Volumes Service Backup erzeugt eine Kopie des Volumes auf Google Cloud Storage (GCS). Es sichert nur die tatsächlichen Daten, die innerhalb des Volume gespeichert sind, nicht den freien Speicherplatz. Es funktioniert wie immer inkrementell, d. h., es überträgt den Volume-Inhalt einmal und von dort auf wird nur geänderte Daten gesichert. Im Vergleich zu klassischen Backup-Konzepten mit mehreren vollständigen Backups spart das Unternehmen viel Storage und senkt dadurch die Kosten. Da der monatliche Preis von Backup-Speicherplatz im Vergleich zu einem Volume niedriger ist, ist es der ideale Ort, um Backup-Versionen länger zu halten.</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">Benutzer können ein Cloud Volumes Service Backup verwenden, um jede Backup-Version auf demselben oder einem anderen Volume innerhalb derselben Region wiederherzustellen. Wenn das Quell-Volume gelöscht wird, werden die Backup-Daten aufbewahrt und müssen unabhängig gemanagt werden (beispielsweise gelöscht).</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Cloud Volumes Service Backup-Dokumentation</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">Anzahl der maximal unterstützten Backup-Versionen</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">Preisgestaltung</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service Backup ist optional in Cloud Volumes Service integriert. Benutzer legen fest, welche Volumes gesichert werden sollen, indem Cloud Volumes Service Backup für einzelne Volumes aktiviert wird. Siehe<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> Weitere Informationen zu Backups finden Sie im<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>, Planung, und<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>.</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">Alle Backup-Daten eines Projekts werden innerhalb eines GCS-Buckets gespeichert, der durch den Service gemanagt wird und für den Benutzer nicht sichtbar ist. Jedes Projekt verwendet einen anderen Bucket. Derzeit befinden sich die Buckets im gleichen Bereich wie die Cloud Volumes Service Volumes, es werden jedoch noch weitere Optionen erläutert. In der Dokumentation finden Sie den aktuellen Status.</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">Der Datentransport von einem Cloud Volumes Service-Bucket zu GCS nutzt Service-interne Google-Netzwerke mit HTTPS und TLS1.2. Die Daten werden im Ruhezustand mit von Google gemanagten Schlüsseln verschlüsselt.</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">Rollen/netappCloudVolumes.admin</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Um Cloud Volumes Service-Backups zu managen (Backups erstellen, löschen und wiederherstellen), muss ein Benutzer über die verfügen<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> Rolle:</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">Weiter: Architekturübersicht.</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">Die übertragenen Daten können auf der NAS-Protokollebene verschlüsselt und das Google Cloud-Netzwerk selbst verschlüsselt werden, wie in den folgenden Abschnitten beschrieben.</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">Datenverschlüsselung während der Übertragung</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">Früher: Datenebenen-Architektur.</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Google Cloud Network</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">Verschlüsselung während der Übertragung</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud verschlüsselt den Datenverkehr auf Netzwerkebene wie in beschrieben<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> In der Google-Dokumentation. Wie im Abschnitt „Cloud Volumes Services Architecture“ erwähnt, wird Cloud Volumes Service aus einem von NetApp gesteuerten PSA Producer-Projekt bereitgestellt.</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">Im Fall von CVS-SW führt der Producer-Mandant Google VMs aus, um den Service bereitzustellen. Der Datenverkehr zwischen Benutzer-VMs und Cloud Volumes Service-VMs wird automatisch durch Google verschlüsselt.</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">Der IEEE 802.1AE Verschlüsselung (MACsec)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">Kapselung</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">Obwohl der Datenpfad für CVS-Performance nicht vollständig auf der Netzwerkebene verschlüsselt ist, verwenden NetApp und Google eine Kombination<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>,<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (Datenverschlüsselung) und Netzwerke mit physischen Einschränkungen zum Schutz der Daten bei der Übertragung zwischen dem Cloud Volumes Service CVS-Performance Servicetyp und Google Cloud</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">Die NAS-Protokolle NFS und SMB bieten optionale Transportverschlüsselung auf Protokollebene.</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> Bietet End-to-End-Verschlüsselung von SMB-Daten und schützt Daten vor abfallenden Ereignissen in nicht vertrauenswürdigen Netzwerken. Sie können die Verschlüsselung sowohl für die Client-/Server-Datenverbindung (nur für SMB3.x-fähige Clients verfügbar) als auch für die Server/Domain-Controller-Authentifizierung aktivieren.</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">Wenn die SMB-Verschlüsselung aktiviert ist, können Clients, die keine Verschlüsselung unterstützen, nicht auf die Freigabe zugreifen.</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service unterstützt RC4-HMAC, AES-128-CTS-HMAC-SHA1 und AES-256-CTS-HMAC-SHA1-Sicherheitschiffren für SMB-Verschlüsselung. SMB verhandelt den vom Server am häufigsten unterstützten Verschlüsselungstyp.</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">Kerberos: NFSv4.1</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">Für NFSv4.1 bietet CVS-Performance Kerberos-Authentifizierung wie in beschrieben<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>. Sie können Kerberos auf Volume-Basis aktivieren.</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">Der derzeit stärkste verfügbare Verschlüsselungstyp für Kerberos ist AES-256-CTS-HMAC-SHA1. NetApp Cloud Volumes Service unterstützt AES-256-CTS-HMAC-SHA1, AES-128-CTS-HMAC-SHA1, DES3 und DES für NFS. Es unterstützt auch ARCFOUR-HMAC (RC4) für CIFS/SMB-Datenverkehr, jedoch nicht für NFS.</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos bietet drei verschiedene Sicherheitsstufen für NFS-Mounts, die Möglichkeiten bieten, wie stark die Kerberos-Sicherheit sein sollte.</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">Allgemeine Mount-Optionen</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">As per RedHat<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> Dokumentation:</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">Je mehr der Kerberos-Sicherheitslevel zu tun hat, desto schlechter ist die Performance, da Client und Server Zeit damit verbringen, NFS-Vorgänge für jedes gesendete Paket zu verschlüsseln und zu entschlüsseln. Viele Clients und NFS Server unterstützen AES-NI-Entlastung der CPUs, um insgesamt eine bessere Benutzererfahrung zu erzielen. Die Auswirkungen von Kerberos 5p (vollständige End-to-End-Verschlüsselung) sind jedoch deutlich höher als die Auswirkungen von Kerberos 5 (Benutzerauthentifizierung).</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">Die folgende Tabelle zeigt Unterschiede in den einzelnen Ebenen in Bezug auf Sicherheit und Performance.</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">Sicherheitsstufe</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="cell">Leistung</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3 – sys</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">Am wenigsten sicher; Klartext mit numerischen Benutzer-IDs/Gruppen-IDs</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">Kann UID, GID, Client-IP-Adressen, Exportpfade, Dateinamen, Berechtigungen in Paketaufnahmen</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">Das Beste für die meisten Fälle</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x – sys</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">Sicherer als NFSv3 (Client-IDs, Namenszeichenfolge/Domänenzeichenfolge-Übereinstimmung), aber immer noch Klartext</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">Kann UID, GID, Client-IP-Adressen, Namensstrings, Domänen-IDs, anzeigen Pfade, Dateinamen und Berechtigungen in Paketaufnahmen exportieren</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">Gut für sequenzielle Workloads (z. B. VMs, Datenbanken, große Dateien)</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">Schlecht mit hoher Dateianzahl/hohen Metadaten (30-50% schlechter)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS – krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">Kerberos-Verschlüsselung für Anmeldeinformationen in jedem NFS-Paket – schließt UID/GID von Benutzern/Gruppen in RPC-Aufrufen in GSS-Wrapper</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">Benutzer, die Zugriff auf das Mount anfordern, benötigen ein gültiges Kerberos-Ticket (entweder über den Benutzernamen/das Passwort oder den Austausch des manuellen Schlüssels); das Ticket läuft nach einem bestimmten Zeitraum ab und der Benutzer muss sich erneut authentifizieren, um Zugriff zu erhalten</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">Keine Verschlüsselung für NFS-Vorgänge oder Zusatz-Protokolle wie Mount/Portmapper/nlm (kann Exportpfade, IP-Adressen, Dateihandles, Berechtigungen, Dateinamen, Uhrzeit/Mtime in Paketaufnahmen)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">Am besten in den meisten Fällen für Kerberos; schlechter als AUTH_SYS</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS – krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">Benutzer, die Zugriff auf das Mount anfordern, benötigen ein gültiges Kerberos-Ticket (entweder über Benutzernamen/Passwort oder den Austausch des manuellen Schlüssels); das Ticket läuft nach einem bestimmten Zeitraum ab und der Benutzer muss sich erneut authentifizieren, um Zugriff zu erhalten</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">Kerberos GSS-Prüfsumme wird zu jedem Paket hinzugefügt, damit die Pakete nicht abgefangen werden. Wenn Prüfsummen übereinstimmen, ist das Gespräch zulässig.</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">Besser als krb5p, da die NFS-Nutzlast nicht verschlüsselt ist; nur der zusätzliche Overhead im Vergleich zu krb5 ist die Integritäts-Prüfsumme. Die Leistung von krb5i wird nicht viel schlechter sein als krb5, aber wird einige Verschlechterung zu sehen.</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS – krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">Benutzer, die Zugriff auf das Mount anfordern, benötigen ein gültiges Kerberos-Ticket (entweder über Benutzernamen/Passwort oder den manuellen Schlüsseltab-Austausch); das Ticket läuft nach einem festgelegten Zeitraum ab und der Benutzer muss sich erneut authentifizieren, um Zugriff zu erhalten</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">Alle Payloads des NFS-Pakets sind mit dem GSS-Wrapper verschlüsselt (Dateihandles, Berechtigungen, Dateinamen, atime/mtime in Paketaufnahmen können nicht angezeigt werden).</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">Umfasst die Integritätsprüfung.</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">Der NFS Operationstyp ist sichtbar (FSINFO, ACCESS, GETATTR usw.).</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">Zusatzprotokolle (Mount, Portmap, nlm usw.) sind nicht verschlüsselt - (kann Exportpfade, IP-Adressen sehen)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">Schlechteste Leistung der Sicherheitsstufen; krb5p muss mehr verschlüsseln/entschlüsseln.</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">Bessere Performance als krb5p mit NFSv4.x für Workloads mit hoher Dateianzahl.</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">In Cloud Volumes Service wird ein konfigurierter Active Directory-Server als Kerberos-Server und LDAP-Server verwendet (um Benutzeridentitäten aus einem RFC2307-kompatiblen Schema zu suchen). Es werden keine anderen Kerberos oder LDAP-Server unterstützt. NetApp empfiehlt besonders, LDAP für das Identitätsmanagement in Cloud Volumes Service zu verwenden. Informationen darüber, wie NFS Kerberos in Paketaufnahmen angezeigt wird, finden Sie im Abschnitt <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">Im nächsten Schritt: Verschlüsselung von Daten im Ruhezustand.</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">Die Sicherheit – insbesondere in der Cloud, wo die Infrastruktur außerhalb der Kontrolle der Storage-Administratoren liegt – ist entscheidend, wenn es um die Übergabe der Daten an die von Cloud-Providern angebotenen Service-Angebote geht. Dieses Dokument bietet einen Überblick über die Sicherheitsangebote, die NetApp Cloud Volumes Service in der Google Cloud zur Verfügung stellt.</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918: Sicherheitsübersicht - NetApp Cloud Volumes Service in Google Cloud</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">Oliver Krause, Justin Parisi, NetApp</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">Dokumentumfang</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service bietet in Google Cloud</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">Die Sicherheit – insbesondere in der Cloud, wo die Infrastruktur außerhalb der Kontrolle der Storage-Administratoren liegt – ist entscheidend, wenn es um die Übergabe der Daten an die von Cloud-Providern angebotenen Service-Angebote geht. Dieses Dokument bietet einen Überblick über die Sicherheitsangebote von NetApp<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>.</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Zielgruppe</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">Die Zielgruppe dieses Dokuments umfasst die folgenden Rollen:</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">Cloud Provider</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">Storage-Administratoren</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">Storage-Architekten</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">Feldressourcen</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">Geschäftliche Entscheidungsträger</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">„Kontaktieren Sie uns.“</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">Wenn Sie Fragen zum Inhalt dieses technischen Berichts haben, finden Sie im Abschnitt <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">Abkürzung</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">Definition</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service, Diensttyp CVS</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS-Performance</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud Volume Service, Servicetyp CVS-Performance</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">Im nächsten Schritt: Wie Cloud Volumes Service in Google Cloud Ihre Daten sichert.</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">Kontaktieren Sie uns unter mailto:doccomments@netapp.com[doccomments@netapp.com^]. Nehmen SIE den TECHNISCHEN BERICHT 4918 in die Betreffzeile auf.</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">NetApp Lösungen für VMware bei Hyperscalern</block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">Erfahren Sie mehr über die Lösungen, die NetApp die VMware Umgebung in allen Hyperscalern zur Verfügung stellt: Migration von Workflows, Erweiterung/Bursting in die Cloud, Backup/Restore und Disaster Recovery.</block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">NetApp Lösungen für VMware Umgebungen</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">Egal, ob Sie in einem Hybrid-Cloud-Modell oder einem „Cloud First“-Modell arbeiten: NetApp bietet eine breite Palette an Lösungen für die gängigsten Anwendungsfälle für das Management von Workloads in einer Cloud oder einer Hybrid-Cloud-Modell.</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">Darüber hinaus bietet NetApp Lösungen für Storage, der als Gast-Storage (mit Anbindung an den Gast) oder als zusätzlicher NFS-Datenspeicher in jedem der Hyperscaler bereitgestellt wird. Alle Lösungen werden im Einklang mit der Klassifizierung von Cloud-Workloads durch VMware kategorisiert. Zu diesen Klassifizierungen gehören:</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">Weitere Informationen zu den für die einzelnen Hyperscaler verfügbaren Lösungen finden Sie unter:</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">Lösungen für AWS/VMC</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">Lösungen für Azure / AVS</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">Lösungen für GCP/GCVE</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="summary">Diese Lösung erfordert eine erfolgreiche Kommunikation zwischen dem lokalen ONTAP Cluster und AWS FSX für die NetApp ONTAP Interconnect Cluster-Netzwerkadressen, die den NetApp SyncMirror Betrieb durchführen. Außerdem muss ein Veeam-Backup-Server auf einen AWS S3-Bucket zugreifen können. Anstelle des Internetverkehrs kann ein vorhandener VPN- oder Direct Connect-Link als private Verbindung zu einem S3-Bucket verwendet werden.</block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">On-Premises</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP unterstützt alle wichtigen Storage-Protokolle für die Virtualisierung, einschließlich iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) und Non-Volatile Memory Express over Fibre Channel (NVMe/FC) für SAN-Umgebungen. ONTAP unterstützt außerdem NFS (v3 und v4.1) und SMB oder S3 für Gastverbindungen. Sie können die für Ihre Umgebung am besten geeigneten Protokolle auswählen und sie nach Bedarf in einem einzigen System kombinieren. Sie können beispielsweise die allgemeine Nutzung von NFS-Datenspeichern mit einigen iSCSI-LUNs oder Gast-Shares erweitern.</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">Diese Lösung nutzt NFS-Datenspeicher für lokale Datenspeicher für Gast-VMDKs sowie iSCSI und NFS für Gast-Applikationsdaten.</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="section-title">Client-Netzwerke</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">VMkernel-Netzwerkports und softwaredefinierte Netzwerke ermöglichen Konnektivität zu ESXi Hosts und ermöglichen die Kommunikation mit Elementen außerhalb der VMware Umgebung. Konnektivität ist abhängig von der Art der verwendeten VMkernel-Schnittstellen.</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">Für diese Lösung wurden die folgenden VMkernel Schnittstellen konfiguriert:</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">Vereinfachtes</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="section-title">Bereitgestellte Storage-Netzwerke</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">Eine LIF (logische Schnittstelle) stellt einen Netzwerkzugriffspunkt für einen Node im Cluster dar. Dies ermöglicht die Kommunikation mit Storage Virtual Machines, die die Daten enthalten, auf die Kunden zugreifen. Sie können LIFs an Ports konfigurieren, über die das Cluster Kommunikation über das Netzwerk sendet und empfängt.</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">Für diese Lösung sind LIFs für die folgenden Storage-Protokolle konfiguriert:</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="section-title">Cloud-Konnektivitätsoptionen</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">Bei der Anbindung von On-Premises-Umgebungen an Cloud-Ressourcen stehen Kunden zahlreiche Optionen zur Verfügung, einschließlich der Implementierung von VPN- oder Direct Connect-Topologien.</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="section-title">Virtuelles privates Netzwerk (VPN)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">VPNs (Virtual Private Networks) werden häufig verwendet, um einen sicheren IPSec-Tunnel mit internetbasierten oder privaten MPLS-Netzwerken zu erstellen. Ein VPN ist einfach einzurichten, aber es fehlt an Zuverlässigkeit (wenn Internet-basiert) und Geschwindigkeit. Der Endpunkt kann über die AWS VPC oder beim VMware Cloud SDDC beendet werden. Für diese Disaster-Recovery-Lösung wurde über das lokale Netzwerk eine Konnektivität mit AWS FSX für NetApp ONTAP hergestellt. Somit kann sie an der AWS VPC (Virtual Private Gateway oder Transit Gateway) gekündigt werden, mit der FSX für NetApp ONTAP verbunden ist.</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">VPN-Einrichtung kann auf Routen oder Richtlinien basieren. Bei einem routingbasierten Setup tauschen die Endpunkte die Routen automatisch aus und Setup lernt die Route zu den neu erstellten Subnetzen. Bei einem richtlinienbasierten Setup müssen Sie die lokalen und Remote-Subnetze definieren. Wenn neue Subnetze hinzugefügt werden und im IPSec-Tunnel kommunizieren dürfen, müssen Sie die Routen aktualisieren.</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">Wenn der IPSec-VPN-Tunnel nicht auf dem Standard-Gateway erstellt wird, müssen Remote-Netzwerk-Routen in Routingtabellen über den lokalen VPN-Tunnel-Endpunkt definiert werden.</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">Die folgende Abbildung zeigt typische VPN-Verbindungsoptionen.</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="section-title">Direktverbindung</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect bietet eine dedizierte Verbindung zum AWS Netzwerk. Durch dedizierte Verbindungen werden Links zu AWS über einen Ethernet-Port mit 1 Gbit/s, 10 Gbit/s oder 100 Gbit/s erstellt. AWS Direct Connect Partner bieten gehostete Verbindungen über vordefinierte Netzwerkverbindungen zwischen sich und AWS und sind von 50 MBit/s bis zu 10 Gbit/s verfügbar. Standardmäßig wird der Datenverkehr unverschlüsselt. Für den sicheren Datenverkehr mit MACsec oder IPsec stehen jedoch Optionen zur Verfügung. MACsec bietet Layer-2-Verschlüsselung, während IPsec Layer-3-Verschlüsselung ermöglicht. MACsec bietet eine bessere Sicherheit, indem die Kommunikationsmittel der Geräte verschleiert werden.</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">Die Router-Ausrüstung des Kunden muss sich an einem AWS Direct Connect-Standort befinden. Um diese Einrichtung einzurichten, können Sie mit dem AWS Partner Network (APN) zusammenarbeiten. Zwischen diesem Router und dem AWS Router wird eine physische Verbindung hergestellt. Damit der Zugriff auf FSX für NetApp ONTAP in VPC möglich ist, müssen Sie entweder über eine private virtuelle Schnittstelle oder eine Transit-virtuelle Schnittstelle von Direct Connect zu einer VPC verfügen. Bei einer privaten virtuellen Schnittstelle ist die Skalierbarkeit der Direct Connect to VPC Verbindung eingeschränkt.</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">Die folgende Abbildung zeigt die Optionen für die Direct Connect-Schnittstelle.</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="section-title">Transit Gateway</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">Dokumentation zu AWS Direct Connect</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">Das Transit-Gateway ist ein Konstrukt auf Regionalebene, das eine erhöhte Skalierbarkeit einer Direct Connect-to-VPC-Verbindung innerhalb einer Region ermöglicht. Wenn eine länderübergreifende Verbindung erforderlich ist, müssen die Transit-Gateways gepeiert werden. Weitere Informationen finden Sie im<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>.</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="section-title">Überlegungen zum Cloud-Netzwerk</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">In der Cloud wird die zugrunde liegende Netzwerkinfrastruktur vom Cloud-Service-Provider gemanagt, während Kunden die VPC-Netzwerke, Subnetze, Routing-Tabellen usw. in AWS managen müssen. Außerdem müssen sie NSX-Netzwerksegmente am Computing-Edge managen. SDDC gruppiert Routen für die externe VPC und Transit Connect.</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">Wird FSX für NetApp ONTAP mit Verfügbarkeit von mehreren Verfügbarkeitszonen auf einer mit VMware Cloud verbundenen VPC implementiert, erhält der iSCSI-Traffic die nötigen Updates für die Routing-Tabelle, um die Kommunikation zu ermöglichen. Standardmäßig ist keine Route von VMware Cloud zum FSX ONTAP-NFS/SMB-Subnetz auf der verbundenen VPC für eine Multi-AZ-Implementierung verfügbar. Für die Definition dieser Route haben wir die VMware Cloud SDDC-Gruppe verwendet, die ein von VMware gemanagtes Transit Gateway ist, um die Kommunikation zwischen den VMware Cloud SDDCs in derselben Region sowie externen VPCs und anderen Transit Gateways zu ermöglichen.</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">Die Kosten für die Datenübertragung sind für die Verwendung eines Transit-Gateways anfallen. Weitere Informationen zu den Kosten für eine Region finden Sie unter<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>.</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDC kann in einer einzelnen Verfügbarkeitszone implementiert werden, so wie bei einem einzelnen Datacenter. Es ist auch eine Stretch-Cluster-Option verfügbar, die wie eine NetApp MetroCluster-Lösung aussieht, die bei Ausfällen in der Verfügbarkeitszone eine höhere Verfügbarkeit und weniger Ausfallzeiten bietet.</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">Um die Datentransferkosten zu minimieren, sollten VMware Cloud SDDC und AWS Instanzen oder Services in derselben Verfügbarkeitszone gehalten werden. NetApp ist besser mit einer Verfügbarkeitszone-ID und nicht mit einem Namen abzustimmen, da AWS die auf das Konto spezifische AZ-Auftragsliste bereitstellt, um die Last über Verfügbarkeitszonen zu verteilen. Ein Konto (US-Ost-1a) könnte beispielsweise auf die AZ-ID 1 verweisen, ein anderer Account (US-Ost-1c) könnte auf die AZ-ID 1 verweisen. Die Verfügbarkeitszone-ID kann auf verschiedene Weise abgerufen werden. Im folgenden Beispiel haben wir die AZ-ID aus dem VPC-Subnetz abgerufen.</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">VMware Dokumentation</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">Im VMware Cloud SDDC wird die Netzwerkumgebung über NSX gemanagt. Das Edge-Gateway (Tier-0 Router) für den Nord-Süd-Traffic-Uplink-Port ist mit der AWS VPC verbunden. Das Computing-Gateway und die Management Gateways (Tier-1 Router) verarbeiten Ost-West-Datenverkehr. Wenn die Uplink-Ports des Edge stark verwendet werden, können Sie Traffic-Gruppen erstellen, die mit bestimmten Host-IPs oder Subnetzen verknüpft werden. Durch die Erstellung einer Datenverkehrsgruppe werden zusätzliche Edge-Nodes zum Trennen des Datenverkehrs erstellt. Prüfen Sie die<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> Wählen Sie die Mindestanzahl der vSphere Hosts aus, die für die Verwendung eines MultiEdge-Setups erforderlich sind.</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">Wenn Sie VMware Cloud SDDC bereitstellen, sind die VMkernel-Ports bereits konfiguriert und können sofort verwendet werden. VMware managt diese Ports, und es müssen keine Updates durchgeführt werden.</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">Folgende Abbildung zeigt Beispielinformationen für den Host VMkernel.</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="section-title">Bereitgestellte Storage-Netzwerke (iSCSI, NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">Für VM-Gast-Storage-Netzwerke erstellen wir normalerweise Port-Gruppen. Mit NSX erstellen wir Segmente, die in vCenter als Port-Gruppen verwendet werden. Da sich Speichernetzwerke in einem routingfähigen Subnetz befinden, können Sie auf die LUNs zugreifen oder die NFS-Exporte mithilfe der Standard-NIC mounten, ohne separate Netzwerksegmente zu erstellen. Zur Trennung des Speicherdatenverkehrs können Sie weitere Segmente erstellen, Regeln definieren und die MTU-Größe für diese Segmente steuern. Um Fehlertoleranz zu schaffen, ist es besser, mindestens zwei Segmente für das Storage-Netzwerk bereitzustellen. Wenn eine Uplink-Bandbreite ein Problem wird, können Sie wie bereits erwähnt Traffic-Gruppen erstellen und IP-Präfixe und Gateways zuweisen, um ein quellbasiertes Routing durchzuführen.</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">Wir empfehlen, die Segmente im DR SDDC mit der Quellumgebung abzustimmen, um zu verhindern, dass beim Failover Netzwerksegmente zugeordnet werden.</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="section-title">Sicherheitsgruppen</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">Viele Sicherheitsoptionen bieten eine sichere Kommunikation zwischen der AWS VPC und dem VMware Cloud SDDC-Netzwerk. Innerhalb des VMware Cloud SDDC-Netzwerks kann der NSX Trace-Flow verwendet werden, um den Pfad einschließlich der verwendeten Regeln zu identifizieren. Anschließend können Sie mithilfe eines Netzwerkanalysators im VPC-Netzwerk den Pfad identifizieren, einschließlich der Routingtabellen, Sicherheitsgruppen und Listen der Netzwerkzugriffssteuerung, die während des Flusses verbraucht werden.</block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="summary">Diese Lösung verwendet NetApp SnapCenter zur Erstellung applikationskonsistenter Backups von SQL Server und Oracle Datenbanken. Zusammen mit Veeam Backup &amp; Replication zum Backup von VMDKs für Virtual Machines stellt dies eine umfassende Disaster-Recovery-Lösung für lokale und Cloud-basierte Datacenter bereit.</block>
  <block id="7236883d93928f76f56ba8cc9207fd1d" category="doc">Implementieren und konfigurieren Sie Windows SnapCenter Server vor Ort</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="section-title">Implementieren Sie Windows SnapCenter Server vor Ort</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">NetApp Documentation Center</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">SnapCenter Software ist über die NetApp Support Site erhältlich und kann auf Microsoft Windows Systemen installiert werden, die sich entweder in einer Domäne oder Arbeitsgruppe befinden. Ein detaillierter Planungsleitfaden und Installationsanweisungen finden Sie unter<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>.</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">Die SnapCenter-Software ist erhältlich unter<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">Nach der Installation können Sie über einen Webbrowser mit _\https://Virtual_Cluster_IP_or_FQDN:8146_ auf die SnapCenter Konsole zugreifen.</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="section-title">Hinzufügen von Storage-Controllern zu SnapCenter</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">Gehen Sie wie folgt vor, um SnapCenter Storage-Controller hinzuzufügen:</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">Wählen Sie im linken Menü Storage Systems aus und klicken Sie dann auf Neu, um mit dem Hinzufügen Ihrer Storage Controller zu SnapCenter zu beginnen.</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">Fügen Sie im Dialogfeld Add Storage System die Management-IP-Adresse für den lokalen ONTAP-Cluster sowie den Benutzernamen und das Passwort hinzu. Klicken Sie dann auf Senden, um die Erkennung des Speichersystems zu starten.</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">Wiederholen Sie diesen Vorgang, um dem SnapCenter das FSX ONTAP-System hinzuzufügen. Wählen Sie in diesem Fall unten im Fenster „Add Storage System“ die Option „More Options“ (Weitere Optionen) aus und klicken Sie auf das Kontrollkästchen für „Secondary“ (sekundär), um das FSX-System als sekundäres Storage-System zu bezeichnen, das mit SnapMirror Kopien oder unseren primären Backup Snapshots aktualisiert wird.</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">Weitere Informationen zum Hinzufügen von Storage-Systemen zum SnapCenter finden Sie in der Dokumentation unter<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>.</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="section-title">Fügen Sie Hosts zum SnapCenter hinzu</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">Der nächste Schritt ist das Hinzufügen von Host-Applikations-Servern zu SnapCenter. Der Prozess ist sowohl für SQL Server als auch für Oracle ähnlich.</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">Wählen Sie im linken Menü Hosts aus und klicken Sie dann auf Hinzufügen, um mit dem Hinzufügen von Speicher-Controllern zu SnapCenter zu beginnen.</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">Fügen Sie im Fenster Hosts hinzufügen den Host-Typ, den Hostnamen und die Anmeldedaten des Host-Systems hinzu. Wählen Sie den Plug-in-Typ aus. Wählen Sie für SQL Server das Plug-in für Microsoft Windows und Microsoft SQL Server aus.</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Füllen Sie für Oracle die erforderlichen Felder im Dialogfeld „Host hinzufügen“ aus, und aktivieren Sie das Kontrollkästchen für das Oracle Database Plug-in. Klicken Sie dann auf Senden, um den Erkennungsvorgang zu starten und den Host zu SnapCenter hinzuzufügen.</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="section-title">SnapCenter-Richtlinien erstellen</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">Richtlinien legen die spezifischen Regeln fest, die für einen Backup-Job zu beachten sind. Dazu gehören u. a. der Backup-Zeitplan, der Replizierungstyp und die Handhabung von SnapCenter für Backup und Verkürzung der Transaktions-Logs.</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">Sie können auf die Richtlinien im Abschnitt Einstellungen des SnapCenter-Webclients zugreifen.</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">SnapCenter-Dokumentation</block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">Vollständige Informationen zum Erstellen von Richtlinien für SQL Server-Backups finden Sie im<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Vollständige Informationen zum Erstellen von Richtlinien für Oracle-Backups finden Sie im<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">*Hinweise:*</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">Wenn Sie den Assistenten zur Erstellung von Richtlinien durchlaufen, beachten Sie den Abschnitt „Replikation“ besonders. In diesem Abschnitt werden die Arten von sekundären SnapMirror Kopien festgelegt, die während des Backup-Prozesses erstellt werden sollen.</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">Die Einstellung „SnapMirror aktualisieren nach dem Erstellen einer lokalen Snapshot Kopie“ bezieht sich auf die Aktualisierung einer SnapMirror Beziehung, wenn diese Beziehung zwischen zwei Storage Virtual Machines besteht, die sich auf dem gleichen Cluster befinden.</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">Die Einstellung „SnapVault aktualisieren nach Erstellen einer lokalen Snapshot Kopie“ wird verwendet, um eine SnapMirror Beziehung zu aktualisieren, die zwischen zwei separaten Clustern und zwischen einem On-Premises ONTAP System und Cloud Volumes ONTAP oder FSxN besteht.</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">Die folgende Abbildung zeigt die vorhergehenden Optionen und deren Aussehen im Backup Policy Wizard.</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="section-title">Erstellen Sie SnapCenter-Ressourcengruppen</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">Mit Ressourcengruppen können Sie die Datenbankressourcen auswählen, die Sie in Ihre Backups aufnehmen möchten, und die Richtlinien für diese Ressourcen.</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">Wechseln Sie im linken Menü zum Abschnitt Ressourcen.</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">Wählen Sie oben im Fenster den Ressourcentyp aus, mit dem Sie arbeiten möchten (in diesem Fall Microsoft SQL Server), und klicken Sie dann auf Neue Ressourcengruppe.</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">Die SnapCenter-Dokumentation umfasst Schritt-für-Schritt-Details zum Erstellen von Ressourcengruppen für SQL Server und Oracle-Datenbanken.</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">Folgen Sie zum Backup von SQL-Ressourcen<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>.</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Folgen Sie zum Backup von Oracle Ressourcen<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>.</block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">NetApp Hybrid-Multi-Cloud-Lösungen für AWS/VMC</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="section-title">Fähigkeiten und Wissen</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Für den Zugriff auf Cloud Volumes Service für AWS sind die folgenden Fähigkeiten und Informationen erforderlich:</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">Zugriff auf und Know-how der On-Premises-Umgebung von VMware und ONTAP</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">Zugang zu und Wissen über VMware Cloud und AWS</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">Zugriff auf und Wissen zu AWS und Amazon FSX ONTAP.</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">Kenntnis Ihrer SDDC und AWS Ressourcen</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">Wissen über die Netzwerkverbindung zwischen Ihren lokalen und Cloud-Ressourcen</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">Kenntnisse über Disaster-Recovery-Szenarien.</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">Wissen über die auf VMware implementierten Applikationen</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="section-title">Administration</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">Unabhängig davon, ob Benutzer und Administratoren mit Ressourcen vor Ort oder in der Cloud interagieren, müssen sie die Möglichkeit und die Berechtigungen haben, diese Ressourcen je nach Bedarf je nach Bedarf an den gewünschten Stellen bereitzustellen. Die Interaktion Ihrer Rollen und Berechtigungen für Ihre On-Premises-Systeme, einschließlich ONTAP und VMware, sowie Ihrer Cloud-Ressourcen wie VMware Cloud und AWS ist für eine erfolgreiche Hybrid-Cloud-Implementierung von entscheidender Bedeutung.</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">Die folgenden Administrationsaufgaben müssen zum Aufbau einer DR-Lösung mit VMware und ONTAP On-Premises, VMware Cloud auf AWS und FSX ONTAP ausgeführt werden.</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">Rollen und Accounts ermöglichen die Bereitstellung folgender Funktionen:</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">ONTAP Storage-Ressourcen</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">VMware VMs, Datenspeicher usw.</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPC und Sicherheitsgruppen</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">Bereitstellung einer lokalen VMware Umgebung und von ONTAP</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">VMware Cloud-Umgebung</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">Ein Filesystem von Amazon für FSX für ONTAP</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">Konnektivität zwischen Ihrer lokalen Umgebung und AWS</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">Konnektivität für die AWS VPC</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">In der virtuellen VMware Umgebung sind Lizenzen für ESXi Hosts, VMware vCenter Server, NSX-Netzwerke und andere Komponenten enthalten, wie dies in der folgenden Abbildung zu sehen ist. Sie werden alle unterschiedlich lizenziert. Es ist wichtig zu verstehen, wie die zugrunde liegenden Komponenten die verfügbare lizenzierte Kapazität nutzen.</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="section-title">ESXi-Hosts</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">Compute-Hosts in einer VMware Umgebung werden mit ESXi implementiert. Bei einer Lizenzierung mit vSphere in verschiedenen Kapazitätsebenen können Virtual Machines die physischen CPUs auf jedem Host und die entsprechenden Merkmale nutzen.</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="section-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">Das Management von ESXi-Hosts und -Storage ist eine der vielen Funktionen, die VMware Administratoren über vCenter Server zur Verfügung gestellt werden. Ab VMware vCenter 7.0 sind je nach Lizenz drei Versionen von VMware vCenter verfügbar:</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">VCenter Server Essentials</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">VCenter Server Foundation</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">VCenter Server Standard</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="section-title">VMware NSX</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSX bietet Administratoren die Flexibilität, die sie für erweiterte Funktionen benötigen. Die Funktionen sind abhängig von der lizenzierten Version der NSX-T Edition aktiviert:</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">Professionell</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">Erweitert</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">Remote Office/Zweigstelle</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">Bei der Lizenzierung mit NetApp ONTAP wird darauf hingewiesen, wie Administratoren Zugriff auf verschiedene Funktionen innerhalb des NetApp Storage erhalten. Eine Lizenz ist ein Datensatz mit einem oder mehreren Softwareberechtigungen. Durch das Installieren von Lizenzschlüsseln, auch bekannt als Lizenzcodes, können Sie bestimmte Funktionen oder Services auf Ihrem Speichersystem verwenden. ONTAP unterstützt beispielsweise alle wichtigen branchenüblichen Client-Protokolle (NFS, SMB, FC, FCoE, iSCSI, Und NVMe/FC) durch Lizenzierung.</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Data ONTAP Funktionslizenzen werden als Pakete ausgegeben, von denen jede mehrere Funktionen oder eine einzelne Funktion enthält. Für ein Paket ist ein Lizenzschlüssel erforderlich, und durch die Installation des Schlüssels können Sie auf alle Funktionen des Pakets zugreifen.</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">Lizenztypen sind wie folgt:</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*Node-Locked-Lizenz.* die Installation einer Node-Locked-Lizenz berechtigt einen Knoten zur lizenzierten Funktionalität. Damit der Cluster die lizenzierte Funktion nutzen kann, muss mindestens ein Node für die Funktionalität lizenziert sein.</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*Master/Site-Lizenz.* Eine Master- oder Site-Lizenz ist nicht an eine bestimmte System-Seriennummer gebunden. Bei der Installation einer Standortlizenz haben alle Knoten im Cluster Anspruch auf die lizenzierte Funktionalität.</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*Demo/temporäre Lizenz.* eine Demo- oder temporäre Lizenz läuft nach einer bestimmten Zeit ab. Mit dieser Lizenz können Sie bestimmte Software-Funktionen ohne Erwerb einer Berechtigung testen.</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*Kapazitätslizenz (nur ONTAP Select und FabricPool).* eine ONTAP Select-Instanz wird entsprechend der Datenmenge lizenziert, die der Benutzer verwalten möchte. Ab ONTAP 9.4 erfordert FabricPool eine Kapazitätslizenz zur Verwendung mit einer Storage-Ebene eines Drittanbieters (beispielsweise AWS).</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="section-title">NetApp SnapCenter</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">Für die Aktivierung von Datensicherungsvorgängen SnapCenter sind mehrere Lizenzen erforderlich. Die Art der installierten SnapCenter Lizenzen hängt von Ihrer Storage-Umgebung und den gewünschten Funktionen ab. Die Standardlizenz von SnapCenter schützt Applikationen, Datenbanken, Dateisysteme und Virtual Machines. Bevor Sie SnapCenter ein Speichersystem hinzufügen, müssen Sie eine oder mehrere SnapCenter-Lizenzen installieren.</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">Um den Schutz von Applikationen, Datenbanken, Dateisystemen und Virtual Machines zu ermöglichen, muss entweder eine Controller-basierte Standardlizenz auf Ihrem FAS- oder AFF-Speichersystem installiert sein oder eine auf den ONTAP Select und Cloud Volumes ONTAP Plattformen installierte Standardkapazitätsbasierte Lizenz.</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">Für diese Lösung finden Sie die folgenden Voraussetzungen zur SnapCenter-Sicherung:</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">Ein auf dem lokalen ONTAP-System erstelltes Volume- und SMB-Share, um die gesicherten Datenbank- und Konfigurationsdateien zu lokalisieren.</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">Eine SnapMirror Beziehung zwischen dem lokalen ONTAP System und FSX oder CVO im AWS-Konto Verwendet für den Transport des Snapshots mit der gesicherten SnapCenter Datenbank und den Konfigurationsdateien.</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">Windows Server wird im Cloud-Konto installiert, entweder auf einer EC2 Instanz oder auf einer VM im VMware Cloud SDDC.</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter installiert auf der Windows EC2 Instanz oder VM in VMware Cloud.</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="section-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">Im Rahmen dieser Lösungsvalidierung setzen wir MS SQL auf, um das Disaster Recovery zu demonstrieren.</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">Weitere Informationen zu Best Practices für MS SQL und NetApp ONTAP finden Sie im folgenden Bericht<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>.</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="section-title">Oracle</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">Im Rahmen dieser Lösungsvalidierung demonstrieren wir ORACLE das Disaster Recovery. Weitere Informationen zu Best Practices mit ORACLE und NetApp ONTAP finden Sie im folgenden<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>.</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="section-title">Veeam</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">Im Rahmen dieser Lösungsvalidierung setzen wir Veeam für die Demonstration der Disaster Recovery ein. Weitere Informationen zu den Best Practices für Veeam und NetApp ONTAP finden Sie im folgenden Bericht<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>.</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">Sie müssen die folgenden Aufgaben ausführen können:</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">Implementieren und Konfigurieren von Domain Services</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">Implementieren von FSX-ONTAP je Applikationsanforderungen in einer bestimmten VPC</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">Konfigurieren Sie VMware Cloud auf dem AWS Computing-Gateway, um den Datenverkehr von FSX ONTAP zu ermöglichen.</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">Konfigurieren einer AWS-Sicherheitsgruppe, um die Kommunikation zwischen VMware Cloud on AWS-Subnetzen und den AWS VPC-Subnetzen zu ermöglichen, bei denen der FSX ONTAP-Service implementiert wird.</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="section-title">VMware Cloud</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">Konfiguration der VMware Cloud auf AWS SDDC</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="section-title">Kontoüberprüfung bei Cloud Manager</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">Ressourcen müssen mit NetApp Cloud Manager implementiert werden können. Führen Sie die folgenden Aufgaben aus, um zu überprüfen, ob Sie können:</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Melden Sie sich für Cloud Central an</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> Wenn Sie noch nicht.</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Melden Sie sich bei Cloud Manager an</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>.</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">Einrichten von Arbeitsbereichen und Benutzern</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>.</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">Einen Konnektor erstellen</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>.</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="section-title">Amazon FSX für NetApp ONTAP</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">Sie müssen die folgende Aufgabe ausführen können, nachdem Sie über ein AWS Konto verfügen:</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">Erstellung eines IAM-Administrationsbenutzers zur Bereitstellung von Amazon FSX für das Filesystem von NetApp ONTAP</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="section-title">Konfigurationsvoraussetzungen</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">Angesichts der verschiedenen Topologien der Kunden konzentriert sich dieser Abschnitt auf die Ports, die für die Kommunikation von lokalen zu Cloud-Ressourcen erforderlich sind.</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="section-title">Erforderliche Ports und Firewall-Überlegungen</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">In den folgenden Tabellen werden die Ports beschrieben, die in Ihrer Infrastruktur aktiviert werden müssen.</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Eine ausführlichere Liste der erforderlichen Ports für die Veeam Backup &amp; Replication-Software finden Sie im folgenden<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>.</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">Eine ausführlichere Liste der Portanforderungen für SnapCenter finden Sie im folgenden<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>.</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">In der folgenden Tabelle sind die Veeam Portanforderungen für Microsoft Windows Server aufgeführt.</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">Von</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">Bis</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">Protokoll</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">Port</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">Hinweise</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">Backup Server</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Microsoft Windows Server</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Port für die Implementierung von Veeam Backup &amp; Replication Komponenten erforderlich.</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">Backup-Proxy</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Der vom Veeam Installer Service verwendete Standardport.</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">Backup-Repository</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500 bis 3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">Standardbereich von Ports, die als Datenübertragungskanäle und zur Erfassung von Protokolldateien verwendet werden.</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">Mounten Sie den Server</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Standardport, der vom Veeam Data Mover verwendet wird.</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">Für jede TCP-Verbindung, die ein Job verwendet, wird ein Port aus diesem Bereich zugewiesen.</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">In der folgenden Tabelle sind die Anforderungen an Veeam-Ports für Linux Server aufgeführt.</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Linux Server</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">Port, der als Kontrollkanal von der Konsole zum Ziel-Linux-Host verwendet wird.</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">In der folgenden Tabelle sind die Portanforderungen für Veeam Backup Server aufgeführt.</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS, TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">Standardport für Verbindungen mit vCenter Server. Port, der als Kontrollkanal von der Konsole zum Ziel-Linux-Host verwendet wird.</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Microsoft SQL Server, der die Veeam Backup &amp; Replication Konfigurationsdatenbank hostet</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Port, der für die Kommunikation mit Microsoft SQL Server verwendet wird, auf dem die Veeam Backup &amp; Replication Konfigurationsdatenbank bereitgestellt wird (wenn Sie eine Standardinstanz von Microsoft SQL Server verwenden).</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">DNS-Server mit Namensauflösung aller Backup-Server</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">Port, der für die Kommunikation mit dem DNS-Server verwendet wird</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">Wenn Sie vCloud Director nutzen, öffnen Sie Port 443 auf den zugrunde liegenden vCenter Servern.</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">In der folgenden Tabelle sind die Anforderungen für Veeam Backup Proxy-Port aufgeführt.</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">Standardport, der vom Veeam Backup VSS Integration Service für das Erstellen eines VSS-Snapshots während des SMB-Dateifreigabedatenstains verwendet wird.</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">Der standardmäßige VMware Web Service-Port kann in vCenter-Einstellungen angepasst werden.</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">In der folgenden Tabelle sind die Anforderungen an SnapCenter-Ports aufgeführt.</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">Porttyp</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">SnapCenter Management-Port</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">Dieser Port wird für die Kommunikation zwischen dem SnapCenter-Client (dem SnapCenter-Benutzer) und dem SnapCenter-Server verwendet. Wird auch zur Kommunikation von den Plug-in-Hosts mit dem SnapCenter-Server verwendet.</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">SnapCenter SMCore-Kommunikations-Port</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">Dieser Port wird für die Kommunikation zwischen dem SnapCenter-Server und den Hosts verwendet, auf denen die SnapCenter-Plug-ins installiert sind.</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Installation von Windows-Plug-in-Hosts</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135, 445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">Diese Ports dienen zur Kommunikation zwischen dem SnapCenter-Server und dem Host, auf dem das Plug-in installiert wird. Die Ports können nach der Installation geschlossen werden. Darüber hinaus sucht Windows Instrumentation Services die Ports 49152 bis 65535, die geöffnet sein müssen.</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Installation durch Linux-Plug-in-Hosts</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">Diese Ports dienen zur Kommunikation zwischen dem SnapCenter-Server und dem Host, auf dem das Plug-in installiert wird. Die Ports werden von SnapCenter verwendet, um Plug-in-Binärdateien auf Linux Plug-in-Hosts zu kopieren.</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">SnapCenter-Plug-ins-Paket für Windows/Linux</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">Dieser Port wird für die Kommunikation zwischen SMCore und Hosts verwendet, auf denen die SnapCenter-Plug-ins installiert sind.</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">VMware vSphere vCenter Server Port</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">Dieser Port wird für die Kommunikation zwischen dem SnapCenter Plug-in für VMware vSphere und vCenter Server verwendet.</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">SnapCenter Plug-in für VMware vSphere Port</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">Dieser Port wird für die Kommunikation vom vCenter vSphere Web-Client und vom SnapCenter-Server verwendet.</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="doc">Backup von SnapCenter Datenbanken für Disaster Recovery</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter ermöglicht das Backup und Recovery seiner zugrunde liegenden MySQL Datenbank und Konfigurationsdaten, um bei einem Ausfall den SnapCenter Server wiederherzustellen. Für unsere Lösung haben wir die SnapCenter-Datenbank und die Konfiguration auf einer AWS EC2 Instanz in unserer VPC wiederhergestellt. Weitere Informationen zu diesem Schritt finden Sie unter<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>.</block>
  <block id="46137d274838eaef40c110eac160dabc" category="section-title">Voraussetzungen für SnapCenter-Backup</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">Für die SnapCenter-Sicherung sind folgende Voraussetzungen erforderlich:</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">Eine auf dem lokalen ONTAP-System erstellte Volume- und SMB-Freigabe, um die gesicherten Datenbank- und Konfigurationsdateien zu lokalisieren.</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">Eine SnapMirror Beziehung zwischen dem lokalen ONTAP System und FSX oder CVO im AWS-Konto Über diese Beziehung wird der Snapshot mit der gesicherten SnapCenter-Datenbank und den Konfigurationsdateien transportiert.</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="section-title">Zusammenfassung des SnapCenter-Backup- und Restore-Prozesses</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">Erstellen Sie ein Volume auf dem lokalen ONTAP System zum Hosten der Backup-db und Konfigurationsdateien.</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">Einrichten einer SnapMirror Beziehung zwischen On-Premises- und FSX/CVO</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">Mounten Sie den SMB-Share.</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">Rufen Sie das Swagger-Autorisierungs-Token zum Ausführen von API-Aufgaben ab.</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">starten sie den db-Wiederherstellungsprozess.</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">Verwenden Sie das xcopy-Dienstprogramm, um das lokale Verzeichnis der db- und Konfigurationsdatei in die SMB-Freigabe zu kopieren.</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">Erstellen Sie auf FSX einen Klon des ONTAP Volumes (kopiert über SnapMirror aus dem lokalen Datacenter).</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">Installieren Sie den SMB-Share von FSX zu EC2/VMware Cloud.</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">Kopieren Sie das Wiederherstellungsverzeichnis aus der SMB-Freigabe in ein lokales Verzeichnis.</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">Führen Sie den Wiederherstellungsprozess für SQL Server aus Swagger aus.</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="section-title">Backup der SnapCenter-Datenbank und -Konfiguration</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter stellt eine Web-Client-Schnittstelle zum Ausführen VON REST-API-Befehlen bereit. Weitere Informationen zum Zugriff auf DIE REST-APIs über Swagger finden Sie in der SnapCenter-Dokumentation unter<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>.</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="section-title">Melden Sie sich bei Swagger an und erhalten Sie ein Autorisierungs-Token</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Nachdem Sie die Seite Swagger aufgerufen haben, müssen Sie ein Autorisierungs-Token abrufen, um den Wiederherstellungsprozess der Datenbank zu starten.</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">Rufen Sie die Webseite der SnapCenter Swagger API auf unter _\https://&lt;SnapCenter Server IP&gt;:8146/Swagger/_.</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">Erweitern Sie den Abschnitt „Auth“, und klicken Sie auf „Probieren Sie es aus“.</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">Geben Sie im Bereich BenutzerbetriebContext die SnapCenter-Anmeldeinformationen und -Rolle ein, und klicken Sie auf Ausführen.</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">Im unten stehenden Antwortkörper können Sie das Token sehen. Kopieren Sie den Token-Text zur Authentifizierung, wenn Sie den Backup-Prozess ausführen.</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="section-title">Backup einer SnapCenter-Datenbank durchführen</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">Gehen Sie dann auf der Seite „Swagger“ auf den Bereich „Disaster Recovery“, um den SnapCenter-Backup-Prozess zu starten.</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">Erweitern Sie den Bereich Disaster Recovery, indem Sie darauf klicken.</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">Erweitern Sie den<block ref="ff68c70c197c21bcd2eda286f1ff14b6" prefix=" " category="inline-code"></block> Und klicken Sie auf „Probieren“.</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">Fügen Sie im Abschnitt SmDRBackupRequest den korrekten lokalen Zielpfad hinzu und wählen Sie Ausführen, um das Backup der SnapCenter-Datenbank und -Konfiguration zu starten.</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">Der Backup-Prozess erlaubt keine direkte Sicherung in einer NFS- oder CIFS-Dateifreigabe.</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="section-title">Überwachen Sie den Backup-Job von SnapCenter</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">Melden Sie sich bei SnapCenter an, um Protokolldateien beim Starten der Datenbankwiederherstellung zu überprüfen. Im Abschnitt „Überwachen“ können Sie Details zum Disaster-Recovery-Backup des SnapCenter Servers anzeigen.</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="section-title">Verwenden Sie das XCOPY-Dienstprogramm, um die Datenbank-Sicherungsdatei in die SMB-Freigabe zu kopieren</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">Als Nächstes müssen Sie das Backup vom lokalen Laufwerk auf dem SnapCenter Server in die CIFS-Freigabe verschieben, die zum Kopieren der Daten durch SnapMirror an den sekundären Speicherort auf der FSX Instanz in AWS verwendet wird. Verwenden Sie xcopy mit spezifischen Optionen, die die Berechtigungen der Dateien behalten.</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">Öffnen Sie eine Eingabeaufforderung als Administrator. Geben Sie an der Eingabeaufforderung die folgenden Befehle ein:</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">Für Unternehmen ist eine bewährte Disaster Recovery-Umgebung (DR) und ein bewährter Plan unerlässlich, um sicherzustellen, dass geschäftskritische Applikationen bei einem schwerwiegenden Ausfall schnell wiederhergestellt werden können. Der Schwerpunkt dieser Lösung liegt auf der Demonstration von DR-Anwendungsfällen. Der Schwerpunkt liegt dabei auf VMware und NetApp Technologien, sowohl vor Ort als auch mit VMware Cloud auf AWS.</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931: Disaster Recovery with VMware Cloud on Amazon Web Services and Guest Connect</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp blickt auf langjährige Erfahrungen in der Integration mit VMware zurück. Zehntausende von Kunden haben sich für NetApp als Storage-Partner für ihre virtualisierte Umgebung entschieden. Diese Integration setzt die Optionen fort, die mit dem Gast in der Cloud verbunden sind, sowie die Integration von aktuellen NFS-Datenspeichern. Die Lösung konzentriert sich auf den Anwendungsfall, der als Gast-vernetzter Storage bezeichnet wird.</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">Im mit dem Gast verbundenen Storage wird die Gast-VMDK auf einem von VMware bereitgestellten Datastore bereitgestellt und die Applikationsdaten werden auf iSCSI oder NFS gespeichert und direkt der VM zugeordnet. Oracle und MS SQL Applikationen werden verwendet, um ein DR-Szenario zu demonstrieren, wie in der folgenden Abbildung dargestellt.</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">NetApp Funktionen für AWS VMC</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">Erfahren Sie mehr über die Funktionen, die NetApp für die AWS VMware Cloud (VMC) zur Verfügung stellt – von NetApp als Storage-Gerät mit Gastverbunden oder als zusätzlicher NFS-Datastore für die Migration von Workflows, Erweiterung/Bursting in die Cloud, Backup/Wiederherstellung und Disaster Recovery.</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="inline-link-macro">Konfiguration von VMC in AWS</block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="inline-link-macro">NetApp Storage-Optionen für VMC</block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">Details anzeigen <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>.</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">NetApp Storage kann innerhalb der AWS VMC auf verschiedene Arten genutzt werden – entweder als angebundenen oder als zusätzlicher NFS-Datenspeicher.</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">Details anzeigen <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>. Details anzeigen <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>.</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">Mit Cloud-Lösungen von NetApp und VMware sind viele Anwendungsfälle einfach in AWS VMC zu implementieren. Anwendungsfälle sind für jeden der von VMware definierten Cloud-Bereiche definiert:</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">NetApp Lösungen für AWS VMC</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">Implementieren und Konfigurieren der Virtualisierungsumgebung auf AWS</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">Wie auch bei lokalen Systemen ist die Planung von VMware Cloud auf AWS von entscheidender Bedeutung für eine erfolgreiche produktionsbereite Umgebung zur Erstellung von VMs und Migration.</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">Im-Gast-Storage ist derzeit die einzige unterstützte Methode zur Verbindung von Cloud Volumes ONTAP (CVO) mit AWS VMC.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="example-title">Implementieren und Konfigurieren von VMware Cloud for AWS</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> Für VMware-basierte Workloads im AWS Ecosystem bietet es ein Cloud-natives Arbeiten. Jedes softwaredefinierte VMware Datacenter (SDDC) wird in einer Amazon Virtual Private Cloud (VPC) ausgeführt und bietet einen vollständigen VMware Stack (einschließlich vCenter Server), softwaredefiniertes NSX-T Networking, softwaredefinierten vSAN Storage sowie einen oder mehrere ESXi Hosts, die Computing- und Storage-Ressourcen für Ihre Workloads bereitstellen.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">In diesem Abschnitt wird beschrieben, wie Sie VMware Cloud auf AWS einrichten und managen und in Kombination mit Amazon FSX für NetApp ONTAP und/oder Cloud Volumes ONTAP auf AWS mit in-Guest Storage verwenden.</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">Für ein AWS Konto registrieren</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Amazon Web Services Konto</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="paragraph">Für ein registrieren <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">Sie brauchen ein AWS-Konto, um zu beginnen, vorausgesetzt, es gibt nicht bereits erstellt. Neu oder bereits vorhanden, Sie benötigen Administratorrechte im Konto für viele Schritte in diesem Verfahren. Siehe das <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> Weitere Informationen zu AWS Zugangsdaten.</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">Für einen My VMware Account registrieren</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">Meine VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="paragraph">Für A registrieren <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> Konto.</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">Für den Zugriff auf das Cloud-Portfolio von VMware (einschließlich VMware Cloud auf AWS) benötigen Sie ein VMware-Kundenkonto oder ein My VMware-Konto. Falls noch nicht geschehen, erstellen Sie ein VMware-Konto <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="example-title">Bereitstellung von SDDC in VMware Cloud</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">Nach der Konfiguration des VMware Kontos und der ordnungsgemäßen Größenbestimmung ist die Implementierung eines softwaredefinierten Datacenters der nächste Schritt auf dem Weg zur Nutzung des VMware Cloud auf AWS Service. Wenn Sie ein SDDC erstellen möchten, wählen Sie eine AWS Region zum Hosten aus, geben Sie dem SDDC einen Namen und legen Sie fest, wie viele ESXi Hosts das SDDC enthalten soll. Wenn Sie noch kein AWS Konto haben, können Sie dennoch ein SDDC mit einer Starterkonfiguration erstellen, das einen einzelnen ESXi Host enthält.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">Melden Sie sich mit Ihren vorhandenen oder neu erstellten VMware Zugangsdaten bei der VMware Cloud Console an.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">Konfigurieren Sie die AWS Region, die Implementierung und den Host-Typ sowie den SDDC-Namen:</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">Stellen Sie eine Verbindung mit dem gewünschten AWS Konto her und führen Sie den AWS Cloud-Formationstack aus.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">In dieser Validierung wird Single-Host-Konfiguration verwendet.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">Wählen Sie die gewünschte AWS VPC aus, mit der die VMC-Umgebung verbunden werden soll.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">VMC-Managementsubnetz konfigurieren: Dieses Subnetz enthält von VMC gemanagte Services wie vCenter, NSX usw. Wählen Sie keinen überlappenden Adressraum mit anderen Netzwerken, die Verbindung zur SDDC-Umgebung benötigen. Folgen Sie abschließend den unten aufgeführten Empfehlungen für CIDR-Größe.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">Prüfen und bestätigen Sie die SDDC-Konfiguration und klicken Sie dann auf Bereitstellen des SDDC.</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">Die Implementierung dauert normalerweise etwa zwei Stunden.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">Nach Abschluss der Fertigstellung ist das SDDC einsatzbereit.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">Implementieren Sie ein SDDC über die VMC-Konsole</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">Einen Schritt-für-Schritt-Leitfaden zur SDDC-Implementierung finden Sie unter <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">So verbinden Sie VMware Cloud mit FSX ONTAP:</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">Wenn die VMware Cloud Implementierung abgeschlossen und mit AWS VPC verbunden ist, müssen Sie Amazon FSX für NetApp ONTAP in ein neues VPC anstatt in der mit der Integration verbundenen VPC implementieren (siehe Abbildung unten). FSX (NFS- und SMB-fließende IPs) ist nicht zugänglich, wenn sie in der verbundenen VPC implementiert werden. ISCSI-Endpunkte wie Cloud Volumes ONTAP funktionieren genauso gut wie die verbundene VPC.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">Eine zusätzliche VPC in derselben Region implementieren und dann Amazon FSX für NetApp ONTAP in die neue VPC implementieren.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">Die Konfiguration einer SDDC-Gruppe in der VMware Cloud Konsole ermöglicht die erforderlichen Netzwerkkonfigurationsoptionen für die Verbindung zur neuen VPC, bei der FSX implementiert wird. Überprüfen Sie in Schritt 3, ob „VMware Transit Connect für Ihre Gruppe konfigurieren“ Gebühren pro Anlage und Datenübertragung anfällt und wählen Sie „Gruppe erstellen“. Dieser Vorgang kann einige Minuten dauern.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">Anweisungen zum Anschließen eines externen VPC</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">Binden Sie die neu erstellte VPC an die gerade erstellte SDDC-Gruppe. Wählen Sie die Registerkarte External VPC aus, und folgen Sie der <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> Für die Gruppe. Dieser Vorgang kann 10 bis 15 Minuten in Anspruch nehmen.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS Transit Gateway</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">Im Rahmen des externen VPC-Prozesses werden Sie über die AWS-Konsole zu einer neuen, gemeinsam genutzten Ressource über den Resource Access Manager aufgefordert. Die gemeinsam genutzte Ressource ist die <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> Management über VMware Transit Connect</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Erstellen Sie den Transit Gateway-Anhang.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">Nehmen Sie wieder an der VMC-Konsole die VPC-Anlage an. Dieser Vorgang dauert etwa 10 Minuten.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">Klicken Sie auf der Registerkarte External VPC auf das Bearbeiten-Symbol in der Spalte Routen und fügen Sie die folgenden erforderlichen Routen hinzu:</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">Fließende IPs</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">Eine Route für den unverankerten IP-Bereich für Amazon FSX für NetApp ONTAP <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Eine Route für den unverankerten IP-Bereich für Cloud Volumes ONTAP (falls zutreffend).</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">Eine Route für den neu erstellten externen VPC-Adressraum.</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">Firewall-Regeln</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">Detaillierte Schritte</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">Außerdem bidirektionalen Datenverkehr zulassen <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> Für den Zugriff auf FSX/CVO. Befolgen Sie diese <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> Für die Firewall des Computing-Gateways für die SDDC-Workload-Konnektivität.</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">Nachdem die Firewall-Gruppen sowohl für das Management- als auch für das Computing-Gateway konfiguriert wurden, ist der Zugriff auf vCenter wie folgt möglich:</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">Als nächsten Schritt müssen Sie überprüfen, ob Amazon FSX ONTAP oder Cloud Volumes ONTAP je nach Ihren Anforderungen konfiguriert ist und dass die Volumes bereitgestellt werden, um Storage-Komponenten aus vSAN auszulagern, um die Implementierung zu optimieren.</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">Regionale Verfügbarkeit – ergänzender NFS-Datenspeicher für VMC</block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">Zusätzliche NFS-Datastore-Option in AWS</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">Nachdem VMware Cloud bereit und mit AWS VPC verbunden ist, muss Amazon FSX für NetApp ONTAP in einer neu festgelegten VPC implementiert werden, nicht jedoch in der ursprünglichen verbundenen oder vorhandenen Standard-VPC.</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">Konfiguration einer SDDC-Gruppe in der VMware Cloud</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">Um zu beginnen, implementieren Sie eine zusätzliche VPC in derselben Region und Verfügbarkeitszone, in der sich SDDC befindet, und implementieren Sie dann Amazon FSX für NetApp ONTAP in die neue VPC.<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> Konsole ermöglicht die Netzwerkkonfigurationsoptionen, die erforderlich sind, um eine Verbindung zur neu benannten VPC herzustellen, in der FSX für ONTAP implementiert wird.</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">FSX für ONTAP wird in derselben verfügbaren Zone wie VMware Cloud auf AWS SDDC implementiert.</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">FSX für ONTAP kann nicht in der verbundenen VPC bereitgestellt werden. Stattdessen müssen Sie sie in einem neuen, benannten VPC bereitstellen und dann die VPC über SDDC-Gruppen mit einem VMware Managed Transit Gateway (vTGW) verbinden.</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">Schritt 1: Amazon FSX für ONTAP in einer neuen, designierten VPC erstellen</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">So erstellen und mounten Sie das Filesystem Amazon FSX für NetApp ONTAP:</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">Öffnen Sie die Amazon FSX-Konsole bei<block ref="3cac88c5e8406527329e138d581346fe" prefix=" " category="inline-code"></block> Und wählen Sie *Create file System*, um den Assistenten *File System Creation* zu starten.</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">Wählen Sie auf der Seite Select File System Type *Amazon FSX for NetApp ONTAP* aus und klicken Sie dann auf *Weiter*. Die Seite *Create File System* wird angezeigt.</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">Wählen Sie für die Erstellungsmethode *Standard Erstellen*.</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">Die Datenspeichergrößen variieren stark vom Kunden zum Kunden. Obwohl die empfohlene Anzahl an Virtual Machines pro NFS-Datenspeicher subjektiv ist, bestimmen viele Faktoren die optimale Anzahl von VMs, die auf den jeweiligen Datenspeicher platziert werden kann. Obwohl die meisten Administratoren nur die Kapazität berücksichtigen, ist die Menge der gleichzeitigen I/O-Vorgänge, die an die VMDKs gesendet werden, einer der wichtigsten Faktoren für die Gesamt-Performance. Verwenden Sie Performance-Statistiken von On-Premises, um die Größe der Datastore Volumes entsprechend festzulegen.</block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">Wählen Sie im Abschnitt *Networking* für Virtual Private Cloud (VPC) die entsprechenden VPC und die bevorzugten Subnetze zusammen mit der Routing-Tabelle aus. In diesem Fall wird Demo- FSxforONTAP-VPC aus dem Dropdown-Menü ausgewählt.</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">Stellen Sie sicher, dass es sich um eine neue, festgelegte VPC und nicht um die verbundene VPC handelt.</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">FSX für ONTAP verwendet standardmäßig 198.19.0.0/16 als Standard-IP-Adressbereich für Endpunktgeräte für das Dateisystem. Stellen Sie sicher, dass der Endpunkt-IP-Adressbereich nicht mit der VMC auf dem AWS SDDC, den zugehörigen VPC-Subnetzen und der On-Premises-Infrastruktur in Konflikt steht. Wenn Sie sich nicht sicher sind, verwenden Sie einen nicht überlappenden Bereich ohne Konflikte.</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">Wählen Sie im Abschnitt *Sicherheit &amp; Verschlüsselung* für den Verschlüsselungsschlüssel den AWS KMS-Verschlüsselungsschlüssel (Key Management Service) aus, der die Daten des Filesystems im Ruhezustand schützt. Geben Sie für das Verwaltungspasswort *Dateisystem* ein sicheres Kennwort für den Benutzer fsxadmin ein.</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">Geben Sie im Abschnitt *Default Storage Virtual Machine Configuration* den Namen der SVM an.</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">Ab GA werden vier NFS-Datastores unterstützt.</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">Geben Sie im Abschnitt *Standard-Volume-Konfiguration* den für den Datastore erforderlichen Volume-Namen und die Größe an und klicken Sie auf *Weiter*. Dies sollte ein NFSv3 Volume sein. Wählen Sie für *Storage-Effizienz* *aktiviert*, um die ONTAP Storage-Effizienzfunktionen (Komprimierung, Deduplizierung und Data-Compaction) zu aktivieren. Verwenden Sie nach der Erstellung die Shell, um die Volume-Parameter mit *_Volume modify_* wie folgt zu ändern:</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Einstellung</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">Volume-Garantie (Space Guarantee-Stil)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">Keine (Thin Provisioning): Standardmäßig festgelegt</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">Fraktionale_Reserve (fractional-Reserve)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0% – Standardeinstellung</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">Snap_Reserve (Prozent-Snapshot-Platz)</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0 %</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">AutoSize (Autosize-Modus)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Aktiviert – standardmäßig festgelegt</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">Automatisches Löschen</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">Volume / älteste_First</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">Volume Tiering Policy</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Nur Snapshot – standardmäßig festgelegt</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">Versuchen Sie es zuerst</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">Autogrow</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">Snapshot-Richtlinie</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">Verwenden Sie den folgenden SSH-Befehl zum Erstellen und Ändern von Volumes:</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*Befehl zum Erstellen eines neuen Datastore Volumes aus Shell:*</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*Hinweis:* die über Shell erstellten Volumes werden in wenigen Minuten in der AWS-Konsole angezeigt.</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*Befehl zum Ändern von Volume-Parametern, die nicht standardmäßig eingestellt sind:*</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">Bei einem anfänglichen Migrationsszenario kann die standardmäßige Snapshot-Richtlinie zu vollständigen Problemen mit der Datastore-Kapazität führen. Um sie zu überwinden, ändern Sie die Snapshot-Richtlinie entsprechend den Anforderungen.</block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">Überprüfen Sie die Konfiguration des Dateisystems, die auf der Seite *Create File System* angezeigt wird.</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">Klicken Sie Auf *Dateisystem Erstellen*.</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">Wiederholen Sie die vorherigen Schritte, um mehr Storage-Virtual Machines oder -Dateisysteme und die Datastore-Volumes entsprechend den Kapazitäts- und Performance-Anforderungen zu erstellen.</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link">Amazon FSX für die Performance von NetApp ONTAP</block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">Weitere Informationen zur Performance von ONTAP finden Sie unter Amazon FSX<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>.</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">Schritt: SDDC-Gruppe erstellen</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">Nach der Erstellung der Dateisysteme und SVMs erstellen Sie mit VMware Console eine SDDC-Gruppe und konfigurieren VMware Transit Connect. Dazu gehen Sie die folgenden Schritte aus und vergessen Sie nicht, dass Sie zwischen der VMware Cloud Console und der AWS Console navigieren müssen.</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">Melden Sie sich an der VMC-Konsole unter an<block ref="80524a1862c565bfe10233035e45c5b3" prefix=" " category="inline-code"></block>.</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">Klicken Sie auf der Seite *Inventory* auf *SDDC Groups*.</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">Klicken Sie auf der Registerkarte *SDDC-Gruppen* auf *AKTIONEN* und wählen Sie *SDDC-Gruppe erstellen*. Aus Demo-Gründen wird die SDDC-Gruppe genannt<block ref="a34cf36b08316aadda6e1c15679a89f8" prefix=" " category="inline-code"></block>.</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">Wählen Sie im Raster Mitgliedschaft die SDDCs aus, die als Gruppenmitglieder aufgenommen werden sollen.</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">Überprüfen Sie, ob „VMware Transit Connect für Ihre Gruppe konfigurieren“ Gebühren pro Anlage und Datenübertragung anfällt. Wählen Sie dann *Gruppe erstellen*. Dieser Vorgang kann einige Minuten dauern.</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">Schritt 3: VMware Transit connect konfigurieren</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">Anweisungen zum Anschließen einer externen VPC an die Gruppe</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">Hängen Sie die neu erstellte festgelegte VPC der SDDC-Gruppe an. Wählen Sie die Registerkarte *External VPC* aus und folgen Sie der<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>. Dieser Vorgang kann 10-15 Minuten dauern.</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">Klicken Sie Auf *Konto Hinzufügen*.</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">Geben Sie das AWS Konto an, über das das FSX für ONTAP Filesystem bereitgestellt wurde.</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">Klicken Sie Auf *Hinzufügen*.</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">Melden Sie sich wieder in der AWS-Konsole bei demselben AWS-Konto an und navigieren Sie zur Service-Seite *Resource Access Manager*. Es gibt eine Schaltfläche, mit der Sie die Ressourcenfreigabe akzeptieren können.</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">Im Rahmen des externen VPC-Prozesses werden Sie über die AWS-Konsole zu einer neuen, gemeinsam genutzten Ressource über den Resource Access Manager aufgefordert. Die gemeinsam genutzte Ressource ist das AWS Transit Gateway, das von VMware Transit Connect verwaltet wird.</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">Klicken Sie auf *Ressourcenfreigabe akzeptieren*.</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">Wieder in der VMC-Konsole sehen Sie jetzt, dass die externe VPC in einem zugehörigen Zustand ist. Das kann einige Minuten dauern.</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">Schritt 4: Anlage des Transit-Gateway-Anhangs erstellen</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">Wechseln Sie in der AWS Konsole zur VPC-Service-Seite und zur VPC, die für die Bereitstellung des FSX-Filesystems verwendet wurde. Hier erstellen Sie einen Transit Gateway-Anhang, indem Sie im Navigationsfenster rechts auf *Transit Gateway Attachment* klicken.</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">Stellen Sie unter *VPC-Anhang* sicher, dass DNS-Support geprüft wird, und wählen Sie die VPC aus, in der FSX für ONTAP bereitgestellt wurde.</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">Klicken Sie auf *Erstellen* *Transit Gateway-Anlage*.</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">Zurück in der VMware Cloud Console, navigieren Sie zurück zur Registerkarte SDDC Group &gt; External VPC. Wählen Sie die AWS Konto-ID für FSX aus, und klicken Sie auf die VPC und dann auf *Akzeptieren*.</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">Diese Option kann einige Minuten dauern, bis sie angezeigt wird.</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">Klicken Sie dann auf der Registerkarte *External VPC* in der Spalte *Routen* auf die Option *Routen hinzufügen* und fügen Sie die gewünschten Routen hinzu:</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">Route für den unverankerten IP-Bereich für Amazon FSX für NetApp ONTAP Floating IPs.</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">Schritt 5: Routing (AWS VPC und SDDC) und Sicherheitsgruppen konfigurieren</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">Erstellen Sie in der AWS Konsole die Route zurück zum SDDC, indem Sie die VPC auf der VPC-Service-Seite lokalisieren und die Routing-Tabelle *main* für die VPC auswählen.</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">Navigieren Sie zur Routentabelle im unteren Bereich und klicken Sie auf *Routen bearbeiten*.</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">Klicken Sie im Fenster *Routen bearbeiten* auf *Route hinzufügen* und geben Sie die CIDR für die SDDC-Infrastruktur ein, indem Sie *Transit Gateway* und die zugehörige TGW-ID auswählen. Klicken Sie auf *Änderungen speichern*.</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">Als nächsten Schritt müssen Sie überprüfen, ob die Sicherheitsgruppe in der zugeordneten VPC mit den richtigen eingehenden Regeln für das CIDR der SDDC-Gruppe aktualisiert wird.</block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="list-text">Aktualisieren Sie die eingehende Regel mit dem CIDR-Block der SDDC-Infrastruktur.</block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">Überprüfen Sie, ob die Routing-Tabelle VPC (wo sich FSX für ONTAP befindet) aktualisiert wird, um Konnektivitätsprobleme zu vermeiden.</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">Aktualisieren Sie die Sicherheitsgruppe, um NFS-Datenverkehr zu akzeptieren.</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">Dies ist der letzte Schritt bei der Vorbereitung der Verbindung zum entsprechenden SDDC. Wenn das Dateisystem konfiguriert, Routen hinzugefügt und Sicherheitsgruppen aktualisiert wird, ist es an der Zeit, die Datenspeicher zu mounten.</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">Schritt 6: NFS-Volume als Datenspeicher an SDDC Cluster anhängen</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">Nachdem das Filesystem bereitgestellt und die Konnektivität vorhanden ist, greifen Sie auf VMware Cloud Console zu, um den NFS-Datastore zu mounten.</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">Öffnen Sie in der VMC-Konsole die Registerkarte *Storage* des SDDC.</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">Klicken Sie auf *DATASTORE ANHÄNGEN* und geben Sie die erforderlichen Werte ein.</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">Die NFS-Server-Adresse ist die NFS IP-Adresse, die unter der Registerkarte FSX &gt; Storage Virtual Machines &gt; Endpunkte in der AWS Konsole zu finden ist.</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">Klicken Sie auf *DATASTORE ANHÄNGEN*, um den Datenspeicher an den Cluster anzuhängen.</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">Validieren Sie den NFS-Datenspeicher durch Zugriff auf vCenter wie unten gezeigt:</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="498fdd311192093265ba745435fc1476" category="doc">Bereitstellung und Konfiguration von Veeam Backup Server</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Technische Dokumentation des Veeam Help Center</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">Veeam Backup &amp; Replication Software verwendet in dieser Lösung das Backup unserer Virtual Machines für Applikationen und die Archivierung einer Kopie der Backups in einem Amazon S3 Bucket mithilfe eines Veeam Scale-Out-Backup-Repositorys (SOBR). Veeam wird auf einem Windows-Server in dieser Lösung implementiert. Eine Anleitung zur Implementierung von Veeam finden Sie im<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>.</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="section-title">Veeam Scale-out-Backup-Repository konfigurieren</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">Nachdem Sie die Software implementiert und lizenziert haben, können Sie ein Scale-out Backup Repository (SOBR) als Ziel-Storage für Backup-Jobs erstellen. Außerdem sollten Sie einen S3-Bucket als Backup von VM-Daten für die Disaster Recovery extern berücksichtigen.</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">Lesen Sie die folgenden Voraussetzungen, bevor Sie beginnen.</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">Erstellen einer SMB-Dateifreigabe auf Ihrem lokalen ONTAP System als Ziel-Storage für Backups</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">Erstellen eines Amazon S3-Buckets, der in den SOBR aufgenommen werden soll Es handelt sich um ein Repository für die externen Backups.</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="section-title">Fügen Sie ONTAP Storage zu Veeam hinzu</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">Zunächst fügen Sie den ONTAP Storage-Cluster und das zugehörige SMB/NFS-Dateisystem als Storage-Infrastruktur in Veeam hinzu.</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Öffnen Sie die Veeam-Konsole, und melden Sie sich an. Navigieren Sie zu Storage Infrastructure, und wählen Sie Add Storage aus.</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">Wählen Sie im Assistenten zum Hinzufügen von Storage NetApp als Storage-Anbieter aus, und wählen Sie dann Data ONTAP aus.</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">Geben Sie die Management-IP-Adresse ein und aktivieren Sie das Kontrollkästchen NAS-Filer. Klicken Sie Auf Weiter.</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">Fügen Sie Ihre Zugangsdaten ein, um auf das ONTAP Cluster zuzugreifen.</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">Wählen Sie auf der Seite NAS Filer die gewünschten Protokolle zum Scannen aus und wählen Sie Weiter.</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">Schließen Sie die Seiten „Übernehmen“ und „Zusammenfassung“ des Assistenten ab, und klicken Sie auf „Fertig stellen“, um den Speicherermittlungsprozess zu starten. Nach Abschluss des Scans wird das ONTAP-Cluster zusammen mit den NAS-Filern als verfügbare Ressourcen hinzugefügt.</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">Erstellen Sie ein Backup-Repository mithilfe der neu erkannten NAS-Freigaben. Wählen Sie in Backup Infrastructure die Option Backup Repositories aus, und klicken Sie auf das Menüelement Add Repository.</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Veeam-Dokumentation</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">Führen Sie alle Schritte im Assistenten für das Neue Backup-Repository aus, um das Repository zu erstellen. Detaillierte Informationen zum Erstellen von Veeam Backup Repositorys finden Sie im<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>.</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="section-title">Fügen Sie den Amazon S3-Bucket als Backup-Repository hinzu</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">Im nächsten Schritt wird der Amazon S3-Storage als Backup-Repository hinzugefügt.</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">Navigieren Sie zu Backup Infrastructure &gt; Backup Repositorys. Klicken Sie Auf Repository Hinzufügen.</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">Wählen Sie im Assistenten zum Hinzufügen von Backup-Repositorys Objekt-Storage und anschließend Amazon S3 aus. Daraufhin wird der Assistent für das Neue Objekt-Speicher-Repository gestartet.</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">Geben Sie einen Namen für das Objekt-Storage-Repository an, und klicken Sie auf Weiter.</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">Geben Sie im nächsten Abschnitt Ihre Anmeldedaten ein. Sie benötigen einen AWS-Zugriffsschlüssel und einen geheimen Schlüssel.</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Wählen Sie nach dem Laden der Amazon Konfiguration Ihr Datacenter, Ihren Bucket und den Ordner aus und klicken Sie auf Anwenden. Klicken Sie abschließend auf Fertig stellen, um den Assistenten zu schließen.</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="section-title">Scale-out-Backup-Repository erstellen</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">Nachdem wir jetzt unsere Storage Repositorys zu Veeam hinzugefügt haben, können wir das SOBR erstellen, um Backup-Kopien automatisch in unseren externen Amazon S3 Objekt-Storage zu Disaster Recovery-Zwecken zu verschieben.</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">Wählen Sie in Backup Infrastructure die Option Scale-Out Repositorys aus, und klicken Sie dann auf das Menüelement Scale-Out Repository hinzufügen.</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">Geben Sie im neuen Scale-Out Backup Repository einen Namen für den SOBR ein, und klicken Sie auf Weiter.</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">Wählen Sie für die Performance-Ebene das Backup-Repository mit der SMB-Freigabe in Ihrem lokalen ONTAP Cluster aus.</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">Wählen Sie für die Richtlinie zur Platzierung entweder Data Locality oder Performance basierend auf Ihren Anforderungen aus. Wählen Sie weiter.</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">Für Kapazitäts-Tiers erweitern wir den SOBR auf Amazon S3 Objekt-Storage. Für Disaster Recovery wählen Sie „Copy Backups to Object Storage“, sobald sie erstellt werden, um unsere sekundären Backups rechtzeitig bereitzustellen.</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">Wählen Sie schließlich Übernehmen und Beenden, um die Erstellung des SOBR abzuschließen.</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="section-title">Erstellen Sie die Scale-out-Backup-Repository-Jobs</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Technische Dokumentation Des Veeam Help Center</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">Der letzte Schritt zur Konfiguration von Veeam ist die Erstellung von Backup-Jobs anhand des neu erstellten SOBR als Backup-Ziel. Das Erstellen von Backupjobs ist ein normaler Teil des Repertoires eines Speicheradministrators und wir decken die einzelnen Schritte hier nicht ab. Nähere Informationen zum Erstellen von Backup-Jobs in Veeam finden Sie auf der<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="doc">Wiederherstellung von Applikations-VMs mit vollständiger Veeam-Wiederherstellung</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="section-title">Backup-Repository erstellen und Backups aus S3 importieren</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">Importieren Sie vom sekundären Veeam-Server die Backups aus S3 Storage und stellen Sie SQL Server und Oracle VMs in Ihr VMware Cloud-Cluster wieder her.</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">So importieren Sie die Backups aus dem S3-Objekt, das Teil des Scale-out-Backup-Repositorys vor Ort war:</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">Gehen Sie zu Backup Repositories und klicken Sie im oberen Menü auf Repository hinzufügen, um den Assistenten zum Hinzufügen von Backup-Repositorys zu starten. Wählen Sie auf der ersten Seite des Assistenten als Backup-Repository-Typ Objekt-Storage aus.</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">Wählen Sie Amazon S3 als Objektspeichertyp aus.</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">Wählen Sie aus der Liste der Amazon Cloud Storage Services Amazon S3 aus.</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">Wählen Sie Ihre voreingegebenen Anmeldedaten aus der Dropdown-Liste aus, oder fügen Sie neue Anmeldedaten für den Zugriff auf die Cloud-Speicherressource hinzu. Klicken Sie auf Weiter, um fortzufahren.</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">Geben Sie auf der Bucket-Seite Datacenter, Bucket, Ordner und gewünschte Optionen ein. Klicken Sie Auf Anwenden.</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">Wählen Sie abschließend Fertigstellen aus, um den Prozess abzuschließen und das Repository hinzuzufügen.</block>
  <block id="076951b7756435f95654310ef960f866" category="section-title">Backups aus S3 Objekt-Storage importieren</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">Führen Sie die folgenden Schritte aus, um die Backups aus dem S3-Repository zu importieren, das im vorherigen Abschnitt hinzugefügt wurde.</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">Wählen Sie aus dem S3-Backup-Repository die Option Backups importieren aus, um den Assistenten zum Importieren von Backups zu starten.</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">Nachdem die Datenbankdatensätze für den Import erstellt wurden, wählen Sie Weiter und dann auf dem Übersichtsbildschirm Beenden, um den Importvorgang zu starten.</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">Nach Abschluss des Imports können Sie die VMs in das VMware Cloud Cluster wiederherstellen.</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="section-title">Wiederherstellung von Applikations-VMs mit vollständiger Wiederherstellung durch Veeam in VMware Cloud</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">Um SQL und Oracle Virtual Machines in VMware Cloud auf AWS Workload Domain/Cluster wiederherzustellen, führen Sie die folgenden Schritte aus.</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">Wählen Sie auf der Veeam-Startseite den Objektspeicher aus, der die importierten Backups enthält, wählen Sie die wiederherzustellenden VMs aus, und klicken Sie dann mit der rechten Maustaste, und wählen Sie die Option gesamte VM wiederherstellen aus.</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">Ändern Sie auf der ersten Seite des Assistenten zur vollständigen VM-Wiederherstellung die VMs, die gesichert werden sollen, falls gewünscht, und wählen Sie Weiter.</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">Wählen Sie auf der Seite Wiederherstellungsmodus die Option Wiederherstellen an einem neuen Speicherort oder mit anderen Einstellungen.</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">Wählen Sie auf der Host-Seite den Ziel-ESXi-Host oder das Ziel-Cluster aus, auf dem die VM wiederhergestellt werden soll.</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">Wählen Sie auf der Seite Datastores den Speicherort des Ziel-Datenspeichers für die Konfigurationsdateien und die Festplatte aus.</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">Ordnen Sie auf der Seite Netzwerk die ursprünglichen Netzwerke auf der VM den Netzwerken im neuen Zielverzeichnis zu.</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">Wählen Sie aus, ob die wiederhergestellte VM nach Malware gescannt werden soll, überprüfen Sie die Übersichtsseite, und klicken Sie auf Fertig stellen, um die Wiederherstellung zu starten.</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="summary">Für das Failover unserer Applikations-VMs und Datenbank-Volumes auf VMware Cloud Volume Services unter AWS musste eine laufende Instanz von SnapCenter Server sowie Veeam Backup and Replication Server installiert und konfiguriert werden. Nach Abschluss des Failover müssen diese Tools auch so konfiguriert werden, dass sie den normalen Backup-Betrieb fortsetzen, bis ein Failback zum lokalen Datacenter geplant und ausgeführt wird.</block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="doc">Cloud-Backup-Tools</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="section-title">Implementierung von Backup-Tools</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">Der SnapCenter-Server und der Veeam Backup &amp; Replication Server können im VMware Cloud SDDC installiert werden oder auf EC2 Instanzen in einer VPC mit Netzwerkkonnektivität zur VMware Cloud Umgebung installiert werden.</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="section-title">SnapCenter Server</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">NetApp Dokumentationszentrum</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">Die SnapCenter Software ist über die NetApp Support Site erhältlich und kann auf Microsoft Windows Systemen installiert werden, die sich entweder in einer Domäne oder einer Arbeitsgruppe befinden. Ein detaillierter Planungsleitfaden und Installationsanweisungen finden Sie unter <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>.</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">Die Software von SnapCenter finden Sie unter<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">Sie können den Veeam Backup &amp; Replication Server auf einem Windows-Server in VMware Cloud auf AWS oder einer EC2-Instanz installieren. Eine detaillierte Anleitung zur Implementierung finden Sie im<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="section-title">Backup-Tools und -Konfiguration</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">Nach der Installation müssen SnapCenter und Veeam Backup &amp; Replication konfiguriert werden, um die notwendigen Aufgaben zur Wiederherstellung von Daten in VMware Cloud auf AWS auszuführen.</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="section-title">SnapCenter-Konfiguration</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">Zum Wiederherstellen von Applikationsdaten, die auf FSX ONTAP gespiegelt wurden, müssen Sie zuerst eine vollständige Wiederherstellung der lokalen SnapCenter-Datenbank durchführen. Nach Abschluss dieses Prozesses wird die Kommunikation mit den VMs wieder hergestellt, und Backups von Applikationen können nun mithilfe von FSX ONTAP als Primärspeicher wieder aufgenommen werden.</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">Implementieren Sie sekundären Windows SnapCenter-Server</block>
  <block id="520d23cd5df8582645ee42124b69ccae" category="paragraph">Eine Liste der Schritte, die auf dem SnapCenter-Server in AWS ausgefüllt werden sollen, finden Sie im Abschnitt <block ref="a29fcfa081b59708af69951be417dc25" category="inline-link-macro-rx"></block>.</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Zum Wiederherstellen von Virtual Machines, die auf Amazon S3 Storage gesichert wurden, muss Veeam Server auf einem Windows-Server installiert und für die Kommunikation mit VMware Cloud, FSX ONTAP und dem S3-Bucket konfiguriert werden, der das ursprüngliche Backup-Repository enthält. Darüber hinaus muss auf FSX ONTAP ein neues Backup Repository konfiguriert werden, um nach der Wiederherstellung neue Backups der VMs durchzuführen.</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">Bereitstellung sekundärer Veeam Backup &amp; Amp; Replication Server</block>
  <block id="82a8a7d9b8f053ce73af1c1b5b8694ff" category="paragraph">Eine vollständige Liste der Schritte, die zum vollständigen Failover der Applikations-VMs erforderlich sind, finden Sie im Abschnitt <block ref="83d03cb08c05a76f36dedd6b85344746" category="inline-link-macro-rx"></block>.</block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="summary">Der in dieser Dokumentation vorgestellte Anwendungsfall konzentriert sich auf bewährte Disaster-Recovery-Technologien, die die Integration von NetApp und VMware hervorheben. NetApp ONTAP Storage-Systeme bieten bewährte Technologien zur Datenspiegelung. Damit können Unternehmen Disaster-Recovery-Lösungen entwerfen, die sich sowohl vor Ort als auch ONTAP Technologien in Verbindung mit den führenden Cloud-Providern befinden.</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">FSX für ONTAP auf AWS ermöglicht eine nahtlose Integration in SnapCenter und SyncMirror zur Replizierung von Applikationsdaten in die Cloud. Veeam Backup &amp; Replication ist eine weitere bekannte Technologie, die sich gut in NetApp ONTAP Storage-Systeme integrieren lässt und Failover auf nativen vSphere Storage bietet.</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">Diese Lösung stellte eine Disaster-Recovery-Lösung dar, bei der Storage von einem ONTAP-System, das SQL Server und Oracle-Applikationsdaten hostet, verwendet wurde. SnapCenter mit SnapMirror ist eine benutzerfreundliche Lösung für den Schutz von Applikations-Volumes auf ONTAP Systemen und die Replizierung auf FSX oder CVO in der Cloud. SnapCenter ist eine DR-fähige Lösung für den Failover aller Applikationsdaten zu VMware Cloud auf AWS.</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">Links zur Lösungsdokumentation</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">Sobald der in dieser Lösung beschriebene Failover-Prozess erfolgreich abgeschlossen ist, setzen SnapCenter und Veeam ihre Backup-Funktionen in AWS wieder ein. FSX für ONTAP ist jetzt als primärer Storage vorgesehen und keine bestehenden SnapMirror Beziehungen zum ursprünglichen lokalen Datacenter vorhanden. Nachdem die normale Funktion wieder aufgenommen wurde, können Daten mit einem Prozess wie in dieser Dokumentation beschrieben in das lokale ONTAP Storage-System gespiegelt werden.</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">Wie in dieser Dokumentation auch dargestellt, können Sie SnapCenter so konfigurieren, dass die Applikationsdaten-Volumes von FSX für ONTAP auf ein ONTAP Storage-System vor Ort gespiegelt werden. Ähnlich lässt sich Veeam für die Replizierung von Backup-Kopien in Amazon S3 konfigurieren. Dazu wird ein Scale-out-Backup-Repository verwendet, damit diese Backups einem Veeam Backup-Server im lokalen Datacenter zugänglich sind.</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">Failback liegt außerhalb des Umfangs dieser Dokumentation, aber Failback unterscheidet sich wenig von dem hier beschriebenen Prozess.</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">NetApp Guest Connected Storage-Optionen für AWS</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS unterstützt NetApp Storage mit Anbindung an Gäste über den nativen FSX-Service (FSX ONTAP) oder über Cloud Volumes ONTAP (CVO).</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">FSX ONTAP</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX für NetApp ONTAP ist ein vollständig gemanagter Service, der zuverlässigen, skalierbaren, hochperformanten und funktionsreichen File Storage auf der Basis des beliebten ONTAP Filesystems von NetApp bietet. FSX für ONTAP kombiniert die bekannten Funktionen, Performance, Funktionen und API-Vorgänge von NetApp Filesystemen mit der Agilität, Skalierbarkeit und Einfachheit eines vollständig gemanagten AWS Service.</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX für ONTAP bietet funktionsreichen, schnellen und flexiblen Shared-File-Storage, der weit über Linux-, Windows- und macOS-Computing-Instanzen zugänglich ist, die in AWS oder vor Ort ausgeführt werden. FSX für ONTAP bietet hochperformanten SSD-Storage (Solid State Drive) mit Latenzzeiten von unter einer Millisekunde. Mit FSX für ONTAP können Sie SSD-Performance-Level für Ihre Workloads erzielen und gleichzeitig die Kosten für SSD-Storage mit nur einem Bruchteil Ihrer Daten bezahlen.</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">Das Datenmanagement mit FSX für ONTAP gestaltet sich einfacher, da Sie Ihre Dateien mit nur einem Mausklick erstellen, klonen und replizieren können. Außerdem führt FSX für ONTAP automatisch ein Tiering Ihrer Daten auf kostengünstigeren, elastischen Storage durch. Dadurch reduzieren Sie die Bereitstellung oder das Management von Kapazität.</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">FSX für ONTAP bietet außerdem hochverfügbaren und langlebigen Storage mit vollständig gemanagten Backups und unterstützt Disaster Recovery über mehrere Regionen hinweg. FSX für ONTAP unterstützt gängige Sicherheits- und Antivirenanwendungen für die Datensicherung und erleichtert so den Schutz und die Sicherung Ihrer Daten.</block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="example-title">Konfiguration von Amazon FSX für NetApp ONTAP mit VMware Cloud auf AWS</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Amazon FSX für NetApp ONTAP Dateifreigaben und LUNs können von VMs gemountet werden, die in der VMware SDDC Umgebung bei VMware Cloud bei AWS erstellt wurden. Die Volumes können auch auf dem Linux-Client eingebunden und mithilfe des NFS- oder SMB-Protokolls auf dem Windows-Client abgebildet werden. LUNs sind unter Linux- oder Windows-Clients als Block-Geräte verfügbar, wenn sie über iSCSI eingebunden werden. Amazon FSX für das NetApp ONTAP Filesystem lässt sich mit den folgenden Schritten schnell einrichten.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">Amazon FSX für NetApp ONTAP und VMware Cloud auf AWS müssen sich in derselben Verfügbarkeitszone befinden, um eine bessere Performance zu erzielen und Datenübertragungsgebühren zwischen Verfügbarkeitszonen zu vermeiden.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="example-title">Amazon FSX für ONTAP Volumes erstellen und mounten</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">So erstellen und mounten Sie Amazon FSX für NetApp ONTAP Filesystem:</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSX-Konsole</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">Öffnen Sie das <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> Und wählen Sie Create File System, um den Assistenten zur Erstellung von Dateisystemen zu starten.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">Wählen Sie auf der Seite Select File System Type „Amazon FSX for NetApp ONTAP“ und anschließend „Weiter“. Die Seite Dateisystem erstellen wird angezeigt.</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">Wählen Sie im Abschnitt Networking für Virtual Private Cloud (VPC) die geeignete VPC und die bevorzugten Subnetze zusammen mit der Routing-Tabelle aus. In diesem Fall wird vmcfsx2.vpc aus dem Dropdown-Menü ausgewählt.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">Wählen Sie für die Erstellungsmethode die Option Standarderstellung. Sie können auch schnell erstellen wählen, aber dieses Dokument verwendet die Option Standard create.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">Wählen Sie im Abschnitt Sicherheit und Verschlüsselung für den Verschlüsselungsschlüssel den AWS KMS-Schlüssel (Key Management Service) aus, der die Daten des Filesystems im Ruhezustand schützt. Geben Sie für das Administratorkennwort des Dateisystems ein sicheres Kennwort für den Benutzer fsxadmin ein.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">Geben Sie in der Virtual Machine das Passwort an, das mit vsadmin für die Administration von ONTAP mit REST-APIs oder der CLI verwendet werden soll. Wenn kein Passwort angegeben wird, kann ein fsxadmin-Benutzer für die Verwaltung der SVM verwendet werden. Stellen Sie im Abschnitt „Active Directory“ sicher, dass Sie Active Directory zur SVM zur Bereitstellung von SMB-Freigaben verbinden. Geben Sie im Abschnitt Konfiguration von Standardspeichern Virtual Machines einen Namen für den Storage ein. In dieser Validierung werden SMB-Freigaben über eine selbst gemanagte Active Directory-Domäne bereitgestellt.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">Geben Sie im Abschnitt Standard-Volume-Konfiguration den Namen und die Größe des Volumes an. Dies ist ein NFS-Volume. Wählen Sie aus, um die ONTAP Storage-Effizienzfunktionen (Komprimierung, Deduplizierung und Data-Compaction) zu aktivieren oder zu deaktivieren.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Überprüfen Sie die Konfiguration des Dateisystems, die auf der Seite Dateisystem erstellen angezeigt wird.</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">Klicken Sie Auf Dateisystem Erstellen.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Erste Schritte mit Amazon FSX für NetApp ONTAP</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">Weitere Informationen finden Sie unter <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">Nachdem das Filesystem wie oben erstellt wurde, erstellen Sie das Volume mit der erforderlichen Größe und dem erforderlichen Protokoll.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">Öffnen Sie das <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">Wählen Sie im linken Navigationsbereich Dateisysteme und anschließend das ONTAP-Dateisystem aus, für das Sie ein Volume erstellen möchten.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Wählen Sie die Registerkarte Volumes aus.</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Wählen Sie die Registerkarte Volume erstellen.</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">Das Dialogfeld Volume erstellen wird angezeigt.</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">Zu Demonstrationszwecken wird ein NFS-Volume in diesem Abschnitt erstellt, das leicht auf VMs eingebunden werden kann, die auf VMware Cloud auf AWS laufen. Nfsdemovol01 wird wie unten dargestellt erstellt:</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="example-title">Mounten Sie FSX ONTAP Volume auf dem Linux Client</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">So mounten Sie das im vorherigen Schritt erstellte FSX ONTAP-Volumen. Führen Sie von den Linux VMs innerhalb von VMC auf dem AWS SDDC folgende Schritte aus:</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Öffnen Sie ein Terminal auf der Instanz mithilfe von Secure Shell (SSH), und melden Sie sich mit den entsprechenden Anmeldedaten an.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">Erstellen Sie mit dem folgenden Befehl ein Verzeichnis für den Mount-Punkt des Volumes:</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">Mounten Sie das Amazon FSX für NetApp ONTAP NFS Volume in das Verzeichnis, das im vorherigen Schritt erstellt wurde.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">Führen Sie einmal ausgeführt den df-Befehl aus, um den Mount zu überprüfen.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="example-title">Hängen Sie FSX ONTAP Volumes an Microsoft Windows Clients an</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Um Dateifreigaben auf einem Amazon FSX-Dateisystem zu verwalten und zuzuordnen, muss die GUI für freigegebene Ordner verwendet werden.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">Öffnen Sie das Startmenü, und führen Sie fsmgmt.msc mit Ausführen als Administrator aus. Dadurch wird das GUI-Tool für freigegebene Ordner geöffnet.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">Klicken Sie auf Aktion &gt; Alle Aufgaben, und wählen Sie mit einem anderen Computer verbinden.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">Geben Sie für einen anderen Computer den DNS-Namen für die SVM (Storage Virtual Machine) ein. In diesem Beispiel wird beispielsweise FSXSMBTESTING01.FSXTESTING.LOCAL verwendet.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP finden Sie den DNS-Namen der SVM in der Amazon FSX-Konsole. Wählen Sie Storage Virtual Machines, wählen Sie SVM aus, und blättern Sie dann zu Endpoints, um den SMB-DNS-Namen zu finden. Klicken Sie auf OK. Das Amazon FSX-Dateisystem wird in der Liste der freigegebenen Ordner angezeigt.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">Wählen Sie im Tool freigegebene Ordner die Option Freigaben im linken Fensterbereich aus, um die aktiven Freigaben für das Amazon FSX-Dateisystem anzuzeigen.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">Wählen Sie nun eine neue Freigabe aus, und schließen Sie den Assistenten zum Erstellen eines freigegebenen Ordners ab.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">Erstellen von SMB-Freigaben</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Weitere Informationen zum Erstellen und Managen von SMB-Freigaben auf einem Amazon FSX-Dateisystem finden Sie unter <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">Nach erfolgter Konnektivität kann die SMB-Freigabe angehängt und für Applikationsdaten verwendet werden. Um dies zu erreichen, kopieren Sie den Freigabepfad und verwenden Sie die Option Netzwerklaufwerk zuordnen, um das Volume auf der VM zu mounten, die auf VMware Cloud auf dem AWS SDDC ausgeführt wird.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="example-title">Verbinden Sie FSX für NetApp ONTAP LUNs mit einem Host über iSCSI</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">ISCSI-Datenverkehr für FSX durchläuft das VMware Transit Connect/AWS Transit Gateway über die im vorherigen Abschnitt angegebenen Routen. Folgen Sie der Dokumentation, um eine LUN in Amazon FSX für NetApp ONTAP zu konfigurieren <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Stellen Sie auf Linux Clients sicher, dass der iSCSI-Daemon ausgeführt wird. Nachdem die LUNs bereitgestellt wurden, lesen Sie die detaillierte Anleitung zur iSCSI-Konfiguration mit Ubuntu (als Beispiel). <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">In diesem Dokument wird die Verbindung der iSCSI-LUN mit einem Windows-Host dargestellt:</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="example-title">Bereitstellen eines LUNs in FSX für NetApp ONTAP:</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">Greifen Sie über den Management-Port des FSX für das Dateisystem ONTAP auf die NetApp ONTAP CLI zu.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">Erstellen Sie die LUNs mit der erforderlichen Größe, wie durch die Ausgabe der Dimensionierung angegeben.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">In diesem Beispiel haben wir eine LUN der Größe 5g (5368709120) erstellt.</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">Erstellen Sie die erforderlichen Initiatorgruppen, um zu steuern, welche Hosts auf bestimmte LUNs zugreifen können.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">Es wurden zwei Einträge angezeigt.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">Ordnen Sie die LUNs Initiatorgruppen mit dem folgenden Befehl zu:</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">Verbinden Sie die neu bereitgestellte LUN mit einer Windows VM:</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">Um den neuen LUN-Server auf einem Windows-Host in der VMware Cloud auf dem AWS SDDC zu verbinden, gehen Sie wie folgt vor:</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">RDP auf die Windows VM gehostet auf der VMware Cloud auf AWS SDDC.</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Navigieren Sie zu Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI Initiator, um das Dialogfeld iSCSI Initiator Properties zu öffnen.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">Wählen Sie auf der Registerkarte Ziele das erkannte Ziel aus und klicken Sie dann auf Anmelden oder Verbinden.</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">Wählen Sie Multipath aktivieren, und wählen Sie dann „Diese Verbindung automatisch wiederherstellen, wenn der Computer startet“ oder „Diese Verbindung zur Liste der bevorzugten Ziele hinzufügen“. Klicken Sie Auf Erweitert.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Die LUNs auf der Storage Virtual Machine (SVM) werden dem Windows Host als Festplatten angezeigt. Neue hinzugefügte Festplatten werden vom Host nicht automatisch erkannt. Lösen Sie einen manuellen Rescan aus, um die Festplatten zu ermitteln, indem Sie die folgenden Schritte ausführen:</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Wenn der Windows-Host zum ersten Mal auf eine neue LUN zugreift, hat sie keine Partition oder kein Dateisystem. Initialisieren Sie die LUN und formatieren Sie optional die LUN mit einem Dateisystem, indem Sie die folgenden Schritte durchführen:</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="example-title">Neue Cloud Volumes ONTAP-Instanz in AWS implementieren (selbst übernehmen)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Cloud Volumes ONTAP-Freigaben und LUNs können von VMs gemountet werden, die in der VMware Cloud on AWS SDDC Umgebung erstellt wurden. Die Volumes können auch auf nativen AWS VM Linux Windows Clients eingebunden werden, und AUF LUNS kann bei Verwendung über iSCSI als Blockgeräte zugegriffen werden, da Cloud Volumes ONTAP iSCSI-, SMB- und NFS-Protokolle unterstützt. Cloud Volumes ONTAP Volumes lassen sich in wenigen einfachen Schritten einrichten.</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">Um Volumes aus einer lokalen Umgebung für Disaster Recovery- oder Migrationszwecke in die Cloud zu replizieren, stellen Sie die Netzwerkverbindung zu AWS her, entweder über ein Site-to-Site-VPN oder DirectConnect. Die Replizierung von Daten zwischen On-Premises-Systemen und Cloud Volumes ONTAP ist im Rahmen dieses Dokuments nicht enthalten. Informationen zur Replizierung von Daten zwischen On-Premises- und Cloud Volumes ONTAP-Systemen finden Sie unter <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">Verwenden Sie die <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Und die präzise Größe der Cloud Volumes ONTAP-Instanzen. Überwachung der lokalen Performance als Eingänge im Cloud Volumes ONTAP Sizer</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">Melden Sie sich bei NetApp Cloud Central an. Der Bildschirm Fabric View wird angezeigt. Wählen Sie die Registerkarte Cloud Volumes ONTAP aus und wechseln Sie zu Cloud Manager. Nach der Anmeldung wird der Bildschirm Arbeitsfläche angezeigt.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Klicken Sie auf der Cloud Manager-Startseite auf „Add a Working Environment“, und wählen Sie AWS als Cloud und den Typ der Systemkonfiguration aus.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">Geben Sie die Details zur zu erstellenden Umgebung an, einschließlich Name der Umgebung und Anmeldedaten des Administrators. Klicken Sie auf Weiter .</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">Wählen Sie die Add-on-Services für die Implementierung von Cloud Volumes ONTAP aus, einschließlich Cloud Data Sense, Cloud Backup und Cloud Insights. Klicken Sie auf Weiter .</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">Wählen Sie auf der Seite HA-Bereitstellungsmodelle die Konfiguration mehrerer Verfügbarkeitszonen aus.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">Geben Sie auf der Seite Region &amp; VPC die Netzwerkinformationen ein, und klicken Sie dann auf Weiter.</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">Wählen Sie auf der Seite Konnektivität und SSH-Authentifizierung Verbindungsmethoden für das HA-Paar und den Mediator aus.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">Geben Sie die unverankerten IP-Adressen an, und klicken Sie dann auf Weiter.</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">Wählen Sie die entsprechenden Routingtabellen aus, um Routen zu den unverankerten IP-Adressen einzuschließen, und klicken Sie dann auf Weiter.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">Wählen Sie auf der Seite Datenverschlüsselung die von AWS gemanagte Verschlüsselung aus.</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">Wählen Sie die Lizenzoption: Pay-as-you-Go oder BYOL für die Nutzung einer vorhandenen Lizenz. In diesem Beispiel wird die Pay-as-you-Go-Option verwendet.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">Wählen Sie zwischen mehreren vorkonfigurierten Paketen, die auf Grundlage des Workload-Typs verfügbar sind, die auf den VMs ausgeführt werden, die auf der VMware Cloud auf dem AWS SDDC ausgeführt werden.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">Wählen Sie die CVO-Instanz aus, um das Volume zu erstellen, und klicken Sie auf die Option Volume erstellen. Wählen Sie die entsprechende Größe und Cloud Manager wählt das Aggregat aus, das Sie enthalten, oder verwenden Sie den erweiterten Zuweisungsmechanismus auf einem bestimmten Aggregat. Für diese Demo wird SMB als Protokoll ausgewählt.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">Nachdem das Volume bereitgestellt wurde, ist es unter dem Fensterbereich Volumes verfügbar. Da eine CIFS-Freigabe bereitgestellt wird, sollten Sie Ihren Benutzern oder Gruppen Berechtigungen für die Dateien und Ordner gewähren und überprüfen, ob diese Benutzer auf die Freigabe zugreifen und eine Datei erstellen können.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">Nachdem das Volume erstellt wurde, verwenden Sie den Mount-Befehl, um eine Verbindung zu dem Share von der VM herzustellen, die auf der VMware Cloud in AWS SDDC Hosts ausgeführt wird.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">Kopieren Sie den folgenden Pfad und verwenden Sie die Option Netzwerklaufwerk zuordnen, um das Volume auf der VM zu mounten, die auf der VMware Cloud in AWS SDDC ausgeführt wird.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Führen Sie die folgenden Schritte aus, um die Cloud Volumes ONTAP-LUN mit einem Host zu verbinden:</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Doppelklicken Sie auf der Seite „Cloud Manager“ auf die Arbeitsumgebung von Cloud Volumes ONTAP, um Volumes zu erstellen und zu verwalten.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Klicken Sie auf Volume hinzufügen &gt; Neues Volume, wählen Sie iSCSI aus und klicken Sie auf Initiatorgruppe erstellen. Klicken Sie auf Weiter .</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">Um dies für den Host zu erreichen, der sich auf VMware Cloud auf AWS SDDC befindet, gehen Sie wie folgt vor:</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP auf die VM, die auf VMware Cloud auf AWS gehostet wird.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">Wählen Sie Multipath aktivieren, und wählen Sie dann automatisch Diese Verbindung wiederherstellen, wenn der Computer startet oder Diese Verbindung zur Liste der bevorzugten Ziele hinzufügen. Klicken Sie Auf Erweitert.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">+<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">LUNs aus der SVM werden dem Windows-Host als Festplatten angezeigt. Neue hinzugefügte Festplatten werden vom Host nicht automatisch erkannt. Lösen Sie einen manuellen Rescan aus, um die Festplatten zu ermitteln, indem Sie die folgenden Schritte ausführen:</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Stellen Sie auf den Linux-Clients sicher, dass der iSCSI-Daemon ausgeführt wird. Nachdem die LUNs bereitgestellt wurden, lesen Sie die detaillierte Anleitung zur iSCSI-Konfiguration für Ihre Linux-Distribution. Beispielsweise kann Ubuntu iSCSI-Konfiguration gefunden werden <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. Führen Sie zur Überprüfung lsblk cmd aus der Shell aus.</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">So mounten Sie das Cloud Volumes ONTAP (DIY) Dateisystem von VMs innerhalb VMC auf AWS SDDC aus:</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938: Mounten Sie Amazon FSX für ONTAP als NFS-Datenspeicher mit VMware Cloud auf AWS</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">Alle erfolgreichen Unternehmen befinden sich auf dem Weg der Transformation und Modernisierung. Im Rahmen dieses Prozesses setzen Unternehmen in der Regel ihre vorhandenen VMware-Investitionen ein, um von den Cloud-Vorteilen zu profitieren und die Migration, den Burst, die Erweiterung und die Bereitstellung von Disaster Recovery für Prozesse so nahtlos wie möglich zu untersuchen. Kunden, die in die Cloud migrieren, müssen die Anwendungsfälle für Flexibilität und Burst, den Ausstieg aus dem Datacenter, die Datacenter-Konsolidierung, End-of-Life-Szenarien, Fusionen, Firmenübernahmen usw.</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">Neueste Integration</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">Obwohl VMware Cloud auf AWS die bevorzugte Option für die Mehrheit der Kunden ist, da es Kunden einzigartige Hybrid-Funktionen bietet, haben begrenzte native Storage-Optionen die Nützlichkeit für Unternehmen mit Storage-lastigen Workloads eingeschränkt. Da Storage direkt an Hosts gebunden ist, besteht die einzige Möglichkeit zur Skalierung des Storage darin, weitere Hosts hinzuzufügen. Dadurch lassen sich die Kosten bei Storage-intensiven Workloads um 35 bis 40 % oder mehr senken. Diese Workloads benötigen zusätzlichen Storage und eine abgegrenzte Performance – keine zusätzliche Leistung, sondern die Kosten für zusätzliche Hosts. Hier ist der<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> Der FSX für ONTAP eignet sich mit VMware Cloud auf AWS für Storage- und Performance-intensive Workloads.</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">Betrachten wir einmal das folgende Szenario: Ein Kunde benötigt acht Hosts für mehr Performance (vCPU/Vmem), hat aber auch einen erheblichen Storage-Bedarf. Basierend auf ihrem Assessment benötigen sie 16 Hosts, um die Storage-Anforderungen zu erfüllen. Dies erhöht die Gesamtbetriebskosten, da diese zusätzliche Leistung anschaffen müssen, wenn überhaupt mehr Storage benötigt wird. Dies gilt für alle Anwendungsfälle, einschließlich Migration, Disaster Recovery, Bursting, Entwicklung/Test, Und so weiter.</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">In diesem Dokument werden die Schritte aufgeführt, die erforderlich sind, um FSX für ONTAP als NFS-Datenspeicher für VMware Cloud auf AWS bereitzustellen und anzuhängen.</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">VMware Cloud Tech Zone</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">Diese Lösung ist auch bei VMware verfügbar. Besuchen Sie das <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">Konnektivitätsoptionen</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">In diesem Abschnitt wird die grundlegende Konnektivitätsarchitektur beschrieben sowie die nötigen Schritte zur Implementierung der Lösung zur Erweiterung des Storage in einem SDDC-Cluster ohne zusätzliche Hosts beschrieben.</block>
  <block id="373604cc33724c808b5ea035d2c5d911" category="paragraph">Amazon FSX für NetApp ONTAP ist ein vollständig gemanagter Service, der zuverlässigen, skalierbaren, hochperformanten und funktionsreichen File Storage auf dem beliebten NetApp ONTAP Filesystem bietet. Amazon FSX für NetApp ONTAP (Multi-AZ) verwendet eine fließende IP-Adresse, die bei einem Ausfall auf Verfügbarkeitszone Failover-Funktion für NAS-Datenverkehr ermöglicht. Diese IP-Adresse befindet sich außerhalb des VPC-CIDR-Adressraumanschlusses und kann daher nicht über ENI an das SDDC weitergeleitet werden. Daher sollte VMware Transit Connect zur Verbindung mit der fließenden IP-Adresse der NAS-Schnittstelle verwendet werden.</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">Die grundlegenden Implementierungsschritte sind wie folgt:</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">Amazon FSX für ONTAP in einem neuen benannten VPC erstellen.</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">Erstellen einer SDDC-Gruppe</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">VMware Transit Connect und einen TGW-Anhang erstellen.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">Konfigurieren von Routing (AWS VPC und SDDC) und Sicherheitsgruppen.</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">Verbinden Sie ein NFS-Volume als Datastore mit dem SDDC-Cluster.</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">Erste Schritte mit VMware Cloud on AWS</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">Bevor Sie FSX für ONTAP als NFS-Datastore bereitstellen und anhängen, müssen Sie zuerst eine VMware auf Cloud SDDC-Umgebung einrichten oder ein vorhandenes SDDC-System mit Upgrade auf v1.20 oder höher installieren. Weitere Informationen finden Sie im <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>.</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">FSX für ONTAP wird derzeit nicht mit Stretch-Clustern unterstützt.</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">Dieses Dokument behandelt die Schritte, die zur Konfiguration von Amazon FSX für ONTAP mit VMware Cloud on AWS erforderlich sind. Amazon FSX für ONTAP bietet hervorragende Optionen zum Implementieren und Managen von Applikations-Workloads und Fileservices sowie zur Senkung der TCO, da die Datenanforderungen nahtlos auf die Applikationsebene reduziert werden. Wie auch immer der Anwendungsfall funktioniert: Wählen Sie VMware Cloud auf AWS zusammen mit Amazon FSX for ONTAP, um schnell von den Vorteilen der Cloud zu profitieren, konsistente Infrastruktur und Abläufe von On-Premises-Systemen zu AWS, bidirektionale Portabilität von Workloads und Kapazität und Performance der Enterprise-Klasse zu realisieren. Es handelt sich dabei um denselben bekannten Prozess und dieselben Verfahren für die Verbindung von Speicher. Denken Sie daran, dass nur die Position der geänderten Daten zusammen mit neuen Namen bekannt ist. Die Tools und Prozesse bleiben dieselben, und Amazon FSX für ONTAP trägt zur Optimierung der generellen Implementierung bei.</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">Wenn Sie mehr über diesen Prozess erfahren möchten, folgen Sie bitte dem detaillierten Video zum Rundgang.</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="doc">Technologie</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Zurück: Lösungsübersicht.</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">Zur Lösung gehören innovative Technologien von NetApp, VMware, Amazon Web Services (AWS) und Veeam.</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="section-title">VMware</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="section-title">VMware Cloud Foundation</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">Die VMware Cloud Foundation Plattform umfasst mehrere Produktangebote, mit denen Administratoren logische Infrastrukturen in einer heterogenen Umgebung bereitstellen können. Diese Infrastrukturen (auch Domänen genannt) sorgen für konsistente Abläufe in Private und Public Clouds. Die begleitende Cloud Foundation Software ist eine Stückliste, die vorab validierte und qualifizierte Komponenten identifiziert, die die Risiken für Kunden minimieren und die Implementierung vereinfachen.</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Zu den Komponenten der Cloud Foundation BOM gehören:</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Cloud Builder</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">SDDC Manager</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">VMware vCenter Server Appliance</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">VRealize Automatisierung</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">VRealize Suite Lifecycle Manager</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">VRealize Log Insight</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">Dokumentation der VMware Cloud Foundation</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">Weitere Informationen zur VMware Cloud Foundation finden Sie unter<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>.</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere ist eine Virtualisierungsplattform, die physische Ressourcen in Computing-, Netzwerk- und Storage-Pools verwandelt, die zur Erfüllung der Workload- und Applikationsanforderungen der Kunden eingesetzt werden können. Zu den wichtigsten Komponenten von VMware vSphere gehören:</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">*ESXi.* dieser VMware-Hypervisor ermöglicht die Abstraktion von Rechen-, Speicher-, Netzwerk- und anderen Ressourcen und stellt sie virtuellen Maschinen und Container-Workloads zur Verfügung.</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">*VCenter.* VMware vCenter schafft eine zentrale Managementerfahrung für die Interaktion mit Computing-Ressourcen, Networking und Storage als Teil Ihrer virtuellen Infrastruktur.</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">Kunden schöpfen das volle Potenzial ihrer vSphere Umgebung aus, indem sie NetApp ONTAP mit umfassender Produktintegration, robustem Support sowie leistungsstarken Funktionen und Storage-Effizienzfunktionen für eine robuste hybride Multi-Cloud-Umgebung nutzen.</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">Weitere Informationen zu VMware vSphere finden Sie im folgenden<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>.</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">Weitere Informationen zu NetApp Lösungen mit VMware finden Sie unter<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>.</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">VMware NSX wird allgemein als Netzwerk-Hypervisor bezeichnet. Es verwendet ein softwaredefiniertes Modell, um virtualisierte Workloads zu verbinden. VMware NSX ist allgegenwärtig vor Ort und in VMware Cloud auf AWS, wo es Netzwerkvirtualisierung und Sicherheit für Kundenapplikationen und Workloads bietet.</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">Weitere Informationen zu VMware NSX finden Sie im hier<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>.</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">Seit fast zwei Jahrzehnten ist die NetApp ONTAP Software eine der führenden Storage-Lösungen für VMware vSphere Umgebungen und wird kontinuierlich mit innovativen Funktionen erweitert, die nicht nur zur Vereinfachung des Managements, sondern auch zu Kostensenkungen beitragen. Die Kombination von ONTAP und vSphere ermöglicht Kosteneinsparungen für Host-Hardware und VMware Software. Sichern Sie Ihre Daten außerdem zu niedrigeren Kosten durch eine konstant hohe Performance und profitieren Sie gleichzeitig von der nativen Storage-Effizienz.</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">Weitere Informationen zu NetApp ONTAP finden Sie hier<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="section-title">NetApp ONTAP Tools für VMware</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">Die ONTAP Tools für VMware kombinieren mehrere Plug-ins in einer einzigen virtuellen Appliance, die ein lückenloses Lifecycle Management für Virtual Machines in VMware Umgebungen mit NetApp Storage-Systemen ermöglicht. Die ONTAP Tools für VMware umfassen Folgendes:</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">*Virtual Storage Console (VSC).* führt umfangreiche administrative Aufgaben für VMs und Datenspeicher mit NetApp Storage aus.</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">*VASA Provider für ONTAP ermöglicht richtlinienbasiertes Storage-Management (SPBM, Storage Policy Based Management) mit VMware Virtual Volumes (VVols) und NetApp Storage.</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">*Storage Replication Adapter (SRA)*. Wiederherstellung von vCenter Datenspeichern und Virtual Machines bei einem Ausfall in Verbindung mit VMware Site Recovery Manager (SRM)</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">ONTAP Tools für VMware ermöglichen Benutzern das Management nicht nur externer Storage, sondern auch die Integration in VVols sowie in VMware Site Recovery Manager. Dies erleichtert die Implementierung und den Betrieb von NetApp Storage aus Ihrer vCenter Umgebung heraus.</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">Weitere Informationen zu NetApp ONTAP-Tools für VMware finden Sie im hier<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>.</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">Die NetApp SnapCenter Software ist eine unkomplizierte Enterprise-Plattform, die die Koordination und das Management der Datensicherung für alle Applikationen, Datenbanken und Filesysteme sicher gestaltet. SnapCenter vereinfacht das Backup, Restore und das Lifecycle Management von Klonen, indem diese Aufgaben an Applikationseigentümer abgegeben werden, ohne darauf zu verzichten, Aktivitäten auf den Storage-Systemen zu überwachen und zu regulieren. Durch die Nutzung von Storage-basiertem Datenmanagement steigert SnapCenter die Performance sowie Verfügbarkeit und verringert gleichzeitig die Test- und Entwicklungszeiten.</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">Das SnapCenter Plug-in für VMware vSphere unterstützt absturzkonsistente und VM-konsistente Backup- und Restore-Vorgänge für Virtual Machines (VMs), Datastores und Virtual Machine Disks (VMDKs). Die Software unterstützt außerdem applikationsspezifische SnapCenter Plug-ins, um applikationskonsistente Backup- und Restore-Vorgänge für virtualisierte Datenbanken und Filesysteme zu sichern.</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">Weitere Informationen zu NetApp SnapCenter finden Sie hier<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>.</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">Datensicherung von Drittanbietern</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replication ist eine Backup-, Recovery- und Datenmanagement-Lösung für Cloud-, virtuelle und physische Workloads. Veeam Backup &amp; Replication verfügt über eine spezielle Integration in NetApp Snapshot Technologie, die vSphere Umgebungen noch weiter schützt.</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Weitere Informationen zu Veeam Backup &amp; Replication finden Sie im folgenden<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>.</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">Public Cloud</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="section-title">Identitäts- und Zugriffsmanagement für AWS</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">AWS-Umgebungen umfassen eine breite Palette an Produkten, darunter Computing, Storage, Datenbank, Netzwerk, Analyse Und vieles mehr, um geschäftliche Herausforderungen zu lösen. Unternehmen müssen festlegen können, wer berechtigt ist, auf diese Produkte, Services und Ressourcen zuzugreifen. Ebenso wichtig ist es, unter welchen Bedingungen Benutzer Konfigurationen bearbeiten, ändern oder hinzufügen dürfen.</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS Identity and Access Management (AIM) stellt eine sichere Kontrollebene für das Management des Zugriffs auf AWS Services und Produkte bereit. Ordnungsgemäß konfigurierte Benutzer, Zugriffsschlüssel und Berechtigungen ermöglichen die Implementierung von VMware Cloud auf AWS und Amazon FSX.</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">Weitere Informationen zu AIM finden Sie im folgenden<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>.</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud auf AWS ermöglicht die Software SDDC der Enterprise-Klasse von VMware in der AWS Cloud mit optimiertem Zugriff auf native AWS Services. VMware Cloud auf AWS basiert auf der VMware Cloud Foundation und integriert die Computing-, Storage- und Netzwerkvirtualisierungsprodukte von VMware (VMware vSphere, VMware vSAN und VMware NSX) mit dem für die Ausführung auf dedizierter, elastischer Bare-Metal-Infrastruktur von AWS optimierten VMware vCenter Server-Management.</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">Weitere Informationen zu VMware Cloud auf AWS finden Sie im<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">Amazon FSX für NetApp ONTAP ist ein vollständig gemanagtes ONTAP System, das als nativer AWS Service verfügbar ist. Die Lösung basiert auf NetApp ONTAP und bietet Ihnen vertraute Funktionen und bietet gleichzeitig die Einfachheit eines vollständig gemanagten Cloud-Service.</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">Amazon FSX für ONTAP unterstützt mehrere Protokolle für verschiedene Computing-Typen, einschließlich VMware in der Public Cloud oder vor Ort. Amazon FSX für ONTAP ist verfügbar für heutige Anwendungsfälle mit Gastverbunden und bietet als Technologievorschau NFS Datastores. So können Unternehmen von bekannten Funktionen ihrer lokalen Umgebungen und in der Cloud profitieren.</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">Weitere Informationen zu Amazon FSX für NetApp ONTAP finden Sie im hier<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>.</block>
  <block id="f201deaeba7cc565253f52d974008543" category="summary">Um ein Failover von Applikations-VMs und Datenbank-Volumes auf VMware Cloud Volume-Services durchzuführen, die in AWS ausgeführt werden, müssen Sie eine laufende Instanz von SnapCenter Server sowie Veeam Backup and Replication Server installieren und konfigurieren. Nach Abschluss des Failover müssen diese Tools auch so konfiguriert werden, dass sie den normalen Backup-Betrieb fortsetzen, bis ein Failback zum lokalen Datacenter geplant und ausgeführt wird.</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="doc">Cloud-Backup-Tools und -Konfiguration</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="section-title">Implementieren Sie sekundären Windows SnapCenter Server</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">SnapCenter Server wird im VMware Cloud SDDC implementiert oder auf einer EC2 Instanz in einer VPC mit Netzwerkkonnektivität für die VMware Cloud-Umgebung installiert.</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">SnapCenter Software ist über die NetApp Support Site erhältlich und kann auf Microsoft Windows Systemen installiert werden, die sich entweder in einer Domäne oder Arbeitsgruppe befinden. Ein detaillierter Planungsleitfaden und Installationsanweisungen finden Sie unter<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>.</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">Die Software von SnapCenter finden Sie unter<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="section-title">Konfigurieren Sie den sekundären Windows SnapCenter-Server</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">Zur Wiederherstellung der Applikationsdaten, die auf FSX ONTAP gespiegelt werden, müssen Sie zuerst eine vollständige Wiederherstellung der lokalen SnapCenter-Datenbank durchführen. Nach Abschluss dieses Prozesses wird die Kommunikation mit den VMs wieder hergestellt, und Backups von Applikationen können nun mithilfe von FSX ONTAP als Primär-Storage wieder aufgenommen werden.</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">Dazu müssen Sie die folgenden Elemente auf dem SnapCenter-Server ausführen:</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">Konfigurieren Sie den Computernamen so, dass er mit dem ursprünglichen lokalen SnapCenter-Server identisch ist.</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">Konfigurieren Sie das Networking für die Kommunikation mit VMware Cloud und der FSX ONTAP-Instanz.</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">Führen Sie das Verfahren aus, um die SnapCenter-Datenbank wiederherzustellen.</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">Vergewissern Sie sich, dass sich SnapCenter im Disaster Recovery-Modus befindet, um sicherzustellen, dass FSX jetzt der primäre Storage für Backups ist.</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">Vergewissern Sie sich, dass die Kommunikation mit den wiederhergestellten virtuellen Maschinen wiederhergestellt wird.</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">SnapCenter Datenbankwiederherstellungsvorgang</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">Weitere Informationen zum Durchführen dieser Schritte finden Sie im Abschnitt <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>.</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">Sie können den Veeam Backup &amp; Replication Server auf einem Windows-Server in der VMware Cloud auf AWS oder in einer EC2-Instanz installieren. Eine detaillierte Anleitung zur Implementierung finden Sie im<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Zum Wiederherstellen von Virtual Machines, die auf Amazon S3 Storage gesichert wurden, müssen Sie den Veeam Server auf einem Windows Server installieren und für die Kommunikation mit VMware Cloud, FSX ONTAP und dem S3-Bucket konfigurieren, der das ursprüngliche Backup-Repository enthält. Außerdem muss auf FSX ONTAP ein neues Backup Repository konfiguriert werden, um nach der Wiederherstellung neue Backups der VMs durchzuführen.</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">Um diesen Prozess durchzuführen, müssen die folgenden Punkte abgeschlossen sein:</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">Konfigurieren Sie das Networking für die Kommunikation mit VMware Cloud, FSX ONTAP und dem S3 Bucket mit dem ursprünglichen Backup-Repository.</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">Konfigurieren Sie eine SMB-Freigabe auf FSX ONTAP als neues Backup Repository.</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">Binden Sie den ursprünglichen S3-Bucket ein, der als Teil des Scale-out-Backup-Repositorys vor Ort verwendet wurde.</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">Nach dem Restore der VM neue Backup-Jobs zum Schutz von SQL und Oracle VMs einrichten.</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">Wiederherstellung von Applikations-VMs mit Veeam Full Restore</block>
  <block id="5ad23c05d5054f7daf749b3a328903be" category="paragraph">Weitere Informationen zum Wiederherstellen von VMs mit Veeam finden Sie im Abschnitt <block ref="145e19bb138e7c87e2d24d78a1c11e93" category="inline-link-macro-rx"></block>.</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="summary">SnapCenter kann SnapMirror Beziehungen innerhalb des primären Storage-Systems (primär &gt; Spiegel) und auf sekundäre Storage-Systeme (primär &gt; Vault) aktualisieren, um langfristige Archivierung und Aufbewahrung zu ermöglichen. Hierfür müssen eine Datenreplizierungsbeziehung zwischen einem Ziel-Volume und einem Quell-Volume mithilfe von SnapMirror festgelegt und initialisiert werden.</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="doc">SnapMirror Beziehungen und Aufbewahrungszeitpläne konfigurieren</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">Die Quell- und Ziel-ONTAP Systeme müssen sich in Netzwerken befinden, die über Amazon VPC Peering, ein Transit-Gateway, AWS Direct Connect oder ein AWS VPN Peering durchgeführt werden.</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">Die folgenden Schritte sind zum Einrichten von SnapMirror Beziehungen zwischen einem lokalen ONTAP System und FSX ONTAP erforderlich:</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">FSX für ONTAP – ONTAP-Benutzerhandbuch</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="paragraph">Siehe<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> Weitere Informationen zum Erstellen von SnapMirror Beziehungen mit FSX.</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="section-title">Zeichnen Sie die logischen Schnittstellen von Intercluster und Ziel auf</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">Für das lokale ONTAP Quellsystem können Sie die LIF-Informationen zwischen Clustern von System Manager oder über die CLI abrufen.</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">Wechseln Sie in ONTAP System Manager zur Seite „Netzwerkübersicht“ und rufen Sie die IP-Adressen des Typs „Intercluster“ ab, die für die Kommunikation mit der AWS VPC konfiguriert sind, bei der FSX installiert ist.</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">Um die Intercluster-IP-Adressen für FSX abzurufen, melden Sie sich in der CLI an und führen Sie den folgenden Befehl aus:</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="section-title">Cluster-Peering zwischen ONTAP und FSX einrichten</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">Zum Erstellen von Cluster-Peering zwischen ONTAP Clustern muss im anderen Peer-Cluster eine eindeutige Passphrase bestätigt werden, die beim Initiierung des ONTAP-Clusters eingegeben wurde.</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">Richten Sie mithilfe des Peering auf dem Ziel-FSX-Cluster ein<block ref="9b5825a8b104756a9fc62c8432005be0" prefix=" " category="inline-code"></block> Befehl. Wenn Sie dazu aufgefordert werden, geben Sie eine eindeutige Passphrase ein, die später im Quellcluster verwendet wird, um den Erstellungsprozess abzuschließen.</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">Im Quell-Cluster können Sie die Cluster-Peer-Beziehung entweder mit ONTAP System Manager oder der CLI einrichten. Navigieren Sie im ONTAP System Manager zu Schutz &gt; Übersicht, und wählen Sie Peer Cluster aus.</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">Füllen Sie im Dialogfeld Peer Cluster die erforderlichen Informationen aus:</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">Geben Sie die Passphrase ein, die zum Erstellen der Peer-Cluster-Beziehung auf dem Ziel-FSX-Cluster verwendet wurde.</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">Wählen Sie<block ref="93cba07454f06a4a960172bbd6e2a435" prefix=" " category="inline-code"></block> Um eine verschlüsselte Beziehung aufzubauen.</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">Geben Sie die Intercluster-LIF-IP-Adresse(n) des Ziel-FSX-Clusters ein.</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">Klicken Sie auf Cluster Peering initiieren, um den Prozess abzuschließen.</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">Überprüfen Sie den Status der Cluster-Peer-Beziehung vom FSX-Cluster mit dem folgenden Befehl:</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="section-title">SVM-Peering-Beziehung einrichten</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">Im nächsten Schritt werden eine SVM-Beziehung zwischen den Ziel- und Quell-Storage Virtual Machines eingerichtet, die die Volumes enthalten, die sich in den SnapMirror Beziehungen befinden.</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">Verwenden Sie für den Quell-FSX-Cluster den folgenden Befehl aus der CLI, um die SVM-Peer-Beziehung zu erstellen:</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">Akzeptieren Sie vom ONTAP-Quellcluster die Peering-Beziehung entweder mit dem ONTAP System Manager oder der CLI.</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">Wählen Sie im ONTAP System Manager unter „Protection &gt; Overview“ die Option „Peer Storage VMs“ unter „Storage VM Peers“ aus.</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">Füllen Sie im Dialogfeld Peer Storage VM die erforderlichen Felder aus:</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">Der Quell-Storage-VM</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">Dem Ziel-Cluster</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">Der Ziel-Storage-VM</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">Klicken Sie auf Peer Storage VMs, um den SVM-Peering-Prozess abzuschließen.</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="section-title">Erstellen einer Snapshot Aufbewahrungsrichtlinie</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter managt Aufbewahrungszeitpläne für Backups, die als Snapshot Kopien auf dem primären Storage-System existieren. Dies wird beim Erstellen einer Richtlinie in SnapCenter festgelegt. SnapCenter managt keine Aufbewahrungsrichtlinien für Backups, die in sekundären Storage-Systemen aufbewahrt werden. Diese Richtlinien werden separat durch eine SnapMirror Richtlinie gemanagt, die auf dem sekundären FSX-Cluster erstellt wurde und mit den Ziel-Volumes in einer SnapMirror Beziehung zum Quell-Volume verknüpft ist.</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">Beim Erstellen einer SnapCenter-Richtlinie haben Sie die Möglichkeit, ein sekundäres Richtlinienetikett anzugeben, das der SnapMirror-Kennzeichnung von jedem Snapshot hinzugefügt wird, der beim Erstellen eines SnapCenter-Backups generiert wird.</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">Auf dem sekundären Storage werden diese Kennungen mit Richtliniensegeln abgeglichen, die mit dem Ziel-Volume verbunden sind, um die Aufbewahrung von Snapshots zu erzwingen.</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">Das folgende Beispiel zeigt ein SnapMirror-Etikett, das an allen Snapshots vorhanden ist, die im Rahmen einer Richtlinie erzeugt wurden, die für die täglichen Backups unserer SQL Server-Datenbank und der Protokoll-Volumes verwendet wird.</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">Weitere Informationen zum Erstellen von SnapCenter-Richtlinien für eine SQL Server-Datenbank finden Sie im<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">Sie müssen zuerst eine SnapMirror-Richtlinie mit Regeln erstellen, die die Anzahl der beizubehaltenden Snapshot-Kopien vorschreiben.</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">Erstellen Sie die SnapMirror-Richtlinie auf dem FSX-Cluster.</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">Fügen Sie der Richtlinie Regeln mit SnapMirror-Labels hinzu, die zu den in den SnapCenter-Richtlinien angegebenen sekundären Richtlinienbezeichnungen passen.</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">Das folgende Skript enthält ein Beispiel für eine Regel, die einer Richtlinie hinzugefügt werden kann:</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">Erstellen Sie für jedes SnapMirror Label zusätzliche Regeln und die Anzahl der zu behaltenden Snapshots (Aufbewahrungszeitraum).</block>
  <block id="2f061612da9689d76bf56673168e2297" category="section-title">Erstellung von Ziel-Volumes</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">Führen Sie den folgenden Befehl auf FSX ONTAP aus, um ein Ziel-Volume auf FSX zu erstellen, das den Empfänger von Snapshot-Kopien aus unseren Quell-Volumes erhält:</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="section-title">SnapMirror Beziehungen zwischen Quell- und Ziel-Volumes erstellen</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">Führen Sie den folgenden Befehl auf FSX ONTAP aus, um eine SnapMirror Beziehung zwischen einem Quell- und Ziel-Volume zu erstellen:</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="section-title">SnapMirror Beziehungen initialisieren</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">Initialisieren Sie die SnapMirror-Beziehung. Bei diesem Prozess wird ein neuer Snapshot initiiert, der vom Quell-Volume erzeugt wird und in das Ziel-Volume kopiert.</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">Um ein Volume zu erstellen, führen Sie den folgenden Befehl auf FSX ONTAP aus:</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="doc">Übersicht - AWS Disaster Recovery mit Gastsystem</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">Dieser Abschnitt enthält Anweisungen, die Benutzer bei der Überprüfung, Konfiguration und Validierung ihrer lokalen und Cloud-Umgebungen zur Verwendung mit NetApp und VMware unterstützen. Der Schwerpunkt dieser Lösung liegt auf dem Anwendungsfall mit VMware Anbindung an den Gastsystem ONTAP AFF On-Premises sowie VMware Cloud und AWS FSX ONTAP für die Cloud. Diese Lösung wird mit zwei Applikationen demonstriert: Oracle und MS SQL in einem Disaster-Recovery-Szenario.</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">NetApp Lösungen für Amazon VMware Managed Cloud (VMC)</block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">Erfahren Sie mehr über die Lösungen von NetApp für AWS.</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">Disaster Recovery mit VMC auf AWS (mit Gast verbunden)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">Migrieren Sie Workloads mithilfe von VMware HCX zu FSxN-Datenspeichern</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="doc">Stellen Sie SQL Server Applikationsdaten wieder her</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">Das folgende Verfahren enthält Anweisungen zur Wiederherstellung eines SQL Servers in VMware Cloud Services in AWS im Falle eines Ausfalls, durch den der Betrieb des lokalen Standorts gewährleistet wird.</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">Es wird davon ausgegangen, dass die folgenden Voraussetzungen abgeschlossen sind, um mit den Wiederherstellungsschritten fortzufahren:</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">Die Windows-Server-VM wurde mithilfe von Veeam Full Restore in VMware Cloud SDDC wiederhergestellt.</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">Zusammenfassung des SnapCenter-Backup- und Restore-Prozesses</block>
  <block id="fe51b70218e2191f0338d4bcb01eb4a7" category="list-text">Es wurde ein sekundärer SnapCenter-Server eingerichtet, und die Wiederherstellung und Konfiguration von SnapCenter Datenbanken wurden anhand der im Abschnitt beschriebenen Schritte abgeschlossen <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="section-title">VM: Post-Restore-Konfiguration für SQL Server VM</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">Nach Abschluss der Wiederherstellung der VM müssen Sie Netzwerke und andere Elemente konfigurieren, die für die erneute Erkennung der Host-VM in SnapCenter konfiguriert werden.</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">Weisen Sie neue IP-Adressen für Management und iSCSI oder NFS zu.</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">Verbinden Sie den Host mit der Windows Domain.</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">Fügen Sie die Hostnamen zum DNS oder zur Hosts-Datei auf dem SnapCenter-Server hinzu.</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">Wenn das SnapCenter-Plug-in mit anderen Domänenanmeldeinformationen bereitgestellt wurde als die aktuelle Domäne, müssen Sie das Anmeldekonto für den Plug-in für Windows-Dienst auf der SQL Server-VM ändern. Starten Sie nach dem Ändern des Anmelde-Kontos den SnapCenter SMCore, das Plug-in für Windows und das Plug-in für SQL Server-Dienste neu.</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">Damit die wiederhergestellten VMs in SnapCenter automatisch wieder aufgeermittelt werden können, muss der FQDN mit der VM übereinstimmen, die ursprünglich der SnapCenter vor Ort hinzugefügt wurde.</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="section-title">Konfigurieren Sie FSX-Speicher für SQL Server Restore</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">Um den Disaster Recovery-Prozess für eine SQL Server VM durchzuführen, müssen Sie die bestehende SnapMirror Beziehung vom FSX Cluster durchbrechen und den Zugriff auf das Volume gewähren. Um das zu tun, führen Sie folgende Schritte durch.</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">Um die vorhandene SnapMirror Beziehung für die SQL Server-Datenbank und Protokoll-Volumes zu unterbrechen, führen Sie den folgenden Befehl aus der FSX-CLI aus:</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">Gewähren Sie den Zugriff auf die LUN, indem Sie eine Initiatorgruppe erstellen, die den iSCSI-IQN der Windows VM des SQL Servers enthält:</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">Schließlich ordnen Sie die LUNs der Initiatorgruppe zu, die Sie gerade erstellt haben:</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">Um den Namen des Pfads zu finden, führen Sie den aus<block ref="b8fdaa53ba08988f3b422c1226f85a2a" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="section-title">Richten Sie Windows VM für iSCSI-Zugriff ein und ermitteln Sie die Dateisysteme</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">Richten Sie von der SQL Server-VM aus Ihren iSCSI-Netzwerkadapter ein, um mit der VMware-Portgruppe zu kommunizieren, die mit Konnektivität zu den iSCSI-Zielschnittstellen auf Ihrer FSX-Instanz eingerichtet wurde.</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">Öffnen Sie das Dienstprogramm iSCSI Initiator Properties, und löschen Sie die alten Verbindungseinstellungen auf den Registerkarten Discovery, Favorite Targets und Targets.</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">Suchen Sie die IP-Adresse(n) für den Zugriff auf die logische iSCSI-Schnittstelle auf der FSX-Instanz/dem FSX-Cluster. Sie finden sie in der AWS Konsole unter Amazon FSX &gt; ONTAP &gt; Storage Virtual Machines.</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">Klicken Sie auf der Registerkarte Erkennung auf Portal ermitteln, und geben Sie die IP-Adressen für Ihre FSX-iSCSI-Ziele ein.</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">Klicken Sie auf der Registerkarte Ziel auf Verbinden, wählen Sie gegebenenfalls Multi-Path aktivieren für Ihre Konfiguration aus, und klicken Sie dann auf OK, um eine Verbindung zum Ziel herzustellen.</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">Öffnen Sie das Computer Management-Dienstprogramm, und bringen Sie die Laufwerke online. Vergewissern Sie sich, dass sie die gleichen Laufwerksbuchstaben wie zuvor gehalten haben.</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="section-title">Verbinden Sie die SQL Server-Datenbanken</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">Öffnen Sie in der SQL Server VM Microsoft SQL Server Management Studio, und wählen Sie Attach aus, um den Prozess der Verbindung zur Datenbank zu starten.</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">Klicken Sie auf Hinzufügen, und navigieren Sie zu dem Ordner, der die primäre SQL Server-Datenbankdatei enthält, wählen Sie sie aus, und klicken Sie auf OK.</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">Wenn sich die Transaktionsprotokolle auf einem separaten Laufwerk befinden, wählen Sie den Ordner aus, der das Transaktionsprotokoll enthält.</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">Wenn Sie fertig sind, klicken Sie auf OK, um die Datenbank anzuhängen.</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="section-title">Bestätigen Sie die SnapCenter-Kommunikation mit dem SQL Server-Plug-in</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">Wenn die SnapCenter Datenbank wieder in den vorherigen Status zurückversetzt wurde, werden die SQL Server Hosts automatisch erneut erkannt. Damit dies korrekt funktioniert, beachten Sie die folgenden Voraussetzungen:</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter muss im Disaster Recovery-Modus platziert werden. Dies kann über die Swagger API oder in den globalen Einstellungen unter Disaster Recovery erreicht werden.</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">Der FQDN des SQL-Servers muss mit der Instanz identisch sein, die im lokalen Datacenter ausgeführt wurde.</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">Die ursprüngliche SnapMirror Beziehung muss unterbrochen werden.</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">Die LUNs, die die Datenbank enthalten, müssen auf die SQL Server-Instanz und die angehängte Datenbank eingebunden werden.</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">Um zu überprüfen, ob sich SnapCenter im Disaster Recovery-Modus befindet, navigieren Sie über den SnapCenter Web-Client zu Einstellungen. Wechseln Sie zur Registerkarte Globale Einstellungen und klicken Sie dann auf Disaster Recovery. Stellen Sie sicher, dass das Kontrollkästchen Disaster Recovery aktivieren aktiviert ist.</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38631d978812c49b6f395a78becd9750" category="summary">Das folgende Verfahren enthält Anweisungen zur Wiederherstellung von Oracle Applikationsdaten in VMware Cloud Services in AWS bei einem Ausfall, der den Betrieb des lokalen Standorts erübrigt.</block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="doc">Stellen Sie Oracle Applikationsdaten wieder her</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">Führen Sie die folgenden Voraussetzungen aus, um mit den Wiederherstellungsschritten fortzufahren:</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">Die Oracle Linux-Server-VM wurde mithilfe von Veeam Full Restore in VMware Cloud SDDC wiederhergestellt.</block>
  <block id="66d808fa42d45f6883d1a223ee26eb0c" category="list-text">Es wurde ein sekundärer SnapCenter-Server erstellt, und die SnapCenter-Datenbank und -Konfigurationsdateien wurden anhand der in diesem Abschnitt beschriebenen Schritte wiederhergestellt <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="section-title">FSX für Oracle Restore konfigurieren – Unterbrechung der SnapMirror Beziehung</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">Damit die sekundären Storage-Volumes, die auf der FSxN-Instanz gehostet werden, auf die Oracle Server zugreifen können, müssen Sie die bestehende SnapMirror-Beziehung unterbrechen.</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">Nach der Anmeldung bei der FSX-CLI führen Sie den folgenden Befehl aus, um die Volumes anzuzeigen, die nach dem richtigen Namen gefiltert wurden.</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">Führen Sie den folgenden Befehl aus, um die bestehenden SnapMirror Beziehungen zu unterbrechen.</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Aktualisieren Sie den Verbindungspfad im Amazon FSX Web-Client:</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">Fügen Sie den Namen des Verbindungspfads hinzu, und klicken Sie auf Aktualisieren. Geben Sie diesen Verbindungspfad an, wenn Sie das NFS Volume vom Oracle Server mounten.</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="section-title">Mounten Sie NFS Volumes auf Oracle Server</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">In Cloud Manager erhalten Sie den Mount-Befehl mit der richtigen NFS-LIF-IP-Adresse zum Mounten der NFS-Volumes, die die Oracle-Datenbankdateien und -Protokolle enthalten.</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">Rufen Sie in Cloud Manager die Liste der Volumes für Ihr FSX-Cluster auf.</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">Wählen Sie im Aktivitätsmenü Mount Command aus, um den Mount-Befehl anzuzeigen und zu kopieren, der auf unserem Oracle Linux-Server verwendet werden soll.</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">Mounten Sie das NFS-Dateisystem auf dem Oracle Linux Server. Die Verzeichnisse zum Mounten des NFS-Shares sind bereits auf dem Oracle Linux-Host vorhanden.</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">Verwenden Sie auf dem Oracle Linux-Server den Mount-Befehl, um die NFS-Volumes zu mounten.</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Wiederholen Sie diesen Schritt für jedes mit den Oracle Datenbanken verbundene Volume.</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">Um den NFS-Mount beim Neustart persistent zu machen, bearbeiten Sie den<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Datei zum Einschließen der Mount-Befehle.</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Starten Sie den Oracle-Server neu. Die Oracle Datenbanken sollten normal gestartet werden und zur Verwendung verfügbar sein.</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR 4942: Migration von Workloads auf FSX ONTAP Datastore mithilfe von VMware HCX</block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">Übersicht: Migration von Virtual Machines mit VMware HCX, FSX ONTAP zusätzlichen Datastores und VMware Cloud</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">Als typischer Anwendungsfall für VMware Cloud (VMC) auf Amazon Web Services (AWS) mit seinem zusätzlichen NFS-Datastore auf Amazon FSX für NetApp ONTAP ist die Migration von VMware Workloads zu verwenden. VMware HCX ist eine bevorzugte Option und bietet verschiedene Migrationsmethoden zum Verschieben von On-Premises-Virtual Machines (VMs) und deren Daten, die auf beliebigen von VMware unterstützten Datastores ausgeführt werden, in VMC-Datastores, darunter zusätzliche NFS-Datastores auf FSX für ONTAP.</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX ist primär eine Mobilitätsplattform, die speziell zur Cloud-übergreifenden Vereinfachung der Workload-Migration, des Ausgleichs von Workloads und der Business Continuity entwickelt wurde. Es wird im Rahmen von VMware Cloud auf AWS enthalten und bietet viele Möglichkeiten zur Migration von Workloads und kann für Disaster-Recovery-Vorgänge (DR) genutzt werden.</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">Dieses Dokument bietet eine Schritt-für-Schritt-Anleitung zur Implementierung und Konfiguration von VMware HCX, einschließlich aller Hauptkomponenten – vor Ort und im Cloud-Datacenter –, die verschiedene VM-Migrationsmechanismen unterstützt.</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">Einführung in HCX-Implementierungen</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">Checkliste B – HCX mit einer VMware Cloud auf AWS SDDC Zielumgebung installieren</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">Weitere Informationen finden Sie unter<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> Und<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>.</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">Diese Liste enthält grundlegende Schritte zur Installation und Konfiguration von VMware HCX:</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">Aktivieren Sie HCX für das softwaredefinierte VMC Datacenter (SDDC) über die VMware Cloud Services Console.</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">Laden Sie das OVA-Installationsprogramm für HCX Connector im lokalen vCenter Server herunter und stellen Sie es bereit.</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">HCX mit einem Lizenzschlüssel aktivieren.</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">Verbinden Sie den VMware HCX Connector vor Ort mit VMC HCX Cloud Manager.</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(Optional) Führen Sie eine Netzwerkerweiterung aus, um das Netzwerk zu erweitern und eine erneute IP-Adresse zu vermeiden.</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">Vorbereitung der HCX-Installation</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">Bevor Sie beginnen, stellen Sie sicher, dass die folgenden Voraussetzungen erfüllt sind. Weitere Informationen finden Sie unter<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>. Nachdem die Voraussetzungen einschließlich Konnektivität erfüllt sind, konfigurieren und aktivieren Sie HCX, indem Sie einen Lizenzschlüssel aus der VMware HCX-Konsole bei VMC generieren. Nach der Aktivierung von HCX wird das vCenter Plug-in implementiert und kann über die vCenter-Konsole zur Verwaltung aufgerufen werden.</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">Die folgenden Installationsschritte müssen ausgeführt werden, bevor Sie mit der HCX-Aktivierung und -Bereitstellung fortfahren:</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">Link zu VMware</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">Verwenden Sie ein vorhandenes VMC SDDC oder erstellen Sie nach diesem Vorgang ein neues SDDC<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> Oder hier<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>.</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">Der Netzwerkpfad von der lokalen vCenter Umgebung zu VMC SDDC muss die Migration von VMs über vMotion unterstützen.</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">Stellen Sie sicher, dass die erforderlichen<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sind für vMotion Traffic zwischen dem lokalen vCenter Server und dem SDDC vCenter zulässig.</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">Das FSX für ONTAP-NFS-Volume sollte als zusätzlicher Datastore im VMC SDDC gemountet werden. Befolgen Sie die in diesem Schritt beschriebenen Schritte, um die NFS-Datenspeicher an den entsprechenden Cluster anzuhängen<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> Oder hier<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>.</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">Die für diese Validierung verwendete On-Premises-Lab-Umgebung wurde zu Testzwecken über ein Site-to-Site-VPN mit AWS VPC verbunden. Dies ermöglichte eine On-Premises-Konnektivität mit AWS und dem VMware Cloud SDDC über ein externes Transit Gateway. HCX-Migration und Netzwerkerweiterungsverkehr fließen über das Internet zwischen On-Premises- und VMware-Cloud-Ziel SDDC. Diese Architektur kann auf private virtuelle Direct Connect-Schnittstellen geändert werden.</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">Das folgende Bild stellt die allgemeine Architektur dar.</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">Schritt 1: HCX über VMC SDDC mit der Option Add-ons aktivieren</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">Melden Sie sich an der VMC-Konsole unter an<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> Und greifen Sie auf das Inventar zu.</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">Um das entsprechende SDDC auszuwählen und auf Add-ons zuzugreifen, klicken Sie auf Details anzeigen im SDDC und wählen Sie die Registerkarte Add-ons aus.</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">Klicken Sie auf Aktivieren für VMware HCX.</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">Dieser Schritt dauert bis zu 25 Minuten.</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">Nachdem die Implementierung abgeschlossen ist, validieren Sie die Implementierung, indem Sie bestätigen, dass HCX Manager und die zugehörigen Plug-ins in der vCenter Console verfügbar sind.</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">Erstellen Sie die entsprechenden Management Gateway-Firewalls, um die erforderlichen Ports für den Zugriff auf HCX Cloud Manager zu öffnen.HCX Cloud Manager ist jetzt für HCX-Vorgänge bereit.</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">Damit der On-Premises Connector mit dem HCX Manager in VMC kommunizieren kann, stellen Sie sicher, dass die entsprechenden Firewall-Ports in der On-Premises-Umgebung geöffnet sind.</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">Navigieren Sie von der VMC-Konsole zum HCX Dashboard, gehen Sie zu Administration und wählen Sie die Registerkarte Systemaktualisierung aus. Klicken Sie auf Download-Link für das OVA-Bild des HCX-Connectors anfordern.</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">Stellen Sie die OVA beim Herunterladen des HCX Connectors im lokalen vCenter Server bereit. Klicken Sie mit der rechten Maustaste auf vSphere Cluster und wählen Sie die Option OVF-Vorlage bereitstellen aus.</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Geben Sie die erforderlichen Informationen im Assistenten zur Bereitstellung von OVF-Vorlagen ein, klicken Sie auf Weiter und anschließend auf Fertig stellen, um die OVA des VMware HCX-Connectors bereitzustellen.</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">Schalten Sie das virtuelle Gerät manuell ein.Schritt-für-Schritt-Anleitungen finden Sie unter<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">Nachdem Sie den VMware HCX Connector OVA vor Ort bereitgestellt und das Gerät gestartet haben, führen Sie die folgenden Schritte aus, um den HCX Connector zu aktivieren. Generieren Sie den Lizenzschlüssel von der VMware HCX Console bei VMC und geben Sie die Lizenz während der VMware HCX Connector-Einrichtung ein.</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">Wählen Sie in der VMware Cloud Console „Inventar“, wählen Sie das SDDC und klicken Sie auf „Details anzeigen“. Klicken Sie auf der Registerkarte Add ons in der Kachel VMware HCX auf Open HCX.</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">Klicken Sie auf der Registerkarte Aktivierungsschlüssel auf Aktivierungsschlüssel erstellen. Wählen Sie den Systemtyp als HCX-Anschluss aus, und klicken Sie auf Bestätigen, um den Schlüssel zu generieren. Kopieren Sie den Aktivierungsschlüssel.</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">Für jeden HCX Connector, der vor Ort eingesetzt wird, ist ein separater Schlüssel erforderlich.</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">Melden Sie sich beim lokalen VMware HCX Connector unter an<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> Administratordaten werden verwendet.</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">Geben Sie im Abschnitt Lizenzierung den Aktivierungsschlüssel ein, der aus Schritt 2 kopiert wurde, und klicken Sie auf Aktivieren.</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">Der HCX-Connector vor Ort muss über einen Internetzugang verfügen, damit die Aktivierung erfolgreich abgeschlossen werden kann.</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">Geben Sie unter Datacenter Location den gewünschten Speicherort für die Installation des VMware HCX Manager vor Ort an. Klicken Sie auf Weiter .</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">Aktualisieren Sie unter Systemname den Namen, und klicken Sie auf Weiter.</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">Wählen Sie Ja, und fahren Sie fort.</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">Geben Sie unter vCenter verbinden die IP-Adresse oder den vollqualifizierten Domänennamen (FQDN) und die Anmeldeinformationen für den vCenter-Server ein, und klicken Sie auf Weiter.</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">Verwenden Sie den FQDN, um später Kommunikationsprobleme zu vermeiden.</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">Geben Sie unter SSO/PSC konfigurieren den FQDN oder die IP-Adresse des Plattform-Services-Controllers an, und klicken Sie auf Weiter.</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">Geben Sie die IP-Adresse oder den FQDN des vCenter-Servers ein.</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">Überprüfen Sie, ob die Informationen korrekt eingegeben wurden, und klicken Sie auf Neu starten.</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">Nach Abschluss wird der vCenter-Server grün angezeigt. Sowohl der vCenter-Server als auch das SSO müssen über die richtigen Konfigurationsparameter verfügen, die mit der vorherigen Seite identisch sein sollten.</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">Dieser Vorgang dauert etwa 10 bis 20 Minuten, und das Plug-in wird dem vCenter Server hinzugefügt.</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">Schritt 4: Koppeln Sie den VMware HCX Connector vor Ort mit VMC HCX Cloud Manager</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">Um ein Standortpaar zwischen dem lokalen vCenter Server und dem VMC SDDC zu erstellen, melden Sie sich beim lokalen vCenter Server an und greifen Sie auf das HCX vSphere Web Client Plug-in zu.</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">Klicken Sie unter Infrastruktur auf Site Pairing hinzufügen. Geben Sie zur Authentifizierung des Remote-Standorts die URL oder IP-Adresse des VMC HCX Cloud Manager und die Anmeldeinformationen für die CloudAdmin-Rolle ein.</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">HCX-Informationen sind auf der Seite SDDC-Einstellungen abrufbar.</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">Klicken Sie auf Verbinden, um die Standortpaarung zu starten.</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">VMware HCX Connector muss in der Lage sein, über Port 443 mit der HCX Cloud Manager IP zu kommunizieren.</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">Die VMware HCX Interconnect (HCX-IX) Appliance bietet sichere Tunnelfunktionen über das Internet und private Verbindungen zum Zielstandort, die Replizierung und vMotion-basierte Funktionen ermöglichen. Das Interconnect bietet Verschlüsselung, Traffic Engineering und SD-WAN. Um die HCI-IX Interconnect Appliance zu erstellen, gehen Sie wie folgt vor:</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">Wählen Sie unter Infrastruktur die Option Interconnect &gt; Multi-Site Service Mesh &gt; Compute Profiles &gt; Create Compute Profile.</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">Computing-Profile beinhalten die Parameter für die Computing-, Storage- und Netzwerkimplementierung, die für die Implementierung einer virtuellen Interconnect Appliance erforderlich sind. Außerdem wird angegeben, welcher Teil des VMware Datacenters für den HCX-Service verfügbar sein soll.</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">Erstellen eines Computing-Profils</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">Ausführliche Anweisungen finden Sie unter<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>.</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">Erstellen Sie nach dem Erstellen des Rechenprofils das Netzwerkprofil, indem Sie Multi-Site Service Mesh &gt; Netzwerkprofile &gt; Netzwerkprofil erstellen auswählen.</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">Das Netzwerkprofil definiert einen Bereich von IP-Adressen und Netzwerken, die von HCX für seine virtuellen Appliances verwendet werden.</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">Dafür benötigen Sie mindestens zwei IP-Adressen. Diese IP-Adressen werden virtuellen Appliances vom Managementnetzwerk zugewiesen.</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">Erstellen eines Netzwerkprofils</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">Ausführliche Anweisungen finden Sie unter<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>.</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">Wenn Sie eine Verbindung mit einem SD-WAN über das Internet herstellen, müssen Sie öffentliche IPs im Abschnitt Netzwerk und Sicherheit reservieren.</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">Um ein Service-Mesh zu erstellen, wählen Sie in der Option Interconnect die Registerkarte Service Mesh aus, und wählen Sie On-Premises- und VMC SDDC-Standorte aus.</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">Das Service-Netz stellt ein lokales und entferntes Compute- und Netzwerkprofil-Paar bereit.</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">Bei diesem Prozess werden HCX-Appliances bereitgestellt, die automatisch am Quell- und Zielspeicherort konfiguriert werden und so eine sichere Transportstruktur erstellen.</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">Wählen Sie die Quell- und Remote-Computing-Profile aus, und klicken Sie auf Weiter.</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">Wählen Sie den Dienst aus, der aktiviert werden soll, und klicken Sie auf Weiter.</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Für die Replication Assisted vMotion Migration, die SRM-Integration und die BS-gestützte Migration ist eine HCX Enterprise-Lizenz erforderlich.</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">Erstellen Sie einen Namen für das Service-Mesh, und klicken Sie auf Fertig stellen, um den Erstellungsvorgang zu starten. Die Implementierung dauert etwa 30 Minuten. Nach der Konfiguration des Service-Mesh wurden die virtuelle Infrastruktur und die für die Migration der Virtual Machines erforderlichen Netzwerke erstellt.</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">Schritt 6: Migration Von Workloads</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX bietet bidirektionale Migrationsservices zwischen zwei oder mehr Umgebungen, beispielsweise On-Premises- und VMC SDDCs. Applikations-Workloads können mithilfe verschiedener Migrationstechnologien wie HCX Bulk Migration, HCX vMotion, HCX Cold Migration, HCX Replication Assisted vMotion (erhältlich mit HCX Enterprise Edition) und HCX OS Assisted Migration (erhältlich mit HCX Enterprise Edition) zu und von aktivierten Standorten migriert werden (mit HCX Enterprise Edition erhältlich).</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">Weitere Informationen über verfügbare HCX-Migrationstechnologien finden Sie unter<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">Die HCX-IX Appliance verwendet den Mobility Agent Service, um vMotion-, Cold- und Replication Assisted vMotion-Migrationen (RAV) durchzuführen.</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">Die HCX-IX Appliance fügt den Mobility Agent-Service als Hostobjekt im vCenter Server hinzu. Der auf diesem Objekt angezeigte Prozessor, Arbeitsspeicher, Speicher und Netzwerkressourcen stellen nicht den tatsächlichen Verbrauch des physischen Hypervisors dar, der die IX-Appliance hostet.</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">In diesem Abschnitt wird der HCX vMotion-Mechanismus beschrieben. Diese Migrationstechnologie nutzt das VMware vMotion Protokoll für die Migration einer VM zu VMC SDDC. Die vMotion Migrationsoption wird verwendet, um den VM-Status einer einzelnen VM gleichzeitig zu migrieren. Während dieser Migrationsmethode kommt es zu keiner Serviceunterbrechung.</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">Eine Netzwerkerweiterung sollte vorhanden sein (für die Portgruppe, an der die VM angeschlossen ist), um die VM zu migrieren, ohne dass eine IP-Adressänderung notwendig ist.</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">Wechseln Sie vom lokalen vSphere-Client zum Inventory, klicken Sie mit der rechten Maustaste auf die zu migrierende VM und wählen Sie HCX Actions &gt; Migrate to HCX Target Site aus.</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">Wählen Sie im Assistenten für die Migration von Virtual Machines die Remote-Standortverbindung (Ziel-VMC SDDC) aus.</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">Fügen Sie einen Gruppennamen hinzu und aktualisieren Sie unter Übertragen und Platzierung die Pflichtfelder (Cluster, Storage und Zielnetzwerk), und klicken Sie auf Validieren.</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">Klicken Sie nach Abschluss der Validierungsprüfungen auf Los, um die Migration zu starten.</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">VMware HCX vMotion und „Cold Migration“ verstehen</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">Der vMotion Transfer erfasst den aktiven VM-Speicher, seinen Ausführungszustand, seine IP-Adresse und seine MAC-Adresse. Weitere Informationen zu den Anforderungen und Einschränkungen von HCX vMotion finden Sie unter<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>.</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">Über das Dashboard HCX &gt; Migration können Sie den Fortschritt und den Abschluss von vMotion überwachen.</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMotion wird mithilfe von VMware Replizierung unterstützt</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">Wie Sie in der VMware Dokumentation möglicherweise schon bemerkt haben, vereint VMware HCX Replication Assisted vMotion (RAV) die Vorteile der Massenmigration mit vMotion. Bei der Massenmigration wird mit vSphere Replication mehrere VMs parallel migriert – die VM wird während der Umschaltung neu gestartet. HCX vMotion migriert ohne Ausfallzeiten, wird aber seriell eine VM nacheinander in einer Replizierungsgruppe ausgeführt. RAV repliziert die VM parallel und hält sie bis zum Switchover-Fenster synchron. Während des Switchover migriert sie eine VM nach dem anderen, ohne Ausfallzeiten für die VM.</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">Im folgenden Screenshot wird das Migrationsprofil als Replication Assisted vMotion angezeigt.</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">Die Dauer der Replizierung kann gegenüber vMotion einer kleinen Anzahl von VMs länger dauern. Mit RAV synchronisieren Sie nur die Deltas und beinhalten den Speicherinhalt. Nachfolgend sehen Sie einen Screenshot des Migrationsstatus: Hier wird die Startzeit der Migration angegeben, und die Endzeit ist unterschiedlich für jede VM.</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">Weitere Informationen zu den HCX-Migrationsoptionen und zur Migration von Workloads von On-Premises zu VMware Cloud on AWS mit HCX finden Sie im<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion erfordert eine Durchsatzfunktion von 100 MB/s oder mehr.</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">Die FSX für das Ziel-VMC für ONTAP-Datenspeicher muss über ausreichend Speicherplatz für die Migration verfügen.</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">Ganz gleich, ob Sie nur auf All-Cloud- oder Hybrid Cloud-Umgebungen abzielen und Daten in On-Premises-Storage eines beliebigen Typs oder Anbieters speichern: Amazon FSX für NetApp ONTAP bietet in Kombination mit HCX hervorragende Optionen für Implementierung und Migration der Workloads, während Sie gleichzeitig die TCO senken, indem die Datenanforderungen nahtlos auf die Applikationsebene reduziert werden. Unabhängig vom Anwendungsfall entscheiden Sie sich für VMC und FSX für ONTAP Datastore, um schnell von den Vorteilen der Cloud zu profitieren. Sie profitieren von konsistenter Infrastruktur und On-Premises- und diversen Clouds, bidirektionaler Portabilität von Workloads sowie Kapazität und Performance der Enterprise-Klasse. Es handelt sich dabei um denselben bekannten Prozess und dieselben Verfahren, die zum Verbinden des Storage und zur Migration von VMs mithilfe der VMware vSphere Replizierung, VMware vMotion oder sogar einer NFC-Kopie verwendet werden.</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">Sie können nun Amazon FSX ONTAP als Datastore mit VMC SDDC nutzen.</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">Daten lassen sich problemlos von lokalen Datacentern zu VMC migrieren, die mit FSX für ONTAP Datastores ausgeführt werden</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">Erweitern und reduzieren Sie den FSX ONTAP Datastore ganz einfach, um die Kapazitäts- und Performance-Anforderungen während der Migration zu erfüllen.</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">Dokumentation zu VMware Cloud</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Dokumentation zu Amazon FSX für NetApp ONTAP</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="summary">Für einen Ausfall im primären Datacenter vor Ort umfasst unser Szenario ein Failover an einen sekundären Standort in einer Amazon Web Services Infrastruktur mit VMware Cloud on AWS. Wir gehen davon aus, dass auf die Virtual Machines und unser On-Premises-ONTAP-Cluster nicht mehr zugegriffen werden kann. Darüber hinaus sind die SnapCenter und Veeam Virtual Machines nicht mehr zugänglich und müssen an unserem sekundären Standort neu erstellt werden.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="doc">Failover</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="section-title">Ausfall am primären Standort</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">In diesem Abschnitt werden das Failover unserer Infrastruktur in die Cloud behandelt. Dabei werden die folgenden Themen behandelt:</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">Wiederherstellung der SnapCenter-Datenbank. Nach dem Einrichten eines neuen SnapCenter Servers stellen Sie die MySQL-Datenbank und die Konfigurationsdateien wieder her und schalten die Datenbank in den Disaster-Recovery-Modus um, damit der sekundäre FSX-Storage zum primären Speichergerät wird.</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Stellen Sie die Virtual Machines der Applikationen mit Veeam Backup &amp; Replication wieder her. Verbinden Sie den S3-Storage mit den VM-Backups, importieren Sie die Backups und stellen Sie sie in VMware Cloud auf AWS wieder her.</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">Stellen Sie die SQL Server Applikationsdaten mithilfe von SnapCenter wieder her.</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">Stellen Sie die Oracle Applikationsdaten mit SnapCenter wieder her.</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="section-title">Wiederherstellung der SnapCenter Datenbanken</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter unterstützt Disaster Recovery-Szenarien, da das Backup und Restore seiner MySQL Datenbank und Konfigurationsdateien gestattet werden. So kann ein Administrator regelmäßige Backups der SnapCenter Datenbank im lokalen Datacenter durchführen und diese Datenbank später in einer sekundären SnapCenter Datenbank wiederherstellen.</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">Führen Sie die folgenden Schritte aus, um auf die SnapCenter Backup-Dateien auf dem Remote-SnapCenter-Server zuzugreifen:</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">SnapMirror Beziehung vom FSX Cluster lösen, wodurch das Volume Lese-/Schreibzugriff ermöglicht.</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">Erstellen Sie (falls erforderlich) einen CIFS-Server und erstellen Sie eine CIFS-Freigabe, die zum Verbindungspfad des geklonten Volume führt.</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">Verwenden Sie xcopy, um die Sicherungsdateien in ein lokales Verzeichnis auf dem sekundären SnapCenter-System zu kopieren.</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">Installieren Sie SnapCenter v4.6.</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">Stellen Sie sicher, dass der SnapCenter-Server über denselben FQDN wie der ursprüngliche Server verfügt. Dies ist erforderlich, damit die datenbankwiederherstellung erfolgreich durchgeführt werden kann.</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">Um den Wiederherstellungsprozess zu starten, führen Sie die folgenden Schritte aus:</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">Navigieren Sie zur Swagger API-Webseite für den sekundären SnapCenter-Server, und folgen Sie den vorherigen Anweisungen, um ein Autorisierungs-Token zu erhalten.</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Navigieren Sie auf der Seite Swagger zum Abschnitt Disaster Recovery, und wählen Sie<block ref="533e3565b4ab97ee497d4500afcfa0ca" prefix=" " category="inline-code"></block>, Und klicken Sie auf Probieren Sie es aus.</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">Fügen Sie das Autorisierungs-Token ein, und fügen Sie im Abschnitt SmDRResterRequest den Namen des Backups und das lokale Verzeichnis auf dem sekundären SnapCenter-Server ein.</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">Wählen Sie die Schaltfläche Ausführen, um den Wiederherstellungsvorgang zu starten.</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">Navigieren Sie in SnapCenter zum Abschnitt Überwachung, um den Fortschritt des Wiederherstellungsjobs anzuzeigen.</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">Um SQL Server Restores von einem sekundären Storage zu aktivieren, müssen Sie die SnapCenter-Datenbank in den Disaster Recovery-Modus schalten. Dies wird als separate Operation durchgeführt und auf der Swagger API Webseite initiiert.</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">Navigieren Sie zum Abschnitt Disaster Recovery, und klicken Sie auf<block ref="6f4ce9a3fde10d5d540991396641c75c" prefix=" " category="inline-code"></block>.</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">Fügen Sie das Benutzerautorisierungs-Token ein.</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">Ändern Sie im Abschnitt SmSetDistasterRecoverySettingsRequest<block ref="b7332a241d968e08b968a292c8d519aa" prefix=" " category="inline-code"></block> Bis<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>.</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">Klicken Sie auf Ausführen, um den Disaster Recovery-Modus für SQL Server zu aktivieren.</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">Siehe Anmerkungen zu weiteren Verfahren.</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="summary">VMware vSphere bietet eine virtualisierte Infrastruktur im Datacenter und bei allen wichtigen Cloud-Providern. Dieses Ecosystem eignet sich ideal für Disaster-Recovery-Szenarien, in denen virtualisierte Computing-Ressourcen unabhängig vom Standort konsistent bleiben. Diese Lösung nutzt virtualisierte VMware Computing-Ressourcen sowohl am Datacenter-Standort als auch in der VMware Cloud on AWS.</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="doc">Computing</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">Diese Lösung verwendet HPE ProLiant DL360 Gen 10 Server mit VMware vSphere v7.0U3. Wir haben sechs Computing-Instanzen implementiert, um für unsere SQL Server und Oracle Server ausreichende Ressourcen bereitzustellen.</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">Wir haben 10 Windows Server 2019 VMs mit SQL Server 2019 mit unterschiedlichen Datenbankgrößen und 10 Oracle Linux 8.5 VMs mit Oracle 19c, auch hier mit unterschiedlichen Datenbankgrößen, eingesetzt.</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">Wir haben ein SDDC in VMware Cloud auf AWS mit zwei Hosts implementiert, um die von unserem primären Standort aus wiederhergestellten Virtual Machines zum Ausführen von zwei Hosts bereitzustellen.</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="summary">NetApp AFF A-Series Systeme bieten eine hochperformante Storage-Infrastruktur mit flexiblen Datenmanagement-Optionen, die für eine Vielzahl von Enterprise-Szenarien Cloud-fähig sind. Bei dieser Lösung haben wir eine ONTAP AFF A300 als unser primäres On-Premises-Storage-System verwendet.</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">NetApp ONTAP zusammen mit den ONTAP Tools für VMware und SnapCenter wurden bei der Lösung eingesetzt, um umfassende Management- und Backup-Funktionen für Applikationen zu bieten, die eng mit VMware vSphere integriert sind.</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">Wir verwendeten ONTAP Storage für die VMware Datenspeicher, die die Virtual Machines und ihre VMDK-Dateien gehostet haben. VMware unterstützt mehrere Storage-Protokolle für verbundene Datastores, und in dieser Lösung haben wir NFS-Volumes für Datastores auf ESXi Hosts genutzt. ONTAP Storage-Systeme unterstützen jedoch alle Protokolle, die von VMware unterstützt werden.</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">In der folgenden Abbildung sind die VMware Storage-Optionen dargestellt.</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">ONTAP Volumes wurden für iSCSI- und über NFS-Gast-verbundenen Storage für unsere Applikations-VMs eingesetzt. Folgende Storage-Protokolle wurden für Applikationsdaten verwendet:</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">NFS-Volumes für mit dem Gast verbundene Oracle-Datenbankdateien.</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">ISCSI LUNs für mit dem Gast verbundene Microsoft SQL Server-Datenbanken und Transaktionsprotokolle.</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Betriebssystem</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">Datenbanktyp</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">Storage-Protokoll</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">Volume-Beschreibung</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="cell">Windows Server 2019</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">Datenbankdateien</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">Log-Dateien</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Oracle binär</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Oracle Daten</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Oracle Recovery-Dateien</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">Außerdem verwendeten wir ONTAP-Storage für das primäre Veeam Backup-Repository und für ein Backup-Ziel für die SnapCenter-Datenbank-Backups.</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">SMB-Freigabe für das Veeam Backup Repository.</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">SMB-Freigabe als Ziel für die SnapCenter-Datenbank-Backups.</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="section-title">Cloud-Storage</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">Diese Lösung umfasst VMware Cloud auf AWS, um Virtual Machines zu hosten, die im Rahmen des Failover-Prozesses wiederhergestellt sind. Ab diesem Text unterstützt VMware vSAN Storage für die Datastores, die VMs und VMDKs hosten.</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">FSX für ONTAP wird als sekundärer Storage für Applikationsdaten verwendet, die mit SnapCenter und SyncMirror gespiegelt werden. Im Rahmen des Failover-Prozesses wird der FSX für ONTAP-Cluster in den primären Storage umgewandelt und die Datenbankapplikationen können die normale Funktion wieder aufnehmen, die auf dem FSX-Storage-Cluster ausgeführt wird.</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="section-title">Einrichtung von Amazon FSX für NetApp ONTAP</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Um AWS FSX für NetApp ONTAP mithilfe von Cloud Manager zu implementieren, folgen Sie den Anweisungen unter<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>.</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">Nach der Implementierung von FSX ONTAP ziehen Sie die ONTAP Instanzen vor Ort per Drag-and-Drop in FSX ONTAP, um die Replizierungseinrichtung der Volumes zu starten.</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">Die folgende Abbildung zeigt unsere FSX ONTAP-Umgebung.</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="section-title">Netzwerkschnittstellen erstellt</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">FSX für NetApp ONTAP verfügt über vorkonfigurierte Netzwerkschnittstellen zur Verwendung in iSCSI-, NFS-, SMB- und Clusternetzwerken.</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="section-title">VM-Datenspeicher-Storage</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">Das VMware Cloud SDDC verfügt über zwei VSAN-Datastores mit Namen<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> Und<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>. Wir haben genutzt<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> Für Host-Management-VMs mit eingeschränktem Zugriff auf Cloud-Admin-Berechtigungen. Für Workloads verwendeten wir<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>.</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">In dieser Lösung bietet SnapCenter applikationskonsistente Snapshots für SQL Server und Oracle Applikationsdaten. Diese Konfiguration sorgt in Kombination mit der SnapMirror Technologie für ultraschnelle Datenreplizierung zwischen unserem lokalen AFF und FSX ONTAP Cluster. Darüber hinaus bietet Veeam Backup &amp; Replication Backup- und Restore-Funktionen für unsere Virtual Machines.</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">In diesem Abschnitt werden die Konfiguration von SnapCenter, SnapMirror und Veeam für Backups und auch für Restores erläutert.</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">In den folgenden Abschnitten werden die Konfiguration und die erforderlichen Schritte zum Abschluss eines Failover am sekundären Standort behandelt:</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="list-text">Implementieren und konfigurieren Sie Windows SnapCenter Server vor Ort.</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">Erfahren Sie mehr über die Funktionen, die NetApp den drei primären Hyperscalern (3) bietet: Von NetApp als Gast-verbundenen Storage-Gerät oder einem zusätzlichen NFS Datastore zur Migration von Workflows, Erweiterung/Bursting in die Cloud, Backup/Restore und Disaster Recovery.</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">Entscheiden Sie sich für die Cloud und überlassen Sie NetApp den Rest.</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">Um die Funktionen für einen bestimmten Hyperscaler anzuzeigen, klicken Sie auf die entsprechende Registerkarte für diesen Hyperscaler.</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">VMware in der Konfiguration von Hyperscalern</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">NetApp Storage-Optionen</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="ccb4d111a650d51ca9a8feb2542610be" category="paragraph">NetApp Storage kann innerhalb jedes der 3 gängigen Hyperscaler auf verschiedene Arten genutzt werden – entweder als angebundenen oder als ergänzender NFS-Datenspeicher –.</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">Bei Cloud-Lösungen von NetApp und VMware lassen sich viele Anwendungsfälle einfach in einem Hyperscaler nach Wahl implementieren. VMware definiert primäre Anwendungsfälle für Cloud-Workloads wie:</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">NetApp Lösungen für AWS/VMC</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">NetApp Lösungen für Azure/AVS</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Erfahren Sie mehr über die NetApp Lösungen für die Google Cloud Platform (GCP)/GCVE</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">Reihe von Blogs über Lösungsfunktionen für alle Inhalte zu NetApp Lösungen</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">NetApp Lösungen: Blogs</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">Überblick über die Blogs mit den wichtigsten Funktionen der zahlreichen NetApp Lösungen.</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">Künstliche Intelligenz</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Englisch</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;F:@facate_soultion_mktg=[AI,Analytics,Artificial-Intelligence]+[AI Blogs on NetApp.com]</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">KI-Blogs auf thePub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="open-title">Enterprise Database</block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Modernisieren Sie Ihren Oracle Datenbankbetrieb in der Hybrid Cloud mit Amazon FSX Storage</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">Hybrid-Cloud-Datenbanklösungen mit SnapCenter</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">Automatisieren Sie Ihre Oracle Datenbankinfrastruktur in der Hybrid Cloud</block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">Hybrid-Multi-Cloud mit VMware</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">Storage-Optimierung für Cloud-basierte VMware Implementierungen</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">Erste Schritte mit der Azure VMware Lösung mit NetApp basierten Cloud-Angeboten</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">Konfiguration der Hybrid Cloud mit FSX für NetApp ONTAP und VMware Cloud auf AWS SDDC mit VMware HCX</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp und VMware Cloud Foundation (VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">Teil 1: Erste Schritte</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">Teil 2: VCF- und ONTAP-Hauptspeicher</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">Teil 3: VCF und Element Hauptlagerung</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">Teil 4: ONTAP Tools für VMware und zusätzlicher Storage</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Astra DevOps – Anwendungsfälle:</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">Integrieren Sie mit NetApp Astra Control ganz einfach die Sicherung in Ihre Kubernetes CI/CD-Pipeline</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps mit NetApp: Nutzen Sie Astra Control zur Durchführung von Post-Mortem-Analysen und zur Wiederherstellung Ihrer Anwendung</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center: Die einfache Schaltfläche für das Datenmanagement Ihrer Applikation</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Installation von NetApp Trident auf Red hat OpenShift – so lösen Sie das Docker ‘toomanyanests Problem!</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="list-text"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">Beschleunigen Sie Ihren Kubernetes-Weg mit VMware Tanzu und ONTAP</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">&lt;Solution Name&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">Autor(en): &lt;Name&gt;, &lt;Titel&gt;, &lt;Unternehmen&gt;</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="section-title">Zweck</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">Diese Lösung eignet sich für folgende Anwendungsfälle:</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">&lt;Anwendungsfall 1&gt;</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">&lt;Anwendungsfall 2&gt; ...</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">&lt;Anwendungsfall n&gt;</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Zielgruppe</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">Die Lösung ist für &lt;Rolle&gt; bestimmt, die an &lt;Goal&gt; interessiert ist.</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">ODER</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">Diese Lösung eignet sich für folgende Komponenten:</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">&lt;Rolle&gt;, wer ist an &lt;Goal&gt;,</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">&lt;Rolle&gt;, wer ist an &lt;Goal&gt; interessiert.</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">Test-/Validierungsumgebung</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">Die Test-/Validierung dieser Lösung wurde in einem Labor durchgeführt, das in der endgültigen Implementierungsumgebung eventuell nicht übereinstimmt. Weitere Informationen finden Sie in den folgenden Abschnitten.</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">Diagramm Zur Lösungsarchitektur</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="example-title">Hardware-/Software-Komponenten</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Hardware*</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">&lt;Hardware-Name&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">&lt;Modell / Version&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">Weitere Informationen</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Software*</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">&lt;Software-Name&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">&lt;Version&gt;</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="example-title">Zusätzliche Anmerkungen</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">Hinweis 1</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">Hinweis 2 ...</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">Hinweis n</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">Die Implementierung dieser Lösung kann abgeschlossen werden:</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">Befolgen Sie die detaillierten Anweisungen mit Screenshots manuell.</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">Sie können die Schritte manuell durchführen, indem Sie zusammen mit Videos die Schritte anzeigen, die ausgeführt werden sollen, oder</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">Befolgen Sie automatisch die Anweisungen im Abschnitt Automatisierung.</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">Detaillierte Anweisungen</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">Schritt 1: &amp;Lt;beschreibende STEP Name&amp;gt;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">Aufgabe 1</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">Aufgabe 2 ...</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">Aufgabe n</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">Schritt 2: &amp;Lt;beschreibende STEP Name&amp;gt;</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">Schritt n: &amp;Lt;beschreibende STEP Name&amp;gt;</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">Video-Präsentation</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">&lt;Details zum Video(e) hier angeben&gt;</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">Automatisierte Implementierung</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">&lt;Hier die automatisierten Schritte/Prozesse/Videos einfügen&gt;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">Andere Implementierungsoptionen</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">&amp;Lt;Beschreibung der Option 1&amp;gt;</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">&lt;Geben Sie hier Details zur Option ein.&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">&amp;Lt;Beschreibung der Option 2&amp;gt;</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">&amp;Lt;Beschreibung der Option n&amp;gt;</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">Beschreibung des Dokuments</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">Beschreibung eines anderen Dokuments</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Hier finden Sie eine Videoserie und Demos, in der die Funktionen vieler NetApp Lösungen vorgestellt werden</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp Lösungen: Videos und Demos</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Überblick über die Videos und Demos, in denen die Besonderheiten vieler NetApp Lösungen hervorgehoben werden.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">NetApp KI-Lösungen</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">Enterprise-Applikationen und -Datenbanken</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">SQL Hochverfügbarkeits-Cluster auf Azure NetApp Files</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">Klonen Sie Mit Der Oracle Multi-Tenant Pluggable Database Unter Verwendung Von Storage Snapshots</block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Automatisierte Oracle 19c RAC-Implementierung auf FlexPod mit Ansible</block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*Fallstudie*</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">SAP auf Azure NetApp Files</block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="example-title">Hybrid-Multi-Cloud (HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[Unterstreichung]#*Videos für AWS/VMC*#</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">VMware HCX Deployment and Configuration Setup für VMC</block>
  <block id="c6434a9743fb403cd78cd2d3a42d9683" category="video-title">VMotion Demonstration mit VMware HCX für VMC und FSxN</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">Demonstration zur Cold-Migration mit VMware HCX für VMC und FSxN</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[Unterstreichung]#*Videos für Azure/AVS*#</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">Demonstration zur Cold-Migration mit VMware HCX für AVS und ANF</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">VMotion-Demo mit VMware HCX für AVS und ANF</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">Massenmigration mit VMware HCX für AVS und ANF</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">VMware Video Collection</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">Container/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">NetApp mit Google Anthos Videos</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">NetApp with VMware Tanzu Videos</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">Videos von NetApp für DevOps</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">Videos von NetApp mit Red hat OpenShift</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="example-title">Lösungsautomatisierung</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Auf dieser Seite wird die Splunk Architektur beschrieben. Kerndefinitionen sind Splunk Distributed-Implementierungen, Splunk SmartStore, Datenfluss, Hardware- und Softwareanforderungen, Anforderungen an einzelne Standorte und mehrere Standorte usw.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk Architektur</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">Früher: Flexible StorageGRID Funktionen für Splunk SmartStore</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Schlüsseldefinitionen</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">In den nächsten beiden Tabellen werden die bei der verteilten Splunk Implementierung verwendeten Splunk und NetApp Komponenten aufgelistet.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">In dieser Tabelle werden die Hardwarekomponenten von Splunk Enterprise für die verteilte Konfiguration aufgelistet.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk Komponente</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexer</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Repository für Splunk Enterprise-Daten</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Universal-Spediteur</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Verantwortlich für die Datenaufnahme und Weiterleitung von Daten an die Indexer</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">Suche Kopf</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">Das Front-End des Benutzers, das zum Suchen von Daten in Indexern verwendet wird</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Cluster-Master</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Management der Splunk Installation von Indexern und Suchköpfen</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Monitoring Console</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Zentrales Monitoring-Tool, das in der gesamten Implementierung zum Einsatz kommt</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Lizenzmaster</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">Mit dem Lizenzmaster werden Splunk Enterprise-Lizenzen verarbeitet</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Bereitstellungsserver</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Aktualisiert Konfigurationen und verteilt Anwendungen auf Verarbeitungskomponenten</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Storage-Komponente</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">All-Flash-Storage für das Management häufig abgerufene Daten Auch als lokaler Speicher bekannt.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">S3 Objekt-Storage für das Management von Daten mit warmen Tiers Verwendet von SmartStore, um Daten zwischen der Tiers mit heißen und warmen Funktionen zu verschieben. Auch Remote Storage bekannt</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">In dieser Tabelle werden die Komponenten in der Splunk Storage-Architektur aufgelistet.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Verantwortliche Komponente</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Bietet Indexer die Möglichkeit, Daten vom lokalen Storage bis zum Objekt-Storage zu verschieben.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Heiß</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Der Landeport, an dem universelle Spediteure neu geschriebene Daten platzieren. Storage kann beschrieben werden, und Daten sind durchsuchbar. Diese Daten-Tier besteht normalerweise aus SSDs oder schnellen HDDs.</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Cache Manager</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Managt den lokalen Cache indizierter Daten, ruft bei einer Suche warme Daten aus dem Remote-Storage ab und entfernt selten genutzte Daten aus dem Cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Warm</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Daten werden logisch zum Bucket gerollt und zuerst vom Hot-Tier in den „warm“-Tier umbenannt. Daten innerhalb dieser Tier werden geschützt, und wie die Hot Tier können aus SSDs oder HDDs mit höherer Kapazität bestehen. Mithilfe gemeinsamer Datensicherheitslösungen werden sowohl inkrementelle als auch vollständige Backups unterstützt.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Verteilte Splunk Implementierungen</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Um größere Umgebungen zu unterstützen, in denen Daten von mehreren Maschinen stammen, müssen große Datenvolumina verarbeitet werden. Wenn viele Benutzer die Daten durchsuchen müssen, können Sie die Implementierung skalieren, indem Sie Splunk Enterprise Instanzen auf mehrere Maschinen verteilen. Dies wird als verteilte Implementierung bezeichnet.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">In einer typischen verteilten Implementierung führt jede Splunk Enterprise-Instanz eine spezielle Aufgabe durch und befindet sich auf einer von drei Verarbeitungsebenen, die den wichtigsten Verarbeitungsfunktionen entsprechen.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">In der folgenden Tabelle sind die Splunk Enterprise-Verarbeitungsstufen aufgelistet.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Ebene</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Dateneingabe</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Spediteur</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Ein Spediteur nimmt Daten auf und leitet die Daten dann an eine Gruppe von Indexern weiter.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indizierung</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Ein Indexer indiziert eingehende Daten, die normalerweise von einer Gruppe von Spediteuren empfangen werden. Der Indexer wandelt die Daten in Ereignisse um und speichert die Ereignisse in einem Index. Der Indexer durchsucht auch die indizierten Daten als Reaktion auf Suchanfragen von einem Suchkopf.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Suchmanagement</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Ein Suchkopf dient als zentrale Ressource für die Suche. Die Suchköpfe in einem Cluster sind austauschbar und haben von jedem Mitglied des Such-Head-Clusters Zugriff auf die gleichen Suchen, Dashboards, Wissensobjekte usw.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">In der folgenden Tabelle sind die wichtigen Komponenten aufgeführt, die in einer verteilten Splunk Enterprise-Umgebung verwendet werden.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Verantwortung</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Index-Cluster-Master</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Koordiniert Aktivitäten und Updates eines Indexer-Clusters</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Indexmanagement</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Indexcluster</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Gruppe der Splunk Enterprise-Indexer, die konfiguriert sind, um Daten miteinander zu replizieren</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Suchkopf-Implementierung</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Übernimmt die Implementierung und Updates für den Cluster-Master</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Suchkopfverwaltung</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Search Head Cluster</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Gruppe von Suchköpfen, die als zentrale Ressource für die Suche dienen</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Balancer Laden</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Wird von geclusterten Komponenten verwendet, um eine steigende Nachfrage durch Suchköpfe, Indexer und S3 Ziel zu bewältigen, um die Last über Cluster-Komponenten zu verteilen.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Lastmanagement für Cluster-Komponenten</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Die folgenden Vorteile von verteilten Splunk Enterprise-Implementierungen:</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Zugriff auf unterschiedliche oder verteilte Datenquellen</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Bereitstellung von Funktionen, die den Datenanforderungen von Unternehmen jeder Größe und Komplexität gerecht werden</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Hochverfügbarkeit und Disaster Recovery mit Datenreplizierung und standortübergreifenden Implementierungen</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore ist eine Indexer-Funktion, die es Remote-Objektspeichern wie Amazon S3 zum Speichern indizierter Daten ermöglicht. Wenn das Datenvolumen einer Implementierung zunimmt, übersteigt die Storage-Nachfrage in der Regel die Nachfrage nach Computing-Ressourcen. Mit SmartStore können Sie Ihre Indexer-Storage- und Computing-Ressourcen kostengünstig managen, indem Sie diese Ressourcen separat skalieren.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore stellt eine Remote-Storage-Ebene und einen Cache-Manager ein. Diese Funktionen ermöglichen es, Daten entweder lokal auf Indexern oder auf der Remote-Speicherebene zu speichern. Der Cache-Manager verwaltet die Datenverschiebung zwischen dem Indexer und dem Remote-Storage-Tier, der auf dem Indexer konfiguriert ist.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Mit SmartStore können Sie den Storage-Platzbedarf der Indexer auf ein Minimum reduzieren und I/O-optimierte Computing-Ressourcen auswählen. Die meisten Daten befinden sich im Remote-Storage. Der Indexer pflegt einen lokalen Cache, der minimale Datenmengen enthält: Hot Buckets, Kopien von „warmen“ Buckets, die an aktiven oder kürzlich durchgeführten Suchen beteiligt sind, und Bucket-Metadaten.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Datenfluss mit Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Wenn Daten, die aus verschiedenen Quellen stammen, die Indexer erreichen, werden sie indiziert und lokal in einem Hot-Bucket gespeichert. Der Indexer repliziert außerdem die Hot-Bucket-Daten in Ziel-Indexer. Bisher ist der Datenfluss identisch mit dem Datenfluss für nicht-SmartStore-Indizes.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Wenn der Hot-Bucket zu „warm“ geht, wird der Datenfluss umgeleitet. Der Indexer der Quelle kopiert den warmen Bucket auf den Remote-Objektspeicher (Remote-Storage-Tier), während die vorhandene Kopie im Cache verbleiben, da Suchen häufig über kürzlich indizierte Daten hinweg ausgeführt werden. Die Ziel-Indexer löschen jedoch ihre Kopien, da der Remote-Speicher hohe Verfügbarkeit bietet, ohne mehrere lokale Kopien zu behalten. Die Master-Kopie des Buckets befindet sich jetzt im Remote-Speicher.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">Die folgende Abbildung zeigt den Datenfluss mit Splunk SmartStore.</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Der Cache-Manager auf dem Indexer ist zentral für den SmartStore-Datenfluss. Je nach Bedarf werden Kopien der Buckets aus dem Remote-Store abgerufen, um Suchanfragen zu bearbeiten. Außerdem entfernt es ältere oder weniger durchsuchte Kopien der Buckets aus dem Cache, da die Wahrscheinlichkeit, dass sie bei der Suche teilnehmen, im Laufe der Zeit abnimmt.</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">Der Job des Cache-Managers besteht darin, die Verwendung des verfügbaren Caches zu optimieren und gleichzeitig sicherzustellen, dass Suchvorgänge sofortigen Zugriff auf die benötigten Buckets haben.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">In der folgenden Tabelle sind die Softwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Je nach den Anforderungen des Kunden können die in einer beliebigen Implementierung dieser Lösung verwendeten Softwarekomponenten abweichen.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Produktfamilie</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Produktname</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Produktversion</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID Objekt-Storage</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise mit SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Anforderungen an einen einzelnen Standort und mehrere Standorte</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">In einer Splunk Enterprise-Umgebung (mittlere und große Implementierungen), in der Daten auf vielen Machines stammen und bei der viele Benutzer die Daten durchsuchen müssen, können Sie Ihre Implementierung skalieren, indem Sie Splunk Enterprise-Instanzen auf einzelne oder mehrere Standorte verteilen.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">In der folgenden Tabelle werden die in einer verteilten Splunk Enterprise-Umgebung verwendeten Komponenten aufgeführt.</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">Gruppe von Splunk Enterprise Indexern, die für die Replikation der Daten des jeweils anderen konfiguriert sind</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Lastausgleich</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Lastmanagement für geclusterte Komponenten</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Diese Abbildung zeigt ein Beispiel für eine verteilte Implementierung an einem Standort.</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Diese Abbildung zeigt ein Beispiel für eine verteilte Implementierung an mehreren Standorten.</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">In den folgenden Tabellen ist die Mindestanzahl der Hardwarekomponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Die Hardwarekomponenten, die in speziellen Implementierungen der Lösung verwendet werden, können je nach den Anforderungen des Kunden variieren.</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">Unabhängig davon, ob Sie Splunk SmartStore und StorageGRID an einem einzelnen Standort oder an mehreren Standorten implementiert haben, werden alle Systeme über den StorageGRID GRID Manager über eine zentrale Konsole gemanagt. Weitere Informationen finden Sie im Abschnitt „Einfache Verwaltung mit Grid Manager“.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">In dieser Tabelle ist die Hardware aufgeführt, die für einen einzelnen Standort verwendet wird.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Festplatte</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Nutzbare Kapazität</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Hinweis</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Admin-Node und Load Balancer</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48, 8 TB (NL-SAS-HDD)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1 PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Remote Storage</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Diese Tabelle enthält die Hardware, die für eine standortübergreifende Konfiguration (pro Standort) verwendet wird.</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Admin-Node und Load Balancer</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID Load Balancer: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">Für Objekt-Storage ist die Verwendung eines Load Balancer erforderlich, um den Cloud-Storage-Namespace bereitzustellen. StorageGRID unterstützt den Lastausgleich von Drittanbietern wie F5 und Citrix. Viele Kunden entscheiden sich jedoch für StorageGRID Balancer der Enterprise-Klasse, um Einfachheit, Ausfallsicherheit und hohe Performance zu erzielen. Der StorageGRID Load Balancer ist als VM, Container oder speziell entwickelte Appliance verfügbar.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">Der StorageGRID SG1000 erleichtert die Nutzung von Hochverfügbarkeitsgruppen (HA) und intelligentem Lastausgleich für S3-Datenpfadverbindungen. Kein anderes Objekt-Storage-System vor Ort bietet einen angepassten Load Balancer.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">Die SG1000-Appliance bietet folgende Funktionen:</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Ein Load Balancer und optional Administrator-Node-Funktionen für ein StorageGRID-System</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">StorageGRID Appliance Installer zur Vereinfachung der Implementierung und Konfiguration von Nodes</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Vereinfachte Konfiguration von S3-Endpunkten und SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Dedizierte Bandbreite (im Vergleich zur Freigabe eines Load Balancer eines Drittanbieters mit anderen Applikationen)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Bis zu 4 x 100 GB/s aggregierte Ethernet-Bandbreite</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">Das folgende Bild zeigt die SG1000 Gateway Services Appliance.</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">Die StorageGRID SG6060 Appliance umfasst einen Computing-Controller (SG6060) und ein Storage-Controller-Shelf (E-Series E2860), das zwei Storage-Controller und 60 Laufwerke enthält. Dieses Gerät bietet die folgenden Funktionen:</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Skalieren Sie vertikal auf bis zu 400 PB in einem Single Namespace.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Bis zu 4x 25 Gbit/s aggregierte Ethernet-Bandbreite.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Umfasst das Installationsprogramm von StorageGRID Appliance zur Vereinfachung der Bereitstellung und Konfiguration von Nodes.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Jede SG6060 Appliance kann ein oder zwei zusätzliche Erweiterungs-Shelfs für insgesamt 180 Laufwerke enthalten.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Zwei E-Series E2800 Controller (Duplexkonfiguration) für die Unterstützung von Storage-Controller-Failover</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Shelf mit fünf Einschüben für Festplatten mit 60 3.5-Zoll-Laufwerken (zwei Solid State-Laufwerke und 58 NL-SAS-Laufwerke).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">Das folgende Bild zeigt die SG6060-Appliance.</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Design von Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">In der folgenden Tabelle ist die Splunk Konfiguration für einen einzelnen Standort aufgeführt.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Kerne</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Speicher</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 Kerne</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Verwaltet die Benutzerdaten</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">User Front End sucht Daten in Indexern</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Verarbeitet Updates für Search Head Cluster</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Management der Splunk Installation und Indexer</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Überwachungskonsole und Lizenzmaster</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Führt ein zentralisiertes Monitoring der gesamten Splunk Implementierung durch und managt Splunk Lizenzen</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">In den folgenden Tabellen wird die Splunk Konfiguration für standortübergreifende Konfigurationen beschrieben.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">In dieser Tabelle ist die Splunk Konfiguration für eine standortübergreifende Konfiguration (Standort A) aufgeführt.</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Verantwortlich für die Datenaufnahme und Weiterleitung von Daten an die Indexer.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Führt ein zentralisiertes Monitoring der gesamten Splunk Implementierung durch und managt Splunk Lizenzen.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">In dieser Tabelle ist die Splunk Konfiguration für eine standortübergreifende Konfiguration (Standort B) aufgeführt.</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">Weiter: SmartStore-Performance an einem Standort.</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DiCp ist ein natives Tool für große Intercluster- und Intracluster-Kopien. Der grundlegende Prozess von Hadoop DistCp ist ein typischer Backup Workflow, bei dem native Hadoop Tools wie MapReduce zum Kopieren von Hadoop Daten von einer HDFS Quelle auf ein entsprechendes Ziel verwendet wird.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop Datensicherung und NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">Zurück: Data Fabric von NetApp für Big-Data-Architektur.</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DiCp ist ein natives Tool für große Intercluster- und Intracluster-Kopien. Der in der Abbildung unten dargestellte grundlegende Hadoop DistCp-Prozess ist ein typischer Backup-Workflow, in dem native Hadoop Tools wie MapReduce zum Kopieren von Hadoop Daten von einer HDFS-Quelle auf ein entsprechendes Ziel verwendet werden. Durch den direkten Zugang zu NetApp NFS können Kunden NFS als Zieladresse für das Hadoop DistCp Tool einstellen, um die Daten von HDFS Quelle in eine NFS-Freigabe über MapReduce zu kopieren. Der direkte NetApp NFS-Zugriff fungiert als NFS-Treiber für das DistCp Tool.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">Weiter: Übersicht über Anwendungsfälle für Hadoop Datensicherung</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Dieser Abschnitt behandelt die Hardware und Software für die Confluent Zertifizierung. Diese Informationen sind auch für die Implementierung von Kafka mit NetApp Storage relevant.</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Früher: Best Practice-Richtlinien.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka Sizing kann mit vier Konfigurationsmodi durchgeführt werden: Einfache, granulare, Reverse und Partitionen.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Einfach</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">Der einfache Modus eignet sich für die ersten Apache Kafka-Anwender oder für die frühen Anwendungsfälle. Für diesen Modus stellen Sie Anforderungen wie Durchsatz MB/s, Lese-Fanout, Aufbewahrung und den Prozentsatz der Ressourcenauslastung bereit (standardmäßig 60 %). Auch die Umgebungen wechseln wie beispielsweise On-Premises (Bare-Metal, VMware, Kubernetes oder OpenStack) oder der Cloud. Basierend auf diesen Informationen bietet die Größenbemessung eines Kafka-Clusters die Anzahl der Server, die für den Broker, den Zookeeper, Apache Kafka Connect Workers, die Schemaregistrierung, einen REST Proxy, ksqlDB und das Confluent Control Center erforderlich sind.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Bei Tiered Storage empfiehlt es sich, den granularen Konfigurationsmodus zu verwenden, um einen Kafka Cluster zu bedimensionieren. Der granulare Modus eignet sich für erfahrene Anwender von Apache Kafka oder für klar definierte Anwendungsfälle. In diesem Abschnitt wird die Größe für Hersteller, Stream-Prozessoren und Verbraucher beschrieben.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Hersteller</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Um die Hersteller für Apache Kafka zu beschreiben (z. B. ein nativer Client, REST Proxy oder Kafka Connector), geben Sie folgende Informationen an:</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Name* Funke.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">*Producer-Typ.* Anwendung oder Dienst, Proxy (REST, MQTT, andere) und bestehende Datenbank (RDBMS, NOSQL, andere). Sie können auch wählen, "Ich weiß nicht."</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Durchschnittlicher Durchsatz.* bei Ereignissen pro Sekunde (z. B. 1,000,000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* Spitzendurchsatz.* bei Ereignissen pro Sekunde (4,000,000 zum Beispiel).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Durchschnittliche Nachrichtengröße.* in Byte, unkomprimiert (max. 1 MB; z. B. 1000).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">*Nachrichtenformat.* Optionen umfassen Avro, JSON, Protokollpuffer, Binärdateien, Text, „Ich weiß es nicht“ und andere.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Replikationsfaktor.* Optionen sind 1, 2, 3 (Confluent-Empfehlung), 4, 5, Oder 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Aufbewahrungszeit.* eines Tages (zum Beispiel). Wie lange sollen Ihre Daten in Apache Kafka gespeichert werden? Geben Sie -1 mit einer beliebigen Einheit für eine unendliche Zeit ein. Der Rechner nimmt eine Aufbewahrungszeit von 10 Jahren für unbegrenzte Aufbewahrung an.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Aktivieren Sie das Kontrollkästchen „Tiered Storage ermöglichen, um die Broker-Anzahl zu verringern und Infinite Storage zu ermöglichen?“</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Wenn Tiered Storage aktiviert ist, kontrollieren die Aufbewahrungsfelder den Hot Set von Daten, die lokal auf dem Broker gespeichert werden. Die Felder zur Aufbewahrung von Archivierung steuern, wie lange Daten im Objekt-Storage für die Archivierung gespeichert werden.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*Archivierung Speicherbindung.* ein Jahr (zum Beispiel). Wie lange möchten Sie, dass Ihre Daten im Archiv-Storage gespeichert werden? Geben Sie -1 mit einer beliebigen Einheit für eine unbegrenzte Dauer ein. Der Rechner geht von einer Aufbewahrung von 10 Jahren für unbegrenzte Aufbewahrung aus.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Wachstumsmultiplikator.* 1 (zum Beispiel). Wenn der Wert dieses Parameters auf dem aktuellen Durchsatz basiert, setzen Sie ihn auf 1. Wenn Sie die Größe basierend auf einem zusätzlichen Wachstum festlegen möchten, setzen Sie diesen Parameter auf einen Wachstumsmultiplikator.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Anzahl der Erzeugerinstanzen.* 10 (zum Beispiel). Wie viele Erzeugerinstanzen werden ausgeführt? Diese Eingabe ist erforderlich, um die CPU-Last in die Berechnung der Größenbemessung einzubeziehen. Ein Leerwert bedeutet, dass die CPU-Last nicht in die Berechnung einbezogen wird.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Anhand dieses Beispieleingangs hat die Größenbemessung folgende Auswirkungen auf die Hersteller:</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Durchschnittlicher Durchsatz in unkomprimierten Bytes: 1 Gbit/s Spitzendurchsatz in unkomprimierten Bytes: 4 GBit/s. Durchschnittlicher Durchsatz in komprimierten Bytes: 400 MBit/s. Spitzendurchsatz in komprimierten Bytes: 1,6 GBit/s. Dies basiert auf einer standardmäßigen Komprimierungsrate von 60 % (Sie können diesen Wert ändern).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Insgesamt erforderlicher Storage für Brokersatz: 31,104 TB einschließlich Replizierung, komprimiert Insgesamt erforderlicher Off-Broker-Archiv-Storage: 378,432 TB, komprimiert Nutzung <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> Für die StorageGRID-Dimensionierung.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Stream-Prozessoren müssen ihre Applikationen oder Services beschreiben, die Daten aus Apache Kafka verbrauchen und dann in Apache Kafka zurückproduzieren. In den meisten Fällen sind diese in ksqlDB oder Kafka-Bächen gebaut.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Name* Funkenstreamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Verarbeitungszeit.* wie lange dauert dieser Prozessor, um eine einzelne Nachricht zu verarbeiten?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (einfache, statusfreie Transformation) [Beispiel], 10 ms (statusfreier in-Memory-Betrieb).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (statusbehafteter Netzwerk- oder Festplattenbetrieb), 1000 ms (RUHEZUSTAND eines Drittanbieters).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">Ich habe diesen Parameter bewertet und weiß genau, wie lange es dauert.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Aufbewahrung der Ausgabe.* 1 Tag (Beispiel). Ein Stream-Prozessor produziert seine Ausgabe zurück an Apache Kafka. Wie lange sollen diese Ausgabedaten in Apache Kafka gespeichert werden? Geben Sie -1 mit einer beliebigen Einheit für eine unbegrenzte Dauer ein.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Aktivieren Sie das Kontrollkästchen „Tiered Storage ermöglichen, um die Broker-Anzahl zu verringern und Infinite Storage zu ermöglichen?“</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*Archivierung Speicherbindung.* 1 Jahr (zum Beispiel). Wie lange möchten Sie, dass Ihre Daten im Archiv-Storage gespeichert werden? Geben Sie -1 mit einer beliebigen Einheit für eine unbegrenzte Dauer ein. Der Rechner geht von einer Aufbewahrung von 10 Jahren für unbegrenzte Aufbewahrung aus.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Output Passthrough Prozentsatz.* 100 (zum Beispiel). Ein Stream-Prozessor produziert seine Ausgabe zurück an Apache Kafka. Welcher Prozentsatz des eingehenden Durchsatzes wird in Apache Kafka zurückeingegeben? Beispiel: Wenn der Eingangsdurchsatz 20 Mbit/s beträgt und dieser Wert 10 ist, beträgt der Ausgangsdurchsatz 2 Mbit/s.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">Von welchen Anwendungen wird das gelesen? Wählen Sie „Spark“, den Namen, der in der herstellerspezifischen Dimensionierung verwendet wird. Basierend auf dem obigen Input, können Sie die folgenden Auswirkungen der Dimensionierung auf Stream-Prozessor-Instanzen und Themen-Partition Schätzungen erwarten:</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Diese Stream-Prozessor-Anwendung erfordert die folgende Anzahl von Instanzen. Auch für die eingehenden Themen sind diese vielen Partitionen wahrscheinlich erforderlich. Kontaktieren Sie Confluent, um diesen Parameter zu bestätigen.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 für durchschnittlichen Durchsatz ohne Wachstumsmultiplikator</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4,000 für Spitzendurchsatz ohne Wachstumsmultiplikator</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 für durchschnittlichen Durchsatz mit einem Wachstumsmultiplikator</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4,000 für Spitzendurchsatz mit einem Wachstumsmultiplikator</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Verbraucher</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Beschreiben Sie Ihre Applikationen oder Services, die Daten aus Apache Kafka verbrauchen und keine Daten zurück in Apache Kafka liefern – beispielsweise einen nativen Client oder Kafka Connector.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Name* Kunde von Spark.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Bearbeitungszeit.* wie lange dauert der Verbraucher, um eine einzelne Nachricht zu verarbeiten?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (z. B. eine einfache und statusfreie Aufgabe wie Protokollierung)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (schnelles Schreiben auf einen Datenspeicher)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (langsame Schreibvorgänge auf einen Datenspeicher)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000 ms (ANRUF eines Drittanbieters)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Ein anderer Benchmark-Prozess bekannter Dauer.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Verbrauchertyp* Anwendung, Proxy oder auf einen vorhandenen Datastore absinken (RDBMS, NoSQL, andere).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">Von welchen Anwendungen wird das gelesen? Schließen Sie diesen Parameter an Hersteller und Stream-Größen an, die zuvor ermittelt wurden.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">Anhand der obigen Angaben müssen Sie die Größe für Verbraucherinstanzen und Schätzungen der Themenpartition ermitteln. Eine Verbraucheranwendung benötigt die folgende Anzahl von Instanzen.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2,000 für durchschnittlichen Durchsatz, kein Wachstumsmultiplikator</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8,000 für Spitzendurchsatz, kein Wachstumsmultiplikator</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2,000 für den durchschnittlichen Durchsatz, einschließlich Wachstums Multiplikator</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8,000 für Spitzendurchsatz, einschließlich Wachstumsmultiplikator</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Auch für die eingehenden Themen ist diese Anzahl von Partitionen wahrscheinlich erforderlich. Kontaktieren Sie Confluent, um die Bestätigung zu bestätigen.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">Zusätzlich zu den Anforderungen für Hersteller, Stream-Prozessoren und Verbraucher müssen Sie die folgenden zusätzlichen Anforderungen erfüllen:</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Wiederherstellungszeit.* zum Beispiel 4 Stunden. Wenn ein Apache Kafka Broker-Host ausfällt, gehen seine Daten verloren und ein neuer Host wird bereitgestellt, um den ausgefallenen Host zu ersetzen. Wie schnell muss dieser neue Host neu erstellt werden? Lassen Sie diesen Parameter leer, wenn der Wert unbekannt ist.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Ressourcenausnutzungsziel (Prozentsatz).* zum Beispiel 60. Wie ausgelastet sollen Ihre Hosts im Durchschnitt des Durchsatzes sein? Conflient empfiehlt eine Auslastung von 60 %, es sei denn, Sie verwenden Conflient Self-Balancing Cluster, in einem solchen Fall kann die Auslastung höher sein.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Beschreiben Sie Ihre Umgebung</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* Welche Umgebung wird Ihr Cluster ausführen?* Amazon Web Services, Microsoft Azure, Google Cloud Platform, Bare-Metal On Premises, VMware On Premises, OpenStack vor Ort oder Kubernates vor Ort?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Hostdetails.* Anzahl der Kerne: 48 (zum Beispiel), Netzwerkkartentyp (10 GbE, 40 GbE, 16 GbE, 1 GbE oder ein anderer Typ).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Speichervolumen.* Host: 12 (zum Beispiel). Wie viele Festplatten oder SSDs werden pro Host unterstützt? Confluent empfiehlt 12 Festplatten pro Host.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Speicherkapazität/Volumen (in GB).* 1000 (zum Beispiel). Wie viel Storage kann ein einzelnes Volume in Gigabyte speichern? Fließend empfiehlt 1-TB-Festplatten.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Speicherkonfiguration.* wie werden Storage Volumes konfiguriert? Confluent empfiehlt RAID10, alle Confluent Funktionen zu nutzen. JBOD, SAN, RAID 1, RAID 0, RAID 5, Weitere Typen werden ebenfalls unterstützt.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Single Volume Throughput (Mbps).* 125 (zum Beispiel). Wie schnell kann ein einzelnes Storage Volume in Megabyte pro Sekunde lesen oder schreiben? Confluent empfiehlt Standard-Festplatten, die in der Regel einen Durchsatz von 125 MB/s haben.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Speicherkapazität (GB).* 64 (zum Beispiel).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Wählen Sie Größe mein Cluster aus, nachdem Sie Ihre Umgebungsvariablen festgelegt haben. Anhand der oben genannten Beispielparameter haben wir für Confluent Kafka folgende Bemessungsparameter ermittelt:</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.* Broker zählen: 22. Der Cluster ist Storage-gebunden. Erwägen Sie die Aktivierung von Tiered Storage zur Reduzierung Ihrer Host-Anzahl und für skalierbaren Storage.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.* Anzahl: 5; Apache Kafka Connect Workers: Anzahl: 2; Schema Registry: Anzahl: 2; REST Proxy: Anzahl: 2; ksqlDB: Anzahl: 2; Confluent Control Center: Anzahl: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Für Plattform-Teams ohne Anwendungsfälle sollte der Reverse-Modus genutzt werden. Verwenden Sie den Partitions-Modus, um zu berechnen, wie viele Partitionen ein einzelnes Thema benötigt. Siehe<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> Für die Dimensionierung basierend auf dem Reverse-Modus und den Partitions-Modus.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 und Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="821c9e3ae35ae3b188264d2461cec030" category="paragraph">TR-4623 beschreibt die integrierte Architektur des Designs NetApp E-Series und Splunk. Optimiert für Storage-Verteilung auf die Nodes, Zuverlässigkeit, Performance, Storage-Kapazität und Dichte Dieses Design nutzt das Splunk Clustered Index-Node-Modell mit höherer Skalierbarkeit und niedrigeren Gesamtbetriebskosten. Die Trennung von Storage und Computing ermöglicht die getrennte Skalierung und spart so die Kosten einer Überprovisionierung. Darüber hinaus enthält dieses Dokument eine Zusammenfassung der Performance-Testergebnisse, die mit einem Splunk Tool zur Computerprotokoll-Simulation erzielt wurden.</block>
  <block id="7c65bf783488e992fb7c72bab3ddbbf2" category="inline-link-macro"><block ref="7c65bf783488e992fb7c72bab3ddbbf2" category="inline-link-rx"></block></block>
  <block id="145793ae401011691a99a02e5087ba8a" category="paragraph"><block ref="145793ae401011691a99a02e5087ba8a" category="inline-link-macro-rx"></block></block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Dieser Verifizierungstest erreichte einen Tiering-Durchsatz von 31,74 GB/s bei einem NetApp ONTAP Storage Controller.</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">Früher: Richtlinien zur Performance Best Practice.</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Dieser Verifizierungstest erreichte einen Tiering-Durchsatz von 31.74 GB/s bei Conflient mit dem NetApp ONTAP Storage Controller.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Was ist Confluent?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-Sink Parameterdetails</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 in ONTAP Best Practices</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3-Objekt-Storage-Management</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">September 2022</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">In dieser Validierung verwendeten wir vier Server als NSD-Server (Network Shared Disk), um physische Laufwerke für GPFS bereitzustellen. GPFS wird auf den NSD-Laufwerken erstellt, um sie als NFS-Exporte zu exportieren, sodass NFS-Clients auf sie zugreifen können, wie in der Abbildung unten gezeigt. Wir haben XCP verwendet, um die Daten aus dem GPFS- exportierten NFS in ein NetApp NFS-Volume zu kopieren.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS zu NetApp ONTAP-NFS</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">Früher: Data Mover-Lösung für KI.</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Grundlagen des GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Die folgenden Node-Typen werden in GPFS verwendet:</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Admin-Knoten.* gibt ein optionales Feld mit einem Knotennamen an, der von den Administrationsbefehlen zur Kommunikation zwischen Knoten verwendet wird. Beispiel: Der Admin-Node<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> Könnte eine Netzwerkprüfung an alle anderen Knoten im Cluster weiterleiten.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Quorum Node.* bestimmt, ob ein Knoten im Pool von Knoten enthalten ist, aus denen Quorum abgeleitet wird. Sie benötigen mindestens einen Node als Quorum-Node.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Manager Node.* gibt an, ob ein Knoten Teil des Node-Pools ist, aus dem Dateisystemmanager und Token-Manager ausgewählt werden können. Es ist eine gute Idee, mehr als einen Knoten als einen Manager-Knoten zu definieren. Wie viele Knoten Sie als Manager festlegen, hängt vom Workload und der Anzahl der GPFS-Serverlizenzen ab. Wenn Sie große parallele Jobs ausführen, benötigen Sie möglicherweise mehr Manager-Knoten als in einem Cluster mit vier Knoten, das eine Web-Anwendung unterstützt.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD Server.* der Server, der jede physische Festplatte für die Verwendung mit GPFS vorbereitet.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Protokollknoten.* der Knoten, der GPFS-Daten direkt über jedes SSH-Protokoll (Secure Shell) mit dem NFS teilt. Für diesen Knoten ist eine GPFS-Serverlizenz erforderlich.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Liste der Vorgänge für GPFS, NFS und XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Dieser Abschnitt enthält eine Liste der Vorgänge, die GPFS erstellen, GPFS als NFS-Export exportieren und die Daten mithilfe von XCP übertragen.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS erstellen</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Gehen Sie zum Erstellen von GPFS wie folgt vor:</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Laden Sie den Datenzugriff für die Linux-Version auf einem der Server auf einer Spectrum-Scale-Lösung herunter, und installieren Sie ihn.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installieren Sie das Voraussetzungspaket (z. B. Chef) in allen Knoten und deaktivieren Sie Security-Enhanced Linux (SELinux) in allen Knoten.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Richten Sie den Installationsknoten ein, und fügen Sie den Admin-Knoten und den GPFS-Knoten zur Cluster-Definitionsdatei hinzu.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Fügen Sie den Manager-Knoten, den Quorum-Knoten, die NSD-Server und den GPFS-Knoten hinzu.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Fügen Sie die GUI-, Admin- und GPFS-Knoten hinzu, und fügen Sie bei Bedarf einen zusätzlichen GUI-Server hinzu.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Fügen Sie einen weiteren GPFS-Knoten hinzu, und überprüfen Sie die Liste aller Knoten.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Geben Sie einen Clusternamen, ein Profil, eine Remote-Shell-Binärdatei, eine Binärdatei und einen Portbereich an, der auf allen GPFS-Knoten in der Cluster-Definitionsdatei festgelegt werden soll.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Zeigen Sie die GPFS-Konfigurationseinstellungen an, und fügen Sie einen zusätzlichen Admin-Node hinzu.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Deaktivieren Sie die Datenerfassung, und laden Sie das Datenpaket auf das IBM Support Center hoch.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Aktivieren Sie NTP und überprüfen Sie die Konfigurationen vor der Installation.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Konfiguration, Erstellung und Prüfung der NSD-Festplatten</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Erstellen Sie das GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Montieren Sie das GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Prüfen und geben Sie die erforderlichen Berechtigungen für das GPFS an.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Prüfen Sie das GPFS-Lesen und Schreiben, indem Sie das ausführen<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS in NFS exportieren</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">So exportieren Sie das GPFS in NFS:</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exportieren Sie GPFS als NFS über das<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installieren Sie die erforderlichen NFS-Server-Pakete.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Starten Sie den NFS-Service.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Listen Sie die Dateien im GPFS auf, um den NFS-Client zu validieren.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Konfigurieren Sie den NFS-Client</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Gehen Sie wie folgt vor, um den NFS-Client zu konfigurieren:</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exportieren Sie das GPFS als NFS über das<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Starten Sie die NFS-Client-Dienste.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Mounten Sie das GPFS über das NFS-Protokoll auf dem NFS-Client.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Überprüfen Sie die Liste der GPFS-Dateien im angehängten NFS-Ordner.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Verschieben Sie die Daten mit XCP von GPFS, exportiertes NFS zu NetApp NFS.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">GPFS-Dateien auf dem NFS-Client validieren.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">Als Nächstes: HDFS und MapR-FS auf ONTAP NFS</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">NetApp moderne Data-Analytics-Lösungen sind eine Sammlung strategischer und technologischer Funktionen, die die Funktionen von NetApp Storage im gesamten KI-Bereich demonstrieren.</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">NetApp Lösungen für moderne Datenanalysen</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Auf dieser Seite werden die Best Practices zur Verbesserung der Performance in dieser Lösung beschrieben.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Leitfaden zu Best Practices für die Performance</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">Zurück: Performance-Tests mit Produce-Consume Workload Generator</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Verwenden Sie für ONTAP, wenn möglich, EINE GET-Größe &gt;=1MB.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Zunehmende<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> Und<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> In<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> Mit Broker Nodes können Sie größere Tiering-Aktivitäten zur S3 Tier drängen. Diese Ergebnisse sind mit<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> Und<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> Auf 32 einstellen.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3-Buckets sollten für acht Komponenten pro Mitgliedaggregat verwendet werden.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Ethernet-Links für den S3-Datenverkehr sollten auf Storage und Client möglichst eine MTU von 9.000 verwenden.</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Dieser Abschnitt enthält eine ausführliche Beschreibung der Anwendungsfälle für die Datensicherung, die den Schwerpunkt dieses Dokuments bilden. Die verbleibenden Abschnitte enthalten ausführlichere Angaben zu den einzelnen Anwendungsfällen, z. B. zum Kundenproblem (Szenario), den Anforderungen und Herausforderungen sowie zu Lösungen.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Übersicht über Anwendungsfälle für die Datensicherung in Hadoop</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">Früher Hadoop Datensicherung und NetApp.</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="817ac2975197bd6c376a7918a798981f" category="section-title">Anwendungsfall 1: Sichern von Hadoop Daten</block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">In diesem Use Case konnte ein großes Finanzinstitut mit in-Place-Analyse die Zeit, in der die langen Backup-Zeitfenster von über 24 Stunden auf weniger als wenige Stunden verkürzt wurden.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="section-title">Anwendungsfall 2: Backup und Disaster Recovery aus der Cloud in On-Premises-Systeme</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">Durch den Einsatz der Data Fabric von NetApp als Bausteine konnte ein großes Rundfunkunternehmen seine Anforderung erfüllen, Backups von Cloud-Daten auf seinem lokalen Datacenter zu erstellen, je nach unterschiedlichen Übertragungsmodi wie On-Demand, unmittelbar Oder auf Basis der Hadoop/Spark-Cluster-Last</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="section-title">Anwendungsfall 3: Enabling DevTest on Existing Hadoop Data</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp Lösungen halfen einem Online-Musikdistributor, schnell mehrere platzsparende Hadoop Cluster in verschiedenen Niederlassungen aufzubauen, um mithilfe von geplanten Richtlinien Berichte zu erstellen und tägliche DevTest-Aufgaben auszuführen.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="section-title">Anwendungsfall 4: Datensicherung und Multi-Cloud-Konnektivität</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Ein großer Service-Provider nutzte die Data Fabric von NetApp, um seinen Kunden aus verschiedenen Cloud-Instanzen Multi-Cloud-Analysen zu liefern.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="section-title">Anwendungsfall 5: Schnellere Analyse-Workloads</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">Eine der größten Finanzdienstleistungsbanken und Investmentbanken setzte die Network-Attached Storage-Lösung von NetApp ein, um die I/O-Wartezeit zu verringern und die Plattform für quantitative Finanzanalysen zu beschleunigen.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">Weiter: Anwendungsfall 1 – Sicherung von Hadoop Daten.</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Moderne Datenanalysen – unterschiedliche Lösungen für verschiedene Analysestrategien</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">In diesem Whitepaper werden die Strategien der modernen NetApp Datenanalyselösungen vorgestellt. Sie enthält detaillierte Informationen zu den Geschäftsergebnissen, Kundenherausforderungen, Technologietrends, alten Mitbewerbern-Architekturen, modernen Workflows, Anwendungsfälle, Branchen, Cloud, Technologiepartner, Data Mover, NetApp Active IQ, NetApp DataOps Toolkit, Hadoop to Spark, softwaredefinierter Storage mit NetApp Astra Control, Containern, Enterprise-Datenmanagement, Archivierung und Tiering zum Erreichen der Ziele von KI und Analytics und wie NetApp und Kunden gemeinsam die Datenarchitektur modernisieren.</block>
  <block id="ef159076e3a244c9e0bc48cdde7742a7" category="inline-link-macro"><block ref="ef159076e3a244c9e0bc48cdde7742a7" category="inline-link-rx"></block></block>
  <block id="bff0b3c76158c2ffdc1105de3c094296" category="paragraph"><block ref="bff0b3c76158c2ffdc1105de3c094296" category="inline-link-macro-rx"></block></block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">Die Data Fabric von NetApp vereinfacht und integriert Datenmanagement für Cloud- und On-Premises-Umgebungen, um die digitale Transformation zu beschleunigen. Die Data Fabric von NetApp bietet konsistente und integrierte Datenmanagement-Services und -Applikationen (Bausteine) für Datentransparenz und -Einblicke, Datenzugriff und -Kontrolle sowie Datensicherung und -Sicherheit.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data Fabric von NetApp für Big Data-Architekturen</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">Die Data Fabric von NetApp vereinfacht und integriert Datenmanagement für Cloud- und On-Premises-Umgebungen, um die digitale Transformation zu beschleunigen.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">Die Data Fabric von NetApp bietet konsistente und integrierte Datenmanagement-Services und -Applikationen (Bausteine) für Datentransparenz und -Einblicke, Datenzugriff und -Kontrolle sowie Datensicherung und -Sicherheit, wie in der folgenden Abbildung dargestellt.</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Bewährte Data-Fabric-Anwendungsfälle von Kunden</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">Die Data Fabric von NetApp bietet Kunden die folgenden neun bewährten Anwendungsfälle:</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Schnellere Analyse-Workloads</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Beschleunigung der DevOps-Transformation</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Aufbau von Cloud-Hosting-Infrastrukturen</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Integration von Cloud-Datenservices</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Schutz und Sicherheit für Daten</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimierung unstrukturierter Daten</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Datacenter-Effizienzgewinne</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Einblicke aus Daten und Datenkontrolle</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Vereinfachung und Automatisierung</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Dieses Dokument umfasst zwei der neun Anwendungsfälle (zusammen mit den zugehörigen Lösungen):</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Direkter Zugriff über NetApp NFS</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">Das NetApp NFS Direct Access (ehemals NetApp in-Place-Analysemodul) (siehe Abbildung unten) ermöglicht Kunden die Ausführung von Big-Data-Analytics-Jobs auf ihren vorhandenen oder neuen NFSv3- oder NFSv4-Daten, ohne die Daten zu verschieben oder zu kopieren. Es verhindert mehrere Datenkopien und macht die Synchronisierung der Daten mit einer Quelle überflüssig. Im Finanzsektor beispielsweise muss der Wechsel von Daten von einem Ort zu einem anderen Ort gesetzlichen Verpflichtungen nachkommen, was keine leichte Aufgabe ist. In diesem Szenario analysiert der direkte NetApp NFS-Zugriff die Finanzdaten vom ursprünglichen Standort. Ein weiterer entscheidender Vorteil besteht darin, dass der NetApp NFS Direct Access die Sicherung von Hadoop Daten mithilfe nativer Hadoop Befehle vereinfacht und Workflows zur Datensicherung mithilfe des umfassenden Datenmanagement-Portfolios von NetApp ermöglicht.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">Der direkte NetApp NFS-Zugriff bietet zwei Arten von Implementierungsoptionen für Hadoop/Spark Cluster:</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Die Hadoop/Spark-Cluster verwenden standardmäßig Hadoop Distributed File System (HDFS) für den Datenspeicher sowie das Standard-Filesystem. Der direkte NetApp NFS-Zugriff ersetzt das Standard-HDFS durch NFS-Storage als Standard-Filesystem, sodass direkte Analysevorgänge bei NFS-Daten möglich sind.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">Bei einer weiteren Implementierungsoption unterstützt der direkte NetApp NFS-Zugriff die Konfiguration von NFS als zusätzlichen Storage zusammen mit HDFS in einem einzelnen Hadoop/Spark-Cluster. In diesem Fall kann der Kunde Daten über NFS-Exporte teilen und gemeinsam mit HDFS-Daten vom selben Cluster aus darauf zugreifen.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Zu den wichtigsten Vorteilen des direkten NetApp NFS-Zugriffs gehören:</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analysiert die Daten vom aktuellen Speicherort, um das Zeit- und Performance-zeitaufwendige Verschieben von Analysedaten in eine Hadoop Infrastruktur wie HDFS zu vermeiden.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Reduziert die Anzahl der Replikate von drei auf eins.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Ermöglicht Benutzern die Trennung von Computing und Storage, um sie unabhängig voneinander zu skalieren.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Datensicherung der Enterprise-Klasse durch Nutzung der umfassenden Datenmanagementfunktionen von ONTAP</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Ist für die Hortonworks Datenplattform zertifiziert.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Ermöglicht Implementierung von hybriden Datenanalysen</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Verringerung der Backup-Zeit durch Nutzung der dynamischen Multithread-Funktion</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Bausteine für Big Data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">Die Data Fabric von NetApp integriert Datenmanagement-Services und -Applikationen (Bausteine) für Datenzugriff, Kontrolle, Sicherung und Sicherheit, wie in der Abbildung unten dargestellt.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Die Abbildung oben beinhaltet folgende Bausteine:</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">*NetApp NFS Direct Access.* bietet die neuesten Hadoop und Spark Cluster mit direktem Zugriff auf NetApp NFS Volumes ohne zusätzliche Software- oder Treiberanforderungen.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">*NetApp Cloud Volumes ONTAP und Cloud-Volume-Services.* softwaredefinierter vernetzter Storage auf Basis von ONTAP, der in Amazon Web Services (AWS) oder Azure NetApp Files (ANF) in Microsoft Azure Cloud-Services ausgeführt wird.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">*NetApp SnapMirror Technologie*. Bietet Datensicherungsfunktionen zwischen lokalen und ONTAP Cloud oder NPS Instanzen.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Cloud-Service-Provider.* zu diesen Anbietern gehören AWS, Microsoft Azure, Google Cloud und IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.* Cloud-basierte Analyseservices wie Amazon Elastic MapReduce (EMR) und Databricks in AWS sowie Microsoft Azure HDInsight und Azure Databricks.</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">Nächster Schritt: Datensicherung mit Hadoop und NetApp.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">In diesen Einstellungen zeigen wir Ihnen, wie man Themen aus Kafka direkt über den Kafka s3 Waschbecken im Objekt-Storage liest und schreibt. Für diesen Test haben wir einen eigenständigen Confluent Cluster verwendet, dieses Setup gilt jedoch für einen verteilten Cluster.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Fließender s3-Anschluss</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Früher: Performance-Tests mit Skalierbarkeit.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Der Amazon S3 Sink Connector exportiert Daten von Apache Kafka Themen entweder im Avro-, JSON- oder Byte-Format in S3-Objekte. Der Amazon S3 Sink Connector fragt regelmäßig Daten aus Kafka ab und lädt sie wiederum nach S3 hoch. Ein Partitioner wird verwendet, um die Daten jeder Kafka-Partition in Stücke zu teilen. Jeder Datenblock wird als S3-Objekt dargestellt. Der Schlüsselname kodiert das Thema, die Kafka-Partition und den Start-Offset dieses Datenblocks.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Laden Sie Confluent Kafka von der Confluent Website herunter.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Packen Sie das Paket in einen Ordner auf Ihrem Server aus.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exportieren Sie zwei Variablen.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Für ein eigenständiges Confluent Kafka Setup erstellt der Cluster einen temporären Stammordner in<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>. Es erstellt auch Zookeeper, Kafka, eine Schemaregistrierung, connect, einen ksql-Server, Control-Center Ordner und kopiert ihre jeweiligen Konfigurationsdateien von<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>. Das folgende Beispiel zeigt:</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Zookeeper Konfigurieren. Sie müssen nichts ändern, wenn Sie die Standardparameter verwenden.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">In der obigen Konfiguration haben wir die aktualisiert<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> Eigenschaft. Standardmäßig benötigen Sie drei Zookeeper für die Auswahl von Kafka Leader.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Wir haben eine myid-Datei in erstellt<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> Mit einer eindeutigen ID:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Wir haben die letzte Anzahl von IP-Adressen für die myid-Datei verwendet. Für Kafka wurden Standardwerte verwendet: Connect, Control Center, Kafka, Kafka-Rest, Konfiguration von ksql-Server und Schema-Registry</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Starten Sie die Kafka-Dienste.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Für jede Konfiguration gibt es einen Protokollordner, der die Fehlerbehebung erleichtert. In einigen Fällen nehmen Services mehr Zeit zum Start in Anspruch. Stellen Sie sicher, dass alle Services betriebsbereit sind.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installieren Sie Kafka Connect mit<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block>.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">Sie können eine bestimmte Version auch mithilfe von installieren<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Standardmäßig ist<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> Ist in installiert<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Aktualisieren Sie den Plug-in-Pfad mit dem neuen<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Beenden Sie die Confluent-Dienste, und starten Sie sie neu.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Konfigurieren Sie die Zugriffs-ID und den geheimen Schlüssel im<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Vergewissern Sie sich, dass der Bucket erreichbar ist.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Konfigurieren der s3-Sink-Eigenschaftendatei für die s3- und Bucket-Konfiguration</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importieren Sie einige Datensätze in den s3-Bucket.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Den s3-Spülkörper-Anschluss einlegen.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Überprüfen Sie den s3-Sink-Status.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Prüfen Sie das Protokoll, um sicherzustellen, dass s3-Sink bereit ist, Themen zu akzeptieren.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Informieren Sie sich in Kafka über die Themen.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Überprüfen Sie die Objekte im s3-Bucket.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Um den Inhalt zu überprüfen, kopieren Sie jede Datei von S3 in Ihr lokales Dateisystem, indem Sie den folgenden Befehl ausführen:</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache Archives</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Um die Datensätze zu drucken, verwenden Sie avro-tools-1.11.0.1.jar (verfügbar im<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>).</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">Als Nächstes: Conflient Self-Rebalancing Cluster.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">In einem Big-Data-Cluster werden die Daten in HDFS oder HCFS gespeichert, z. B. MapR-FS, Windows Azure Storage Blob, S3 oder Google Filesystem. Wir haben Tests mit HDFS, MapR-FS und S3 als Quelle durchgeführt, um Daten mithilfe von NIPAM in den NetApp ONTAP-NFS-Export zu kopieren. Dazu verwenden wir den hadoop-Distcp-Befehl des Quellsystems.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">Früher: Herausforderungen für Kunden.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">In einem Big-Data-Cluster werden die Daten in HDFS oder HCFS gespeichert, z. B. MapR-FS, Windows Azure Storage Blob, S3 oder Google Filesystem. Wir haben die Tests mit HDFS, MapR-FS und S3 als Quelle durchgeführt, um Daten mithilfe von NIPAM in den NetApp ONTAP-NFS-Export zu kopieren<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl aus der Quelle.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Das folgende Diagramm zeigt die typische Datenverschiebung von einem Spark-Cluster mit HDFS-Storage auf ein NetApp ONTAP-NFS-Volume, sodass NVIDIA KI-Vorgänge verarbeiten kann.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Der<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl kopiert die Daten über das MapReduce-Programm. NIPAM funktioniert mit MapReduce als Treiber für den Hadoop Cluster beim Kopieren der Daten. NIPAM kann eine Last für einen Export über mehrere Netzwerkschnittstellen verteilen. Dieser Prozess maximiert den Netzwerkdurchsatz, indem die Daten beim Kopieren der Daten von HDFS oder HCFS auf NFS über mehrere Netzwerkschnittstellen verteilt werden.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM wird nicht mit MapR unterstützt oder zertifiziert.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">Next: Data Mover Solution for KI.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Bei dieser Lösung hat NetApp die Migration von Daten von Data Lake (HDFS) und MapR Cluster-Daten zu ONTAP NFS validiert. Die Daten residierten in MapR-FS und HDFS. NetApp XCP führte ein neues Feature ein, das die Daten direkt von einem verteilten Dateisystem wie HDFS und MapR-FS in ONTAP NFS migriert.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS und MapR-FS auf ONTAP NFS</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">Früher: GPFS zu NetApp ONTAP NFS.</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">Bei dieser Lösung hat NetApp die Migration von Daten von Data Lake (HDFS) und MapR Cluster-Daten zu ONTAP NFS validiert. Die Daten residierten in MapR-FS und HDFS. NetApp XCP führte ein neues Feature ein, das die Daten direkt von einem verteilten Dateisystem wie HDFS und MapR-FS in ONTAP NFS migriert. XCP verwendet asynchrone Threads und HDFS C-API-Aufrufe zur Kommunikation und Übertragung von Daten aus MapR- FS sowie HDFS. Die folgende Abbildung zeigt die Datenmigration von Data Lake (HDFS) und MapR-FS zu ONTAP NFS. Mit dieser neuen Funktion, müssen Sie nicht die Quelle als NFS-Share exportieren.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Warum wechseln Kunden von HDFS und MapR-FS zu NFS?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">Die meisten Hadoop Distributionen wie Cloudera und Hortonworks verwenden HDFS und MapR Distributionen verwendet zum Speichern von Daten ihr eigenes Filesystem namens MapR-FS. HDFS- und MapR-FS-Daten bieten Data Scientists wertvolle Einblicke, die in Machine Learning (ML) und Deep Learning (DL) verwendet werden können. Die Daten in HDFS und MapR-FS werden nicht gemeinsam genutzt, d. h. sie können nicht von anderen Applikationen verwendet werden. Kunden sind auf der Suche nach gemeinsam genutzten Daten, insbesondere im Bankensektor, in dem vertrauliche Kundendaten von mehreren Applikationen genutzt werden. Die neueste Version von Hadoop (3.x oder höher) unterstützt die NFS-Datenquelle, auf die ohne zusätzliche Software von Drittanbietern zugegriffen werden kann. Bei der neuen NetApp XCP Funktion können die Daten direkt von HDFS und MapR-FS auf NetApp NFS verschoben werden, um den Zugriff auf mehrere Applikationen zu ermöglichen</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Der Test wurde in Amazon Web Services (AWS) durchgeführt, um die Daten von MapR-FS zu NFS für den anfänglichen Performance-Test mit 12 MAPR Nodes und 4 NFS Servern zu übertragen.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Größe</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">VCPU</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Netzwerk</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS-Server</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">I3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488 gib</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">7500 x NVMe-SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR Nodes</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384 gib</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe-SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Nach den ersten Tests erhielten wir einen Durchsatz von 20 Gbit/s und konnten 2 PB pro Tag an Daten übertragen.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863: TR-4863: Best-Practice Guidelines for NetApp XCP - Data Mover, File Migration and Analytics</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">Weitere Informationen zur HDFS-Datenmigration ohne HDFS-Export in NFS finden Sie im Abschnitt „Implementierungsschritte – NAS“ in<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">Als Nächstes: Geschäftliche Vorteile.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">In diesem Abschnitt werden die Erfahrungen aus dieser Zertifizierung vorgestellt.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Best Practices-Richtlinien</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">Früher: Confluent Self-Rebalancing Cluster.</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Basierend auf unserer Validierung ist S3 Objekt-Storage ideal für Conflient, um Daten zu speichern.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Wir können SAN mit hohem Durchsatz (speziell FC) verwenden, um den Broker häufig verwendete Daten oder lokale Festplatten zu erhalten, da wir in der Conflient Tiered Storage-Konfiguration, Die Größe der im Datenvermittler-Verzeichnis enthaltenen Daten richtet sich nach der Segmentgröße und der Aufbewahrungszeit, wenn die Daten in den Objekt-Storage verschoben werden.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Objektspeicher bieten eine bessere Performance, wenn Segment.Bytes höher ist. Wir haben 512 MB getestet.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">In Kafka wird die Länge des Schlüssels oder Wertes (in Bytes) für jeden Datensatz, der zum Thema produziert wird, durch das gesteuert<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> Parameter. Bei StorageGRID hat sich die Performance bei der Aufnahme und Wiederherstellung von S3-Objekten auf höhere Werte erhöht. 512 Byte sorgte beispielsweise für einen Abruf von 5,8 GB/s, 1024 Bytes sorgten für einen s3-Abruf von 7,5 GB/s und 2048 Bytes für fast 10 GB/s.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">In der folgenden Abbildung sind die S3-Objektaufnahme und -Abruf basierend auf dargestellt<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Kafka Tuning.* um die Performance von Tiered Storage zu verbessern, können Sie TierFetcherNumThreads und TierArchivNumThreads erhöhen. Als allgemeine Richtlinie möchten Sie TierFetcherNumThreads erhöhen, um mit der Anzahl der physischen CPU-Kerne zu übereinstimmen und TierArchivNumThreads auf die Hälfte der CPU-Kerne zu erhöhen. Wenn Sie zum Beispiel in den Servereigenschaften eine Maschine mit acht physischen Kernen haben, setzen Sie confluent.Tier.fetcher.num.threads = 8 und confluent.Tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Zeitintervall für Thema löscht.* Wenn ein Thema gelöscht wird, beginnt das Löschen der Log-Segment-Dateien im Objektspeicher nicht sofort. Stattdessen gibt es ein Zeitintervall mit einem Standardwert von 3 Stunden, bevor das Löschen dieser Dateien erfolgt. Sie können die Konfiguration confluent.tier.topic.delete.check.interval.ms ändern, um den Wert dieses Intervalls zu ändern. Wenn Sie ein Thema oder Cluster löschen, können Sie die Objekte auch manuell im jeweiligen Bucket löschen.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*ACLs auf internen Tiered Storage-Themen.* eine Best Practice für On-Premises-Implementierungen ist die Aktivierung einer ACL-Autorisierung für die internen Themen für Tiered Storage. Legen Sie ACL-Regeln fest, um den Zugriff auf diese Daten nur dem Broker-Benutzer zu beschränken. Dies sichert interne Themen und verhindert nicht autorisierten Zugriff auf Tiered Storage-Daten und Metadaten.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Ersetzen Sie den Benutzer<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> Mit dem eigentlichen Brokerchef in Ihrer Implementierung</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Beispiel: Der Befehl<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> Legt ACLs zum internen Thema für Tiered Storage fest. Derzeit gibt es nur ein einziges internes Thema im Zusammenhang mit Tiered Storage. Das Beispiel erstellt eine ACL, die die Hauptberechtigung von Kafka für alle Vorgänge im internen Thema erhält.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">Als Nächstes: Dimensionierung.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="b1567dc4fc97586a9f0b9a3cc9b7fafa" category="doc">NVA-1157-DEPLOY: Apache Spark Workload mit NetApp Storage-Lösung</block>
  <block id="a9828ed348eedd7a35b76de35fda7796" category="paragraph">NVA-1157-DEPLOY beschreibt die Performance- und Funktionvalidierung von Apache Spark SQL auf NetApp NFS AFF Storage-Systemen. Es werden die Konfigurations-, Architektur- und Performance-Tests auf Basis verschiedener Szenarien sowie Empfehlungen für den Einsatz von Spark mit NetApp ONTAP Datenmanagement-Software besprochen. Außerdem werden die Testergebnisse auf Basis mehrerer Festplatten (JBOD) im Vergleich zum NetApp AFF A800 Storage Controller erfasst.</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-macro"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="b2bbcfd654a3dd74458969dc7e877cd4" category="paragraph"><block ref="b2bbcfd654a3dd74458969dc7e877cd4" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">In diesem Szenario wurde die Analyseplattform einer großen Finanzdienstleistungsbank und einer Investmentbank mit der NetApp NFS Storage-Lösung modernisiert, um erhebliche Verbesserungen bei der Analyse von Investitionsrisiken und Derivaten für ihr Asset Management und ihren quantitativen Geschäftsbereich zu erzielen.</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">Zurück: Anwendungsfall 4: Datensicherung und Multi-Cloud-Konnektivität.</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Szenario</block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">In der bestehenden Umgebung des Kunden nutzte die für die Analyseplattform verwendete Hadoop Infrastruktur den internen Storage der Hadoop Server. Aufgrund der proprietären JBOD-Umgebung konnten viele interne Kunden innerhalb des Unternehmens ihr quantitatives Modell von Monte Carlo nicht nutzen, eine Simulation, die auf den wiederkehrenden Proben von Echtzeitdaten beruht. Die suboptimale Fähigkeit, die Auswirkungen der Unsicherheit auf die Marktbewegungen zu verstehen, diente dem Geschäftsbereich quantitative Vermögensverwaltung als ungünstig.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">Anforderungen und Herausforderungen zu bewältigen</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">Die quantitative Geschäftseinheit der Bank wollte eine effiziente Prognosemethode, um präzise und zeitnahe Vorhersagen zu treffen. Das Team erkannte daher, dass eine Modernisierung der Infrastruktur nötig ist, die bestehende I/O-Wartezeit reduziert und die Performance bei Analyseapplikationen wie Hadoop und Spark verbessert wird, um Investitionsmodelle effizient zu simulieren, potenzielle Gewinne zu messen und Risiken zu analysieren.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Nutzen</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">Der Kunde hatte JBOD die vorhandene Spark-Lösung. Anschließend wurden NetApp ONTAP, NetApp StorageGRID und Minio Gateway auf NFS genutzt, um die I/O-Wartezeit für die quantitative Finanzgruppe der Bank zu verringern, die Simulationen und Analysen zu Investitionsmodellen ausführt, die potenzielle Gewinne und Risiken bewerten. Zeigt die Spark-Lösung mit NetApp Storage.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Wie in der obigen Abbildung gezeigt, wurden AFF A800, A700 Systeme und StorageGRID implementiert, um über die NFS- und S3-Protokolle auf Parkett-Dateien in einem Hadoop-Cluster mit sechs Nodes mit Spark sowie YARN- und Hive-Metadaten-Services für den Datenanalyse-Betrieb zuzugreifen.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">Eine Direct-Attached Storage-Lösung (das) in der alten Kundenumgebung hatte den Nachteil, dass Computing und Storage unabhängig voneinander skaliert werden mussten. Mit der NetApp ONTAP Solution für Spark konnte die Geschäftseinheit der Bank für Finanzanalyse Storage von Computing-Ressourcen entkoppeln und Infrastrukturressourcen nach Bedarf nahtlos effizienter bereitstellen.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">ONTAP mit NFS wurden die Computing-Server-CPUs nahezu vollständig für Spark SQL-Jobs genutzt, sodass die I/O-Wartezeit um fast 70 % reduziert wurde. Dadurch verbessert sich die Computing-Leistung und die Performance für Spark-Workloads. Mit der höheren CPU-Auslastung konnte der Kunde dann auch GPUs wie GPUDirect nutzen, um eine weitere Plattformmodernisierung zu ermöglichen. Darüber hinaus bietet StorageGRID eine kostengünstige Storage-Option für Spark-Workloads, und Minio Gateway bietet über das S3-Protokoll sicheren Zugriff auf NFS-Daten. Für Ihre Daten in der Cloud empfiehlt NetApp Cloud Volumes ONTAP, Azure NetApp Files und NetApp Cloud Volumes Service.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Auf dieser Seite werden die Komponenten beschrieben, die zur Fertigstellung dieser Lösung verwendet werden, einschließlich NetApp StorageGRID, Splunk Enterprise und Splunk SmartStore.</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">Weiter: Intelligentes Tiering und Kosteneinsparungen.</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID ist eine hochperformante und kostengünstige Objekt-Storage-Plattform. Die Lösung bietet intelligentes, richtlinienbasiertes globales Datenmanagement unter Verwendung einer verteilten, Node-basierten Grid-Architektur. Dank des universellen globalen Objekt-Namespace, der komplexe Datenmanagement-Funktionen vereint, vereinfacht es das Management von unstrukturierten Daten im Petabyte-Bereich und Milliarden von Objekten. Der Zugriff auf einzelne Objekte ist über alle Standorte hinweg möglich und vereinfacht Hochverfügbarkeitsarchitekturen bei kontinuierlichem Objektzugriff unabhängig von Standort- oder Infrastrukturausfällen.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">Dank Mandantenfähigkeit können mehrere Applikationen für unstrukturierte Cloud- und Enterprise-Daten sicher im selben Grid gewartet werden. Dies erhöht den ROI und die Anwendungsfälle für StorageGRID. Unternehmen haben die Möglichkeit, diverse Service-Level mit metadatengestützten Objekt-Lebenszyklus-Richtlinien zu erstellen. Auf diese Weise lassen sich Langlebigkeit, Schutz und Performance an mehreren Standorten optimieren. Benutzer können Richtlinien anpassen und die Datenlandschaft unterbrechungsfrei neu ausrichten, wenn sich ihre Anforderungen ändern.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore nutzt StorageGRID als Remote-Storage-Tier und ermöglicht Kunden die Implementierung mehrerer geografisch verteilter Standorte für zuverlässige Verfügbarkeit und Langlebigkeit, die als einzelner Objekt-Namespace dargestellt werden. So kann Splunk SmartStore von der hohen Performance, der hohen Kapazität von StorageGRID und der Möglichkeit profitieren, mithilfe einer einzelnen URL zur Interaktion mit den Objekten auf Hunderte von Nodes an mehreren physischen Standorten zu skalieren. Diese einzelne URL sorgt außerdem für unterbrechungsfreie Storage-Erweiterung, Upgrades und Reparaturen – sogar über einen einzelnen Standort hinaus. Die StorageGRID Policy Engine für das Datenmanagement optimiert Performance- und Datenaufbewahrungszeit und die Erfüllung der Anforderungen an die Datenlokalität.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, ein führendes Unternehmen bei der Sammlung und Analyse von maschinell generierten Daten, vereinfacht und modernisiert DIE IT durch seine Funktionen zur betrieblichen Analyse. Darüber hinaus werden damit auch Business-Analysen, Sicherheit und IoT-Anwendungsfälle expandiert. Storage ist ein wichtiger Faktor für eine erfolgreiche Splunk Softwareimplementierung.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Maschinell generierte Daten sind der am schnellsten wachsende Typ von Big Data. Das Format ist unvorhersehbar und stammt aus vielen verschiedenen Quellen, oft mit hohen Raten und großen Volumen. Diese Workload-Eigenschaften werden oft als digitale Abgase bezeichnet. Splunk SmartStore hilft, diese Daten sinnvoll zu nutzen, und bietet intelligentes Daten-Tiering, um heiße und warme Daten auf der kostengünstigsten Storage-Tier optimal abzulegen.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore ist eine Indexer-Funktion, die Objekt-Storage (auch als Remote-Storage- oder Remote-Storage-Tiers bezeichnet) nutzt, z. B. StorageGRID zum Speichern von warmen Daten mithilfe des S3-Protokolls.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">Mit dem zunehmenden Datenvolumen einer Implementierung übersteigt die Storage-Nachfrage in der Regel die Nachfrage nach Computerressourcen. Mit SmartStore können Sie Ihre Indexer-Storage- und Computing-Ressourcen kostengünstig managen, indem Sie Computing und Storage separat skalieren.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore führt über das S3-Protokoll und einen Cache-Manager eine Remote-Storage-Ebene ein. Diese Funktionen ermöglichen es, Daten entweder lokal auf Indexern oder auf Remote-Speicher zu speichern. Der Cache-Manager im Indexer verwaltet die Datenverschiebung zwischen dem Indexer und der Remote-Storage-Tier. Die Daten werden gemeinsam mit Bucket-Metadaten in Buckets („heiße“ und „warme“) gespeichert.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Mit SmartStore können Sie den Storage-Bedarf der Indexer auf ein Minimum reduzieren und I/O-optimierte Computing-Ressourcen auswählen, da sich die meisten Daten auf der Remote-Storage-Tier befinden. Der Indexer verwaltet einen lokalen Cache, der die minimale Datenmenge darstellt, die erforderlich ist, um die angeforderten und prognostizierten Ergebnisse zurückzugeben. Der lokale Cache enthält Buckets, Kopien von Buckets, die an aktiven oder kürzlich durchgeführten Suchen beteiligt sind, und Bucket-Metadaten.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Mit Splunk SmartStore mit StorageGRID können Kunden die Umgebung inkrementell und mit leistungsstarkem und kostengünstigem Remote-Storage skalieren und gleichzeitig die Gesamtlösung mit hoher Flexibilität erweitern. Dadurch können Kunden jederzeit jeder beliebigen Menge Komponenten (Hot-Storage und/oder S3-Warmspeicher) in beliebiger Menge hinzufügen, ganz gleich, ob mehr Indexer benötigt, die Datenaufbewahrung geändert wird oder die Aufnahmerate ohne Unterbrechungen erhöht werden kann.</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">Als Nächstes: Flexible StorageGRID Funktionen für Splunk SmartStore</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">In diesem Dokument wird beschrieben, wie Daten aus Big-Data-Analysen und HPC-Systemen (High-Performance-Computing) verschoben und in AI-Workflows (künstliche Intelligenz) genutzt werden können. KI verarbeitet NFS-Daten in der Regel durch NFS-Exporte. Möglicherweise liegen die KI-Daten jedoch auf einer Plattform für Big-Data-Analysen und High-Performance-Computing (HPC) vor. Dies können Hadoop Distributed File System (HDFS), ein Binary Large Object (Blob), S3 Storage oder das General Parallel File System (GPFS) von IBM sein. In diesem Dokument beschreiben wir, wie Daten von einer Big-Data-Analyseplattform und GPFS mit Hadoop-nativen Befehlen, dem NetApp in-Place Analytics Module (NIPAM) und NetApp XCP verschoben werden. In diesem Dokument werden außerdem die geschäftlichen Vorteile erläutert, die das Verschieben von Daten von Big Data und HPC hin zur KI mit sich bringt.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Dieser Abschnitt fasst dieses Dokument zu den NetApp Storage-Lösungen für Apache Spark zusammen.</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">Früher: Python-Skripte für jeden größeren Anwendungsfall.</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">In diesem Dokument befassen wir uns mit der Apache Spark Architektur, mit Kundenanwendungsfällen und dem NetApp Storage-Portfolio, bezogen auf Big Data, moderne Analysen sowie KI, ML und DL. Bei unseren Performance-Validierungstests, die auf branchenüblichen Benchmark-Tools und Kundennachfrage basieren, haben die NetApp Spark-Lösungen eine überragende Performance im Vergleich zu nativen Hadoop Systemen gezeigt. Anhand einer Kombination aus in diesem Bericht vorgestellten Kundenanwendungsfällen und Performance-Ergebnissen können Sie eine passende Spark-Lösung für Ihre Implementierung auswählen.</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">In diesem Abschnitt werden die detaillierten Schritte aufgeführt, die erforderlich sind, um GPFS zu konfigurieren und Daten mithilfe von NetApp XCP in NFS zu verschieben.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS zu NFS - detaillierte Schritte</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">Früher: Geschäftsvorteile.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Konfigurieren Sie GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Laden Sie Spectrum Scale Data Access für Linux auf einem der Server herunter und installieren Sie ihn.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installieren Sie das Voraussetzungspaket (einschließlich Chef und Kernel Header) auf allen Knoten.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Deaktivieren Sie SELinux in allen Knoten.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Richten Sie den Installations-Node ein.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Fügen Sie den Admin-Knoten und den GPFS-Knoten zur Cluster-Definitionsdatei hinzu.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Fügen Sie den Manager-Knoten und den GPFS-Knoten hinzu.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Fügen Sie den Quorum-Knoten und den GPFS-Knoten hinzu.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Fügen Sie die NSD-Server und den GPFS-Knoten hinzu.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Fügen Sie die GUI-, Admin- und GPFS-Nodes hinzu.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Fügen Sie einen weiteren GUI-Server hinzu.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Fügen Sie einen weiteren GPFS-Knoten hinzu.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Alle Nodes überprüfen und auflisten.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Geben Sie einen Cluster-Namen in der Cluster-Definitionsdatei an.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Geben Sie das Profil an.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Geben Sie die Remote-Shell-Binärdatei an, die vom GPFS verwendet werden soll; verwenden Sie<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Geben Sie die Binärdatei an, die vom GPFS verwendet werden soll; verwenden<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Geben Sie den für alle GPFS-Knoten zu eingestellten Portbereich an; verwenden Sie<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Zeigen Sie die GPFS-Konfigurationseinstellungen an.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Fügen Sie einen Admin-Node hinzu.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Aktivieren Sie NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Vor der Installation die Konfigurationen überprüfen.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Konfigurieren Sie die NSD-Festplatten.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Erstellen Sie die NSD-Festplatten.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Überprüfen Sie den Status der NSD-Festplatte.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Prüfen und geben Sie die erforderlichen Berechtigungen für das GPFS an.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Prüfen Sie das GPFS Lesen und Schreiben, indem Sie das ausführen<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">So exportieren Sie GPFS in NFS:</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Listen Sie die Dateien in GPFS auf, um den NFS-Client zu validieren.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Konfigurieren Sie den NFS-Client</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installieren Sie Pakete im NFS-Client.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Die Liste der GPFS-Dateien im angehängten Ordner NFS validieren.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Verschieben Sie die Daten mit XCP vom GPFS- exportierten NFS zum NetApp NFS.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">Nächste: MapR-FS auf ONTAP NFS</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">In diesem Anwendungsfall muss der Kunde schnell und effizient neue Hadoop/Spark-Cluster erstellen, die auf einem vorhandenen Hadoop-Cluster basieren und große Mengen an Analysedaten für DevTest und Reporting-Zwecke im selben Datacenter und an Remote-Standorten enthalten sind.</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">Zurück: Anwendungsfall 2: Backup und Disaster Recovery von der Cloud in On-Premises-Systeme.</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">Bei diesem Szenario wurden mehrere Spark/Hadoop-Cluster aus einer umfangreichen Hadoop-Data-Lake-Implementierung vor Ort und an Disaster-Recovery-Standorten erstellt.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Zu den wesentlichen Anforderungen und Herausforderungen dieses Anwendungsfalls gehören:</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Erstellen Sie mehrere Hadoop Cluster für DevTest, QA oder jeden anderen Zweck, für den Zugriff auf dieselben Produktionsdaten erforderlich ist. Die Herausforderung besteht hier darin, einen sehr großen Hadoop Cluster mehrmals unmittelbar und äußerst platzsparend zu klonen.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Synchronisieren Sie Hadoop Daten mit DevTest- und Reporting-Teams, um betriebliche Effizienz zu erzielen.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Verteilen Sie Hadoop Daten mit denselben Anmeldedaten über Produktions- und neue Cluster.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Verwenden Sie geplante Richtlinien, um effizient QA-Cluster zu erstellen, ohne das Produktions-Cluster zu beeinträchtigen.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone Technologie wird zur Erfüllung der soeben beschriebenen Anforderungen verwendet. Die FlexClone Technologie ist die Kopie einer Snapshot Kopie für Lese-/Schreibzugriffe. Die Daten werden aus den Daten der übergeordneten Snapshot Kopie gelesen, und verbraucht nur zusätzlichen Speicherplatz für neue/geänderte Blöcke. Sie ist schnell und platzsparend.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Zunächst wurde eine Snapshot Kopie des vorhandenen Clusters mithilfe einer NetApp Konsistenzgruppe erstellt.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">Snapshot Kopien innerhalb von NetApp System Manager oder der Eingabeaufforderung für den Storage-Administrator Die Snapshot Kopien der Konsistenzgruppen sind applikationskonsistente Snapshot Kopien von Gruppen, und das FlexClone Volume wird basierend auf Snapshot Kopien der Konsistenzgruppen erstellt. Es ist erwähnenswert, dass ein FlexClone Volume die NFS-Exportrichtlinie des übergeordneten Volume übernimmt. Nach der Erstellung der Snapshot Kopie muss für DevTest und Reporting ein neuer Hadoop Cluster installiert werden, wie in der Abbildung unten dargestellt. Das in-Place-Analysemodul greift über in-Place-Analytics-Module-Benutzer und Gruppenautorisierung für die NFS-Daten auf das geklonte NFS-Volume vom neuen Hadoop-Cluster zu.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">Um einen ordnungsgemäßen Zugriff zu haben, muss das neue Cluster die gleiche UID und die gleiche GUID für die Benutzer haben, die in den in-Place Analytics Module-Benutzern und Gruppenkonfigurationen konfiguriert wurden.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Dieses Bild zeigt den Hadoop Cluster für DevTest.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">Als Nächstes: Anwendungsfall 4: Datensicherung und Multi-Cloud-Konnektivität</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp verfügt über drei Storage-Portfolios: FAS/AFF, E-Series und Cloud Volumes ONTAP. Wir haben AFF und die E-Series mit ONTAP Storage-System für Hadoop Lösungen mit Apache Spark validiert. Die Data Fabric von NetApp integriert Datenmanagementservices und Applikationen (Bausteine) für Datenzugriff, Kontrolle, Schutz und Sicherheit.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark-Lösungen im Überblick</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">Früher: Lösungstechnologie.</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">NetApp verfügt über drei Storage-Portfolios: FAS/AFF, E-Series und Cloud Volumes ONTAP. Wir haben AFF und die E-Series mit ONTAP Storage-System für Hadoop Lösungen mit Apache Spark validiert. Die Data Fabric von NetApp integriert Datenmanagement-Services und -Applikationen (Bausteine) für Datenzugriff, Kontrolle, Sicherung und Sicherheit, wie in der Abbildung unten dargestellt.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Die Data-Fabric-Strategie bietet Datenmanagementservices und Applikationen.</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">*NetApp NFS Direct Access.* bietet die neuesten Hadoop und Spark Cluster mit direktem Zugriff auf NetApp NFS Volumes ohne zusätzliche Software- oder Treiberanforderungen.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">*NetApp SnapMirror Technologie.* bietet Datensicherungsfunktionen zwischen On-Premises-Umgebungen und ONTAP Cloud oder NPS Instanzen.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">In der folgenden Abbildung ist die Spark-Lösung mit NetApp Storage dargestellt.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Zündende Lösung mit NetApp Storage</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">Die ONTAP Spark Lösung verwendet das NetApp NFS Direct-Access-Protokoll für in-Place-Analysen sowie KI-, ML- und DL-Workflows, wobei auf vorhandene Produktionsdaten zugegriffen wird. Produktionsdaten, die Hadoop-Nodes zur Verfügung stehen, werden exportiert, um in-Place-Analysen und KI-, ML- und DL-Jobs auszuführen. Die Daten können in Hadoop Nodes entweder mit direkt oder ohne NetApp NFS verarbeitet werden. In Spark mit dem Standalone oder<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Cluster Manager, Sie können ein NFS-Volume mithilfe von konfigurieren<block ref="9e2ac298651bd7b0cfb93c36f03ec623" prefix=" " category="inline-code"></block>. Wir haben drei Anwendungsfälle mit unterschiedlichen Datensätzen validiert. Die Details dieser Validierungen finden Sie im Abschnitt „Testergebnisse“. (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">Abbildung: Die Positionierung von NetApp Apache Spark/Hadoop Storage</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Positionierung von NetApp Apache Spark/Hadoop Storage</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Es wurden die einzigartigen Funktionen der E-Series Spark-Lösung, die All Flash FAS/FAS ONTAP Spark-Lösung und die StorageGRID Spark-Lösung identifiziert und detaillierte Validierungen und Tests durchgeführt. Basierend auf unseren Beobachtungen empfiehlt NetApp die E-Series Lösung für Greenfield-Installationen und neue skalierbare Implementierungen. Die All Flash FAS/FAS Lösung für in-Place-Analysen, KI-, ML- und DL-Workloads nutzt dabei vorhandene NFS-Daten sowie StorageGRID für AI, ML und DL sowie moderne Datenanalysen, wenn Objekt-Storage benötigt wird.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Empfohlene NetApp Lösungen für Spark</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Ein Data Lake ist ein Storage-Repository für große Datensätze in nativer Form, das für Analytics-, KI-, ML- und DL-Jobs verwendet werden kann. Wir haben ein Data-Lake-Repository für die E-Series, All Flash FAS/FAS und StorageGRID SG6060 Spark Lösungen erstellt. Das E-Series System bietet HDFS Zugriff auf das Hadoop Spark-Cluster, während auf vorhandene Produktionsdaten über das NFS-Direktzugriffsprotokoll auf den Hadoop-Cluster zugegriffen wird. Für Datensätze, die sich im Objekt-Storage befinden, bietet NetApp StorageGRID sicheren Zugriff über S3 und S3A.</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">Weiter: Zusammenfassung der Anwendungsfälle.</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Dieses Dokument enthält Best Practice-Richtlinien zum Einsatz von Kafka mit NetApp Storage. Hierzu zählen Conflient Kafka Zertifizierungstests, Performance-Ergebnisse, Tuning, Kafka Connectors und die Funktion zur selbstständigen Ausbalancierung.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">Zurück: Dimensionierung.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Dieses Dokument enthält Best Practices für die Verwendung von Confluent Tiered Storage mit NetApp Storage, einschließlich Verifizierungstests, Tiered Storage-Performance-Ergebnissen, Tuning, Conflient S3-Konnektoren und der Self-Balancing-Funktion. Der NetApp StorageGRID Objekt-Storage zieht ILM-Richtlinien in Betracht, bietet fließende Performance mit mehreren Performance-Tests zur Verifizierung und S3 APIs nach Branchenstandard. Dies ist eine optimale Wahl für Conflient Tiered Storage.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Was ist Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Infinite Storage in Conflient Plattform</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage – Best Practices und Sizing</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Amazon S3 Spülenanschluss für Confluent Platform</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka – Größen</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID Dimensionierung</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Anwendungsfälle für Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Kafka-Cluster mit Selbstausgleich in Plattform 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">Dezember 2021</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Dieser Abschnitt behandelt die Hardware und Software, die für die Performance-Verifizierung in der Conflient Platform Implementierung mit NetApp ONTAP für Tiered Storage verwendet werden. In der folgenden Tabelle werden die Lösungsarchitektur und die Basiskomponenten behandelt.</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Der AFF A900 Storage Controller von ONTAP, der zusammen mit dem fließenden Speicher betrieben wird, sind verteilte Systeme für Datenströme. Beide Systeme sind horizontal skalierbar und fehlertolerant und bieten unter Last eine hervorragende Performance. Sie ergänzen sich gegenseitig in der verteilten Datenstreaming und der Stream-Verarbeitung und senken dabei die Storage-Kosten mithilfe von Datenreduzierungstechnologien, die den Platzbedarf von Daten minimieren. Der AFF A900 Storage-Controller bietet eine hervorragende Performance und ermöglicht gleichzeitig die Abkopplung von Computing- und Storage-Ressourcen. Dies vereinfacht die Systemadministration und ermöglicht die unabhängige Skalierung von Ressourcen.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Abbildung der Lösungsübersicht.</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">Details zur Lösungsarchitektur</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Plattformkomponente</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Umgebungskonfiguration</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent Platform Version 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 x Zookeeper</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 x Broker Server</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5-mal Tools-Server</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x Kontrollzentrum</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Betriebssystem auf allen Knoten</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (ubuntu 18.04)</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP für Buckets</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 AFF A900 HA-Paar (High Availability, Hochverfügbarkeit</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSDs</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3-Protokoll</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100 GbE</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 Fujitsu PRIMERGY RX2540 Server</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 CPUs; 16 physische Kerne insgesamt</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 GB physischer Speicher</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Dual-Port mit 100 GbE</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">Diese Seite beschreibt die Performance von Splunk SmartStore auf einem NetApp StorageGRID Controller. Splunk SmartStore verschiebt warme Daten in Remote-Storage – der StorageGRID Objekt-Storage in der Performance-Validierung.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">SmartStore-Performance an einem Standort</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">Früher: Splunk Architektur.</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">In diesem Abschnitt wird die Performance von Splunk SmartStore auf einem NetApp StorageGRID Controller beschrieben. Splunk SmartStore verschiebt warme Daten in Remote-Storage – in diesem Fall StorageGRID Objekt-Storage bei der Performance-Validierung.</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Wir haben EF600 für Hot/Cache Storage und StorageGRID 6060 für Remote Storage genutzt. Für die Performance-Validierung haben wir folgende Architektur verwendet. Wir haben zwei Suchköpfe, vier schwere Forwarder verwendet, um die Daten an Indexer weiterzuleiten, sieben Splunk Event Generators (Eventgens) um die Echtzeitdaten zu generieren, und 18 Indexer, um die Daten zu speichern.</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">In dieser Tabelle ist die Hardware aufgeführt, die für die SmartStorage-Leistungsvalidierung verwendet wird.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Schwerer Spediteur</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 Kerne</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SCHLITTEN 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">User Front-End sucht Daten in Indexern</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validierung der Leistung von SmartStore Remote Store</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">In dieser Leistungsvalidierung haben wir den SmartStore-Cache auf allen Indexern für 10 Tage Daten im lokalen Speicher konfiguriert. Wir haben die aktiviert<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (750 MB Bucket-Größe) im Splunk Cluster Manager und trieb die Änderungen an alle Indexer. Um die Upload-Performance zu messen, haben wir 10 Tage lang 10 TB pro Tag aufgenommen und alle Hot Buckets zum Warmlaufen gerollt. Der maximale und durchschnittliche Durchsatz pro Instanz sowie die Bereitstellung wurden über das SmartStore Monitoring Console Dashboard erfasst.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Dieses Bild zeigt die in einem Tag aufgenommenen Daten.</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Wir haben den folgenden Befehl vom Cluster-Master ausgeführt (der Indexname ist<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>). Anschließend haben wir über die SmartStore Monitoring Console Dashboards den maximalen und durchschnittlichen Upload-Durchsatz pro Instanz und die gesamte Implementierung erfasst.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Der Cluster-Master verfügt über eine passwortfreie Authentifizierung für alle Indexer (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Zum Messen der Download-Performance haben wir alle Daten aus dem Cache entfernt, indem wir die CLI „entfernen“ zweimal ausführen. Verwenden Sie dazu den folgenden Befehl.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Wir führten den folgenden Befehl vom Cluster Master aus und führten die Suche aus dem Suchkopf auf 10 Tagen Daten aus dem Remote-Speicher von StorageGRID aus. Anschließend haben wir über die SmartStore Monitoring Console Dashboards den maximalen und durchschnittlichen Upload-Durchsatz pro Instanz und die gesamte Implementierung erfasst.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Die Indexer-Konfigurationen wurden vom SmartStore Cluster-Master gedrängt. Der Cluster-Master hatte die folgende Konfiguration für den Indexer.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Wir haben die folgende Suchanfrage auf den Suchkopf ausgeführt um die Performance Matrix zu sammeln.</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Wir haben die Performance-Informationen vom Cluster-Master erfasst. Die Spitzen-Performance betrug 61,34 GB/s.</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">Die durchschnittliche Performance betrug etwa 29 GB/s.</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Performance von StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Die SmartStore-Leistung basiert auf der Suche nach bestimmten Mustern und Zeichenfolgen aus großen Datenmengen. In dieser Validierung werden die Ereignisse mit generiert<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> Auf einem bestimmten Splunk Index (Eventgen-Test) durch den Suchkopf, und die Anfrage geht an StorageGRID für die meisten Anfragen. Das folgende Bild zeigt die Treffer und Fehlschläge der Abfragedaten. Die Treffer Daten stammen von der lokalen Festplatte und die Auslassungen stammen aus dem StorageGRID Controller.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">Die grüne Farbe zeigt die Hits Data und die orangefarbene Farbe zeigt die Fehldaten an.</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Wenn die Abfrage für die Suche auf StorageGRID ausgeführt wird, wird die Zeit für die S3-Abrufrate von StorageGRID im folgenden Bild angezeigt.</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Verwendung der StorageGRID-Hardware</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">Die StorageGRID-Instanz hat einen Load Balancer und drei StorageGRID Controller. Die CPU-Auslastung aller drei Controller beträgt 75 % bis 100 %.</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore mit NetApp Storage Controller – Vorteile für den Kunden</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Abkopplung von Computing und Storage* der Splunk SmartStore entkoppelt Computing und Storage und ermöglicht dadurch eine unabhängige Skalierung.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*On-Demand-Daten* SmartStore ermöglicht Daten in der Nähe von On-Demand-Computing und bietet Flexibilität bei Computing und Storage sowie Kosteneffizienz, um eine längere Datenaufbewahrung nach Bedarf zu erreichen.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*AWS S3 API-konform.* SmartStore nutzt die AWS S3 API zur Kommunikation mit Storage zur Wiederherstellung, einem API-konformen AWS S3- und S3-konformen Objektspeicher wie StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*Reduziert Speicherbedarf und Kosten.* SmartStore reduziert den Speicherbedarf für veraltete Daten (warm/kalt). Da NetApp Storage Datensicherung bietet, Ausfälle beseitigt und hohe Verfügbarkeit gewährleistet, ist nur eine einzige Kopie der Daten erforderlich.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Hardwarefehler.* Node-Ausfall in einer SmartStore-Bereitstellung macht die Daten nicht unzugänglich und hat eine wesentlich schnellere Indexer-Wiederherstellung nach Hardwareausfall oder Datenungleichgewicht.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Applikations- und datenorientierter Cache:</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Indexer entfernen und On-Demand-Setup-down-Cluster einrichten.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Storage Tier ist nicht mehr an die Hardware gebunden.</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Auf dieser Seite werden die Herausforderungen erläutert, denen sich Kunden beim Zugriff auf Daten aus Big-Data-Analysen für den KI-Betrieb stellen müssen.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">Herausforderungen für Kunden</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Beim Zugriff auf Daten aus Big-Data-Analysen für den KI-Betrieb könnten Kunden die folgenden Herausforderungen bewältigen:</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Kundendaten liegen in einem Data-Lake-Repository. Der Data Lake kann verschiedene Datentypen enthalten, darunter strukturierte, unstrukturierte, halbstrukturierte, Log-Dateien und Machine-to-Machine-Daten. Alle diese Datentypen müssen in KI-Systemen verarbeitet werden.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">Die KI ist nicht mit Hadoop-Dateisystemen kompatibel. Eine typische KI-Architektur kann nicht direkt auf HDFS- und HCFS-Daten zugreifen, die in ein KI-verständliches File-System (NFS) verschoben werden müssen.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Die Verschiebung von Data-Lake-Daten in die KI erfordert normalerweise spezielle Prozesse. Die Datenmenge im Data Lake kann sehr groß sein. Ein Kunde muss über eine effiziente, hohe Durchsatzleistung und eine kostengünstige Möglichkeit verfügen, Daten in KI-Systeme zu verschieben.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Synchronisieren von Daten Wenn ein Kunde Daten zwischen der Big Data-Plattform und der KI synchronisieren möchte, können die über KI verarbeiteten Daten manchmal mit Big Data für die analytische Verarbeitung verwendet werden.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">Als Nächstes: Data Mover-Lösung.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">In diesem Abschnitt werden die Geschäftsvorteile dieser Lösung beschrieben.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Geschäftsvorteile</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">Früher: HDFS und MapR-FS zu ONTAP NFS.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Das Verschieben von Daten von Big Data-Analysen zu KI bietet folgende Vorteile:</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">Daten aus verschiedenen Hadoop Filesystemen und GPFS in ein einheitliches NFS-Storage-System extrahieren</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Hadoop – integrierte und automatisierte Möglichkeit zum Datentransfer</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Einsparungen bei der Bibliotheksentwicklung beim Verschieben von Daten von Hadoop Filesystemen</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Maximale Performance durch aggregierten Durchsatz mehrerer Netzwerkschnittstellen aus einer einzigen Datenquelle mithilfe von NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Geplante und On-Demand-Methoden zum Datentransfer</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">Storage-Effizienz und Managementfunktionalität der Enterprise-Klasse für Unified NFS-Daten mithilfe von ONTAP Datenmanagement-Software</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Mit der Hadoop Methode zur Datenübertragung entstehen keine Kosten für Datenverschiebungen</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">Weiter: GPFS zu NFS-detaillierte Schritte.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Dieser Anwendungsfall ist relevant für einen Cloud-Service-Partner, der für Multi-Cloud-Konnektivität für Big-Data-Analysedaten von Kunden steht.</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">Zurück: Anwendungsfall 3 – Enabling DevTest on Existing Hadoop Data.</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">In diesem Szenario werden die in AWS empfangenen IoT-Daten aus verschiedenen Quellen an einem zentralen Standort in NPS gespeichert. Der NPS Storage ist mit Spark/Hadoop Clustern in AWS und Azure verbunden, sodass Big-Data-Analyseapplikationen in diversen Clouds ausgeführt werden und auf dieselben Daten zugreifen können.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Kunden möchten Analysejobs in denselben Daten mithilfe mehrerer Clouds ausführen.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Daten müssen von unterschiedlichen Quellen wie On-Premises und Cloud über verschiedene Sensoren und Hubs empfangen werden.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">Die Lösung muss effizient und kostengünstig sein.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">Die größte Herausforderung ist der Aufbau einer kostengünstigen und effizienten Lösung, die hybride Analyseservices zwischen On-Premises-Systemen und verschiedenen Clouds bereitstellt.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Dieses Bild zeigt die Datensicherungs- und Multi-Cloud-Konnektivitätslösung.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">Wie in der Abbildung oben gezeigt, werden die Daten von Sensoren gestreamt und über Kafka in den AWS Spark-Cluster aufgenommen. Die Daten werden in einem NFS-Share in NPS gespeichert, der sich außerhalb des Cloud-Providers in einem Equinix Datacenter befindet. Da NetApp NPS über Direct Connect und Express Route Verbindungen mit Amazon AWS und Microsoft Azure verbunden ist, können Kunden das in-Place-Analysemodul für den Zugriff auf Daten von Amazon- und AWS-Analyse-Clustern nutzen. Dieser Ansatz ist die Lösung dafür, dass Cloud-Analysen über mehrere Hyperscaler hinweg durchgeführt werden können.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Da sowohl On-Premises- als auch NPS-Storage auf ONTAP Software ausgeführt werden, kann SnapMirror die NPS Daten in das On-Premises-Cluster spiegeln. Dadurch profitieren Hybrid-Cloud-Analysen von On-Premises-Systemen und mehreren Clouds.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Um die beste Performance zu erzielen, empfiehlt NetApp normalerweise, mehrere Netzwerkschnittstellen und direkte Verbindungs-/Express-Routen zu verwenden, um auf die Daten von Cloud-Instanzen zuzugreifen.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">Weiter: Anwendungsfall 5 – Beschleunigung von Analyse-Workloads.</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Mit dem NetApp StorageGRID Setup haben wir die Tiered Storage-Tests mit drei bis vier Nodes für die Produktion und für Verbraucher durchgeführt.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Performance-Tests mit Skalierbarkeit</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">Früher: Confluent Überprüfung.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Wir haben die Tiered Storage-Tests mit drei bis vier Nodes für Producer und Verbraucher-Workloads mithilfe des NetApp StorageGRID Setups durchgeführt. Laut unseren Tests waren die Fertigstellungszeit und die Performance-Ergebnisse direkt proportional zur Anzahl der StorageGRID Nodes. Das StorageGRID-Setup benötigte mindestens drei Nodes.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">Die Zeit bis zur Fertigstellung des Produce- und Consumer-Vorgangs sank linear, wenn die Anzahl der Storage Nodes gestiegen ist.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Die Performance für den s3-Abrufvorgang ist basierend auf der Anzahl der StorageGRID-Nodes linear gestiegen. StorageGRID unterstützt bis zu 200 StorageGRID Nodes.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">Weiter: Anschluss mit fließenden s3.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Wir haben diese Zertifizierung zusammen mit Confluent Platform mit Kafka für Tiered Storage in NetApp StorageGRID durchgeführt.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Confluent Verification</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Wir haben eine Überprüfung mit Confluent Platform 6.2 Tiered Storage in NetApp StorageGRID durchgeführt. Die NetApp und Conflient Teams haben diese Verifizierung gemeinsam durchgeführt und die für die Verifizierung erforderlichen Testfälle durchgeführt.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Plattformeinrichtung fließend</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Zur Überprüfung wurde folgendes Setup verwendet.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">Zur Überprüfung wurden drei Zookeeper, fünf Broker, fünf Testskripte mit Servern, benannte Tools mit 256 GB RAM und 16 CPUs verwendet. Für NetApp Storage haben wir StorageGRID mit einem SG1000 Load Balancer mit vier SGF6024s verwendet. Der Storage und die Broker waren über 100-GbE-Verbindungen verbunden.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">Die folgende Abbildung zeigt die Netzwerktopologie der Konfiguration, die für die Confluent-Überprüfung verwendet wird.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Die Tools-Server fungieren als Anwendungsclients, die Anfragen an Confluent Nodes senden.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Fließende Tiered Storage-Konfiguration</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">Für die Tiered Storage-Konfiguration sind in Kafka die folgenden Parameter erforderlich:</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">Zur Überprüfung wurde StorageGRID mit dem HTTP-Protokoll verwendet, aber HTTPS funktioniert auch. Der Zugriffsschlüssel und der Geheimschlüssel werden im Dateinamen im gespeichert<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> Parameter.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp Objekt-Storage – StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Wir haben Single-Site-Konfiguration in StorageGRID für die Verifikation konfiguriert.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Verifizierungstests</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Wir haben die folgenden fünf Testfälle für die Verifizierung abgeschlossen. Diese Tests werden im Trogdor-Rahmen durchgeführt. Die ersten beiden waren Funktionstests und die verbleibenden drei waren Performance-Tests.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Korrektheit des Objektspeichers</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Dieser Test bestimmt, ob alle grundlegenden Vorgänge (zum Beispiel get/put/delete) auf der Objektspeicher-API gut gemäß den Anforderungen an Tiered Storage funktionieren. Es ist ein grundlegender Test, dass jeder Objektspeicher-Service den folgenden Tests voraus sein sollte. Es handelt sich um einen durchsetzungsfähigen Test, der entweder besteht oder ausfällt.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Funktionstest der Tiering-Funktion</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Dieser Test prüft, ob die End-to-End-Tiered Storage-Funktionalität einem durchsetzungsfähigen Test gut funktioniert, der entweder erfolgreich oder ausfallen sollte. Der Test erstellt ein Testthema, das standardmäßig mit aktiviertem Tiering und einer stark reduzierten Hotset-Größe konfiguriert ist. Es erzeugt einen Ereignisstrom zum neu erstellten Testthema, wartet darauf, dass die Broker die Segmente im Objektspeicher archivieren und dann den Ereignisstrom nutzt und überprüft, ob der verbrauchte Strom mit dem erzeugten Stream übereinstimmt. Die Anzahl der Nachrichten, die an den Ereignisstrom erzeugt werden, ist konfigurierbar, sodass der Benutzer je nach Testanforderungen eine ausreichend große Arbeitslast generieren kann. Die reduzierte Hotset-Größe stellt sicher, dass der Verbraucher außerhalb des aktiven Segments nur aus dem Objektspeicher bedient wird; dies hilft, die Richtigkeit des Objektspeichers auf Lesevorgänge zu prüfen. Diesen Test haben wir mit und ohne Objektspeicherfehlereinspritzung durchgeführt. Wir haben einen Node-Ausfall simuliert, indem wir den Service Manager Service in einem der Nodes in StorageGRID unterbrechen und validieren, dass die End-to-End-Funktionalität mit dem Objekt-Storage kompatibel ist.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Tier-Fetch-Benchmark</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Dieser Test bestätigte die Lese-Performance des Tiered Objekt-Storage und prüfte den Bereich, in dem Leseanforderungen unter hoher Last aus vom Benchmark erzeugten Segmenten abgerufen werden. In dieser Benchmark hat Confluent benutzerdefinierte Clients entwickelt, um die Tier-fetch-Anforderungen zu erfüllen.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Erstellen von Benchmark-Workloads für die Nutzung</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Dieser Test erzeugte über die Archivierung von Segmenten einen indirekten Schreib-Workload auf dem Objektspeicher. Der Lese-Workload (Segmente Lesen) wurde aus dem Objekt-Storage generiert, wenn Verbrauchergruppen die Segmente abgerufen haben. Dieser Workload wurde durch das Testskript generiert. In diesem Test wurde die Performance von Lese- und Schreibvorgängen im Objekt-Storage in parallelen Threads überprüft. Wir haben wie bei dem Tiering-Funktionstest mit und ohne Objektspeicher-Fehlereinspritzung getestet.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Benchmarks für Retention Workloads</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Bei diesem Test wurde die Löschleistung eines Objektspeichers unter einem hohen Workload für die Aufbewahrung von Themen überprüft. Der Retention Workload wurde mit einem Testskript generiert, das parallel zu einem Testthema viele Nachrichten erzeugt. Das Testthema wurde mit einer aggressiven größenbasierten und zeitbasierten Aufbewahrungseinstellung konfiguriert, die dazu führte, dass der Ereignisstrom kontinuierlich aus dem Objektspeicher gelöscht wurde. Die Segmente wurden anschließend archiviert. Dies führte zu einer großen Anzahl von Löschungen im Objekt-Storage durch den Vermittler und die Sammlung der Performance bei Löschvorgängen im Objektspeicher.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">Weiter: Performance-Tests mit Skalierbarkeit.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Dieses Whitepaper enthält Richtlinien zum Verschieben von Big-Data-Analysedaten und HPC-Daten mithilfe von NetApp XCP und NIPAM in die KI. Außerdem werden die geschäftlichen Vorteile erläutert, die sich aus dem Verschieben von Daten von Big Data und HPC hin zur KI ergeben.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: Big Data-Analysedaten in der künstlichen Intelligenz</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">In diesem Dokument wird beschrieben, wie Big-Data-Analysedaten und HPC-Daten in die KI verschoben werden. KI verarbeitet NFS-Daten durch NFS-Exporte, während Kunden ihre KI-Daten oft in einer Big-Data-Analyseplattform wie HDFS, Blob oder S3 Storage und HPC-Plattformen wie GPFS speichern. Dieses Whitepaper enthält Richtlinien zum Verschieben von Big-Data-Analysedaten und HPC-Daten mithilfe von NetApp XCP und NIPAM in die KI. Außerdem werden die geschäftlichen Vorteile erläutert, die sich aus dem Verschieben von Daten von Big Data und HPC hin zur KI ergeben.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Konzepte und Komponenten</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Big-Data-Analysesstorage</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">Big-Data-Analysen sind der größte Storage-Anbieter für HDFS. Ein Kunde setzt häufig ein Hadoop-kompatibles Filesystem (HCFS) wie Windows Azure Blob Storage, MapR File System (MapR-FS) und S3 Objekt-Storage ein.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Allgemeines paralleles Dateisystem</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM GPFS ist ein Enterprise-Dateisystem, das eine Alternative zu HDFS bietet. GPFS bietet für Anwendungen die Flexibilität, die Blockgröße und das Replikationslayout zu bestimmen, was eine gute Performance und Effizienz bietet.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetApp in-Place-Analysemodule</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382: NetApp in-Place-Analysemodul</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">Das NetApp in-Place-Analysemodul (NIPAM) dient als Treiber für Hadoop Cluster zum Zugriff auf NFS-Daten. Es verfügt über vier Komponenten: Einen Verbindungspool, einen NFS InputStream, einen Datei-Handle-Cache und einen NFS OutputStream. Weitere Informationen finden Sie unter<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop Distributed Copy</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) ist ein Tool für verteilte Kopien, das für große Cluster- und Clusteraufgaben eingesetzt wird. Dieses Tool verwendet MapReduce für Datenverteilung, Fehlerbehandlung und Reporting. Es erweitert die Liste der Dateien und Verzeichnisse und gibt sie ein, um Aufgaben zuzuordnen, um die Daten aus der Quellliste zu kopieren. Das Bild unten zeigt die DiCp-Operation in HDFS und nicht HDFS.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp verschiebt Daten zwischen den beiden HDFS-Systemen ohne zusätzlichen Treiber. NetApp liefert den Treiber für nicht-HDFS-Systeme. Für ein NFS-Ziel bietet NIPAM den Treiber, Daten zu kopieren, die Hadoop DistCp verwendet, um mit NFS-Zielen beim Kopieren von Daten zu kommunizieren.</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">Die NetApp Cloud Volumes Service ist ein Cloud-nativer Fileservice mit höchster Performance. Dieser Service hilft Kunden, ihre Produkteinführungszeiten zu verkürzen, indem sie ihre Ressourcen schnell nach oben oder unten einrichten und NetApp Funktionen zur Steigerung der Produktivität und Reduzierung der Mitarbeiterausfallzeiten nutzen. Die Cloud Volumes Service ist die richtige Alternative für Disaster Recovery und Backups in der Cloud, da sie den Platzbedarf im Datacenter reduziert und den Verbrauch von nativem Public-Cloud-Storage verringert.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">Bei NetApp XCP handelt es sich um eine Client-Software, die eine schnelle und zuverlässige Datenmigration zwischen NetApp und NetApp zu ermöglichen. Dieses Tool dient zum Kopieren einer großen Menge unstrukturierter NAS-Daten von einem beliebigen NAS-System auf einen NetApp Storage Controller. Das XCP Migration Tool verwendet eine Multicore-Multichannel-I/O-Streaming-Engine, die viele Anfragen parallel verarbeitet, z. B. Datenmigration, Datei- oder Verzeichnislisten und Speicherplatzberichte. Dies ist das NetApp Datenmigrationstool standardmäßig. Mit XCP können Daten von einem Hadoop Cluster und HPC auf einen NetApp NFS Storage kopiert werden. Die folgende Abbildung zeigt den Datentransfer aus einem Hadoop und HPC Cluster auf ein NetApp NFS-Volume mit XCP.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync ist eine hybride Datenreplizierungssoftware als Service, die NFS, S3 und CIFS Daten nahtlos und sicher zwischen lokalem Storage und Cloud Storage überträgt und synchronisiert. Diese Software wird für Datenmigration, Archivierung, Zusammenarbeit, Analysen usw. verwendet. Nach der Datenübertragung synchronisiert Cloud Sync kontinuierlich die Daten zwischen Quelle und Ziel. In Zukunft wird das Delta übertragen. Außerdem werden die Daten in Ihrem eigenen Netzwerk, in der Cloud oder lokal gesichert. Diese Software basiert auf einem Pay-as-you-go-Modell, das eine kostengünstige Lösung bietet und Monitoring- und Berichtsfunktionen für Ihren Datentransfer bereitstellt.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">Als Nächstes: Herausforderungen für Kunden.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">In diesem Dokument werden Hybrid-Cloud-Datenlösungen beschrieben, die NetApp AFF und FAS Storage-Systeme, NetApp Cloud Volumes ONTAP, NetApp Connected Storage sowie NetApp FlexClone Technologie für Spark und Hadoop einsetzen. Mit diesen Lösungsarchitekturen können Kunden eine geeignete Datensicherungslösung für ihre Umgebung wählen. NetApp hat diese Lösungen basierend auf der Interaktion mit Kunden und eigenen Business-Anwendungsfällen entwickelt.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657: NetApp Hybrid-Cloud-Datenlösungen – Spark und Hadoop auf Basis von Kundenanwendungsfällen</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam und Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">In diesem Dokument werden Hybrid-Cloud-Datenlösungen beschrieben, die NetApp AFF und FAS Storage-Systeme, NetApp Cloud Volumes ONTAP, NetApp Connected Storage sowie NetApp FlexClone Technologie für Spark und Hadoop einsetzen. Mit diesen Lösungsarchitekturen können Kunden eine geeignete Datensicherungslösung für ihre Umgebung wählen. NetApp hat diese Lösungen basierend auf der Interaktion mit Kunden und eigenen Business-Anwendungsfällen entwickelt. Dieses Dokument enthält folgende detaillierte Informationen:</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Warum wir Datensicherung für Spark und Hadoop-Umgebungen sowie auf Kundenherausforderungen benötigen</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">Die Data Fabric basiert auf der NetApp Vision und den Bausteinen und Services.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Wie diese Bausteine zur Erstellung flexibler Datensicherungs-Workflows eingesetzt werden können</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Vor- und Nachteile verschiedener Architekturen, die auf realistischen Kundenanwendungsfällen basieren. Jeder Anwendungsfall umfasst die folgenden Komponenten:</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Kundenszenarien</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">Verbessern Lassen</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Zusammenfassung der Lösungen</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Warum Hadoop Datensicherung?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">In einer Hadoop und Spark-Umgebung müssen die folgenden Aspekte berücksichtigt werden:</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Software oder menschliches Versagen.* menschliches Versagen bei Software-Updates während der Durchführung von Hadoop-Datenoperationen kann zu fehlerhaftem Verhalten führen, das unerwartete Ergebnisse aus dem Job verursachen kann. In diesem Fall müssen wir die Daten schützen, um Fehler oder unangemessene Ergebnisse zu vermeiden. Als Ergebnis eines schlecht ausgeführten Softwareupdates auf eine Traffic-Signal-Analyse-Anwendung, eine neue Funktion, die nicht richtig Analyse von Verkehrssignaldaten in Form von Klartext. Die Software analysiert weiterhin JSON und andere nicht-Text-Dateiformate, was zu einem Echtzeit-System zur Verkehrssteuerung führt, in dem Vorhersageergebnisse vorliegen, die keine Datenpunkte enthalten. Dies kann zu fehlerhaften Ausgängen führen, die zu Unfällen an den Verkehrssignalen führen können. Datensicherheit kann dieses Problem lösen, indem sie die Möglichkeit bietet, schnell ein Rollback zur vorherigen Applikationsversion durchführen zu können.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Größe und Umfang.* die Größe der Analysedaten wächst Tag für Tag aufgrund der stetig wachsenden Zahl von Datenquellen und Volumen. Social Media, mobile Apps, Data Analytics und Cloud-Computing-Plattformen sind die wichtigsten Datenquellen des aktuellen Big Data-Marktes, der sehr schnell zunimmt und daher die Daten zur Sicherstellung akkurater Datenabläufe geschützt werden müssen.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">*Der native Datenschutz von Hadoop.* Hadoop hat einen nativen Befehl, um die Daten zu schützen, aber dieser Befehl bietet keine Konsistenz der Daten während des Backups. Es unterstützt nur Backups auf Verzeichnisebene. Die von Hadoop erstellten Snapshots sind schreibgeschützt und können nicht zur direkten Wiederverwendung der Backup-Daten verwendet werden.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Herausforderungen bei der Datensicherung für Hadoop und Spark Kunden</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Kunden in Hadoop und Spark stehen vor der Herausforderung, die Backup-Zeit zu reduzieren und die Backup-Zuverlässigkeit zu steigern, ohne während der Datensicherung die Performance im Produktions-Cluster zu beeinträchtigen.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Kunden müssen außerdem Ausfallzeiten bei Recovery Point Objective (RPO) und Recovery Time Objective (RTO) minimieren und ihre Disaster-Recovery-Standorte vor Ort und in der Cloud kontrollieren, um optimale Business Continuity zu erzielen. Diese Kontrollfunktion ergibt sich in der Regel aus Management Tools der Enterprise-Klasse.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Die Umgebungen mit Hadoop und Spark sind kompliziert, da nicht nur das Datenvolumen sehr groß ist und immer größer wird, sondern auch die Geschwindigkeit, mit der die Daten ankommen. Bei diesem Szenario ist es schwierig, schnell effiziente, aktuelle DevTest- und QA-Umgebungen aus den Quelldaten zu erstellen. NetApp kennt diese Herausforderungen und bietet die in diesem Whitepaper vorgestellten Lösungen.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">Als Nächstes: Data Fabric von NetApp für Big-Data-Architekturen</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Dieses Dokument beschreibt die Performance-Benchmarks für die Confluent Plattform auf NetApp ONTAP mithilfe eines Tiered Storage Benchmark Kits.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: Fließend mit den NetApp ONTAP Storage Controllern</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Damit die Confluent Platform skalierbarer und flexibler wird, muss sie in der Lage sein, Workloads sehr schnell zu skalieren und auszugleichen. Durch Tiered Storage können große Datenmengen in Conflient gemanagt werden, indem diese Betriebskosten reduziert werden. Eine wesentliche Idee besteht darin, den Storage von der Datenverarbeitung zu trennen, wodurch jede unabhängig voneinander skaliert werden kann.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Mit zahlreichen branchenführenden Innovationen vereint die Datenmanagement-Software NetApp ONTAP vielfältige Vorteile in jedem Bereich der Daten.</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">Als Nächstes: Lösung.</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Dieser Abschnitt behandelt die Hardware und Software, die für die Confluent-Überprüfung verwendet werden. Diese Informationen gelten für die Implementierung der Conflient Plattform mit NetApp Storage. Die folgende Tabelle deckt die getestete Lösungsarchitektur und Basiskomponenten ab.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Conflient Kafka Version 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Drei Zookeeper</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Fünf Broker Server</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Fünf-Tools-Server</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">One Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Ein Kontrollzentrum</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Alle Server</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID für Tiered Storage</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID Software</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (Load Balancer)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (Netzwerkkonnektivität zwischen Broker und StorageGRID Instanzen)</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Jeweils ausgestattet mit: * 2 CPUs, insgesamt 16 physischen Kernen * Intel Xeon * 256 GB physischem Speicher * 100 GbE Dual Port</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Dieser Test basiert auf der Self-Balancing-Cluster-Funktion, die das Ausbalancieren anhand von Änderungen in der Cluster-Topologie oder ungleichmäßiger Last automatisiert.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Confluent Self balancing Clusters</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">Früher: Kafka s3 Stecker.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Wenn Sie bereits einen Kafka Cluster gemanagt haben, kennen Sie die Herausforderungen, die sich aus der manuellen Neuzuteilung von Partitionen an verschiedene Broker ergeben, um sicherzustellen, dass der Workload über das Cluster hinweg ausgeglichen wird. Für Unternehmen mit großen Implementierungen im Kafka-Bereich kann das Umstellen großer Datenmengen eine enorme Herausforderung, ein mühsames und riskantes sein, vor allem, wenn geschäftskritische Applikationen auf dem Cluster basieren. Selbst für die kleinsten Anwendungsfälle von Kafka ist dieser Vorgang allerdings zeitaufwändig und fehleranfällig.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">In unserem Labor haben wir die Funktion Confluent Self-Balancing Cluster getestet, die die Ausbalancierung auf Basis von Cluster-Topologieänderungen oder unausgeglichenen Lasten automatisiert. Der Test zur Neuverteilung bei einem Knoten hilft dabei, die Zeit zu messen, die zum Hinzufügen eines neuen Brokers erforderlich ist, wenn ein Node ausfällt oder der Skalierungsknoten eine Ausbalancierung der Daten zwischen Brokern erfordert. In klassischen Kafka-Konfigurationen wächst die Menge der auszubalancieren, während der Cluster wächst. Bei Tiered Storage ist die Ausbalancierung jedoch auf kleine Datenmengen beschränkt. Basierend auf unserer Validierung dauert die Lastverteilung im Tiered Storage in einer klassischen Kafka-Architektur nur Sekunden oder Minuten und wächst linear mit dem Cluster.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">In Self-Balancing-Clustern sind Partitions-Rebalons vollständig automatisiert. Dies optimiert den Durchsatz von Kafka, beschleunigt die Skalierung von Vermittlern und entlastet den Betrieb eines großen Clusters. Bei Clustern mit Selbstausgleich überwachen die Verzerrung der Daten zwischen den Brokern und weist Partitionen kontinuierlich neu zu, um die Cluster-Performance zu optimieren. Bei der Skalierung der Plattform nach oben oder unten erkennen Self-Balancing-Cluster automatisch das Vorhandensein neuer Broker oder das Entfernen alter Broker und lösen eine nachfolgende Neuzuweisung von Partitionen aus. So können Sie problemlos Broker hinzufügen und ausmustern und Ihre Kafka Cluster damit im Wesentlichen flexibler gestalten. Diese Vorteile entstehen ohne manuelles Eingreifen, komplexe Mathematik oder das Risiko menschlicher Fehler, die für gewöhnlich eine Partition neu zugewiesen werden. Auf diese Weise werden Datenabstände in wesentlich kürzerer Zeit abgeschlossen und Sie können sich auf wichtigere Event-Streaming-Projekte konzentrieren, anstatt Ihre Cluster ständig zu überwachen.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">Als Nächstes: Best Practice-Richtlinien.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">Die Lösung ermöglicht es, Computing-, Hot Storage- oder S3-Ressourcen hinzuzufügen, um den wachsenden Bedarf an Benutzern oder Aufnahmeraten über einzelne oder standortübergreifende Implementierungen hinweg zu decken.</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Performance.* durch die Kombination aus Splunk SmartStore und NetApp StorageGRID können Daten mithilfe des Objekt-Storage schnell zwischen Hot Buckets und warmen Buckets migriert werden. StorageGRID beschleunigt den Migrationsprozess, da sie schnelle Performance für große Objekt-Workloads bietet.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Standortfähig.* mit der verteilten StorageGRID Architektur kann Splunk SmartStore die Implementierung über einen einzigen globalen Namespace auf einzelne und mehrere Standorte ausweiten. Dort können Daten unabhängig vom Speicherort der Daten von jedem Standort aus abgerufen werden.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Bessere Skalierbarkeit.* Storage-Ressourcen können unabhängig von den Computing-Ressourcen skaliert werden, um den wachsenden Anforderungen in der Splunk Umgebung gerecht zu werden. Damit wird die TCO verbessert.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Kapazität.* schnell wachsende Volumes werden in Splunk Implementierungen mit StorageGRID durch Skalierung eines Single Namespace auf über 560 PB gerecht.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Datenverfügbarkeit.* Datenverfügbarkeit, Performance, geografische Verteilung, Aufbewahrung, Schutz, Und Storage-Kosten mithilfe von metadatengestützten Richtlinien, die sich dem geschäftlichen Nutzen der Daten dynamisch anpassen.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Von Splunk bereitgestellter Richtlinien</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">Steigern Sie die Performance mit dem SmartStore-Cache, der eine Komponente des Indexers ist, der die Übertragung von Bucket-Kopien zwischen lokalem (heißem) und externem (warmem) Storage verarbeitet. Die Splunk Dimensionierung für diese Lösung basiert auf der<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>. Die Lösung ermöglicht es, Computing-, Hot Storage- oder S3-Ressourcen hinzuzufügen, um den wachsenden Bedarf an Benutzern oder Aufnahmeraten über einzelne oder standortübergreifende Implementierungen hinweg zu decken.</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">Weiter: Intelligentes Tiering und Kosteneinsparungen.</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">Python-Skripte für jeden größeren Anwendungsfall</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">Früher: Hybrid Cloud-Lösung.</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Die folgenden drei Python-Skripte entsprechen den drei getesteten Hauptanwendungsfällen. Zunächst einmal<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>.</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Das zweite Skript lautet<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Das dritte Skript ist<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>.</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Dieser Abschnitt enthält die detaillierten Schritte, die erforderlich sind, um MapR-FS-Daten mithilfe von NetApp XCP in ONTAP-NFS zu verschieben.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS zu ONTAP NFS</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">Zurück: GPFS zu NFS - Detaillierte Schritte.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Stellen Sie drei LUNs für jeden MapR Node bereit und übertragen Sie die LUNs bei allen MapR Nodes.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Wählen Sie während der Installation neu hinzugefügte LUNs für MapR Cluster-Festplatten aus, die für MapR-FS verwendet werden.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">Dokumentation zu MapR 6.1</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">Installieren Sie ein MapR Cluster gemäß dem<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Prüfen Sie die grundlegenden Hadoop Vorgänge mit MapReduce-Befehlen wie<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Sorgen Sie dafür, dass Kundendaten im MapR-FS gespeichert bleiben. Wir haben beispielsweise mithilfe von Teragen etwa ein Terabyte an Probendaten in MapR-FS generiert.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Konfigurieren Sie MapR-FS als NFS-Export.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Deaktivieren Sie den nlockmgr-Service auf allen MapR-Nodes.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exportieren Sie bestimmte Ordner aus MapR-FS auf alle MapR Nodes im<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> Datei: Exportieren Sie den übergeordneten Ordner nicht mit anderen Berechtigungen, wenn Sie Unterordner exportieren.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Aktualisieren Sie den MapR-FS NFS-Service.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Weisen Sie einem bestimmten Server oder einem Server-Satz im MapR-Cluster einen virtuellen IP-Bereich zu. Anschließend weist das MapR Cluster einem bestimmten Server eine IP für den NFS-Datenzugriff zu. Die IPs ermöglichen eine hohe Verfügbarkeit, was bedeutet, dass im Falle eines Ausfalls eines Servers oder Netzwerks mit einem bestimmten IP die nächste IP aus dem Bereich der IPs für den NFS-Zugriff verwendet werden kann.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Wenn Sie NFS-Zugriff aus allen MapR Nodes ermöglichen möchten, können Sie jedem Server einen Satz virtueller IPs zuweisen und die Ressourcen aus jedem MapR Node für den NFS-Datenzugriff verwenden.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Überprüfen Sie die virtuellen IPs, die auf jedem MapR Node zugewiesen sind, und verwenden Sie sie für den NFS-Datenzugriff.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Mounten Sie das NFS- exportierte MapR-FS mit der zugewiesenen virtuellen IP zur Überprüfung des NFS-Vorgangs. Dieser Schritt ist jedoch nicht für den Datentransfer mittels NetApp XCP erforderlich.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">NetApp XCP für die Übertragung von Daten vom MapR-FS NFS Gateway zum ONTAP NFS konfigurieren</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Konfigurieren Sie den Katalogspeicherort für XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Kopieren Sie die Lizenzdatei in<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Aktivieren Sie XCP mithilfe des<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Überprüfen Sie die Quelle für den NFS-Export.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Übertragen Sie die Daten mit XCP von mehreren MapR Nodes aus diversen Quell-IPs und ONTAP LIFs (Multiple-Ziel-IPs).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Die Lastverteilung am Storage Controller prüfen.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise ist die marktführende SIEM-Lösung für Resultate in Sicherheits-, IT- und DevOps-Teams. Der Einsatz von Splunk ist in allen Unternehmen unserer Kunden deutlich gestiegen. Daher müssen mehr Datenquellen hinzugefügt und die Daten für einen längeren Zeitraum beibehalten werden, was die Splunk Infrastruktur belastet.</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">Zurück: Single-Site SmartStore Leistung.</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Die Kombination aus Splunk SmartStore und NetApp StorageGRID wurde entwickelt, um eine skalierbare Architektur für Unternehmen bereitzustellen, die eine höhere Aufnahme-Performance mit SmartStore und StorageGRID Objekt-Storage sowie die höhere Skalierbarkeit für eine Splunk Umgebung über mehrere geografische Regionen hinweg erzielen kann.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">NetApp StorageGRID Dokumentationsmaterialien</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Splunk Enterprise-Dokumentation</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise über SmartStore</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Splunk Enterprise Distributed Deployment Guide</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterprise Management von Indexern und Indexern</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">Juli 2022</block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Diese Seite beschreibt die Leistungsvalidierung von Confluent innerhalb der Parameter dieser Lösung.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validierung der Performance in einem fließenden Verhältnis</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Wir haben die Verifizierung mit der Conflient Plattform für Tiered Storage auf NetApp ONTAP durchgeführt. Die NetApp und Conflient Teams haben diese Verifizierung gemeinsam bearbeitet und die erforderlichen Testfälle ausgeführt.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Fließende Einrichtung</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Für das Setup wurden drei Zookeeper, fünf Broker und fünf Testserver mit 256 GB RAM und 16 CPUs verwendet. Für NetApp Storage haben wir ONTAP mit einem AFF A900 HA Paar verwendet. Der Storage und die Broker waren über 100-GbE-Verbindungen verbunden.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">Die folgende Abbildung zeigt die Netzwerktopologie der Konfiguration für die Tiered Storage-Verifizierung.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Diese Grafik zeigt die Netzwerktopologie der Konfiguration für die Tiered Storage-Verifizierung.</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Die Tools-Server fungieren als Anwendungsclients, die Ereignisse an oder von Confluent Nodes senden oder empfangen.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Dabei wurden die folgenden Testparameter verwendet:</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">Zur Überprüfung haben wir ONTAP mit dem HTTP-Protokoll verwendet, aber HTTPS haben auch funktioniert. Der Zugriffsschlüssel und der Geheimschlüssel werden im Dateinamen im gespeichert<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> Parameter.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp Storage Controller – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Wir haben zur Verifizierung eine Single HA-Paar-Konfiguration in ONTAP konfiguriert.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Diese Abbildung zeigt, wie die Umgebung zur Verifizierung als ein einziges HA-Paar konfiguriert wurde.</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Überprüfungsergebnisse</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Wir haben die folgenden fünf Testfälle für die Verifizierung abgeschlossen. Die ersten beiden waren Funktionstests und die verbleibenden drei waren Performance-Tests.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Dieser Test führt grundlegende Vorgänge wie Abrufen, Put und Löschen im Objektspeicher durch, der mithilfe von API-Aufrufen für den Tiered Storage verwendet wird.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Dieser Test überprüft die End-to-End-Funktionen des Objekt-Storage. Es erstellt ein Thema, erstellt einen Ereignisstrom zum neu erstellten Thema, wartet auf die Broker, um die Segmente im Objektspeicher zu archivieren, verbraucht den Ereignisstrom und validiert die verbrauchten Streams mit dem erzeugten Stream. Diesen Test haben wir mit und ohne Objektspeicherfehlereinspritzung durchgeführt. Wir haben einen Node-Ausfall simuliert, indem wir den Service Manager Service in einem der Nodes in ONTAP unterbrechen und validieren, dass die End-to-End-Funktionalität mit dem Objekt-Storage kompatibel ist.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Produzieren-Workload-Generator zur Nutzung</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Dieser Test generiert über die Archivierung von Segmenten indirekt einen Schreib-Workload auf dem Objektspeicher. Der Lese-Workload (Segmente Lesen) wurde aus dem Objekt-Storage generiert, wenn Verbrauchergruppen die Segmente abgerufen haben. Dieser Workload wurde von einem TOCC-Skript generiert. In diesem Test wurde die Performance von Lese- und Schreibvorgängen im Objekt-Storage in parallelen Threads überprüft. Wir haben wie bei dem Tiering-Funktionstest mit und ohne Objektspeicher-Fehlereinspritzung getestet.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Retention Workload Generator</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Im Rahmen dieses Tests wurde die Löschleistung eines Objektspeichers unter einem anspruchsvollen Thema Aufbewahrung Workload überprüft. Der Retention Workload wurde mit einem TOCC-Skript erzeugt, das viele Nachrichten parallel zu einem Testthema erzeugt. Das Testthema wurde mit einer aggressiven größenbasierten und zeitbasierten Aufbewahrungseinstellung konfiguriert, die dazu führte, dass der Ereignisstrom kontinuierlich aus dem Objektspeicher gelöscht wurde. Die Segmente wurden anschließend archiviert. Dies führte dazu, dass der Vermittler zahlreiche Löschungen im Objekt-Storage erfasst und bei der Performance der Objektspeicher-Löschvorgänge erfasst wurde.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Fließend</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Informationen zur Überprüfung finden Sie im<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> Website.</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">Der nächste Schritt: Performance-Tests mit dem Produce-Consume Workload Generator.</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID verfügt über eine Vielzahl von Funktionen, die Benutzer nutzen und an ihre sich ständig ändernde Umgebung anpassen können. Ob Implementierung oder Skalierung Ihres Splunk SmartStore: Ihre Umgebung muss zügig auf Änderungen reagieren, sie sollte unterbrechungsfrei für Splunk sein. Mit den flexiblen StorageGRID Datenmanagement-Richtlinien (ILM) und Traffic Classifiers (QoS) planen und anpassen Sie Ihre Umgebung.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Flexible StorageGRID Funktionen für Splunk SmartStore</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Einfaches Management mit Grid Manager</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager ist eine browserbasierte grafische Schnittstelle, mit der Sie Ihr StorageGRID System an weltweit verteilten Standorten über eine zentrale Konsole konfigurieren, managen und überwachen können, wie im folgenden Bild dargestellt.</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Führen Sie die folgenden Aufgaben über die Grid Manager-Oberfläche aus:</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Verwalten global verteilter Repositorys mit mehreren Petabyte für Objekte wie Bilder, Videos und Datensätze.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Grid-Nodes und -Services überwachen, um die Objektverfügbarkeit zu gewährleisten</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Mithilfe von ILM-Regeln (Information Lifecycle Management) managen Sie Objektdaten über einen längeren Zeitraum. Diese Regeln regeln, was mit den Objektdaten nach der Aufnahme geschieht, wie sie vor Verlust geschützt sind, wo Objektdaten gespeichert werden und wie lange.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Überwachung von Transaktionen, Performance und Vorgängen im System</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">NetApp StorageGRID App für Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">Die NetApp StorageGRID App für Splunk ist eine applikationsspezifische App für Splunk Enterprise. Diese App funktioniert in Verbindung mit dem NetApp StorageGRID Add-On für Splunk. Das Tool gibt einen Überblick über den StorageGRID-Zustand, Kontoausnutzungsdaten, Sicherheitsprüfungen, Ressourcenauslastung und Monitoring usw.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">Das folgende Bild zeigt die StorageGRID App für Splunk.</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM-Richtlinien</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID verfügt über flexible Datenmanagement-Richtlinien. Dazu gehören die Aufbewahrung mehrerer Kopien Ihrer Objekte und die Verwendung von EC-Schemata (Erasure Coding) wie 2+1 und 4+2 (und vielen anderen) zum Speichern von Objekten, je nach spezifischen Performance- und Datensicherungsanforderungen. Wenn sich Workloads und Anforderungen im Laufe der Zeit ändern, ist es üblich, dass sich auch ILM-Richtlinien im Laufe der Zeit ändern müssen. Das Ändern von ILM-Richtlinien ist eine zentrale Funktion, mit der sich StorageGRID-Kunden schnell und einfach an die sich ständig verändernde Umgebung anpassen können.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID skaliert die Performance, indem weitere Nodes hinzugefügt werden. Dabei können es sich um VMs oder Bare Metal oder speziell entwickelte Appliances wie das SG5712, SG5760, SG6060 oder SGF6024 handelt. In unseren Tests haben wir mit der SG6060 Appliance die wichtigsten Performance-Anforderungen des SmartStore mit einem Grid mit mindestens drei Nodes übertroffen. Wenn Kunden ihre Splunk Infrastruktur mit zusätzlichen Indexern skalieren, können sie mehr Storage-Nodes hinzufügen, um Performance und Kapazität zu steigern.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Lastausgleich und Endpunktkonfiguration</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Admin-Nodes in StorageGRID stellen die Grid Manager-Benutzeroberfläche (Benutzeroberfläche) und DEN REST-API-Endpunkt zum Anzeigen, Konfigurieren und Managen des StorageGRID-Systems sowie Audit-Protokolle zur Nachverfolgung der Systemaktivitäten bereit. Um einen hochverfügbaren S3-Endpunkt für Splunk SmartStore Remote-Storage zu bieten, haben wir den StorageGRID Load Balancer implementiert, der als Service auf Admin-Nodes und Gateway-Nodes ausgeführt wird. Darüber hinaus managt der Load Balancer auch den lokalen Datenverkehr und spricht mit dem GSLB (Global Server Load Balancing), um die Disaster Recovery zu unterstützen.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Zur weiteren Verbesserung der Endpoint-Konfiguration bietet StorageGRID Richtlinien für die Traffic-Klassifizierung, die in den Admin-Node integriert sind, mit denen Sie Ihren Workload-Datenverkehr überwachen und verschiedene QoS-Limits (Quality of Service) auf Ihre Workloads anwenden können. Richtlinien zur Traffic-Klassifizierung werden auf Endpunkte im StorageGRID Load Balancer Service für Gateway-Nodes und Admin-Nodes angewendet. Diese Richtlinien unterstützen die Begrenzung und das Monitoring des Datenverkehrs.</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">Als Nächstes: Splunk Architektur.</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">In diesem Szenario verfügt der Kunde über ein großes Hadoop Repository vor Ort, für Disaster-Recovery-Zwecke sollten die Daten gesichert werden. Die aktuelle Backup-Lösung des Kunden ist jedoch kostspielig und mit einem langen Backup-Fenster von mehr als 24 Stunden verbunden.</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">Zurück: Übersicht über Anwendungsfälle für Hadoop Datensicherung.</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Abwärtskompatibilität der Software:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">Die vorgeschlagene alternative Backup-Lösung sollte mit den derzeit verwendeten Softwareversionen im Hadoop-produktiven Cluster kompatibel sein.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Zur Einhaltung der verpflichteten SLAs sollte die vorgeschlagene alternative Lösung sehr niedrige RPOs und RTOs erzielen.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">Das mit der NetApp Backup-Lösung erstellte Backup kann sowohl in dem lokalen Hadoop Cluster im Datacenter als auch in dem Hadoop Cluster verwendet werden, der am Disaster-Recovery-Standort am Remote-Standort ausgeführt wird.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">Die vorgeschlagene Lösung muss kostengünstig sein.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">Die vorgeschlagene Lösung muss die Performance-Auswirkungen auf die derzeit laufenden, in der Produktion laufenden Analysen während der Backup-Zeiten verringern.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">Bestehende Backup-Lösung des Kunden</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">Die Abbildung unten zeigt die ursprüngliche native Hadoop Backup-Lösung.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Die Produktionsdaten sind über das Zwischenbackup Cluster auf Band geschützt:</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1-Daten werden durch Ausführen des auf HDFS2 kopiert<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Der Backup-Cluster fungiert als NFS-Gateway und die Daten werden manuell über Linux auf Tapes kopiert<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> Befehl über die Tape Library.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Zu den Vorteilen der ursprünglichen nativen Hadoop Backup-Lösung gehören:</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">Die Lösung basiert auf nativen Hadoop-Befehlen, sodass der Anwender sich nicht mit neuen Verfahren vertraut machen muss.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">Die Lösung nutzt eine branchenübliche Architektur und Hardware.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Zu den Nachteilen der ursprünglichen nativen Hadoop-Backup-Lösung zählen:</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">Die lange Backup-Zeitdauer beträgt mehr als 24 Stunden, wodurch die Produktionsdaten gefährdet werden.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Erhebliche Performance-Verschlechterung des Clusters während der Backup-Zeiten</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">Das Kopieren auf Tape ist ein manueller Vorgang.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">Die Backup-Lösung ist in Bezug auf die erforderliche Hardware und die Arbeitsstunden, die für manuelle Prozesse erforderlich sind, teuer.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Backup-Lösungen</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">Auf der Grundlage dieser Herausforderungen und Anforderungen und unter Berücksichtigung des vorhandenen Backup-Systems wurden drei mögliche Backup-Lösungen vorgeschlagen. In den folgenden Abschnitten werden die drei verschiedenen Backup-Lösungen beschrieben, die als Lösung A bis Lösung C. bezeichnet wurden</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Lösung A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">Lösung A fügt das in-Place-Analysemodul zum Backup-Hadoop-Cluster hinzu. Damit können sekundäre Backups in NetApp NFS-Storage-Systemen erstellt werden, wodurch die Tape-Anforderungen entfallen werden, wie in der Abbildung unten dargestellt.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Zu den detaillierten Aufgaben für Solution A gehören:</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Das Hadoop Produktions-Cluster verfügt über die zu schützenden Analysedaten des Kunden in HDFS.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Der Hadoop Backup Cluster mit HDFS fungiert als Zwischenstandort der Daten. Nur ein paar Festplatten (JBOD) bieten den Storage für HDFS sowohl bei Produktions- als auch bei Backup-Hadoop-Clustern.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Der Schutz der Hadoop Produktionsdaten ist durch Ausführen des vor dem Produktions-Cluster HDFS und dem Backup-Cluster HDFS geschützt<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Der Hadoop Snapshot schützt die Daten vor der Produktion auf das Hadoop Backup-Cluster.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Der NetApp ONTAP Storage Controller liefert ein NFS-exportiertes Volume, das dem Hadoop Backup-Cluster bereitgestellt wird.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">Durch Ausführen des<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Befehl mittels MapReduce und multiplen Mappern werden die Analysedaten über das in-Place-Analysemodul vor dem Hadoop Backup-Cluster in NFS geschützt.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Nachdem die Daten im NFS auf dem NetApp Storage-System gespeichert wurden, werden mithilfe von NetApp Snapshot, SnapRestore und FlexClone Technologien die Hadoop Daten nach Bedarf gesichert, wiederhergestellt und dupliziert.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Hadoop Daten lassen sich mit SnapMirror Technologie in der Cloud sowie an Disaster Recovery-Standorten sichern.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">Die Vorteile der Lösung A umfassen:</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Die Produktionsdaten von Hadoop sind vor dem Backup-Cluster geschützt.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Die HDFS-Daten werden durch NFS geschützt, sodass sie in der Cloud und bei der Disaster-Recovery-Wiederherstellung gesichert sind.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Verbessert die Performance durch Auslagerung von Backup-Vorgängen auf das Backup-Cluster.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Keine manuellen Tape-Vorgänge mehr nötig</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Ermöglicht Enterprise Management-Funktionen über NetApp Tools.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Erfordert minimale Änderungen an der vorhandenen Umgebung.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">Ist eine kostengünstige Lösung.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">Der Nachteil dieser Lösung ist, dass ein Backup-Cluster und zusätzliche Mappern benötigt werden, um die Performance zu verbessern.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Der Kunde hat vor Kurzem eine Lösung A implementiert, weil es einfach, kostengünstig und insgesamt Performance bietet.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">In dieser Lösung können SAN-Festplatten von ONTAP anstelle von JBOD verwendet werden. Diese Option entlastet den Storage für das Backup-Cluster an ONTAP, allerdings sind die SAN-Fabric-Switches erforderlich.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Lösung B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">Lösung B fügt dem Hadoop Cluster in der Produktionsumgebung das in-Place-Analysemodul hinzu, wodurch der Bedarf an einem Backup-Hadoop-Cluster entfällt, wie in der Abbildung unten dargestellt.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Zu den detaillierten Aufgaben für Lösung B gehören:</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Der NetApp ONTAP Storage Controller stellt den NFS-Export in das produktive Hadoop Cluster bereit.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Hadoop als native Cloud<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl schützt die Hadoop Daten vom Produktions-Cluster HDFS durch NFS über das in-Place-Analysemodul.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Nachdem die Daten im NFS auf dem NetApp Storage-System gespeichert wurden, werden die Snapshot, SnapRestore und FlexClone Technologien verwendet, um die Hadoop Daten nach Bedarf zu sichern, wiederherzustellen und zu duplizieren.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">Zu den Vorteilen von Lösung B gehören:</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Das produktive Cluster wird für die Backup-Lösung leicht modifiziert, wodurch die Implementierung vereinfacht und die zusätzlichen Infrastrukturkosten gesenkt werden.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Ein Backup-Cluster für den Backup-Vorgang ist nicht erforderlich.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS-Produktionsdaten werden bei der Umwandlung in NFS-Daten geschützt.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">Die Lösung ermöglicht Enterprise Management-Funktionen über NetApp Tools.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">Der Nachteil dieser Lösung ist, dass sie im Produktionscluster implementiert wird, was zusätzliche Administratoraufgaben im Produktionscluster hinzufügen kann.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Lösung C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">In Lösung C werden die NetApp SAN-Volumes für HDFS-Storage direkt in dem Hadoop Produktions-Cluster bereitgestellt, wie in der Abbildung unten gezeigt.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Zu den detaillierten Schritten für Lösung C gehören:</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">Der NetApp ONTAP SAN-Storage wird im Hadoop Cluster in der Produktionsumgebung für HDFS-Storage bereitgestellt.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Mit NetApp Snapshot und SnapMirror Technologien werden die HDFS-Daten aus dem Hadoop Cluster in der Produktionsumgebung gesichert.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">Für den Hadoop/Spark-Cluster während des Backup-Prozesses mit Snapshot-Kopien werden keine Performance-Auswirkungen auf die Produktion erzielt, da sich das Backup auf Storage-Ebene befindet.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">Die Snapshot Technologie ermöglicht Backups, die innerhalb von Sekunden abgeschlossen werden, unabhängig von der Größe der Daten.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">Lösung C bietet u. a. folgende Vorteile:</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">Platzsparende Backups können mithilfe der Snapshot Technologie erstellt werden.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">Als Nächstes: Anwendungsfall 2: Backup und Disaster Recovery von der Cloud in On-Premises-Systeme.</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">In diesem technischen Bericht werden die Vorteile beschrieben, die NetApp einer Splunk SmartStore-Lösung bietet und zugleich ein Framework für die Entwicklung und Dimensionierung von Splunk SmartStore in Ihrer Umgebung demonstriert. Das Ergebnis ist eine einfache, skalierbare und ausfallsichere Lösung mit überzeugender TCO.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: NetApp StorageGRID with Splunk SmartStore</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">Karthikeyan Nagalingam, Bobby Oommen, Joseph Kandatilparambil</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise ist die marktführende SIEM-Lösung (Security Information and Event Management), die Resultate in allen Sicherheits-, IT- und DevOps-Teams erzielt. Datenvolumen wachsen weiterhin exponentiell, wodurch Unternehmen enorme Chancen nutzen können, diese enorme Ressource zu nutzen. Splunk Enterprise wird in einer Vielzahl von Anwendungsfällen weiter eingesetzt. Mit den wachsenden Anwendungsfällen nimmt auch die Menge der von Splunk Enterprise aufgenommenen und -Prozesse zu. Die herkömmliche Architektur von Splunk Enterprise ist ein verteiltes Scale-out-Design und bietet hervorragende Datenzugriff und -Verfügbarkeit. Allerdings sehen sich Unternehmen, die diese Architektur verwenden, mit steigenden Kosten konfrontiert, die durch Skalierung entstehen, um das schnell wachsende Datenvolumen zu bewältigen.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore mit NetApp StorageGRID löst diese Herausforderung durch die Bereitstellung eines neuen Implementierungsmodells, in dem Computing und Storage entkoppelt sind. Mit dieser Lösung können Splunk Enterprise-Umgebungen nicht nur eine hervorragende Skalierbarkeit und Flexibilität bieten, sondern sie ermöglicht es Unternehmen, über einzelne und mehrere Standorte hinweg zu skalieren. Gleichzeitig sinken die Kosten, da Computing und Storage unabhängig skaliert werden können und intelligentes Tiering zu kostengünstigem Cloud- basiertem S3 Objekt-Storage hinzugefügt wird.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">Die Lösung optimiert das Datenvolumen im lokalen Storage und sorgt gleichzeitig für eine bessere Such-Performance, sodass Computing und Storage nach Bedarf skaliert werden können. SmartStore wertet Datenzugriffsmuster automatisch aus, um zu ermitteln, welche Daten für Echtzeitanalysen zur Verfügung stehen müssen und welche Daten im kostengünstigen S3-Objekt-Storage gespeichert werden sollten.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">In diesem technischen Bericht werden die Vorteile beschrieben, die NetApp einer Splunk SmartStore-Lösung bietet und zugleich ein Framework für die Entwicklung und Dimensionierung von Splunk SmartStore in Ihrer Umgebung demonstriert. Das Ergebnis ist eine einfache, skalierbare und ausfallsichere Lösung mit überzeugender TCO. StorageGRID bietet das skalierbare und kostengünstige S3-Protokoll/API-basierten Objekt-Storage, auch Remote-Storage genannt, mit dem Unternehmen ihre Splunk Lösung zu niedrigeren Kosten skalieren und gleichzeitig die Ausfallsicherheit verbessern können.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore bezieht sich auf Objekt-Storage als Remote-Stores oder Remote-Storage-Tiers.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">Über NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID ist eine softwaredefinierte Objekt-Storage-Lösung für große Archive, Medien-Repositorys und Web-Datastores. Mit StorageGRID verfügt NetApp über zwei Jahrzehnte Erfahrung in der Bereitstellung branchenführender innovativer Datenmanagement- und Innovationslösungen, die Unternehmen dabei unterstützen, ihre Informationen sowohl vor Ort als auch in Public-, Private- oder Hybrid-Cloud-Implementierungen zu managen und optimal auszunutzen.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID bietet sicheren, langlebigen Storage für unstrukturierte Daten jeder Größenordnung. Die integrierten, metadatengestützten Lifecycle Management-Richtlinien optimieren den Speicherort Ihrer Daten während ihrer gesamten Lebensdauer. Inhalte werden zur richtigen Zeit am richtigen Ort und auf der richtigen Storage-Tier platziert, um Kosten zu senken. Dank eines Single Namespace können Daten unabhängig vom geografischen Standort des StorageGRID Storage über einen einzelnen Anruf abgerufen werden. Kunden können mehrere StorageGRID Instanzen zwischen Datacentern und in der Cloud-Infrastruktur implementieren und managen.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Ein StorageGRID System besteht aus weltweit verteilten, redundanten und heterogenen Nodes, die sich sowohl in vorhandene als auch in Client-Applikationen der nächsten Generation integrieren lassen.</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape: Kürzlich hat NetApp im neuesten Bericht „IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment“ unter den Marktführern gelistet. StorageGRID wurde bereits seit fast 20 Jahren erfolgreich in Produktionsumgebungen in den anspruchsvollsten Branchen implementiert und ist ein führender Anbieter unstrukturierter Daten.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">StorageGRID bietet folgende Vorteile:</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Implementierung mehrerer StorageGRID-Instanzen zum Zugriff auf Daten von jedem Standort zwischen Datacentern und der Cloud über einen einzelnen Namespace, der leicht auf Hunderte Petabyte skaliert werden kann</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Flexibles Implementieren und zentrales Management über Infrastrukturübergreifend</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Durch mehrstufiges Erasure Coding (EC) sorgen Sie für eine beispiellose Datenaufbewahrung mit einer Verfügbarkeit von durchschnittlich 99,999 %.</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Mehr Hybrid-Multi-Cloud-Funktionen mit validierten Integrationen in Amazon S3 Glacier und Azure Blob</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Erfüllen Sie gesetzliche Vorgaben und erleichtern Sie die Compliance durch manipulationssichere Datenaufbewahrung, ohne proprietäre APIs oder die Festlegung auf einen Anbieter.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID Startseite</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Weitere Informationen dazu, wie StorageGRID Sie bei der Lösung komplexerer Management-Probleme unstrukturierter Daten unterstützt, finden Sie im<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>.</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Informationen Zu Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise ist eine Plattform, mit der Daten genutzt werden können. Daten, die von verschiedenen Quellen wie Log-Dateien, Websites, Geräten, Sensoren und Applikationen generiert werden, werden an Splunk Indexer gesendet und analysiert. So erhalten Sie umfassende Einblicke aus den Daten. Sie kann Verletzungen des Datenschutzes erkennen, Kunden- und Produkttrends aufzeigen, Chancen finden, die Infrastruktur zu optimieren oder umsetzbare Erkenntnisse für eine Vielzahl von Anwendungsfällen gewinnen.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Über Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore erschließt die Vorteile der Splunk Architektur und vereinfacht zugleich eine kostengünstige Skalierung. Die Abkopplung von Computing- und Storage-Ressourcen führt zu einem für I/O optimierten Indexer-Node mit deutlich geringerem Storage-Bedarf, da nur eine Teilmenge an Daten als Cache gespeichert wird. Sie müssen keinen zusätzlichen Rechen- oder Storage-Ressourcen hinzufügen, wenn nur eine dieser Ressourcen benötigt wird, was Ihnen erhebliche Kosteneinsparungen ermöglicht. Sie können kostengünstigen und einfach skalierbaren S3-basierten Objekt-Storage verwenden, der die Umgebung weiter vereinfacht, Kosten senkt und einen massiveren Datensatz ermöglicht.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore bietet Unternehmen einen erheblichen Mehrwert, darunter:</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Senkung der Storage-Kosten durch Verschieben von warmen Daten auf kostenoptimierten S3 Objekt-Storage</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Nahtlose Skalierbarkeit dank Abkopplung von Storage und Computing</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Vereinfachung von Business Continuity durch Einsatz von stabilem Cloud-nativem Storage</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">Als Nächstes: Die Vorteile dieser Lösung.</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Auf dieser Seite wird die in dieser Lösung verwendete Technologie beschrieben.</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">Früher: Lösung.</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="paragraph">In diesem Abschnitt wird die in dieser Lösung verwendete Technologie beschrieben.</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP Storage Controller</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP ist ein hochperformantes Storage-Betriebssystem der Enterprise-Klasse.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 unterstützt die Amazon Simple Storage Service (S3) APIs. ONTAP unterstützt einen Teilbereich der S3-API-Aktionen von Amazon Web Services (AWS) und ermöglicht die Darstellung von Daten in ONTAP-basierten Systemen über Cloud-Provider (AWS, Azure und GCP) und On-Premises hinweg.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID Software ist die Flaggschiff der NetApp Lösung für Objekt-Storage. ONTAP ergänzt StorageGRID durch die Bereitstellung eines On-the-Edge-Aufnahmerepunkts und einen Vorverarbeitungspunkt auf der Basis von NetApp für Objektdaten, eine Erweiterung der Data Fabric Strategie bei der Erweiterung des NetApp Produktportfolios und eine Steigerung des Mehrwerts des NetApp Produktportfolios.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">Der Zugriff auf einen S3-Bucket wird über autorisierte Benutzer- und Client-Applikationen bereitgestellt. Im folgenden Diagramm ist die Applikation, die auf einen S3-Bucket zugreift, dargestellt.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">In dieser Grafik wird die Applikation angezeigt, die auf einen S3-Bucket zugreift.</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Primäre Anwendungsfälle</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">Durch die Unterstützung von S3-APIs soll primär der Zugriff auf Objekte auf ONTAP bereitgestellt werden. Die Unified Storage-Architektur von ONTAP unterstützt jetzt Dateien (NFS und SMB), Blöcke (FC und iSCSI) und Objekte (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Native S3-Applikationen</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">Eine wachsende Anzahl von Applikationen kann ONTAP-Unterstützung für Objektzugriff über S3 nutzen. Obwohl sich der Bedarf an hoher Performance in nativen S3-Applikationen für Archivierungs-Workloads eignet, wächst auch hier schnell der Bedarf an:</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analysen</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Künstliche Intelligenz</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Edge-to-Core-Aufnahme</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="list-text">Machine Learning</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Kunden können jetzt vertraute Management-Tools wie ONTAP System Manager verwenden, um hochperformanten Objekt-Storage für Entwicklung und Betrieb in ONTAP bereitzustellen und so die Effizienz und Sicherheit von ONTAP Storage zu nutzen.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool-Endpunkte</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">Ab ONTAP 9.8 unterstützt FabricPool Tiering für Buckets in ONTAP, sodass auch ONTAP-zu-ONTAP-Tiering genutzt werden kann. Dies ist eine hervorragende Option für Kunden, die eine vorhandene FAS-Infrastruktur als Objektspeicher-Endpunkt nutzen möchten.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool unterstützt Tiering zu ONTAP auf zwei Arten:</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Lokales Cluster Tiering.* inaktive Daten werden mithilfe von Cluster LIFs zu einem Bucket auf dem lokalen Cluster verschoben.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Remote Cluster Tiering.* inaktive Daten werden auf einem Bucket auf einem Remote-Cluster ähnlich wie auf einem herkömmlichen FabricPool Cloud Tier mit IC LIFs auf dem FabricPool Client und Daten-LIFs auf dem ONTAP Objektspeicher verschoben.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 ist die richtige Lösung, wenn Sie S3-Funktionen auf vorhandenen Clustern ohne zusätzliche Hardware und Management wünschen. Für Implementierungen mit über 300 TB ist NetApp StorageGRID immer noch die Vorzeige-NetApp Lösung für Objekt-Storage. Bei der Nutzung von ONTAP oder StorageGRID als Cloud-Tier ist keine FabricPool Lizenz erforderlich.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP für Confluent Tiered Storage</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Jedes Datacenter muss geschäftskritische Applikationen unterbrechungsfrei laufen lassen und wichtige Daten verfügbar und sicher halten. Das neue NetApp AFF A900 System wird durch ONTAP Enterprise Edition Software und einem äußerst Resilience Design unterstützt. Unser neues, blitzschnelles NVMe-Storage-System beseitigt Unterbrechungen geschäftskritischer Prozesse, minimiert das Performance-Tuning und schützt Ihre Daten vor Ransomware-Angriffen.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Von der ersten Implementierung bis zur Skalierung Ihres Confluent Clusters muss Ihre Umgebung schnell an Änderungen angepasst werden, die unterbrechungsfrei auf Ihre geschäftskritischen Applikationen abgestimmt sind. Mit ONTAP Lösungen für Enterprise-Datenmanagement, Quality of Service (QoS) und Performance können Unternehmen ihre Umgebung planen und anpassen.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">Der Einsatz von NetApp ONTAP und Confluent Tiered Storage vereinfacht zusammen das Management von Apache Kafka Clustern durch die Nutzung von ONTAP als Scale-out Storage-Ziel und ermöglicht eine unabhängige Skalierung von Computing- und Storage-Ressourcen für Conflient.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Ein ONTAP S3 Server baut auf den ausgereiften Scale-out-Storage-Funktionen von ONTAP auf. Die ONTAP Cluster lassen sich nahtlos skalieren, indem die S3-Buckets erweitert werden, um neu hinzugefügte Nodes im ONTAP Cluster zu verwenden.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Einfaches Management mit ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">Bei ONTAP System Manager handelt es sich um eine browserbasierte grafische Oberfläche, mit der Sie Ihren ONTAP Storage Controller an weltweit verteilten Standorten über eine zentrale Konsole konfigurieren, managen und überwachen können.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">In dieser Abbildung wird der Arbeitsbereich des ONTAP-System-Managers angezeigt.</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">ONTAP S3 lässt sich mit System Manager und der ONTAP CLI konfigurieren und verwalten. Wenn Sie S3 aktivieren und Buckets mithilfe von System Manager erstellen, bietet ONTAP Best-Practice-Standards für eine vereinfachte Konfiguration. Wenn Sie den S3-Server und die Buckets aus der CLI konfigurieren, können Sie sie nach Bedarf auch mit System Manager managen oder umgekehrt.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Wenn Sie mit System Manager einen S3-Bucket erstellen, konfiguriert ONTAP ein Service-Level für die Standard-Performance, das auf Ihrem System am höchsten verfügbar ist. Bei einem AFF-System wäre die Standardeinstellung „Extreme“. Performance-Service-Level sind vordefinierte, anpassungsfähige QoS-Richtliniengruppen. Anstelle eines der Standard-Service-Level können Sie eine benutzerdefinierte QoS-Richtliniengruppe oder keine Richtliniengruppe angeben.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Zu den vordefinierten anpassungsfähigen QoS-Richtliniengruppen gehören:</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extreme.* wird für Anwendungen verwendet, die die niedrigste Latenz und höchste Performance benötigen.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Performance.* wird für Applikationen mit geringen Performance-Anforderungen und Latenz verwendet.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Wert* wird für Applikationen verwendet, bei denen Durchsatz und Kapazität wichtiger sind als die Latenz.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Benutzerdefiniert.* Geben Sie eine benutzerdefinierte QoS-Richtlinie oder keine QoS-Richtlinie an.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Wenn Sie *für Tiering* verwenden auswählen, werden keine Leistungsservicelevel ausgewählt und das System versucht, kostengünstige Medien mit optimaler Leistung für die Tiered Data auszuwählen.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP versucht, diesen Bucket auf lokalen Tiers bereitzustellen, die über die am besten geeigneten Festplatten verfügen und dem ausgewählten Service-Level gerecht werden. Wenn Sie jedoch angeben müssen, welche Festplatten in den Bucket enthalten sind, sollten Sie S3-Objekt-Storage aus der CLI konfigurieren, indem Sie die lokalen Tiers (Aggregat) angeben. Wenn Sie den S3-Server über die CLI konfigurieren, können Sie ihn bei Bedarf weiterhin mit System Manager managen.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Wenn Sie angeben können, welche Aggregate für Buckets verwendet werden, können Sie dies nur über die CLI tun.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform ist eine umfassende Daten-Streaming-Plattform, auf die Sie als kontinuierliche Echtzeit-Streams auf einfache Weise auf Daten zugreifen, diese speichern und managen können. Confluent wurde von den ursprünglichen Schöpfern von Apache Kafka erbaut und erweitert die Vorteile von Kafka mit Funktionen der Enterprise-Klasse, ohne Kafka-Management oder -Monitoring zu belasten. Heute basieren mehr als 80 % der Fortune 100 auf Data Streaming-Technologie, und die meisten nutzen Confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Warum Confluent?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Durch die Integration von historischen und Echtzeit-Daten in eine einzige, zentrale Quelle der Wahrheit erleichtert Confluent den Aufbau einer völlig neuen Kategorie moderner, ereignisgesteuerter Anwendungen, die Erstellung einer universellen Datenpipeline und die Nutzung leistungsstarker neuer Anwendungsfälle mit voller Skalierbarkeit, Leistung und Zuverlässigkeit.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Wofür wird Confluent verwendet?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Mit der Conflient Platform können Sie sich darauf konzentrieren, wie Sie aus Ihren Daten einen geschäftlichen Nutzen ziehen können, statt sich um die zugrunde liegenden Mechanismen sorgen zu müssen, wie beispielsweise der Transport oder die Integration von Daten zwischen verschiedenen Systemen. Confluent Platform vereinfacht insbesondere die Anbindung von Datenquellen an Kafka, die Erstellung von Streaming-Applikationen sowie die Sicherung, Überwachung und das Management der Kafka Infrastruktur. Heute kommt die Confluent Platform für eine Vielzahl von Anwendungsfällen in zahlreichen Branchen zum Einsatz, von Finanzdienstleistungen über Omnichannel-Einzelhandel, autonomen Fahrzeugen bis hin zu Betrugserkennung, Microservices und IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">Die folgende Abbildung zeigt die Komponenten der Confluent Platform.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Diese Grafik zeigt die Komponenten der Confluent Platform.</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Überblick über die Confluent Event Streaming Technologie</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Der Kern der Confluent Platform ist<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>, Die beliebteste verteilte Open Source Streaming-Plattform. Kafka bietet u. a. folgende zentrale Funktionen:</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Veröffentlichen und abonnieren Sie Datenströme.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Fehlertolerante Speicherung von Datenströmen</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Verarbeiten von Datensätzen.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Die Confluent Platform umfasst außerdem Schema Registry, REST Proxy, insgesamt 100+ vordefinierte Kafka-Anschlüsse und ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Überblick über die Enterprise-Funktionen der Confluent Plattform</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent Control Center.* ein UI-basiertes System zur Verwaltung und Überwachung von Kafka. Damit können Sie Kafka Connect ganz einfach verwalten und Verbindungen zu anderen Systemen erstellen, bearbeiten und verwalten.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Fließend für Kubernetes.* der fließende für Kubernetes ist ein Kubernetes Operator. Kubernetes-Betreiber erweitern die Orchestrierungsfunktionen von Kubernetes um spezielle Funktionen und Anforderungen für eine spezifische Plattform-Applikation. Bei Confluent Platform müssen dazu die Implementierung von Kafka auf Kubernetes erheblich vereinfacht und typische Aufgaben im Infrastruktur-Lebenszyklus automatisiert werden.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Kafka Connect Connectors.* Steckverbinder verbinden Kafka Connect mit anderen Systemen wie Datenbanken, Schlüsselwertspeicher, Suchindizes und Dateisystemen. Confluent Hub verfügt über herunterladbare Anschlüsse für die beliebtesten Datenquellen und Waschbecken, einschließlich vollständig getestete und unterstützte Versionen dieser Anschlüsse mit Confluent Platform. Weitere Details finden Sie hier<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Self-Balancing Cluster.* bietet automatisches Load Balancing, Fehlererkennung und Selbstheilung. Auch das Hinzufügen oder Dekommissionierung von Vermittlern nach Bedarf ohne manuelles Tuning ist möglich.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*Fließende Cluster-Verknüpfung.* verbindet Cluster direkt miteinander und spiegelt Themen von einem Cluster zum anderen über eine Link-Bridge. Die Cluster-Verknüpfung vereinfacht die Einrichtung von Implementierungen mit mehreren Rechenzentren, mehreren Clustern und Hybrid Clouds.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Confluent Auto Data Balancer.* überwacht Ihren Cluster für die Anzahl der Broker, die Größe der Partitionen, die Anzahl der Partitionen und die Anzahl der Führer innerhalb des Clusters. Auf diese Weise können Sie Daten verschieben, um einen geraden Workload über Ihr Cluster zu erstellen, und gleichzeitig den Datenverkehr neu verteilen, um die Auswirkungen auf die Produktions-Workloads bei der Ausbalancierung zu minimieren.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Confluent Replikator.* macht es einfacher als je zuvor, mehrere Kafka Cluster in mehreren Rechenzentren zu pflegen.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Tiered Storage.* bietet Optionen zur Speicherung großer Kafka-Datenmengen mit Ihrem bevorzugten Cloud-Provider und reduziert so die Betriebskosten und die Kosten. Mit Tiered Storage können Sie Daten auf kostengünstigem Objekt-Storage und Vermittlern nur dann aufbewahren, wenn Sie mehr Computing-Ressourcen benötigen.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Confluent JMS Client.* Confluent Platform enthält einen JMS-kompatiblen Client für Kafka. Dieser Kafka-Client implementiert die JMS 1.1 Standard-API und verwendet Kafka-Broker als Backend. Dies ist nützlich, wenn vorhandene Anwendungen JMS verwenden und Sie den vorhandenen JMS-Nachrichten-Broker durch Kafka ersetzen möchten.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT Proxy.* bietet eine Möglichkeit, Daten direkt an Kafka von MQTT-Geräten und Gateways zu veröffentlichen, ohne dass ein MQTT-Broker in der Mitte nötig ist.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent Security Plugins.* Confluent Security Plugins werden verwendet, um Sicherheitsfunktionen zu verschiedenen Tools und Produkten der Confluent Platform hinzuzufügen. Derzeit gibt es ein Plugin für den Confluent REST Proxy, das hilft, die eingehenden Anfragen zu authentifizieren und den authentifizierten Principal an Anfragen an Kafka zu verbreiten. Auf diese Weise können Confluent REST Proxy-Clients die mandantenfähigen Sicherheitsfunktionen des Kafka-Brokers nutzen.</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">Als Nächstes: Validierung der Performance mit Confluent.</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Auf dieser Seite werden die wichtigsten Anwendungsfälle und Architekturen für KI, ML und DL im Detail beschrieben.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Anwendungsfälle und Architekturen für KI, ML und DL</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">Zurück – Übersicht zu Anwendungsfällen</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Größere Anwendungsfälle und Methoden für KI, ML und DL können in die folgenden Abschnitte unterteilt werden:</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLP-Pipelines und TensorFlow Distributed Inferenzierung</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">Die folgende Liste enthält die beliebtesten Open-Source-NLP-Bibliotheken, die von der Data Science-Community unter verschiedenen Entwicklungsstufen übernommen wurden:</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Natural Language Toolkit (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>. Das komplette Toolkit für alle NLP-Techniken. Es wurde seit den frühen 2000er Jahren erhalten.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>. Eine einfach zu bedienende NLP-Tools Python-API, die auf NLTK und Pattern aufgebaut ist.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>. NLP-Dienste und -Pakete in Java, entwickelt von der Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>. Thema Modellierung für Menschen begann als Sammlung von Python-Skripten für das Projekt der Tschechischen Digital Mathematics Library.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">Spacy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>. Durchgängige industrielle NLP-Workflows mit Python und Cython mit GPU-Beschleunigung für Transformatoren.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Fasttext</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>. Eine kostenlose, leichte, Open-Source-NLP-Bibliothek für das Lernen von Wortschaltungen und Satzklassifizierung, die im AI Research Lab (FAIR) von Facebook erstellt wurde.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Funken ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">Spark NLP ist eine einzige, einheitliche Lösung für alle NLP-Aufgaben und -Anforderungen, die skalierbare, leistungsstarke und hochpräzise NLP-gestützte Software für reale Produktionsanwendungsfälle ermöglicht. Es nutzt Transfer-Learning und implementiert modernste Algorithmen und Modelle in der Forschung und Industrie. Da Spark keine volle Unterstützung für die oben genannten Bibliotheken hat, wurde Spark NLP auf der Basis aufgebaut<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Um die Vorteile der universellen in-Memory Distributed Data Processing Engine von Spark als NLP-Bibliothek der Enterprise-Klasse für unternehmenskritische Produktions-Workflows zu nutzen. Die Kommentatoren nutzen regelbasierte Algorithmen, Machine Learning und TensorFlow, um Deep-Learning-Implementierungen zu unterstützen. Dies betrifft gängige NLP-Aufgaben, einschließlich aber nicht beschränkt auf Tokenisierung, Lemmatisierung, Stemming, Teil-of-Speech-Tagging, benannte Entity-Erkennung, Rechtschreibprüfung und Sentiment-Analyse.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Bidirektionale Encoder-Darstellungen von Transformatoren (BERT) ist eine Transformatorbasierte Machine Learning-Technik für NLP. Es popularisierte das Konzept der Vorausbildung und Feinabstimmung. Die Transformatorarchitektur in BERT entstand aus maschineller Übersetzung, die langfristige Abhängigkeiten besser modelt als rezidierende Neural Network (RNN)-basierte Sprachmodelle. Außerdem wurde die MLM-Aufgabe (Masked Language Modeling) eingeführt, bei der zufällige 15 % aller Token maskiert und das Modell sie vorhersagt, wodurch eine echte Bidirektionalität möglich ist.</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters-TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">FinanzphraseBank</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">Sentiment Analysis for Financial News</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Dokument-DL erklären</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">Die Analyse der Finanzstimmung ist aufgrund der Fachsprache und des Mangels an gekennzeichneten Daten in diesem Bereich schwierig.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, Ein Sprachmodell basierend auf vortrainierten BERT, wurde Domain angepasst<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>, Ein Finanzkorpus, und fein abgestimmt mit beschrifteten Daten (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>) Für die Klassifizierung der Finanzstimmung. Forscher haben 4, 500 Sätze aus Nachrichten-Artikeln mit finanziellen Begriffen extrahiert. Dann 16 Experten und Master Studenten mit Finanz-Hintergrund bezeichnet die Sätze als positiv, neutral und negativ. Wir haben einen End-to-End Spark-Workflow entwickelt, um die Stimmung für die von 2016 bis 2020 am NASDAQ am Markt vertelefonisch unter den Top-10-Unternehmen zu analysieren und FinBERT sowie zwei weitere vortrainierte Pipelines (<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>) Von Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Die zugrunde liegende Deep-Learning-Engine für Spark NLP ist TensorFlow, eine End-to-End-Open-Source-Plattform für Machine Learning, die den einfachen Modellbau, die robuste ML-Produktion an jedem Ort und leistungsstarke Experimente ermöglicht. Deshalb bei der Ausführung unserer Pipelines in Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> Modus, wir hatten im Wesentlichen Distributed TensorFlow mit Daten und Modellparallelisierung über einen Master- und mehrere Worker-Node sowie über den auf dem Cluster angebundenen Network-Attached Storage.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod Distributed Training</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969: NetApp Lösungen für Hadoop</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">Die Kernvalidierung für MapReduce-bezogene Performance wird mit TeraGen, TeraSort, TeraValidate und DFSIO (Lese- und Schreibvorgänge) durchgeführt. Die Ergebnisse der TeraGen und TeraSort Validierung werden in vorgestellt<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> Für E-Series und im Abschnitt „Storage Tiering“ (xref) für AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod auf Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Auf Kundenwünsche basieren verteilte Schulungen mit Spark auf einer der wichtigsten Nutzungsfälle. In diesem Dokument wurden von verwendet<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> Spark-Performance mit NetApp On-Premises-, Cloud-nativen und Hybrid-Cloud-Lösungen mit NetApp All Flash FAS (AFF) Storage-Controllern, Azure NetApp Files und StorageGRID validieren</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Das Paket Horovod on Spark bietet eine praktische Wrapper für Horovod, mit der verteilte Trainings-Workloads in Spark-Clustern einfach ausgeführt werden. Es ermöglicht einen eng aneinander auslaufenden Modelldesign-Loop, in dem Datenverarbeitung, Modelltraining und Modellevaluierung in Spark ausgeführt werden, wo sich die Trainings- und Inferenzdaten befinden.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann Store Sales</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Es gibt zwei APIs für die Ausführung von Horovod auf Spark: Eine High-Level Estimator API und eine Low-Level-Run-API. Obwohl beide den gleichen zugrunde liegenden Mechanismus verwenden, um Horovod auf Spark-Executoren zu starten, abstrahiert die Estimator-API die Datenverarbeitung, Modelltrainingschleife, Modell Checkpointing, Kennzahlenerfassung und verteilte Schulung. Wir haben Horovod Spark Estimators, TensorFlow und Keras eingesetzt, um eine End-to-End-Datenvorbereitung und einen verteilten Trainings-Workflow auf Basis der zu ermöglichen<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> Die Wettbewerbssituation.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Python-Skripte für jeden größeren Anwendungsfall.</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">Das Skript<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> Finden Sie im Abschnitt <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> Sie besteht aus drei Teilen:</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">Der erste Teil führt verschiedene Schritte zur Datenvorverarbeitung über einen ersten Satz von CSV-Dateien durch, die von Kaggle bereitgestellt und von der Community gesammelt werden. Die Eingabedaten werden mit einem in ein Trainingssatz unterteilt<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> Teilmenge und ein Testdatensatz.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">Der zweite Teil definiert ein Keras Deep Neural Network (DNN)-Modell mit logarithmischer Sigmoid-Aktivierungsfunktion und einem Adam-Optimizer und führt Distributed Training des Modells mit Horovod on Spark durch.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">Der dritte Teil führt eine Prognose für den Testdatensatz durch. Dabei wird das beste Modell verwendet, durch das der Validierungssatz insgesamt für absolute Fehler minimiert wird. Anschließend wird eine CSV-Ausgabedatei erstellt.</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">„Maschinelles Lernen“</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">Siehe Abschnitt <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> Für verschiedene Laufzeitvergleichsergebnisse.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Deep Learning mit mehreren Mitarbeitern und Keras für die CTR-Vorhersage</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">Aufgrund der jüngsten Fortschritte BEI ML-Plattformen und -Applikationen wird jetzt viel Aufmerksamkeit auf das Lernen in großen Umgebungen gerichtet. Die Klickrate (Klickrate, CTR) ist definiert als die durchschnittliche Anzahl der Klickrate pro hundert Online-Werbeeindrücke (ausgedrückt als Prozentsatz). Es wird in verschiedenen Branchen und Anwendungsfällen, darunter digitales Marketing, Einzelhandel, E-Commerce und Service-Provider, häufig als wichtige Metrik eingeführt. Sehen Sie unsere<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> Weitere Details zu den Applikationen von CTR und einer End-to-End-Cloud-KI-Workflow-Implementierung mit Kubernetes, Distributed Data ETL und Modelltraining mit Dask und CUDA ML</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte Klicken Sie auf Protokolldatensatz</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">In diesem technischen Bericht haben wir eine Variation der verwendet<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (Siehe TR-4904) für verteiltes Deep Learning mit Keras für mehrere Mitarbeiter, um einen Spark-Workflow mit Deep and Cross Network (DCN) Modellen zu erstellen, und vergleicht seine Leistung hinsichtlich der Log-Loss-Fehlerfunktion mit einem Basismodell des Spark ML Logistic Regression. DCN erfasst effiziente Interaktionen von Funktionen in begrenzt abstufenden Graden, erlernt hochnichtlineare Interaktionen, erfordert keine manuelle Funktionstechnik oder umfassende Suche und hat geringe Rechenkosten.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Daten für webbasierte Empfehlungssysteme sind meist diskret und kategorisch. Dies führt zu einem großen und spärlichen Speicherplatz, der für die Untersuchung von Funktionen eine Herausforderung darstellt. Dies hat die meisten Großsysteme auf lineare Modelle wie logistische Regression beschränkt. Das Erkennen häufig prädiktiver Funktionen und gleichzeitig das Erforschen von unsichtbaren oder seltenen Cross-Funktionen ist jedoch der Schlüssel für gute Vorhersagen. Lineare Modelle sind einfach, auswertbar und einfach zu skalieren, aber sie sind in ihrer Ausdruckskraft begrenzt.</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">Kreuzstücke hingegen haben sich als bedeutsam erwiesen, um die Ausdruckskraft der Modelle zu verbessern. Leider ist oftmals eine manuelle Funktionstechnik oder eine umfassende Suche erforderlich, um solche Funktionen zu identifizieren. Die Verallgemeinerung von Interaktionen mit unsichtbaren Funktionen ist oft schwierig. Die Verwendung eines neuronalen Netzwerks wie DCN vermeidet aufgabenspezifischen Funktionengineering, indem die Funktionsübergänge explizit automatisch angewendet werden. Das Cross-Netzwerk besteht aus mehreren Ebenen, wobei der höchste Grad an Interaktionen durch die Schichttiefe bestimmt wird. Jede Ebene erzeugt Interaktionen in höherer Reihenfolge, die auf bestehenden basieren, und behält die Interaktionen von vorherigen Ebenen.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Ein Deep Neural Network (DNN) verspricht sehr komplexe Interaktionen über verschiedene Funktionen hinweg. Im Vergleich zu DCN benötigt es jedoch fast eine Größenordnung von mehr Parametern, ist nicht in der Lage, Querfunktionen explizit zu bilden und kann möglicherweise nicht effizient lernen einige Arten von Feature-Interaktionen. Das Cross Network ist speichereffizient und einfach zu implementieren. Die gemeinsame Schulung der Cross- und DNN-Komponenten ermöglicht eine effiziente Erfassung prädiktiver Feature-Interaktionen und liefert hochmoderne Performance im Criteo CTR-Datensatz.</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">Ml</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">Mllib</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">Ein DCN-Modell beginnt mit einer Einbettung- und Stapelschicht, gefolgt von einem Cross-Netzwerk und einem tiefen Netzwerk parallel. Auf diese wiederum folgt eine endgültige Kombinationsschicht, die die Ausgänge der beiden Netzwerke miteinander kombiniert. Ihre Eingabedaten können ein Vektor mit spärlichen und dichten Funktionen sein. In Spark, beide<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> Und<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> Bibliotheken enthalten den Typ<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>. Daher ist es wichtig, dass die Benutzer zwischen den beiden unterscheiden und beim Aufruf ihrer jeweiligen Funktionen und Methoden achtsam sind. Bei empfohlenen Web-Scale-Systemen wie der CTR-Vorhersage handelt es sich beispielsweise um kategorische Merkmale<block ref="bf8b858b1d67b8d7c2676d6a7353c3c9" prefix=" " category="inline-code"></block>. Solche Funktionen werden oft als ein-Hot-Vektoren kodiert, z. B.<block ref="624411787ac52373d7cc41183768999c" prefix=" " category="inline-code"></block>. One-Hot-Encoding (OHE) mit<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> Ist nützlich beim Umgang mit Datensätzen aus der realen Welt mit sich ständig verändernden und wachsenden Vokabularen. Wir haben Beispiele in geändert<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> Um große Vokabularblätter zu verarbeiten, erstellen Einbettungsvektoren in der Einbettung- und Stapelschicht unseres DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo Display Ads-Datensatz</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">Der<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> Sagt die Durchklickrate für Werbeanzeigen aus. Es verfügt über 13 ganzzahlige Merkmale und 26 kategorische Merkmale, in denen jede Kategorie eine hohe Kardinalität hat. Bei diesem Datensatz ist eine Verbesserung von 0.001 im Logloss aufgrund der großen Eingangsgröße praktisch signifikant. Eine kleine Verbesserung der Vorhersagegenauigkeit für eine große Nutzerbasis kann möglicherweise zu einer großen Steigerung der Unternehmenseinnahmen führen. Der Datensatz enthält 11 GB Benutzerprotokolle von einem Zeitraum von 7 Tagen, was bedeutet etwa 41 Millionen Datensätzen. Wir haben Spark genutzt<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> Zur zufälligen Aufteilung der Daten für das Training (80 %), der Cross-Validierungen (10 %) und der verbleibenden 10 % für Tests</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN wurde unter TensorFlow mit Keras implementiert. Die Implementierung des Modelltrainings mit DCN umfasst vier Hauptkomponenten:</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Datenverarbeitung und Einbettung.* echte Funktionen werden durch Anwendung eines Logtransform normalisiert. Für kategorische Merkmale binden wir die Merkmale in dichte Vektoren der Dimension 6×(Category Cardinality)1/4 ein. Das Verketten aller Formationen ergibt einen Vektor der Dimension 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Optimierung.* Wir haben die Mini-Batch stochastische Optimierung mit dem Adam Optimizer angewendet. Die Batch-Größe wurde auf 512 gesetzt. Die Batch-Normalisierung wurde auf das tiefe Netzwerk angewendet und die Gradient-Clip-Norm wurde auf 100 gesetzt.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*Regularisierung.* Wir verwendeten das frühe Stoppen, da L2-Regularisierung oder Dropout nicht als wirksam erwiesen wurde.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hyperparameter.* die Ergebnisse werden anhand einer Rastersuche über die Anzahl der ausgeblendeten Schichten, die versteckte Ebenengröße, die anfängliche Lernrate und die Anzahl der Querschichten berichtet. Die Anzahl der versteckten Schichten reichte von 2 bis 5, mit versteckten Schichtgrößen von 32 bis 1024. Bei DCN betrug die Anzahl der Querschichten von 1 bis 6. Die erste Lernrate wurde von 0.0001 auf 0.001 mit Schritten von 0.0001 abgestimmt. Alle Experimente haben einen frühen Stopp bei Trainingsschritt 150,000 durchgeführt, über den die Überlastung begann.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">XDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">AutoInt</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">Neben DCN haben wir auch andere gängige Deep-Learning-Modelle für die CTR-Vorhersage getestet, einschließlich<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>,<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>, und<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>.</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Zur Validierung verwendete Architekturen</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Für diese Validierung haben wir vier Worker-Nodes und einen Master-Node mit einem AFF A800 HA-Paar verwendet. Die Verbindung aller Cluster-Mitglieder wurde über 10-GbE-Netzwerk-Switches hergestellt.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Für diese Validierung der NetApp Spark-Lösungen haben wir drei verschiedene Storage-Controller verwendet: E5760, E5724 und AFF-A800. Die Storage-Controller der E-Series wurden mit fünf Daten-Nodes mit SAS-Verbindungen mit 12 Gbit/s verbunden. Der AFF HA-Paar-Storage Controller liefert exportierte NFS-Volumes über 10-GbE-Verbindungen zu Hadoop Worker-Nodes. Die Hadoop Cluster-Mitglieder wurden über 10-GbE-Verbindungen in den Hadoop Lösungen der E-Series, AFF und StorageGRID Hadoop verbunden.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Zur Validierung verwendete Architekturen.</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">Weiter: Testergebnisse.</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Auf dieser Seite werden die verschiedenen Bereiche beschrieben, in denen diese Lösung verwendet werden kann.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Zusammenfassung des Anwendungsfalls</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">Weiter: Übersicht über die NetApp Spark-Lösungen</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Streaming von Daten</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark kann Streamingdaten verarbeiten, die für ETL-Prozesse (Extrahieren, Transformieren, Laden), Anreicherung, Auslösen von Ereigniserkennung und komplexe Sitzungsanalysen verwendet werden:</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.* Daten werden kontinuierlich gereinigt und aggregiert, bevor sie in Datenspeicher geschoben werden. Netflix nutzt Kafka- und Spark-Streaming, um eine Online-Filmempfehlungen und eine Lösung für das Daten-Monitoring in Echtzeit zu erstellen, mit der täglich Milliarden von Ereignissen aus unterschiedlichen Datenquellen verarbeitet werden können. Herkömmliche ETL für die Batch-Verarbeitung wird jedoch unterschiedlich behandelt. Diese Daten werden zuerst gelesen und dann in ein Datenbankformat konvertiert, bevor sie in die Datenbank geschrieben werden.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Datenanreicherung.* Spark Streaming bereichert die Live-Daten mit statischen Daten, um eine Echtzeitdatenanalyse zu ermöglichen. So können Online-Werbetreibende beispielsweise personalisierte, gezielte Werbeanzeigen liefern, die von Informationen über das Kundenverhalten geleitet werden.</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*Trigger Event Detection.* mit Spark Streaming können Sie ungewöhnliche Verhaltensweisen erkennen und schnell darauf reagieren, die möglicherweise schwerwiegende Probleme darstellen könnten. So verwenden Finanzinstitute beispielsweise Auslöser zum Erkennen und Stoppen von Betrugstransaktionen, und Krankenhäuser verwenden Auslöser, um gefährliche Gesundheitsänderungen zu erkennen, die in den Vitalparamalen eines Patienten nachgewiesen wurden.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Komplexe Sitzungsanalyse.* Spark Streaming erfasst Ereignisse wie Benutzeraktivitäten nach der Anmeldung an einer Website oder Anwendung, die dann gruppiert und analysiert werden. Beispielsweise setzt Netflix diese Funktionalität ein, um Filmempfehlungen in Echtzeit bereitzustellen.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link">TR-4912: Best Practice Guidelines für Conflient Kafka Tiered Storage mit NetApp</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">Weitere Informationen zur Konfiguration von Streaming-Daten, Confluent Kafka Verification und Performance-Tests finden Sie unter<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>.</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Das in Spark integrierte Framework ermöglicht es Ihnen, mithilfe der Machine Learning Library (MLlib) wiederholte Abfragen zu Datensätzen durchzuführen. MLlib wird in Bereichen wie Clustering, Klassifizierung und Größenreduzierung für einige gängige Big Data-Funktionen wie Predictive Intelligence, Kundensegmentierung zu Marketingzwecken und Sentiment-Analyse verwendet. MLlib wird zur Netzwerksicherheit verwendet, um Echtzeit-Inspektionen von Datenpaketen auf Anzeichen schädlicher Aktivität durchzuführen. Sicherheitsanbieter lernen neue Bedrohungen kennen und halten sich vor Hackern, während sie ihre Kunden in Echtzeit schützen.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">Deep Learning</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow ist ein beliebtes Deep-Learning-Framework, das in der Branche verwendet wird. TensorFlow unterstützt das verteilte Training auf einem CPU- oder GPU-Cluster. Dieses Distributed Training ermöglicht die Ausführung der IT-Abteilung bei großen Datenmengen mit vielen tiefgreifenden Schichten.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Bis ziemlich lange Zeit, wenn wir TensorFlow mit Apache Spark verwenden wollten, mussten wir alle erforderlichen ETL für TensorFlow in PySpark ausführen und dann Daten auf Intermediate Storage schreiben. Diese Daten werden dann für den tatsächlichen Trainingsprozess auf den TensorFlow Cluster geladen. Bei diesem Workflow musste der Benutzer zwei verschiedene Cluster verwalten, eines für ETL und eines für das verteilte Training von TensorFlow. Das Ausführen und Warten mehrerer Cluster war normalerweise langwierig und zeitaufwendig.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">DataFrames und RDD in früheren Spark-Versionen waren nicht gut für Deep Learning geeignet, da der zufällige Zugriff nur begrenzt verfügbar war. In Spark 3.0 mit Projekt Wasserstoff wird native Unterstützung für die Deep-Learning-Frameworks hinzugefügt. Dieser Ansatz ermöglicht nicht-MapReduce-basierte Planung auf dem Spark-Cluster.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Interaktive Analyse</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark ist schnell genug, um explorative Abfragen ohne Sampling mit anderen Entwicklungssprachen als Spark, einschließlich SQL, R und Python, durchzuführen. Spark setzt Visualisierungstools ein, um komplexe Daten zu verarbeiten und interaktiv zu visualisieren. Spark mit strukturiertem Streaming führt interaktive Abfragen gegen Live-Daten in Web-Analytics durch, die es Ihnen ermöglichen, interaktive Abfragen gegen die aktuelle Sitzung eines Webbesuchers durchzuführen.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Empfehlungssystem</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Im Laufe der Jahre haben Empfehlungssysteme zu erheblichen Veränderungen in unserem Leben geführt, da Unternehmen und Verbraucher auf dramatische Veränderungen im Online-Shopping, Online-Entertainment und vielen anderen Branchen reagiert haben. Diese Systeme gehören tatsächlich zu den offensichtlichsten Erfolgen von KI in der Produktion. In vielen praktischen Anwendungsfällen werden Empfehlungssysteme mit konversationaler KI oder Chatbots kombiniert, die mit einem NLP-Backend interfasiert werden, um relevante Informationen zu erhalten und nützliche Rückschlüsse zu gewinnen.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Heute setzen viele Einzelhändler neue Geschäftsmodelle ein, wie Online-Kauf und Abholung im Geschäft, Abholung von Bordsteinseiten, Selbstauszahlungnahme, Scannen und Los und vieles mehr. Diese Modelle haben sich während der COVID-19 Pandemie durch die Verbesserung des Einkaufs sicherer und bequemer für die Verbraucher. KI ist entscheidend für die wachsenden digitalen Trends, die vom Verbraucherverhalten beeinflusst werden und umgekehrt. Um die steigenden Anforderungen der Verbraucher zu erfüllen, die Kundenzufriedenheit zu erhöhen, die betriebliche Effizienz zu verbessern und den Umsatz zu steigern, unterstützt NetApp seine Enterprise-Kunden und Unternehmen dabei, Machine-Learning- und Deep-Learning-Algorithmen zu nutzen, um schneller und genauer Empfehlungen zu entwickeln.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Es gibt verschiedene gängige Techniken zur Bereitstellung von Empfehlungen, wie kollaborative Filterung, Content-basierte Systeme, das Deep Learning Recomender Modell (DLRM) und hybride Techniken. Kunden nutzten bereits PySpark, um kollaborative Filterfunktionen für die Erstellung von Empfehlungssystemen zu implementieren. Spark MLlib implementiert alternierende geringste Quadrate (als) für kollaborative Filterung, ein sehr beliebter Algorithmus bei Unternehmen vor dem Aufstieg von DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Natürliche Sprachverarbeitung</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">Conversational AI, ermöglicht durch natürliche Sprachverarbeitung (NLP), ist der Zweig der KI, die Computer helfen, mit Menschen zu kommunizieren. NLP ist in allen Branchen vertikale und viele Anwendungsfälle verbreitet, von intelligenten Assistenten und Chatbots bis hin zu Google-Suche und Predictive Text. Laut A<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Prognose: Bis 2022 werden 70 % der Menschen täglich mit umgangssprachlichen KI-Plattformen interagieren. Für ein qualitativ hochwertiges Gespräch zwischen Mensch und Maschine müssen schnelle, intelligente und natürliche Reaktionen erfolgen.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Kunden benötigen eine große Menge an Daten, um ihre NLP- und ASR-Modelle (Automatic Speech Recognition) zu verarbeiten und zu trainieren. Darüber hinaus müssen sie Daten zwischen dem Edge-Bereich, dem Core-Bereich und der Cloud verschieben. Dazu müssen sie in wenigen Millisekunden Inferenz durchführen, um eine natürliche Kommunikation mit dem Menschen zu gewährleisten. NetApp AI und Apache Spark sind eine ideale Kombination für Computing, Storage, Datenverarbeitung, Modelltraining, Feintuning, Und -Einsatz,</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">Die Sentimentanalyse ist ein Untersuchungsfeld innerhalb des NLP, in dem positive, negative oder neutrale Gefühle aus dem Text extrahiert werden. Die Sentiment-Analyse hat verschiedene Anwendungsfälle: Von der Ermittlung der Mitarbeiterleistung im Support Center in Gesprächen mit Anrufern bis hin zur Bereitstellung geeigneter automatisierter Chatbot-Antworten. Es wurde auch verwendet, um den Aktienkurs eines Unternehmens auf der Grundlage der Wechselwirkungen zwischen Firmenvertretern und dem Publikum bei vierteljährlichen Ertragsaufrufen vorherzusagen. Darüber hinaus kann die Sentiment-Analyse verwendet werden, um die Sicht eines Kunden auf die Produkte, Dienstleistungen oder Unterstützung der Marke zu bestimmen.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Funke NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">Stimmung in den Finanznachrichten</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">Wir haben das verwendet<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> Bibliothek von<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> So laden Sie vortrainierte Pipelines und bidirektionale Encoder-Darstellungen von Transformatoren (BERT) Modellen einschließlich<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> Und<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, Durchführung der Tokenisierung, Named Entity Recognition, Modelltraining, Anpassung und Sentiment Analyse nach Maß. Spark NLP ist die einzige Open-Source-NLP-Bibliothek in Produktion, die hochmoderne Transformatoren wie BERT, ALBERT, ELECTRA, XLNet, DistilBERT, Roberta, Deberta, XLM- Roberta, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT und GPT2. Die Bibliothek funktioniert nicht nur in Python und R, sondern auch im JVM Ökosystem (Java, Scala und Kotlin) im großen Maßstab, indem sie Apache Spark nativ erweitert.</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">Next: Große Anwendungsfälle und Architekturen für KI, ML und DL</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">Zurück: Details zur Lösungsarchitektur.</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID ist eine hochperformante, kostengünstige Objekt-Storage-Plattform. Mithilfe von Tiered Storage werden die meisten Daten von Conflient Kafka, die im lokalen Storage oder im SAN-Storage des Brokers gespeichert sind, in den Remote-Objektspeicher ausgelagert. Diese Konfiguration führt zu deutlichen betrieblichen Verbesserungen, da der Zeit- und Kostenaufwand für den Ausgleich, die Erweiterung, die Verkleinerung von Clustern oder den Austausch eines ausgefallenen Brokers verringert wird. Objekt-Storage spielt eine wichtige Rolle beim Management von Daten, die sich auf der Objektspeicher-Tier befinden. Aus diesem Grund ist die Wahl des richtigen Objekt-Storage wichtig.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID bietet intelligentes, richtlinienbasiertes globales Datenmanagement unter Verwendung einer verteilten, Node-basierten Grid-Architektur. Dank des universellen globalen Objekt-Namespace, der komplexe Datenmanagement-Funktionen vereint, vereinfacht es das Management von unstrukturierten Daten im Petabyte-Bereich und Milliarden von Objekten. Der Zugriff auf einzelne Objekte ist über alle Standorte hinweg möglich und vereinfacht Hochverfügbarkeitsarchitekturen bei kontinuierlichem Objektzugriff, unabhängig von Standort- oder Infrastrukturausfällen.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">Dank Mandantenfähigkeit können mehrere unstrukturierte Cloud- und Enterprise-Datenapplikationen sicher im selben Grid gewartet werden. Dies erhöht den ROI und die Anwendungsfälle für NetApp StorageGRID. Sie haben die Möglichkeit, diverse Service-Level mit metadatengestützten Objekt-Lebenszyklus-Richtlinien zu erstellen. So optimieren Sie Langlebigkeit, Schutz und Performance an mehreren Standorten und Regionen. Benutzer können Datenmanagement-Richtlinien anpassen sowie Traffic-Grenzen überwachen und anwenden, um sich unterbrechungsfrei an die Datenlandschaft anzupassen, wenn sich ihre Anforderungen ständig ändern.</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">Der StorageGRID Grid Manager ist eine browserbasierte grafische Oberfläche, mit der Sie Ihr StorageGRID System an weltweit verteilten Standorten über eine zentrale Konsole konfigurieren, managen und überwachen können.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">Sie können die folgenden Aufgaben über die StorageGRID Grid Manager-Oberfläche ausführen:</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Richtlinien für das Information Lifecycle Management</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM-Richtlinie</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM-Regeln</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID verfügt über flexible Datenmanagement-Richtlinien. Dazu zählen die Aufbewahrung von Replikatkopien Ihrer Objekte und die Verwendung von EC-Schemata (Erasure Coding) wie 2+1 und 4+2 (u. a.) zum Speichern Ihrer Objekte, je nach spezifischen Performance- und Datensicherungsanforderungen. Wenn sich Workloads und Anforderungen im Laufe der Zeit ändern, ist es üblich, dass sich auch ILM-Richtlinien im Laufe der Zeit ändern müssen. Das Ändern von ILM-Richtlinien ist eine zentrale Funktion, mit der sich StorageGRID-Kunden schnell und einfach an die sich ständig verändernde Umgebung anpassen können. Bitte prüfen Sie das <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> Und <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> Einrichtung in StorageGRID.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 ODER SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID skaliert die Performance, indem weitere Storage-Nodes hinzugefügt werden. Dabei können es sich um VMs, Bare Metal oder speziell entwickelte Appliances wie die handelt <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. In unseren Tests haben wir mit der SGF6024 Appliance die wesentlichen Performance-Anforderungen von Apache Kafka übertroffen. Das Grid mit drei Nodes war eine minimale Größe. Wenn Kunden ihren Kafka Cluster mit zusätzlichen Vermittlern skalieren, können sie zur Steigerung von Performance und Kapazität weitere Storage-Nodes hinzufügen.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Load Balancer- und Endpunkt-Konfiguration</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Admin-Nodes in StorageGRID stellen die Grid Manager-Benutzeroberfläche (Benutzeroberfläche) und DEN REST-API-Endpunkt zum Anzeigen, Konfigurieren und Managen des StorageGRID-Systems sowie Audit-Protokolle zur Nachverfolgung der Systemaktivitäten bereit. Um einen hochverfügbaren S3-Endpunkt für Conflient Kafka Tiered Storage zu bieten, haben wir den StorageGRID Load Balancer implementiert, der als Service auf Admin-Nodes und Gateway-Nodes ausgeführt wird. Darüber hinaus managt der Load Balancer auch den lokalen Datenverkehr und spricht mit dem GSLB (Global Server Load Balancing), um die Disaster Recovery zu unterstützen.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Zur weiteren Verbesserung der Endpoint-Konfiguration bietet StorageGRID Richtlinien für die Traffic-Klassifizierung, die in den Admin-Node integriert sind, mit denen Sie Ihren Workload-Datenverkehr überwachen und verschiedene Quality of Service (QoS)-Einschränkungen für Ihre Workloads anwenden können. Richtlinien zur Traffic-Klassifizierung werden auf Endpunkte im StorageGRID Load Balancer Service für Gateway-Nodes und Admin-Nodes angewendet. Diese Richtlinien können bei der Gestaltung und Überwachung des Verkehrs helfen.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Verkehrsklassifizierung in StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID verfügt über integrierte QoS-Funktionen. Richtlinien zur Traffic-Klassifizierung unterstützen das Monitoring verschiedener Arten von S3 Traffic, der von einer Client-Applikation stammt. Anschließend können Sie Richtlinien erstellen und anwenden, um Höchstwerte für diesen Datenverkehr festzulegen. Diese basieren auf der ein-/Ausfahrbandbreite, der Anzahl der gleichzeitigen Lese-/Schreibanfragen oder der Anfraquote für Lese- und Schreibvorgänge.</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka ist eine Framework-Implementierung eines Software-Busses mit Stream Processing geschrieben in Java und Scala. Das Ziel ist eine einheitliche Plattform mit hohem Durchsatz und niedriger Latenz für die Verarbeitung von Echtzeit-Datenfeeds. Kafka kann sich mit einem externen System für den Datenexport und den Import über Kafka Connect verbinden und Kafka Streams, eine Java Stream Processing Library, zur Verfügung stellen. Kafka verwendet ein binäres, TCP-basiertes Protokoll, das für Effizienz optimiert ist und auf einer Abstraktion basiert, die Nachrichten automatisch gruppiert, um den Overhead von NetzwerkRoundtrip zu reduzieren. Dies ermöglicht größere sequenzielle Festplattenoperationen, größere Netzwerkpakete und zusammenhängende Speicherblöcke. Kafka kann also einen sprunghafte Strom zufälliger Nachrichtenschreibvorgänge in lineare Schreibvorgänge verwandeln. Die folgende Abbildung zeigt den grundlegenden Datenfluss von Apache Kafka.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka speichert Schlüsselwertbotschaften, die aus einer willkürlichen Anzahl von Prozessen stammen, die Produzenten genannt werden. Die Daten lassen sich innerhalb verschiedener Themen in unterschiedliche Partitionen unterpartitionieren. Innerhalb einer Partition werden Nachrichten streng nach ihren Offsets (der Position einer Nachricht innerhalb einer Partition) geordnet und zusammen mit einem Zeitstempel indiziert und gespeichert. Andere Prozesse, die Verbraucher genannt werden, können Nachrichten von Partitionen lesen. Zur Stream-Verarbeitung bietet Kafka die Streaming-API, mit der Java-Applikationen geschrieben werden können, die Daten aus Kafka verbrauchen und Ergebnisse an Kafka schreiben. Apache Kafka arbeitet auch mit externen Streamverarbeitungssystemen wie Apache Apex, Apache Flink, Apache Spark, Apache Storm und Apache NiFi zusammen.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka läuft auf einem Cluster aus einem oder mehreren Servern (sogenannten Brokern) und die Partitionen aller Themen sind über die Cluster Nodes verteilt. Darüber hinaus werden Partitionen zu mehreren Brokern repliziert. Diese Architektur ermöglicht es Kafka, massive Nachrichten-Streams fehlertolerant zu liefern und hat es ermöglicht, einige der herkömmlichen Messaging-Systeme wie Java Message Service (JMS), Advanced Message Queuing Protocol (AMQP) usw. zu ersetzen. Seit Version 0.11.0.0 bietet Kafka transaktionale Schreibvorgänge, die mithilfe der Streaming-API exakt einmal Stream-Verarbeitung sorgen.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka unterstützt zwei Themenarten: Regelmäßig und verdichtet. Normale Themen können mit einer Aufbewahrungszeit oder mit einer Speicherplatzbindung konfiguriert werden. Wenn Datensätze älter als die angegebene Aufbewahrungszeit sind oder wenn der gebundene Speicherplatz für eine Partition überschritten wird, kann Kafka alte Daten in freien Speicherplatz löschen. Standardmäßig werden Themen mit einer Aufbewahrungszeit von 7 Tagen konfiguriert, es ist aber auch möglich, Daten unbegrenzt zu speichern. Bei verdichteten Themen verfallen Datensätze aufgrund von Zeit- oder Raumgrenzen nicht. Stattdessen behandelt Kafka spätere Nachrichten als Aktualisierungen älterer Nachrichten mit dem gleichen Schlüssel und garantiert, dass sie nie die neueste Nachricht pro Schlüssel löschen. Benutzer können Nachrichten vollständig löschen, indem sie eine sogenannte Tombstone-Nachricht mit dem Null-Wert für einen bestimmten Schlüssel schreiben.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">In Kafka gibt es fünf große APIs:</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*Producer API.* erlaubt eine Anwendung, Streams von Datensätzen zu veröffentlichen.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer API.* ermöglicht eine Anwendung, Themen zu abonnieren und Datenströme zu verarbeiten.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*Connector API.* führt die wiederverwendbaren Producer- und Consumer-APIs aus, die die Themen mit den vorhandenen Anwendungen verknüpfen können.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*Streams API.* Diese API wandelt die Input Streams in Output um und erzeugt das Ergebnis.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*Admin API.* zur Verwaltung von Kafka-Themen, Brokern und anderen Kafka-Objekten.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Die Consumer and Producer APIs bauen auf dem Kafka Messaging-Protokoll auf und bieten eine Referenzimplementierung für Kafka-Verbraucher und -Produzenten in Java an. Das zugrunde liegende Messaging-Protokoll ist ein binäres Protokoll, mit dem Entwickler ihre eigenen Verbraucher- oder Producer-Clients in jeder Programmiersprache schreiben können. Damit erschließt sich Kafka aus dem Java Virtual Machine (JVM) Ecosystem. Eine Liste der nicht-Java-Clients wird im Apache Kafka Wiki gepflegt.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Anwendungsfälle für Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka ist besonders beliebt bei Messaging, Website-Aktivitäten-Tracking, Metriken, Log-Aggregation, Stream Processing, Event Sourcing und Protokollierung übergeben.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka bietet einen verbesserten Durchsatz, integrierte Partitionierung, Replizierung und Fehlertoleranz und ist somit eine gute Lösung für große Applikationen zur Nachrichtenverarbeitung.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka kann die Aktivitäten eines Benutzers (Seitenaufrufe und Suchen) in einer Pipeline für die Nachverfolgung als Set von Veröffentlichungsdaten in Echtzeit neu erstellen.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka wird häufig für Daten aus betrieblichen Monitoring eingesetzt. Dazu gehört die Zusammenfassung von Statistiken aus verteilten Applikationen zur Erstellung zentralisierter Feeds von Betriebsdaten.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Viele Anwender verwenden Kafka als Ersatz für eine Log-Aggregationslösung. Die Log-Aggregation sammelt üblicherweise physische Log-Dateien von den Servern und stellt sie zur Verarbeitung an einem zentralen Ort (z. B. einem Dateiserver oder HDFS). Kafka abstrahiert Dateidetails und ermöglicht eine saubere Abstraktion von Protokoll- oder Ereignisdaten als Nachrichtenstrom. Die Verarbeitung mit niedriger Latenz wird vereinfacht, es werden diverse Datenquellen und verteilte Datennutzung unterstützt.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Viele Anwender von Kafka verarbeiten Daten in mehreren Etappen, in denen aus Kafka-Themen Rohdaten gesammelt und dann aggregiert, angereichert oder anderweitig in neue Themen umgewandelt werden, um sie weiter zu nutzen oder nachbearbeiten zu können. So könnte beispielsweise eine Verarbeitungspipeline für die Empfehlung von Nachrichtenartikeln Artikelinhalte aus RSS-Feeds kriechen und in ein "Artikel"-Thema veröffentlichen. Eine weitere Verarbeitung könnte diesen Inhalt normalisieren oder deduplizieren und den bereinigten Artikelinhalt in einem neuen Thema veröffentlichen. In einer letzten Phase der Verarbeitung könnte möglicherweise versucht werden, diesen Inhalt an Anwender zu empfehlen. Solche Verarbeitungspipelines erstellen Grafiken von Echtzeit-Datenströmen auf Basis der einzelnen Themen.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">Event Souring ist eine Art Anwendungsdesign, bei der Zustandsänderungen als eine zeitgeordnete Sequenz von Datensätzen protokolliert werden. Da Kafka sehr große gespeicherte Protokolldaten unterstützt, eignet es sich hervorragend als Back-End für eine Anwendung dieser Art.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka kann eine Art externes Commit-Log für ein verteiltes System dienen. Das Protokoll hilft beim Replizieren von Daten zwischen Nodes und dient als Mechanismus zur Neusynchronisierung zur Wiederherstellung fehlgeschlagener Nodes. Die Log-Data-Compaction-Funktion in Kafka unterstützt diesen Anwendungsfall.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Conflient Platform ist eine Plattform für Unternehmen, die Kafka mit fortschrittlichen Funktionen abrundet, die dazu dienen, die Applikationsentwicklung und -Konnektivität zu beschleunigen, Transformationen durch Stream-Verarbeitung zu ermöglichen, skalierbare Enterprise-Prozesse zu vereinfachen und anspruchsvolle Architekturanforderungen zu erfüllen. Confluent wurde von den ursprünglichen Schöpfern von Apache Kafka erbaut und erweitert die Vorteile von Kafka mit Funktionen der Enterprise-Klasse, ohne Kafka-Management oder -Monitoring zu belasten. Heute sind mehr als 80 % der Fortune 100-Unternehmen auf Data-Streaming-Technologie gestützt – und die meisten von ihnen nutzen Confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Mit der Conflient Platform können Sie sich darauf konzentrieren, wie Sie aus Ihren Daten einen geschäftlichen Nutzen ziehen können, statt sich um die zugrunde liegenden Mechanismen sorgen zu müssen, wie beispielsweise der Transport oder die Integration von Daten zwischen verschiedenen Systemen. Confluent Platform vereinfacht insbesondere die Anbindung von Datenquellen an Kafka, die Erstellung von Streaming-Applikationen sowie die Sicherung, Überwachung und das Management der Kafka Infrastruktur. Heute wird Confluent Platform für eine Vielzahl von Anwendungsbeispielen in zahlreichen Branchen eingesetzt, von Finanzdienstleistungen über Omnichannel-Einzelhandel und autonome Fahrzeuge bis hin zur Betrugserkennung, Microservices und IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">Die folgende Abbildung zeigt die Komponenten der Conflient Kafka Platform.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Überblick über die Event-Streaming-Technologie von Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Der Kern der Confluent Platform ist<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>, Die beliebteste verteilte Open-Source-Streaming-Plattform. Kafka bietet folgende wichtige Funktionen:</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Überblick über die Enterprise-Funktionen der Confluent Plattform</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent Control Center.* Ein GUI-basiertes System zur Verwaltung und Überwachung von Kafka. Damit können Sie Kafka Connect ganz einfach verwalten und Verbindungen zu anderen Systemen erstellen, bearbeiten und verwalten.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Confluent Connectors to Kafka.* Connectors verwenden die Kafka Connect API, um Kafka mit anderen Systemen wie Datenbanken, Schlüsselwertspeicher, Suchindizes und Dateisystemen zu verbinden. Confluent Hub verfügt über herunterladbare Anschlüsse für die beliebtesten Datenquellen und Waschbecken, einschließlich vollständig getestete und unterstützte Versionen dieser Anschlüsse mit Confluent Platform. Weitere Details finden Sie hier<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Self-Balancing Cluster.* bietet automatisches Load Balancing, Fehlererkennung und Selbstheilung. Broker können nach Bedarf und ohne manuelles Tuning hinzugefügt oder ausmustern.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Confluent Auto Data Balancer.* überwacht Ihren Cluster für die Anzahl der Broker, die Größe der Partitionen, Anzahl der Partitionen und die Anzahl der Führer innerhalb des Clusters. Auf diese Weise können Sie Daten verschieben, um einen geraden Workload über Ihr Cluster zu erstellen, und gleichzeitig den Datenverkehr neu verteilen, um die Auswirkungen auf die Produktions-Workloads bei der Ausbalancierung zu minimieren.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">Als Nächstes: Confluent Verification.</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">Die Data Mover-Lösung für KI basiert auf der Anforderung der Kunden, Hadoop Daten vom KI-Betrieb zu verarbeiten. NetApp verschiebt Daten mithilfe von NIPAM von HDFS in NFS. In einem Anwendungsfall musste der Kunde Daten on-Premises zu NFS verschieben und ein anderer Kunde Daten von Windows Azure Storage Blob zu Cloud Volumes Service verschieben, um die Daten aus den GPU-Cloud-Instanzen in der Cloud zu verarbeiten.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Data Mover-Lösung für KI</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">Früher: Data Mover-Lösung.</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Details zur Data Mover-Lösung:</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Die Entwicklung der Data Mover-Lösung ist wie folgt nötig:</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN bietet HDFS und NAS stellt die NFS-Volumes über NIPAM in den produktiven Data-Lake-Cluster bereit.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">Die Kundendaten sind in HDFS und NFS. Die NFS-Daten können Produktionsdaten von anderen Applikationen sein, die für Big-Data-Analysen und KI-Vorgänge verwendet werden.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">Die NetApp FlexClone Technologie erstellt einen Klon des Produktions-NFS-Volumes und stellt ihn vor Ort dem KI-Cluster bereit.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Daten aus einer HDFS SAN LUN werden mit NIPAM und dem in ein NFS-Volume kopiert<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl. NIPAM verwendet die Bandbreite mehrerer Netzwerkschnittstellen zum Datentransfer. Dieser Prozess verkürzt die Kopierzeit der Daten, sodass mehr Daten übertragen werden können.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Beide NFS-Volumes werden dem KI-Cluster für KI-Vorgänge bereitgestellt.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Zur Verarbeitung von On-Premises-NFS-Daten mit GPUs in der Cloud werden die NFS-Volumes mit NetApp SnapMirror Technologie in NetApp Private Storage (NPS) gespiegelt und bei GPUs an Cloud-Service-Provider angehängt.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">Der Kunde möchte Daten in EC2/EMR-, HDInsight- oder DataProc-Services in GPUs von Cloud-Service-Providern verarbeiten. Beim Hadoop Data Mover werden die Daten mit NIPAM und dem Service von Hadoop auf die Cloud Volumes Services verschoben<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Die Cloud Volumes Service-Daten werden über das NFS-Protokoll KI bereitgestellt.über AI aufbereitete Daten können über NIPAM, SnapMirror und NPS an einen On-Premises-Standort für Big Data-Analysen neben dem NVIDIA Cluster gesendet werden.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">In diesem Szenario verfügt der Kunde über große Dateidaten im NAS-System an einem Remote-Standort, der für die KI-Verarbeitung auf dem NetApp Storage Controller vor Ort benötigt wird. In diesem Szenario ist es besser, mit dem XCP Migration Tool die Daten mit einer schnelleren Geschwindigkeit zu migrieren.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">Der Hybrid-Anwendungsfall kann mit Cloud Sync On-Premises-Daten von NFS-, CIFS- und S3-Daten in die Cloud migrieren und umgekehrt für die KI-Verarbeitung verwenden. Dazu werden GPUs wie die in einem NVIDIA-Cluster verwendet. Für die NFS-Datenmigration zu NetApp ONTAP-NFS werden sowohl Cloud Sync als auch das XCP Migrationstool verwendet.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">Weiter: GPFS auf NetApp ONTAP-NFS.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Wir haben mithilfe der Skripts TeraSort und TeraValidate im Benchmark-Tool TeraGen die Spark-Performance-Validierung mit E5760, E5724 und AFF-A800 Konfigurationen gemessen. Darüber hinaus wurden drei wesentliche Anwendungsfälle getestet: Spark NLP Pipelines und TensorFlow Distributed Training, Horovod Distributed-Training und Multi-Worker Deep Learning mit Keras für CTR Prediction bei DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Testergebnisse</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">Früher: Große Anwendungsfälle und Architekturen für KI, ML und DL</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Wir haben mithilfe der Skripts TeraSort und TeraValidate im Benchmark-Tool TeraGen die Spark-Performance-Validierung mit E5760, E5724 und AFF-A800 Konfigurationen gemessen. Darüber hinaus wurden drei wesentliche Anwendungsfälle getestet: Spark NLP Pipelines und TensorFlow Distributed Training, Horovod Distributed-Training und Multi-Worker Deep Learning mit Keras für CTR Prediction bei DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Sowohl für die E-Series als auch für die StorageGRID Validierung verwendeten wir Hadoop Replizierungsfaktor 2. Für die AFF Validierung verwendeten wir nur eine Datenquelle.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">In der folgenden Tabelle ist die Hardwarekonfiguration für die Spark-Performance-Validierung aufgeführt.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Typ</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop Worker-Nodes</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Laufwerkstyp</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Laufwerke pro Node</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Storage Controller</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Single High Availability (HA)-Paar</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Single HA-Paar</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">In der folgenden Tabelle sind die Softwareanforderungen aufgeführt.</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK Runtime Environment</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64-Bit-Server-VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Funke</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Analyse der finanziellen Stimmung</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Tao-Rahmen</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">Wir haben veröffentlicht<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>, In der mithilfe der eine End-to-End-Conversational KI-Pipeline aufgebaut wurde<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, AFF Storage und NVIDIA DGX-System. Die Pipeline führt Stapelverarbeitung von Audiosignalen, ASR (Automatic Speech Recognition), Transfer Learning und Sentiment-Analysen durch und nutzt dabei das DataOps Toolkit,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>, Und das<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>. Wir haben den Anwendungsfall der Sentiment-Analyse auf die Finanzdienstleistungsbranche ausgeweitet und einen SparkNLP-Workflow entwickelt, drei BERT-Modelle für verschiedene NLP-Aufgaben wie die benannte Anerkennung von Unternehmen geladen und die Quartalsgewinne der NASDAQ Top 10-Unternehmen in Sentenniveal getitelt.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Das folgende Skript<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> Verwendet das FinBERT-Modell, um Transkripte in HDFS zu verarbeiten und positive, neutrale und negative Stimmungswerte zu erzielen, wie in der folgenden Tabelle dargestellt:</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">Die folgende Tabelle enthält eine Analyse der Stimmung bei den Gewinnen und Satzungen der NASDAQ Top 10-Unternehmen von 2016 bis 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Einschätzung zählt und Prozentsatz</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Alle 10 Unternehmen</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Positive Ergebnisse</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Nullwerte</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Negative Zählung</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Nicht kategorisierte Anzahl</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(Gesamtanzahl)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">In Bezug auf Prozentsätze sind die meisten Sätze, die von den CEOs und CFOs gesprochen werden, faktisch und tragen daher eine neutrale Stimmung. Während eines Gewinnanrufs stellen Analysten Fragen, die eine positive oder negative Stimmung vermitteln könnten. Es lohnt sich, noch einmal quantitativ zu untersuchen, wie sich negative oder positive Stimmungen auf die Aktienkurse am gleichen oder nächsten Handelstag auswirken.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">In der folgenden Tabelle ist die Sentiment-Analyse auf Satzebene für NASDAQ Top 10-Unternehmen aufgeführt, in Prozent.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Stimmungsanteil</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positiv</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13 % erzielt</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06 % erzielt</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69 % erzielt</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24 % erzielt</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07 % erzielt</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08 % erzielt</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44 % erzielt</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25 % erzielt</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23 % erzielt</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutral</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17 % erzielt</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02 % erzielt</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82 % erzielt</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87 % erzielt</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42 % erzielt</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50 % erzielt</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65 % erzielt</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77 % erzielt</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44 % erzielt</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Negativ</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43 % erzielt</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92 % erzielt</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49 % erzielt</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52 % erzielt</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51 % erzielt</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42 % erzielt</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91 % erzielt</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96 % erzielt</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33 % erzielt</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Ohne Kategorie</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27 % erzielt</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37 % erzielt</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01 % erzielt</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">Hinsichtlich der Workflow-Laufzeit wurde gegenüber der Workflow-Laufzeit eine deutliche 4,78-fache Verbesserung erzielt<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Modus zu einer verteilten Umgebung in HDFS und eine weitere Verbesserung von 0.14 % durch Nutzung von NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Wie in der folgenden Abbildung dargestellt, verbesserte Daten- und Modellparallelität die Datenverarbeitung und die Inferenzgeschwindigkeit des verteilten TensorFlow-Modells. Der Datenspeicherort in NFS führte zu einer etwas besseren Laufzeit, da der Workflow-Engpass das Herunterladen von vortrainierten Modellen ist. Wenn wir die Datensatzgröße der Transkripte erhöhen, ist der Vorteil von NFS offensichtlicher.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Ende-zu-Ende-Workflow-Laufzeit der Zündung NLP-Sentimentanalyse.</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Verteiltes Training mit Horovod Leistung</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">„Python-Skripte für jeden größeren Anwendungsfall“</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">Mit dem folgenden Befehl wurden Laufzeitinformationen und eine Protokolldatei in unserem Spark-Cluster unter Verwendung einer einzigen erzeugt<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> Node mit 160 Ausführenden mit jeweils einem Kern. Der Ausführende-Speicher wurde auf 5 GB beschränkt, um einen Fehler außerhalb des Arbeitsspeichers zu vermeiden. Siehe Abschnitt <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> Weitere Details zur Datenverarbeitung, Modellschulung und Berechnung der Modellgenauigkeit finden Sie in<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Die daraus resultierende Laufzeit mit zehn Trainingsepochen war wie folgt:</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Es dauerte mehr als 43 Minuten, Eingabedaten zu verarbeiten, ein DNN-Modell zu trainieren, die Genauigkeit zu berechnen und TensorFlow Checkpoints und eine CSV-Datei für Vorhersageergebnisse zu erstellen. Wir limitierten die Anzahl der Trainingsepochen auf 10, die in der Praxis oft auf 100 gesetzt werden, um eine zufriedenstellende Modellgenauigkeit zu gewährleisten. Die Trainingszeit wird in der Regel linear mit der Anzahl der Epochen skaliert.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Als nächstes verwendeten wir die vier Worker Nodes, die im Cluster verfügbar sind, und führten das gleiche Skript in aus<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Modus mit Daten in HDFS:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Die daraus resultierende Laufzeit wurde wie folgt verbessert:</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">Mit Horovods Modell und Datenparallelität in Spark haben wir eine 5,29fache Laufzeitgeschwindigkeit von gesehen<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Vs<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Modus mit zehn Trainingsepochen. Dies wird in der folgenden Abbildung mit den Legenden dargestellt<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> Und<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>. Das zugrunde liegende TensorFlow DNN-Modelltraining kann mit GPUs weiter beschleunigt werden, falls verfügbar. Wir planen diese Tests durchzuführen und die Ergebnisse in einem zukünftigen technischen Bericht zu veröffentlichen.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Bei unserem nächsten Test wurden die Laufzeiten mit Eingabedaten im NFS verglichen und HDFS. Das NFS-Volume auf der AFF A800 wurde angehängt<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> Über die fünf Nodes (ein Master, vier Mitarbeiter) in unserem Spark-Cluster verteilt Wir führten einen ähnlichen Befehl aus wie bei früheren Tests, mit<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> Parameter, der jetzt auf NFS-Mount zeigt:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Die daraus resultierende Laufzeit mit NFS war wie folgt:</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Wie in der folgenden Abbildung dargestellt, gab es eine weitere 1,43x Geschwindigkeitsnachbildung. Da ein NetApp All-Flash-Storage an seinen Cluster angeschlossen ist, können Kunden von den Vorteilen einer schnellen Datenübertragung und -Verteilung für Horovod Spark-Workflows profitieren. So wird 7.55-mal schneller als auf einem einzelnen Node ausgeführt.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark Workflow Laufzeit.</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Deep-Learning-Modelle für die Vorhersageleistung von CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Für Empfehlungssysteme, die zur Maximierung der CTR entwickelt wurden, müssen Sie lernen, anspruchsvolle Funktionsinteraktionen hinter Benutzerverhalten zu erlernen, die mathematisch von niedrig bis hoch berechnet werden können. Interaktionen zwischen Low-Order- und High-Order-Funktionen sollten für ein gutes Deep-Learning-Modell genauso wichtig sein, ohne das eine oder andere per Bicken zu tun. Deep Factorisation Machine (DeepFM), ein maschinell basiertes neuronales Netz zur Faktorisierung, kombiniert für das Feature Learning in einer neuen neuronalen Netzwerkarchitektur Factorisationsmaschinen für Empfehlung und Deep Learning.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Wide &amp;amp; Deep Modelle</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">Obwohl herkömmliche Factorisierungsmaschinen paarweise Interaktionen als inneres Produkt latenter Vektoren zwischen Features modellieren und theoretisch Informationen in hoher Reihenfolge erfassen können, verwenden maschinelle Lernende in der Regel aufgrund der hohen Rechen- und Speicherkomplexität nur Interaktionen in zweiter Reihenfolge. Deep Neural Network Varianten wie Googles<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> Zum anderen lernt man in einer hybriden Netzwerkstruktur anspruchsvolle Feature-Interaktionen, indem man ein linear weites Modell mit einem tiefen Modell kombiniert.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Es gibt zwei Eingänge zu diesem Wide &amp; Deep Model, einen für das zugrunde liegende breite Modell und den anderen für die Tiefe, der letzte Teil von denen noch erfordert fachkundige Feature-Engineering und macht damit die Technik weniger generierbar für andere Domains. Im Gegensatz zum Wide &amp; Deep Model lässt sich DeepFM ohne jede Funktionstechnik effizient mit RAW-Funktionen Schulen, da sein breites Teil und das tiefe Teil denselben Eingang und den Einbettungsvektor teilen.</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">„Python-Skripte für jeden größeren Anwendungsfall.“</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">Wir haben den Criteo bearbeitet<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 GB) Datei in einer CSV-Datei namens<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> In einem NFS-Mount gespeichert<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> Wird verwendet<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> Aus dem Abschnitt <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> Innerhalb dieses Skripts die Funktion<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> Führt mehrere String-Methoden durch, um Tabs zu entfernen und einzufügen<block ref="f89bb99ea60d9e9cbbc95ce1a8f1a63a" prefix=" " category="inline-code"></block> Als Trennzeichen und<block ref="918d67b3695a9c52a0e182a621fc33da" prefix=" " category="inline-code"></block> Als neue Zeile. Beachten Sie, dass Sie nur das Original verarbeiten müssen<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> Einmal, damit der Code-Block als Kommentare angezeigt wird.</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">Für die folgenden Tests der verschiedenen DL-Modelle haben wir verwendet<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Als Eingabedatei. Bei nachfolgenden Testläufen wurde die CSV-Eingabedatei in einen Spark DataFrame mit einem Schema mit einem Feld von eingelesen<block ref="cdb10f764735165c687209f811432621" prefix=" " category="inline-code"></block>, Ganzzahlige dichte Funktionen<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>, Und spärliche Merkmale<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>. Im Folgenden<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> Befehl nimmt einen CSV-Eingang ein, trainiert DeepFM-Modelle mit 20% Teilung zur Kreuzvalidierung und wählt das beste Modell nach zehn Trainingsepochen, um Vorhersagegenauigkeit auf dem Prüfsatz zu berechnen:</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Beachten Sie, dass seit der Datendatei<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Ist über 11 GB, müssen Sie eine ausreichende einstellen<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> Größer als die Datensatzgröße, um Fehler zu vermeiden.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache Arrow</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">In der obigen<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> Konfiguration wurde ebenfalls aktiviert<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>, Die einen Spark DataFrame in einen Pandas DataFrame mit dem konvertiert<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> Methode.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Nach der zufälligen Aufteilung befinden sich im Trainingdatensatz über 36 M und 9 M-Muster im Testsatz:</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">Da sich dieser technische Bericht auf CPU-Tests ohne GPUs konzentriert, ist es zwingend erforderlich, dass Sie TensorFlow mit den entsprechenden Compiler-Flags erstellen. Dieser Schritt verhindert das Aufrufen von GPU-beschleunigten Bibliotheken und nutzt die Advanced Vector Extensions (AVX)- und AVX2-Anweisungen in vollem Umfang. Diese Eigenschaften sind für lineare algebraische Berechnungen wie vectorisierte Addition, Matrix-Multiplikationen innerhalb eines Vorschub-Forward oder Back-Propagation DNN-Training konzipiert. Fused Multiply Add (FMA)-Anweisung, die mit AVX2 über 256-Bit-Floating-Point-Register (FP) verfügbar ist, ist ideal für Integer-Code und Datentypen, was zu einer doppelten Geschwindigkeit führt. Für FP-Code und Datentypen erreicht AVX2 eine Beschleunigung von 8 % über AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Um TensorFlow von der Quelle zu erstellen, empfiehlt NetApp die Verwendung<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>. Für unsere Umgebung haben wir in der Shell-Eingabeaufforderung die folgenden Befehle zur Installation ausgeführt<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block>, Und Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Sie müssen GCC 5 oder höher aktivieren, damit während des Builds C++17-Funktionen verwendet werden können, die von RHEL with Software Collections Library (SCL) bereitgestellt werden. Die folgenden Befehle werden installiert<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> Und GCC 11.2.1 auf unserem RHEL 7.9 Cluster:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">Artikel</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Beachten Sie, dass die letzten beiden Befehle aktiviert sind<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>, Die verwendet<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1). Stellen Sie auch sicher, dass Sie<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> Version ist größer als 1.8.3 (dies kommt mit RHEL 7.9). Weitere Informationen finden Sie hier<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> Für Aktualisierung<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> Bis 2.24.1.</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">„Python-Skripte für jeden Hauptanwendungsfall“,</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">Wir gehen davon aus, dass Sie die neueste TensorFlow Master-Repo bereits geklont haben. Erstellen Sie dann ein<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> Verzeichnis mit einem<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> Datei zum Erstellen von TensorFlow aus der Quelle mit AVX, AVX2 und FMA Führen Sie die aus<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> Datei und geben Sie den richtigen Python-Binärspeicherort an.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> Ist für unsere Tests deaktiviert, da wir keine GPU verwendet haben. A<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> Die Datei wird entsprechend Ihren Einstellungen erzeugt. Außerdem haben wir die Datei bearbeitet und gesetzt<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> Um die HDFS-Unterstützung zu aktivieren. Siehe<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> Im Abschnitt <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> Für eine vollständige Liste von Einstellungen und Flags.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Nachdem Sie TensorFlow mit den richtigen Flags erstellt haben, führen Sie das folgende Skript aus, um den Datensatz Criteo Display Ads zu bearbeiten, ein DeepFM-Modell zu trainieren und den Bereich unter der Receiver Operating Characteristic Curve (ROC AUC) aus den Vorhersagewerten zu berechnen.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Nach zehn Epochen des Trainings erhielten wir die AUC-Punktzahl auf dem Testdatensatz:</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">Ähnlich wie bei früheren Anwendungsfällen haben wir die Spark-Workflow-Laufzeit mit Daten an verschiedenen Standorten verglichen. Die folgende Abbildung zeigt einen Vergleich der Deep-Learning-CTR-Vorhersage für eine Spark-Workflows-Laufzeit.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Vergleich der Deep-Learning-CTR-Vorhersage für eine Spark-Workflows-Laufzeit</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">Als Nächstes: Hybrid Cloud-Lösung.</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Wir haben während eines Produzieren-Workloads mit einem AFF A900 HA-Paar NetApp Storage Controller Tiered Storage-Tests mit fünf oder acht Broker Nodes durchgeführt. Unsere Tests ergaben, dass sich die Zeit bis zur Fertigstellung und die Performance-Ergebnisse mit der Anzahl der Broker Nodes skalieren lassen, bis die Auslastung von AFF A900 Ressourcen hundertprozentig erreichte. Das Setup des ONTAP Storage Controllers benötigte mindestens ein HA-Paar.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Performance-Tests mit dem Produce-Consume Workload Generator</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">Früher: Confluent Performance Validierung.</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Die Performance für den S3-Abruffvorgang ist basierend auf der Anzahl der Conflient Broker Nodes linear gestiegen. Der ONTAP Storage Controller unterstützt bis zu 12 HA-Paare in einer einzelnen Implementierung.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Das folgende Diagramm zeigt kombinierten S3-Tiering-Datenverkehr mit fünf oder acht Broker-Nodes. Wir maximierter die Performance eines AFF A900 Single HA-Paars.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Dieses Diagramm zeigt kombinierten S3-Tiering-Datenverkehr mit fünf oder acht Broker-Nodes.</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Im folgenden Diagramm wird der Kafka-Durchsatz bei etwa 31,74 GB/s dargestellt.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Dieses Diagramm zeigt den Kafka-Durchsatz bei etwa 31,74 GB/s.</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Außerdem beobachteten wir einen ähnlichen Durchsatz im ONTAP Storage Controller<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> Bericht.</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">Als Nächstes: Richtlinien zu Best Practices zur Performance.</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Dieser Nutzungsfall basiert auf einem Rundfunkkunden, der Cloud-basierte Analysedaten in seinem On-Premises-Datacenter sichern muss.</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">Zurück: Anwendungsfall 1 - Sichern von Hadoop-Daten.</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Dieser Nutzungsfall basiert auf einem Rundfunkkunden, der Cloud-basierte Analysedaten in seinem On-Premises-Datacenter sichern muss, wie in der folgenden Abbildung dargestellt.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">In diesem Szenario werden die IoT-Sensordaten in die Cloud aufgenommen und mithilfe eines Open-Source-Apache Spark-Clusters in AWS analysiert. Die Anforderung besteht darin, die verarbeiteten Daten aus der Cloud in On-Premises-Systeme zu sichern.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">Das Aktivieren der Datensicherung sollte keine Performance-Auswirkungen auf das Produktions-Spark/Hadoop-Cluster in der Cloud haben.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Cloud-Sensordaten müssen effizient und sicher in On-Premises-Systeme verschoben und geschützt werden.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilität bei der Übertragung von Daten aus der Cloud unter unterschiedlichen Bedingungen in On-Demand-Umgebungen, sofort und während Low-Cluster-Ladezeiten</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Kunden nutzen den AWS Elastic Block Store (EBS) für ihren Spark-Cluster-HDFS-Storage, um Daten von Remote-Sensoren über Kafka zu empfangen und einzuspielen. Dementsprechend fungiert HDFS-Storage als Quelle für die Backup-Daten.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Um diese Anforderungen zu erfüllen, wird NetApp ONTAP Cloud in AWS implementiert und eine NFS-Share wird als Backup-Ziel für den Spark/Hadoop-Cluster erstellt.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">Nach der Erstellung der NFS-Freigabe wird das in-Place-Analysemodul genutzt, um die Daten aus dem HDFS EBS Storage in die ONTAP-NFS-Freigabe zu kopieren. Nachdem sich die Daten in ONTAP Cloud im NFS befinden, können Sie mit SnapMirror Technologie die Daten sicher und effizient aus der Cloud in den On-Premises-Storage spiegeln.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Dieses Bild zeigt Backup und Disaster Recovery von der Cloud zu einer On-Premises-Lösung.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">Weiter: Anwendungsfall 3 – Enabling DevTest on Existing Hadoop Data.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">In diesem Abschnitt wird beschrieben, wer an den Inhalten dieser Lösung interessiert sein könnte.</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">Die Welt der Analyse und Data Science hat unterschiedliche Disziplinen in DER IT und in den Bereichen Business zu berühren:</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps-Engineers benötigen die Tools, um neue KI- und ML-Applikationen in ihre CI- und CD-Pipelines zu integrieren.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Cloud-Administratoren und -Architekten müssen in der Lage sein, Hybrid-Cloud-Ressourcen einzurichten und zu managen.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Unternehmensbenutzer möchten Zugriff auf Analytics-, KI-, ML- und DL-Applikationen haben.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">In diesem technischen Bericht werden, wie NetApp AFF, E-Series, StorageGRID, NFS Direct Access, Apache Spark, Horovod und Keras helfen dabei, jede dieser Rollen dem Unternehmen einen Mehrwert zu bieten.</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">Als Nächstes: Lösungstechnologie.</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Dieses Dokument enthält eine Beschreibung der Best Practice-Richtlinien zum Einsatz von Kafka auf einem NetApp Storage Controller.</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka ist eine Community-verteilte Event-Streaming-Plattform, die täglich Billionen von Ereignissen bewältigen kann. Kafka wurde ursprünglich als Messaging-Warteschlange konzipiert und basiert auf einer Abstraktion eines verteilten Commit-Protokolls. Seit der Gründung und Open-sourcing von LinkedIn im Jahr 2011 hat sich Kafka von einer Nachrichtenwarteschlange zu einer vollwertigen Event-Streaming-Plattform entwickelt. Confluent liefert die Distribution von Apache Kafka mit der Confluent Platform. Die Confluent Platform ergänzt Kafka um zusätzliche Community- und kommerzielle Funktionen, die das Streamingerlebnis sowohl von Betreibern als auch von Entwicklern in der Produktion in großem Maßstab verbessern sollen.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">Dieses Dokument beschreibt die Best Practice-Richtlinien für die Verwendung von Confluent Tiered Storage auf dem Objekt-Storage-Angebot von NetApp, indem es folgende Inhalte zur Verfügung stellt:</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Fließende Verifizierung mit NetApp Objekt-Storage – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Tiered Storage-Performance-Tests</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Best Practice-Richtlinien für Conflient auf NetApp Storage-Systeme</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Warum Confluent Tiered Storage?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Dieser Artikel von Confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent hat sich zur standardmäßigen Streaming-Plattform in Echtzeit für viele Applikationen entwickelt. Dies gilt insbesondere für Big Data, Analysen und Streaming Workloads. Tiered Storage ermöglicht Benutzern die Trennung von Computing und Storage auf der Conflient Plattform. Mit sie lassen sich Daten kostengünstiger speichern, nahezu unbegrenzte Datenmengen speichern und On-Demand-Workloads skalieren. Administrative Aufgaben wie die Ausbalancierung von Daten und Mandanten werden vereinfacht. S3-kompatible Storage-Systeme profitieren von all diesen Funktionen, um Daten bei allen Ereignissen an einem Ort zu dezentralisieren. Dadurch ist ein komplexes Daten-Engineering überflüssig. Weitere Informationen dazu, warum Sie Tiered Storage für Kafka verwenden sollten, finden Sie hier <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Warum NetApp StorageGRID für Tiered Storage?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID ist eine der Objekt-Storage-Plattformen von NetApp, StorageGRID ist eine softwaredefinierte, objektbasierte Storage-Lösung, die dem Branchenstandard entsprechende Objekt-APIs, einschließlich der S3 API (Amazon Simple Storage Service) unterstützt. StorageGRID speichert und managt unstrukturierte Daten jeder Größenordnung und stellt sicheren und langlebigen Objekt-Storage zur Verfügung. Inhalte werden zur richtigen Zeit am richtigen Ort und in der richtigen Storage-Tier platziert. Dies optimiert Workflows und senkt die Kosten für global verteilte Rich Media.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Das größte Unterscheidungsmerkmal von StorageGRID ist die Policy Engine für Information Lifecycle Management (ILM), die ein richtlinienbasiertes Management des Daten-Lebenszyklus ermöglicht. Die Richtlinien-Engine kann Metadaten verwenden, um zu managen, wie die Daten über ihre gesamte Lebensdauer gespeichert werden. So kann sie anfänglich auf eine optimale Performance aufsetzt und bei zunehmenden Alter der Daten automatisch auf Kosten und Langlebigkeit optimiert werden.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Aktivieren Von Confluent Tiered Storage</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">Die grundlegende Idee von Tiered Storage besteht darin, die Storage-Aufgaben von der Datenverarbeitung zu trennen. Dank dieser Trennung ist es viel einfacher, dass Storage Tiers und die Datenverarbeitungs-Tier unabhängig skaliert werden können.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Eine Tiered Storage-Lösung für Confluent muss zwei Faktoren berücksichtigen. Zunächst muss die IT sich um häufige Objekt-Storage-Konsistenz und Verfügbarkeiteigenschaften wie Inkonsistenzen bei LISTENVORGÄNGEN und gelegentlichen Nichtverfügbarkeit von Objekten handeln. Zweitens muss sie die Interaktion zwischen Tiered Storage und Kafkas Replizierungs- und Fehlertoleranz-Modell korrekt handhaben, einschließlich der Möglichkeit, dass Zombie-Führungskräfte weiterhin Tier-Offset-Bereiche nutzen. NetApp Objekt-Storage bietet sowohl die konsistente Objektverfügbarkeit als auch das HA-Modell, sodass der müde Storage für Tier-Offset-Bereiche verfügbar ist. NetApp Objekt-Storage bietet eine konsistente Objektverfügbarkeit sowie ein HA-Modell, um den müden Storage für Tier-Offset-Bereiche verfügbar zu machen.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Mit Tiered Storage können Sie hochperformante Plattformen für Lese- und Schreibvorgänge mit niedriger Latenz in Reichweite des Datenstreamings nutzen. Außerdem können Sie kostengünstigere und skalierbare Objektspeicher wie NetApp StorageGRID für historische Lesevorgänge mit hohem Durchsatz nutzen. Außerdem verfügen wir über technische Lösungen für Spark mit netapp Storage Controller und erhalten weitere Informationen. Die folgende Abbildung zeigt, wie Kafka in eine Echtzeit-Analyse-Pipeline passt.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">Die folgende Abbildung zeigt, wie NetApp StorageGRID zu einem Objekt-Storage Tier von Conflient Kafka passt.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">Weiter: Details zur Lösungsarchitektur.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">Folgende Referenzen wurden in dieser TR verwendet:</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark Architektur und Komponenten</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Anwendungsfälle für Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Apache Herausforderungen</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Deep and Cross Network for Ad Click Predictions</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">Streaming-ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">NetApp E-Series Lösungen für Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">Sentiment-Analyse aus Kundenkommunikation mit NetApp KI</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps-Toolkit</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">In diesem Abschnitt werden die Art und die Komponenten von Apache Spark sowie deren Beitrag zu dieser Lösung beschrieben.</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">Zurück: Zielgruppe.</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark ist ein beliebtes Programmierungs-Framework für Hadoop Applikationen, das direkt mit Hadoop Distributed File System (HDFS) zusammenarbeitet. Spark ist produktionsbereit, unterstützt die Verarbeitung von Streaming-Daten und ist schneller als MapReduce. Spark verfügt über ein in-Memory-Daten-Caching und sorgt so für eine effiziente Iteration. Die Spark Shell ist interaktiv für das Lernen und die Erforschung von Daten. Mit Spark können Sie Anwendungen in Python, Scala oder Java erstellen. Funkenanwendungen bestehen aus einem oder mehreren Jobs, die eine oder mehrere Aufgaben haben.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Jede Spark-Anwendung verfügt über einen Spark-Treiber. Im YARN-Client-Modus wird der Treiber lokal auf dem Client ausgeführt. Im YARN-Cluster-Modus wird der Treiber im Cluster auf dem Anwendungsmaster ausgeführt. Im Cluster-Modus wird die Applikation weiterhin ausgeführt, auch wenn die Verbindung des Clients getrennt wird.</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Es gibt drei Cluster Manager:</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Standalone.* dieser Manager ist ein Teil von Spark, was es einfach macht, einen Cluster einzurichten.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.* Dies ist ein allgemeiner Clustermanager, der auch MapReduce und andere Anwendungen ausführt.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN.* Dies ist ein Resource Manager in Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">Der Resilient Distributed Dataset (RDD) ist die primäre Komponente von Spark. RDD erstellt die verlorenen und fehlenden Daten aus dem Speicher des Clusters neu und speichert die ursprünglichen Daten, die aus einer Datei stammen oder programmgesteuert erstellt werden. RDDs werden aus Dateien, Daten im Speicher oder einem anderen RDD erstellt. Die Funkenprogrammierung führt zwei Vorgänge durch: Transformation und Aktionen. Durch Transformation wird ein neues RDD auf Basis eines vorhandenen erstellt. Aktionen geben einen Wert aus einem RDD zurück.</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">Transformationen und Aktionen gelten auch für Spark DataFrames und DataFrames. Ein Datensatz ist eine verteilte Sammlung von Daten, die die Vorteile von RDDs (starke Eingabe, Verwendung von Lambda-Funktionen) mit den Vorteilen der optimierten Ausführung von Spark SQL bietet. Ein Datensatz kann aus JVM-Objekten erstellt und anschließend mithilfe von funktionalen Transformationen (Map, FlatMap, Filter usw.) manipuliert werden. Ein DataFrame ist ein Datensatz, der in benannte Spalten organisiert ist. Es ist konzeptionell gleichbedeutend mit einer Tabelle in einer relationalen Datenbank oder einem Datenrahmen in R/Python. Datenframes können aus einer Vielzahl von Quellen wie strukturierten Datendateien, Tabellen in Hive/HBase, externen Datenbanken vor Ort oder in der Cloud oder vorhandenen RDDs erstellt werden.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Funkenanwendungen umfassen einen oder mehrere Spark-Jobs. Die Jobs führen Aufgaben in Ausführenden aus, und die Ausführenden werden in YARN-Containern ausgeführt. Jeder Ausführende wird in einem einzigen Container ausgeführt und Ausführende existieren während des gesamten Lebenszyklus einer Applikation. Ein Executor wird nach dem Start der Anwendung repariert und YARN ändert nicht die Größe des bereits zugewiesenen Containers. Ein Ausführender kann Aufgaben gleichzeitig auf Speicherdaten ausführen.</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">Weiter: Übersicht über die NetApp Spark-Lösungen</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Das vorliegende Dokument befasst sich in erster Linie mit der Apache Spark-Architektur, Anwendungsfällen von Kunden und dem NetApp Storage-Portfolio in Bezug auf Big Data Analytics und künstliche Intelligenz. Daneben werden unter Verwendung branchenüblicher KI-Tools, Machine Learning und Deep-Learning-Tools auf einem typischen Hadoop-System verschiedene Testergebnisse vorgestellt, sodass Sie die entsprechende Spark-Lösung wählen können.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: NetApp Storage-Lösungen für Apache Spark: Architektur, Anwendungsfälle und Performance-Ergebnisse</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">In diesem Dokument geht es um die Apache Spark-Architektur, Anwendungsfälle von Kunden und das NetApp Storage-Portfolio in Bezug auf Big Data Analytics und künstliche Intelligenz (KI). Er enthält zudem diverse Testergebnisse mit branchenüblichen Tools KI, Machine Learning (ML) und Deep Learning (DL) gegen ein typisches Hadoop System, sodass Sie die entsprechende Spark-Lösung wählen können. Zunächst benötigen Sie eine Spark-Architektur, geeignete Komponenten und zwei Implementierungsmodi (Cluster und Client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Dieses Dokument enthält auch Anwendungsfälle, um Konfigurationsprobleme zu lösen, und es enthält eine Übersicht über das NetApp Storage-Portfolio, das für Big Data Analytics und KI, ML und DL mit Spark relevant ist. Abschließend werden die Testergebnisse aus Spark-spezifischen Anwendungsfällen und dem NetApp Spark-Lösungsportfolio erstellt.</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Dieser Abschnitt befasst sich mit den Herausforderungen von Kunden mit Big Data-Analysen und KI/ML/DL in wachsenden Datenbranchen wie Einzelhandel, digitales Marketing, Banking, diskrete Fertigung, Prozessfertigung Öffentlicher Sektor und Professional Services.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Unvorhersehbare Performance</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Herkömmliche Hadoop Implementierungen nutzen in der Regel Standard-Hardware. Zur Verbesserung der Performance müssen Netzwerk, Betriebssystem, Hadoop Cluster, Ecosystem-Komponenten wie Spark und Hardware abgestimmt werden. Selbst bei einer Feinanpassung aller Ebenen kann das gewünschte Performance-Niveau nur schwer erreicht werden, da Hadoop auf Standard-Hardware ausgeführt wird, die nicht für eine hohe Performance in der Umgebung konzipiert wurde.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Medien- und Node-Ausfälle</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Selbst unter normalen Bedingungen ist Standard-Hardware fehleranfällig. Wenn eine Festplatte in einem Daten-Node ausfällt, ist dieser Node standardmäßig von Hadoop Master als fehlerhaft erachtet. Anschließend werden bestimmte Daten von diesem Node über das Netzwerk von Replikaten auf einen gesunden Node kopiert. Dieser Prozess verlangsamt die Netzwerkpakete für alle Hadoop Jobs. Anschließend muss das Cluster die Daten wieder kopieren und die über- replizierten Daten entfernen, wenn der ungesunde Node in einen ordnungsgemäßen Zustand zurückkehrt.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop Anbieterbindung</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop Distributoren verfügen über eigene Hadoop Distributionen, welche sich dem Kunden an diese Distributionen anschloss. Viele Kunden benötigen jedoch Unterstützung für in-Memory-Analysen, die den Kunden nicht an bestimmte Hadoop Distributionen binden. Sie brauchen die Freiheit, Distributionen zu ändern und trotzdem ihre Analysen mit ihnen zu bringen.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Fehlende Unterstützung für mehr als eine Sprache</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Kunden benötigen für ihre Aufgaben oft Unterstützung für mehrere Sprachen neben MapReduce Java-Programmen. Optionen wie SQL und Skripte bieten mehr Flexibilität, um Antworten zu erhalten, mehr Optionen für die Organisation und den Abruf von Daten und eine schnellere Möglichkeit zum Verschieben von Daten in ein Analyse-Framework.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Nutzschwierigkeiten</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Seit einiger Zeit haben sich die Leute darüber beschwert, dass Hadoop nur schwer zu bedienen ist. Auch wenn Hadoop mit jeder neuen Version einfacher und leistungsstärker geworden ist, bleibt diese Kritik bestehen. Hadoop erfordert, dass Sie Java- und MapReduce-Programmiermuster kennen. Dies ist eine Herausforderung für Datenbankadministratoren und Mitarbeiter mit klassischen Scripting-Kenntnissen.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Komplizierte Frameworks und Tools</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">KI-Teams von Unternehmen stehen vor mehreren Herausforderungen. Selbst wenn Experten im Bereich Data Science wissen, Tools und Frameworks für verschiedene Implementierungökosysteme und -Applikationen nicht einfach zwischen Lösungen übersetzen können. Eine Data-Science-Plattform sollte sich nahtlos in die entsprechenden Big-Data-Plattformen integrieren lassen, die auf Spark basieren, mit einfacher Datenverschiebung, wiederverwendbaren Modellen, sofort verwendbarem Code und Tools, die Best Practices für Prototyping, Validierung, Versionierung, Freigabe, Wiederverwendung, Und schnelle Implementierung von Modellen in der Produktion.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Warum NetApp?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">Mit NetApp können Sie Ihre Spark-Erfahrung auf folgende Weise verbessern:</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">Durch den direkten Zugriff mit NetApp NFS (in der Abbildung unten dargestellt) können Kunden Big-Data-Analytics-Jobs auf ihren vorhandenen oder neuen NFSv3- oder NFSv4-Daten ausführen, ohne die Daten zu verschieben oder zu kopieren. Es verhindert mehrere Datenkopien und macht die Synchronisierung der Daten mit einer Quelle überflüssig.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Effizienterer Storage und weniger Server-Replizierung. Beispielsweise erfordert die NetApp E-Series Hadoop Lösung zwei statt drei Datenreplikate. Zur FAS Hadoop Lösung ist eine Datenquelle erforderlich, jedoch keine Replizierung oder Kopie der Daten. NetApp Storage-Lösungen produzieren zudem weniger Datenverkehr zwischen Servern.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Bessere Hadoop Jobs und Clusterverhalten bei Laufwerks- und Node-Ausfällen</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">Bessere Performance bei der Datenaufnahme:</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Alternative Apache Spark-Konfigurationen</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">So muss zum Beispiel im Finanz- und Gesundheitswesen das Verschieben von Daten von einem Ort zum anderen den gesetzlichen Verpflichtungen entsprechen, was keine einfache Aufgabe ist. In diesem Szenario analysiert NetApp NFS Direct Access die Finanz- und Gesundheitsdaten vom ursprünglichen Standort aus. Ein weiterer entscheidender Vorteil besteht darin, dass der NetApp NFS Direct Access die Sicherung von Hadoop Daten durch native Hadoop Befehle vereinfacht und Workflows zur Datensicherung mit dem umfassenden Datenmanagement-Portfolio von NetApp ermöglicht.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS Direct Access bietet zwei Arten von Implementierungsoptionen für Hadoop/Spark Cluster:</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Hadoop oder Spark-Cluster verwenden standardmäßig das Hadoop Distributed File System (HDFS) für die Datenspeicherung sowie das Standard-Filesystem. Der direkte NetApp NFS-Zugriff ersetzt das Standard-HDFS durch NFS-Storage als Standarddateisystem und ermöglicht so direkte Analysen für NFS-Daten.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">Bei einer anderen Implementierungsoption unterstützt der direkte NetApp NFS-Zugriff die Konfiguration von NFS als zusätzlichen Storage zusammen mit HDFS in einem einzelnen Hadoop oder Spark-Cluster. In diesem Fall kann der Kunde Daten über NFS-Exporte teilen und gemeinsam mit HDFS-Daten vom selben Cluster aus darauf zugreifen.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Zu den wichtigsten Vorteilen des direkten NetApp NFS-Zugriffs gehören:</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">Analyse der Daten vom aktuellen Standort, was das verlagern Zeit- und Performance-verschlingt, Analysedaten in eine Hadoop Infrastruktur wie HDFS zu verschieben</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Reduzierung der Anzahl der Replikate von drei auf eins.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Benutzer können Computing und Storage entkoppeln, um sie unabhängig voneinander zu skalieren.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Datensicherung der Enterprise-Klasse durch Nutzung der umfassenden Datenmanagementfunktionen von ONTAP</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Zertifizierung mit der Hortonworks Datenplattform.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Hybrid-Datenanalyselösungen:</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Kürzere Backup-Zeiten durch Nutzung von dynamischen Multithread-Kapazitäten</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">Siehe<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Für Backups von Hadoop Daten, Backup und Disaster Recovery von der Cloud bis hin zum On-Premises-System; DevTest für vorhandene Hadoop Daten, Datensicherung und Multi-Cloud-Konnektivität sowie beschleunigte Analyse-Workloads</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">In den folgenden Abschnitten werden Storage-Funktionen beschrieben, die für Spark Kunden wichtig sind.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Storage Tiering</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Mit Hadoop Storage Tiering können Sie Dateien mit unterschiedlichen Storage-Typen gemäß einer Storage Policy speichern. Storage-Typen sind enthalten<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block>,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block>,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block>,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block>, und<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>.</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">Die folgende Abbildung zeigt die Performance der NetApp Lösungen für eine Hadoop SSD.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Zeit zum Sortieren von 1 TB Daten.</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 NetApp E-Series Lösung für Hadoop</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">In der NL-SAS-Basiskonfiguration wurden acht Computing-Nodes und 96 NL-SAS-Laufwerke verwendet. Durch diese Konfiguration wurden 1 TB Daten in 4 Minuten und 38 Sekunden erzeugt. Siehe<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> Finden Sie Details zur Cluster- und Storage-Konfiguration.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Mit TeraGen generierte die SSD-Konfiguration 1 TB an Daten 15,66-mal schneller als die NL-SAS-Konfiguration. Darüber hinaus verwendete die SSD-Konfiguration die Hälfte der Computing-Nodes und die Hälfte der Festplattenlaufwerke (insgesamt 24 SSD-Laufwerke). Basierend auf der Abschlusszeit war der Job fast doppelt so schnell wie die NL-SAS-Konfiguration.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Performance-Skalierung: Horizontale Skalierung</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Wenn von einem Hadoop Cluster in einer AFF Lösung mehr Rechenleistung benötigt wird, können Daten-Nodes mit einer entsprechenden Anzahl Storage Controller hinzugefügt werden. NetApp empfiehlt, mit vier Daten-Nodes pro Storage Controller Array zu beginnen und die Anzahl je nach Workload-Merkmalen auf acht Daten-Nodes pro Storage Controller zu erhöhen.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF und FAS sind ideal für in-Place-Analysen. Auf Basis von Berechnungsanforderungen können Node-Manager hinzugefügt werden und unterbrechungsfreier Betrieb ermöglichen es Ihnen, einen Storage-Controller nach Bedarf ohne Ausfallzeit hinzuzufügen. AFF und FAS bieten umfangreiche Funktionen, darunter NVME-Media-Unterstützung, garantierte Effizienz, Datenreduzierung, QOS, prädiktive Analysen, Cloud-Tiering, Replizierung, Cloud-Implementierung und Sicherheit. Um Kunden dabei zu unterstützen, die Anforderungen zu erfüllen, bietet NetApp Funktionen wie Filesystem-Analysen, Kontingente und integrierten Lastausgleich ohne zusätzliche Lizenzkosten. NetApp bietet eine bessere Performance bei gleichzeitigen Aufgaben, niedrigerer Latenz, einfacheren Abläufen und einem höheren Durchsatz von mehreren Gigabyte pro Sekunde als unsere Mitbewerber. Darüber hinaus wird NetApp Cloud Volumes ONTAP bei allen drei großen Cloud-Providern ausgeführt.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Performance-Skalierung – vertikale Skalierung</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Vertikale Skalierungsfunktionen ermöglichen es, bei Bedarf zusätzliche Storage-Kapazität Festplattenlaufwerke zu AFF, FAS und E-Series Systemen hinzuzufügen. Mit Cloud Volumes ONTAP besteht die Skalierung von Storage auf PB-Ebene aus zwei Faktoren: das tiering selten genutzter Daten aus Block-Storage in Objektspeicher und das Stapeln von Cloud Volumes ONTAP Lizenzen ohne zusätzliche Rechenleistung.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Mehrere Protokolle</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp Systeme unterstützen die meisten Protokolle in Hadoop Implementierungen, einschließlich SAS, iSCSI, FCP, InfiniBand Und NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Betriebliche und unterstützte Lösungen</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MapR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">Zertifizierung</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">Partner</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">Die in diesem Dokument beschriebenen Hadoop Lösungen werden von NetApp unterstützt. Diese Lösungen sind auch für größere Hadoop Distributoren zertifiziert. Weitere Informationen finden Sie im<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> Standort, die<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> Standort und Cloudera zur Verfügung<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> Und<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> Standorte.</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">Als Nächstes: Zielgruppe.</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">Früher: MapR-FS zu ONTAP NFS.</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp in-Place-Analysemodule Best Practices</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup Volume Best Practices und Implementierungsleitfaden</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Version 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">Januar 2022</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">Mit NetApp XCP Daten direkt von HDFS und MapR-FS zu NFS verschieben</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">Januar 2020</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">XCP ist als Standard-Data Mover enthalten. MapR-FS zu NFS und GPFS zu NFS-Datentransfer hinzugefügt</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">November 2018</block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp bietet eine einfache und skalierbare Lösung für Splunk SmartStore, mit der die Performance und Ausfallsicherheit maximiert und gleichzeitig eine überzeugende TCO erzielt werden kann.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Da Kunden Splunk Data Analytics sehr einfach und leistungsfreundlich nutzen können, möchten sie natürlich eine stetig wachsende Datenmenge indizieren. Mit zunehmender Datenmenge wächst auch die für den Service erforderliche Computing- und Storage-Infrastruktur.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Intelligentes Tiering und Kosteneinsparungen</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">Zurück: Vorteile dieser Lösung.</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Da Kunden Splunk Data Analytics sehr einfach und leistungsfreundlich nutzen können, möchten sie natürlich eine stetig wachsende Datenmenge indizieren. Mit zunehmender Datenmenge wächst auch die für den Service erforderliche Computing- und Storage-Infrastruktur. Da auf ältere Daten weniger häufig referenziert wird, wird das Bestellen derselben Menge an Computing-Ressourcen und der Verbrauch kostspieliger Primärspeicher immer ineffizienter. Zur Skalierung profitieren Kunden davon, dass „warme“ Daten auf eine kostengünstigere Tier verschoben werden und so Datenverarbeitungs- und Primärspeicher für heiße Daten freigegeben werden.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore mit StorageGRID bietet Unternehmen eine skalierbare, performante und kostengünstige Lösung. Da SmartStore datenorientiert ist, werden Datenzugriffsmuster automatisch ausgewertet, um zu ermitteln, welche Daten für Echtzeitanalysen (wichtige Daten) genutzt werden müssen und welche Daten im kostengünstigeren Langzeitspeicher (warme Daten) gespeichert werden sollten. SmartStore nutzt die branchenübliche AWS S3 API dynamisch und intelligent und platziert Daten in den von StorageGRID bereitgestellten S3 Storage. Dank der flexiblen Scale-out-Architektur von StorageGRID kann die Tier mit „heißen“ Daten kosteneffizient je nach Bedarf wachsen. Die Node-basierte Architektur von StorageGRID sorgt dafür, dass die Performance- und Kostenanforderungen optimal erfüllt werden.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">Folgende Abbildung zeigt Splunk und StorageGRID Tiering.</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">Die branchenführende Kombination aus Splunk SmartStore und NetApp StorageGRID bietet die Vorteile einer entkoppelten Architektur in einer Full-Stack-Lösung.</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">Weiter: Lösungsübersicht.</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Dieser Abschnitt enthält eine Zusammenfassung der von NetApp zur Erfüllung verschiedener Hadoop Datensicherungsanforderungen bereitgestellten Anwendungsfälle und Lösungen.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">Zurück: Anwendungsfall 5 – Beschleunigen Sie Analyse-Workloads.</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Dieser Abschnitt enthält eine Zusammenfassung der von NetApp zur Erfüllung verschiedener Hadoop Datensicherungsanforderungen bereitgestellten Anwendungsfälle und Lösungen. Mit der Data Fabric von NetApp profitieren Kunden von folgenden Vorteilen:</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">Dank der umfassenden Datenmanagement-Funktionen und der Integration in native Hadoop Workflows können die passenden Datensicherungslösungen flexibel gewählt werden.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Reduzieren Sie das Backup-Fenster für Hadoop Cluster um beinahe 70 %.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Keine Performance-Auswirkungen durch Hadoop Cluster-Backups</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Datensicherung und Datenzugriff über mehrere Clouds gleichzeitig von verschiedenen Cloud-Providern für eine zentrale Quelle der Analysedaten</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Schnelle und platzsparende Hadoop Cluster-Kopien mit FlexClone Technologie</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Weitere Informationen zu den in diesem Dokument beschriebenen Daten finden Sie in den folgenden Dokumenten bzw. auf den folgenden Websites:</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp Big-Data-Analyselösungen</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Apache Spark Workload mit NetApp Storage</block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">NetApp Storage-Lösungen für Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop on Data Fabric basiert auf NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Danksagungen</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Vertriebsmitarbeiter, Vertrieb Australien/Victoria District, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, Business Development Manager, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Director MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Systems Engineer, ANZ Victoria District SE, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Januar 2018</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Aktualisiert mit Anwendungsfall #5: Analytics-Workloads beschleunigen</block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Ein modernes Enterprise-Datacenter ist eine Hybrid Cloud, die diverse verteilte Infrastrukturumgebungen über eine kontinuierliche Datenmanagementebene mit einem konsistenten Betriebsmodell verbindet – vor Ort und/oder in mehreren Public Clouds. Um die Vorteile einer Hybrid Cloud optimal nutzen zu können, müssen Sie die Daten nahtlos zwischen Ihren lokalen und Multi-Cloud-Umgebungen verschieben können, ohne dass Datenkonvertierung oder Applikationsrefakturierung erforderlich ist.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Hybrid Cloud-Lösung</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">Zurück: Testergebnisse.</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Die Kunden haben angegeben, dass sie den Weg in die Hybrid Cloud entweder durch das verlagern von sekundärem Storage in die Cloud beginnen. Dies ist u. a. für Datensicherung oder die Verlagerung weniger geschäftskritischer Workloads wie Applikationsentwicklung und DevOps in die Cloud möglich. Dann wechseln sie zu geschäftskritischeren Workloads. Zu den beliebtesten Hybrid-Cloud-Workloads gehören Web- und Content-Hosting, DevOps und Applikationsentwicklung, Datenbanken, Analysen und Container-Applikationen. Die Komplexität, Kosten und Risiken von Enterprise-KI-Projekten haben bislang die Einführung der KI von der Testphase in die Produktion gehindert.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Mit einer Hybrid-Cloud-Lösung von NetApp profitieren Kunden von integrierten Tools für Sicherheit, Daten-Governance und Compliance mit einer einzigen Konsole für Daten- und Workflow-Management in verteilten Umgebungen. Gleichzeitig können sie die TCO basierend auf ihrer Nutzung optimieren. Die folgende Abbildung zeigt eine beispielhafte Lösung eines Cloud-Service-Partners, der für die Bereitstellung von Multi-Cloud-Konnektivität für Big Data-Analysedaten des Kunden beauftragt ist.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Beispiellösung eines Cloud-Service-Partners.</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">In diesem Szenario werden die in AWS empfangenen IoT-Daten aus verschiedenen Quellen an einem zentralen Standort in NetApp Private Storage (NPS) gespeichert. Der NPS Storage ist mit Spark oder Hadoop Clustern in AWS und Azure verbunden, sodass Big-Data-Analyseapplikationen in diversen Clouds ausgeführt werden, die auf dieselben Daten zugreifen. Zu den wesentlichen Anforderungen und Herausforderungen dieses Anwendungsfalls gehören:</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Daten müssen von unterschiedlichen Quellen wie On-Premises- und Cloud-Umgebungen über unterschiedliche Sensoren und Hubs empfangen werden.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">Die Lösung muss effizient und kosteneffektiv sein.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">Die größte Herausforderung ist der Aufbau einer kostengünstigen und effizienten Lösung, die Hybrid-Analyseservices für verschiedene On-Premises- und Cloud-Umgebungen bietet.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Unsere Datensicherungs- und Multi-Cloud-Konnektivitätslösung behebt die Probleme bei Cloud-Analyseapplikationen über diverse Hyperscaler hinweg. Wie in der Abbildung oben gezeigt, werden die Daten von Sensoren gestreamt und über Kafka in den AWS Spark-Cluster aufgenommen. Die Daten werden in einem NFS-Share in NPS gespeichert, der sich außerhalb des Cloud-Providers in einem Equinix Datacenter befindet.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Da NetApp NPS über Direct Connect und Express Route Verbindungen mit Amazon AWS und Microsoft Azure verbunden ist, können Kunden das in-Place-Analysemodul für den Zugriff auf Daten von Amazon- und AWS-Analyse-Clustern nutzen. Da sowohl On-Premises- als auch NPS-Storage auf ONTAP Software ausgeführt wird,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> Die NPS Daten können in das On-Premises-Cluster gespiegelt werden und dabei Hybrid-Cloud-Analysen für On-Premises-Systeme und diverse Clouds bieten.</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">Um die beste Performance zu erzielen, empfiehlt NetApp normalerweise, mehrere Netzwerkschnittstellen und direkte Verbindung oder Express Routen zu verwenden, um auf die Daten von Cloud-Instanzen zuzugreifen. Wir bieten unter anderem eine Data Mover-Lösung an<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> Und<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> Damit Kunden applikationsspezifische, sichere und kostengünstige Hybrid-Cloud-Spark-Cluster erstellen können,</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">Weiter: Python-Skripte für jeden größeren Anwendungsfall.</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">Protokoll der neuesten Änderungen im NetApp Solutions-Begleitmaterial</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">Änderungsprotokoll mit NetApp Lösungen</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">Kürzliche Änderungen im NetApp Solutions-Begleitmaterial. Die letzten Änderungen werden zuerst aufgeführt.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">Alle Änderungen</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">*Datum*</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">*Lösungsbereich*</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">*Beschreibung der Änderung*</block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">10/25/2022</block>
  <block id="80d05b7bca341d02b41c7f6cb32ad23b" category="cell">Link zu VMware Dokumentarfilm für FSX ONTAP als NFS-Datenspeicher hinzugefügt</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">Zusätzliche Referenz im Blog zum Konfigurieren von Hybrid Clouds mit FSX ONTAP und VMC auf AWS SDDC mithilfe von VMware HCX</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">09/30/2022</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">Lösung zur Migration von Workloads zu FSxN-Datastore mit VMware HCX hinzugefügt</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">09/29/2022</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">Lösung zur Migration von Workloads zu einem ANF-Datastore unter Verwendung von VMware HCX hinzugefügt</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">09/14/2022</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">Links zu TCO-Rechenmaschinen und Simulatoren für FSxN/VMC und ANF/AVS hinzugefügt</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">Zusätzliche NFS-Datastore-Option für AWS/VMC hinzugefügt</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">08/25/2022</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">Datenbank</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">Zusätzlicher Blog: Modernisieren Sie Ihren Oracle-Datenbankbetrieb in der Hybrid Cloud mit Amazon FSX Storage</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">KI</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">Neue Lösung: NVIDIA AI Enterprise mit NetApp und VMware</block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">08/23/2022</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">Aktualisierte Angaben zur aktuellen Verfügbarkeit der Region für alle zusätzlichen NFS-Datastore-Optionen</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">08/05/2022</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">„Neustart erforderlich“-Informationen für die empfohlenen ESXi- und ONTAP-Einstellungen hinzugefügt</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">07/28/2022</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">Zusätzliche DR-Lösung mit SnapCenter und Veeam für AWS/VMC (Gast-vernetzter Storage)</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">07/21/2022</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">Zusätzliche DR-Lösung mit CVO und JetStream for AVS (Gast-vernetzter Storage)</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">06/29/2022</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">WP-7357: Oracle Database Deployment on EC2/FSX Best Practices</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">06/16/2022</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">NVIDIA DGX SuperPOD mit dem NetApp Design-Leitfaden hinzugefügt</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">06/10/2022</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">AVS mit nativer ANF-Datastore-Übersicht und DR mit JetStream hinzugefügt</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">06/07/2022</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">Die Unterstützung für die Region AVS wurde aktualisiert, um die Ankündigung/den Support für die öffentliche Vorschau anzupassen</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">Datenanalysen</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Link zu NetApp EF600 mit Splunk Enterprise-Lösung hinzugefügt</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">06/02/2022</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">Zusätzliche Liste der regionalen Verfügbarkeit von NFS-Datastores für NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">05/20/2022</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">Neue BeeGFS Design and Deployment Guides für SuperPOD</block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">04/01/2022</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">Organisierte Inhalte in Hybrid-Multi-Cloud mit VMware Lösungen: Landing Pages für jeden Hyperscaler und Aufnahme der verfügbaren Lösung (Anwendungsfall</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">03/29/2022</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">Hat einen neuen TR hinzugefügt: DevOps mit NetApp Astra</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">03/08/2022</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">Neues Video: Schnellere Softwareentwicklung mit Astra Control und NetApp FlexClone Technologie</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">03/01/2022</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">Neue Abschnitte zu NVA-1160 hinzugefügt: Installation von Astra Control Center über OperatorHub und Ansible</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">Allgemein</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">Erstellung von Landing Pages, um Inhalte für KI und moderne Data Analytics besser zu organisieren</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">01/22/2022</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">Hinzugefügter TR: Datenverschiebung mit E-Series und BeeGFS für KI- und Analyse-Workflows</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">12/21/2021</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">Erstellte Landing Pages, um Inhalte für die Virtualisierung und Hybrid-Multi-Cloud mit VMware besser zu organisieren</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">Hinzugefügt eine neue Video-Demo: Nutzen Sie NetApp Astra Control, um Post-Mortem-Analysen durchzuführen und Ihre Anwendung in NVA-1160 wieder verfügbar zu machen</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/06/2021</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">Erstellung von Hybrid-Multi-Cloud mit VMware Inhalten für die Virtualisierungsumgebung und Storage-Optionen mit Gast-Anbindung</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">11/15/2021</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">Neue Video-Demo: Data Protection in CI/CD-Pipeline mit Astra Control zu NVA-1160</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">Moderne Datenanalysen</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">Neue Inhalte: Best Practices für Confluent Kafka</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">11/02/2021</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">Automatisierung</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">10/29/2021</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">Neue Inhalte: TR-4657 – NetApp Hybrid-Cloud-Datenlösungen: Spark und Hadoop</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Automatisierte Datensicherung für Oracle Datenbanken</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">10/26/2021</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">Zusätzlicher Blog-Abschnitt für Enterprise-Applikationen und Datenbanken zu NetApp Lösungen. Zwei Blogs zu Datenbank-Blogs hinzugefügt.</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">10/18/2021</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 – Hybrid-Cloud-Datenbanklösungen mit SnapCenter</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">10/14/2021</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">Blog-Serie Parts 1-4 von NetApp mit VMware VCF hinzugefügt</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">10/04/2021</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">Neue Video-Demo: Workload-Migration Using Astra Control Center to NVA-1160</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">09/23/2021</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">Datenmigration</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">Neue Inhalte: NetApp Best Practices für NetApp XCP</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">09/21/2021</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">Neue Inhalte oder ONTAP für VMware vSphere Administratoren, VMware vSphere Automatisierung</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">09/09/2021</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">Integration von F5 BIG-IP Load Balancer mit OpenShift in NVA-1160</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">08/05/2021</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Neue Technologieintegration in NVA-1160: NetApp Astra Control Center auf Red hat OpenShift</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">07/21/2021</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">Automated Deployment of Oracle19c for ONTAP on NFS</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 – SQL Server on Azure NetApp Files: Real Deployment View</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">06/16/2021</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">Neues Video-Demo Installing OpenShift Virtualization: Red hat OpenShift mit NetApp hinzugefügt</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">Hat eine neue Video-Demo hinzugefügt: Bereitstellung einer Virtual Machine mit OpenShift Virtualisierung: Red hat OpenShift mit NetAppp</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">06/14/2021</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Neue Lösung: Microsoft SQL Server auf Azure NetApp Files</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">06/11/2021</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">Neue Video-Demo: Workload-Migration Using Astra Trident and SnapMirror to NVA-1160</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">06/09/2021</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">NVA-1160: Advanced Cluster Management for Kubernetes on Red hat OpenShift mit NetApp um einen neuen Anwendungsfall ergänzt</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">05/28/2021</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">Neuer Anwendungsfall für NVA-1160-OpenShift-Virtualisierung mit NetApp ONTAP hinzugefügt</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">05/27/2021</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">Neuer Anwendungsfall für NVA-1160- Mandantenfähigkeit in OpenShift mit NetApp ONTAP hinzugefügt</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">05/26/2021</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">NVA-1160 - Red hat OpenShift mit NetApp hinzugefügt</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">05/25/2021</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">Hinzugefügt am Blog: Installing NetApp Trident on Red hat OpenShift – How to Solve the Docker ‘toomanyanests’ Ausgabe!</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">05/19/2021</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">Link zu FlexPod-Lösungen hinzugefügt</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">Konvertierte AI Control Plane Lösung von PDF zu HTML</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">05/17/2021</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">Kachel „Solution Feedback“ wurde zur Hauptseite hinzugefügt</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">05/11/2021</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">Automatisierte Implementierung von Oracle 19c für ONTAP auf NFS wurde hinzugefügt</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">05/10/2021</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">Neues Video: How to Use VVols with NetApp and VMware Tanzu Basic, Teil 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">05/06/2021</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Oracle Datenbank</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">Link zu Oracle 19c RAC-Datenbanken in FlexPod DataCenter mit Cisco UCS und NetApp AFF A800 über FC hinzugefügt</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">05/05/2021</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">Video zu FlexPod Oracle NVA (1155) und Automatisierung hinzugefügt</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">05/03/2021</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">Desktop-Virtualisierung</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">Zusätzlicher Link zu FlexPod Lösungen für die Desktop-Virtualisierung</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">04/30/2021</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">Video: Verwendung von VVols mit NetApp und VMware Tanzu Basic, Teil 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">04/26/2021</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">Hinzugefügt am Blog: VMware Tanzu mit ONTAP beschleunigt Ihren Kubernetes-Prozess</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">04/06/2021</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">Hinzugefügt: „About this Repository“</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">03/31/2021</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Hinzugefügter TR-4886 – KI-Inferenzierung am Edge: NetApp ONTAP mit Lenovo ThinkSystem Solution Design</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">03/29/2021</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NVA-1157 - Apache Spark Workload mit NetApp Storage-Lösung hinzugefügt</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">03/23/2021</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">Video: Verwendung von VVols mit NetApp und VMware Tanzu Basic, Teil 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">03/09/2021</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">Hinzugefügte Inhalte der E-Series und kategorisierte KI-Inhalte</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">03/04/2021</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">Neue Inhalte: Erste Schritte mit der Automatisierung von NetApp Lösungen</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">02/18/2021</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">TR-4597 - VMware vSphere für ONTAP hinzugefügt</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">02/16/2021</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">Automatisierte Implementierungsschritte für KI-Edge-Inferenz</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">02/03/2021</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">Landing Page für alle SAP- und SAP HANA-Inhalte hinzugefügt</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">02/01/2021</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">VDI mit NetApp VDS, zusätzliche Inhalte für GPU-Nodes</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">01/06/2021</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">Neue Lösung: NetApp ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches (Design und Implementierung)</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">12/22/2020</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">Erste Version des NetApp Solutions Repository</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">KI/Data Analytics</block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">Hybrid-Multi-Cloud</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">Enterprise-Applikationen und DB</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP Solutions Repository</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">Weitere Informationen zu Updates für SAP und SAP HANA finden Sie in den Inhalten „Update History“ für jede der Lösungen im <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">Datensicherung und Datenmigration</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">Konfigurieren Sie die Anmeldedaten.</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">Credential-Typen Erstellen. Bei Lösungen, die ONTAP verwenden, müssen Sie den Anmeldeinformationstyp so konfigurieren, dass er mit den Einträgen für Benutzernamen und Kennwort übereinstimmt.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Navigieren Sie zu Administration → Credential Types, und klicken Sie auf Add.</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">Fügen Sie den folgenden Inhalt in die Eingabekonfiguration ein:</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Fügen Sie den folgenden Inhalt in die Konfiguration des Injektors ein, und klicken Sie dann auf Speichern:</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">Credential für ONTAP erstellen</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Navigieren Sie zu Resources → Credentials, und klicken Sie auf Add.</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">Geben Sie den Namen und die Organisationsdetails für die ONTAP Credentials ein</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">Wählen Sie den im vorherigen Schritt erstellten Anmeldeinformationstyp aus.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">Geben Sie unter „Typdetails“ den Benutzernamen und das Kennwort für Ihre Quell- und Zielcluster ein.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">Klicken Sie Auf Speichern</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Credential für Oracle erstellen</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Geben Sie den Namen und die Organisationsdetails für Oracle ein</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">Wählen Sie den Typ der Geräteanmeldeinformationen aus.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">Geben Sie unter „Typdetails“ den Benutzernamen und das Kennwort für die Oracle-Hosts ein.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">Wählen Sie die richtige Privilege-Eskalationsmethode aus, und geben Sie Benutzernamen und Kennwort ein.</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">Wiederholen Sie den Vorgang, falls dies für eine andere Anmeldedaten für den dr_oracle-Host erforderlich ist.</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP- und CVO-Einrichtung</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*Konfigurieren und starten Sie die Jobvorlage.*</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">Erstellen Sie die Job-Vorlage.</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">Geben Sie den Namen „ONTAP/CVO Setup“ ein</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">Wählen Sie den Jobtyp aus; Ausführen konfiguriert das System anhand eines Playbooks.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Wählen Sie den entsprechenden Bestand, das Projekt, das Playbook und die Zugangsdaten für das Playbook aus.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">Wählen Sie das Playbook „ontap_Setup.yml“ für eine On-Premises-Umgebung aus oder wählen Sie das playbook cvo_Setup.yml zur Replizierung in eine CVO Instanz aus.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">Fügen Sie globale Variablen, die aus Schritt 4 kopiert wurden, in das Feld Vorlagenvariablen unter der Registerkarte YAML ein.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">Wir verwenden diese Vorlage und kopieren sie in andere Playbooks.</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">Melden Sie sich bei der NetApp Support-Website an und laden Sie die neueste Version des NetApp Astra Control Center herunter. Dazu ist eine Lizenz erforderlich, die an Ihr NetApp Konto angehängt ist. Nach dem Download des Tarballs, übertragen Sie es auf die Admin-Workstation.</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra: Anmelde-Website</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Um mit einer Testlizenz für Astra Control zu beginnen, besuchen Sie die<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">Entpacken Sie den tar-Ball und ändern Sie das Arbeitsverzeichnis in den resultierenden Ordner.</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">Bevor Sie mit der Installation beginnen, schieben Sie die Astra Control Center-Bilder in eine Bildregistrierung.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Sie können dies entweder mit Docker oder Podman tun. Anweisungen für beide werden in diesem Schritt angegeben.</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">Exportieren Sie den FQDN der Registrierung mit dem Namen der Organisation/des Namespace/Projekts als Umgebungsvariable ‘registry’.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">Melden Sie sich bei der Registrierung an.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">Wenn Sie verwenden<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> Benutzer, um sich bei der privaten Registrierung anzumelden, dann Token statt Passwort verwenden -<block ref="7d7ac4e834205786dd5590244b8666d4" prefix=" " category="inline-code"></block>.</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">Alternativ können Sie ein Service-Konto erstellen, dem Registry-Editor und/oder der Registry-Viewer-Rolle zuweisen (ob Sie Push/Pull-Zugriff benötigen) und sich mithilfe des Token des Service-Kontos bei der Registrierung anmelden.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">Erstellen Sie eine Shell-Skriptdatei, und fügen Sie den folgenden Inhalt darin ein.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">Wenn Sie nicht vertrauenswürdige Zertifikate für Ihre Registrierung verwenden, bearbeiten Sie das Shell-Skript und verwenden Sie es<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> Für den Podman-Push-Befehl<block ref="0860f2134645f92280f543681a4900f8" prefix=" " category="inline-code"></block>.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">Machen Sie die Datei ausführbar.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">Das Shell-Skript ausführen.</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">Wenn Sie verwenden<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> Benutzer, um sich bei der privaten Registrierung anzumelden, dann Token statt Passwort verwenden -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">Laden Sie anschließend die TLS-Zertifikate der Bildregistrierung auf die OpenShift-Knoten hoch. Erstellen Sie dazu im Namespace openshift-config eine configmap mit den TLS-Zertifikaten und patchen Sie sie auf die Cluster-Image-Konfiguration, damit das Zertifikat vertrauenswürdig ist.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">Wenn Sie eine interne OpenShift-Registrierung mit Standard-TLS-Zertifikaten vom Ingress Operator mit einer Route verwenden, müssen Sie den vorherigen Schritt dennoch befolgen, um die Zertifikate auf den Routing-Hostnamen zu patchen. Um die Zertifikate aus dem Ingress Operator zu extrahieren, können Sie den Befehl verwenden<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Erstellen Sie einen Namespace<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Zur Installation des Astra Control Center Operators.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">Erstellen Sie ein Geheimnis mit Anmeldeinformationen, um sich in der Bildregistrierung anzumelden<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Namespace.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Bearbeiten Sie den Astra Control Center Operator CR<block ref="29815934e812e1cfba6cc38eff0d17d3" prefix=" " category="inline-code"></block>, Ein Satz aller Ressourcen, die Astra Control Center implementiert. Suchen Sie im Operator CR die Bereitstellungsdefinition für<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> Und geben Sie den FQDN für Ihre Registrierung zusammen mit dem Namen der Organisation ein, den Sie erhalten haben, während Sie die Bilder in die Registrierung schieben (in diesem Beispiel<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>) Durch Ersetzen des Textes<block ref="e7fbb61ffc587682a801796b46db408a" prefix=" " category="inline-code"></block> Und geben Sie den Namen des Geheimnisses an, in dem wir gerade erschaffen haben<block ref="0d9b54b29da54379cca6b8782b9faae5" prefix=" " category="inline-code"></block> Abschnitt. Überprüfen Sie weitere Details des Bedieners, speichern und schließen Sie sie.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">Erstellen Sie den Operator, indem Sie den folgenden Befehl ausführen.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">Erstellen Sie einen dedizierten Namespace für die Installation aller Astra Control Center-Ressourcen.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">Erstellen Sie das Geheimnis für den Zugriff auf die Image-Registrierung in diesem Namespace.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Bearbeiten Sie die Datei Astra Control Center CRD<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> Und geben Sie den FQDN, die Registrierungsdetails für Bilder, die E-Mail-Adresse des Administrators und weitere Details ein.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Erstellen Sie den Astra Control Center CRD im dafür erstellten Namespace.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">Der vorherigen Datei<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> Ist die Mindestversion des Astra Control Center CRD. Wenn Sie die CRD mit mehr Kontrolle erstellen möchten, wie z. B. die Definition einer anderen als der Standard zum Erstellen von PVCs oder die Bereitstellung von SMTP-Details für E-Mail-Benachrichtigungen, können Sie die Datei bearbeiten<block ref="70b058e54d2bda749060070a7f9c4e5c" prefix=" " category="inline-code"></block>Geben Sie die benötigten Details ein und erstellen Sie die CRD.</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">Zeitplanung für das Playbook „Binary and Database Replication“</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">Kopieren Sie die zuvor erstellte Jobvorlage.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">Suchen Sie die ONTAP/CVO Setup-Vorlage und klicken Sie rechts ganz auf Copy Template</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">Klicken Sie auf Vorlage bearbeiten in der kopierten Vorlage, und ändern Sie den Namen in Binary and Database Replication Playbook.</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">Behalten Sie für die Vorlage denselben Bestand, dasselbe Projekt und dieselben Anmeldeinformationen bei.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">Wählen Sie das Playbook ora_Replication_cg.yml als ausführtes Playbook aus.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">Die Variablen bleiben die gleichen, aber die CVO Cluster-IP muss in der Variablen dst_Cluster_ip festgelegt werden.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">Planen Sie die Jobvorlage.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">Klicken Sie auf die Playbook-Vorlage „Binary and Database Replication“, und klicken Sie anschließend oben auf „Schedules“.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">Klicken Sie auf Hinzufügen, fügen Sie den Namenszeitplan für die Binärdatei und die Datenbankreplikation hinzu, wählen Sie das Startdatum/die Startzeit am Anfang der Stunde, wählen Sie die Zeitzone Lokale Zeitzone und die Häufigkeit aus. Ausführungshäufigkeit wird häufig aktualisiert, dass die SnapMirror Replizierung aktualisiert wird.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">Für die Log-Volume-Replizierung wird ein separater Zeitplan erstellt, sodass der Zeitplan in einer häufigeren Kadenz repliziert werden kann.</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">Erstellen von Anmeldungstypen. Bei Lösungen, die ONTAP nutzen, müssen Sie den Anmeldeinformationstyp so konfigurieren, dass er mit den Einträgen für Benutzername und Passwort übereinstimmt, werden auch Einträge für Cloud Central und AWS hinzugefügt.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Fügen Sie den folgenden Inhalt in die Konfiguration des Injektors ein, und klicken Sie auf Speichern:</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">Credential für ONTAP/CVO/AWS erstellen</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">Geben Sie unter „Type Details“ den Benutzernamen und das Kennwort für Ihre Quell- und CVO-Cluster, Cloud Central/Manager, AWS Access/Secret Key und Cloud Central Refresh Token ein.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Credential für Oracle (Quelle) erstellen</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Geben Sie den Namen und die Organisationsdetails für Oracle Host ein</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Credential für Oracle Destination erstellen</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">Geben Sie den Namen und die Organisationsdetails für den DR Oracle-Host ein</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">Geben Sie unter „Typdetails“ den Benutzernamen (ec2-user oder wenn Sie ihn von der Standardeinstellung geändert haben, geben Sie diesen ein) und den SSH Private Key ein</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">Wählen Sie die richtige Methode zur Eskalation von Berechtigungen (sudo) aus, und geben Sie bei Bedarf den Benutzernamen und das Kennwort ein.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">Bevor Sie mit der Installation beginnen, schieben Sie die Astra Control Center-Bilder in eine Bildregistrierung. Hierfür wählen Sie entweder Docker oder Podman. In diesem Schritt werden Anweisungen für beide angegeben.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">Podman</block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">Wenn Sie nicht vertrauenswürdige Zertifikate für Ihre Registrierung verwenden, bearbeiten Sie das Shell-Skript und verwenden Sie es<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> Für den Podman-Push-Befehl<block ref="fec4f991fbdc39b7083cbf10fdc5cd9d" prefix=" " category="inline-code"></block>.</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">Wenn Sie private Bildregistries verwenden, die nicht öffentlich vertrauenswürdig sind, laden Sie die TLS-Zertifikate der Bildregistrierung auf die OpenShift-Knoten hoch. Erstellen Sie dazu im Namespace openshift-config eine configmap mit den TLS-Zertifikaten und patchen Sie sie auf die Cluster-Image-Konfiguration, damit das Zertifikat vertrauenswürdig ist.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Erstellen Sie einen Namespace<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Für Astra Control Center.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">Melden Sie sich bei der Red hat OpenShift GUI-Konsole mit Zugriff auf Cluster-Administratoren an.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Wählen Sie in der Dropdown-Liste Perspektive den Eintrag Administrator aus.</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Navigieren Sie zu Operators &gt; OperatorHub, und suchen Sie nach Astra.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">Wählen Sie<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> kachel und klicken Sie auf<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">ACC-Benutzerziegel</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">Übernehmen Sie im Bildschirm Operator installieren alle Standardparameter, und klicken Sie auf<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">DETAILS DES MITARBEITERS</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">Warten Sie, bis die Installation des Bedieners abgeschlossen ist.</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">ACC-Operator wartet auf Installation</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">Sobald die Installation des Bedieners erfolgreich abgeschlossen ist, navigieren Sie zu, um auf zu klicken<block ref="6423332325de5a7100cc070ffad7a372" prefix=" " category="inline-code"></block>.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">INSTALLATION DURCH ACC-Operator abgeschlossen</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">Klicken Sie dann auf<block ref="43f8527e733785e2ca7a92853d30e4f7" prefix=" " category="inline-code"></block> Im Astra Control Center Kachel im Operator.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">ACC-Instanz erstellen</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Füllen Sie die aus<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> Formularfelder und klicken Sie auf<block ref="686e697538050e4664636337cc3b834f" prefix=" " category="inline-code"></block>.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">Bearbeiten Sie optional den Instanznamen des Astra Control Center.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">Aktivieren oder deaktivieren Sie optional Auto Support. Es wird empfohlen, die Auto Support-Funktion beizubehalten.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Geben Sie den FQDN für Astra Control Center ein.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Geben Sie die Astra Control Center-Version ein. Die neueste wird standardmäßig angezeigt.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Geben Sie einen Kontonamen für das Astra Control Center und die Administratordetails wie Vorname, Nachname und E-Mail-Adresse ein.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">Geben Sie die Richtlinie zur Rückgewinnung von Volumes ein. Die Standardeinstellung wird beibehalten.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">Geben Sie in der Bildregistrierung den FQDN für Ihre Registrierung zusammen mit dem Namen der Organisation ein, den Sie erhalten haben, während Sie die Bilder in die Registrierung schieben (in diesem Beispiel<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>)</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">Wenn Sie eine Registrierung verwenden, für die eine Authentifizierung erforderlich ist, geben Sie den geheimen Namen im Abschnitt Image Registry ein.</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Konfigurieren Sie Skalierungsoptionen für Astra Control Center Ressourceneinschränkungen.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">Geben Sie den Namen der Speicherklasse ein, wenn PVCs in eine nicht-Standardspeicherklasse platziert werden sollen.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">Definieren Sie die Einstellungen für die Verarbeitung von CRD.</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">Planen des Log Replication Playbook</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">Klicken Sie auf Vorlage bearbeiten in der kopierten Vorlage, und ändern Sie den Namen in Log Replication Playbook.</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">Wählen Sie als auszuführenden Playbook die ora_Replication_logs.yml aus.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Klicken Sie auf die Playbook-Vorlage für Protokollreplikation, und klicken Sie anschließend oben auf „Schedules“.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">Klicken Sie auf Hinzufügen, fügen Sie den Namensplan für die Protokollreplizierung hinzu, wählen Sie das Startdatum/die Startzeit am Beginn der Stunde, wählen Sie die Zeitzone Lokal und die Häufigkeit der Ausführung aus. Ausführungshäufigkeit wird häufig aktualisiert, dass die SnapMirror Replizierung aktualisiert wird.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">Es wird empfohlen, den Protokollplan so einzustellen, dass er jede Stunde aktualisiert wird, um sicherzustellen, dass die Wiederherstellung auf die letzte stündliche Aktualisierung erfolgt.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="doc">VARS</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="doc">Host VARS-Konfiguration</block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="doc">Plattformen von NetApp</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">Unternehmen führen zunehmend DevOps-Praktiken ein, um neue Produkte zu erstellen, Release-Zyklen zu verkürzen und neue Funktionen hinzuzufügen. Dank ihrer angeborenen Agilität spielen Container und Microservices eine entscheidende Rolle bei der Unterstützung von DevOps-Praktiken. Das Praktizieren von DevOps auf Produktionsskala in einer Enterprise-Umgebung stellt jedoch ihre eigenen Herausforderungen und stellt bestimmte Anforderungen an die zugrunde liegende Infrastruktur, wie beispielsweise die folgenden:</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">Hochverfügbarkeit auf allen Ebenen im Stack</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">Einfache Implementierungsverfahren</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">Unterbrechungsfreier Betrieb und Upgrades</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">API-gestützte, programmierbare Infrastruktur, um die Flexibilität von Microservices Schritt zu halten</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">Mandantenfähigkeit mit garantierter Performance</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">Gleichzeitige Ausführung virtualisierter und containerisierter Workloads</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">Die Möglichkeit, die Infrastruktur unabhängig von den Workload-Anforderungen zu skalieren</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Die Container-Plattform Red hat OpenShift ist eine vollständig unterstützte Kubernetes-Plattform für Unternehmen. Red hat verbessert Open-Source-Kubernetes und stellt damit eine Applikationsplattform bereit, die vollständig integriert ist, um Container-Applikationen zu erstellen, bereitzustellen und zu managen.</block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">Weitere Informationen finden Sie auf der OpenShift-Website<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp verfügt über verschiedene Storage-Systeme, die sich perfekt für Enterprise Datacenter und Hybrid-Cloud-Implementierungen eignen. Das NetApp Portfolio umfasst NetApp ONTAP, NetApp Element und NetApp E-Series Storage-Systeme, die persistenten Storage für Container-Applikationen bereitstellen können.</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">Weitere Informationen finden Sie auf der NetApp Website<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">Das NetApp Astra Control Center bietet umfassende Storage- und applikationsorientierte Datenmanagement-Services für zustandsorientierte Kubernetes-Workloads, die in einer On-Premises-Umgebung implementiert und mit der bewährten NetApp Datensicherungstechnologie unterstützt werden.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">Weitere Informationen finden Sie auf der NetApp Astra Website<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen wie {k8s_Distribution_Name}.</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">Weitere Informationen finden Sie auf der Astra Trident Website<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp verfügt über mehrere Storage-Plattformen, die für die Bereitstellung, Sicherung und das Management von Daten für Container-Applikationen mit Astra und Astra Control qualifiziert sind.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF und FAS Systeme führen NetApp ONTAP aus und liefern Storage sowohl für File-basierte (NFS) als auch für blockbasierte Anwendungsfälle (iSCSI).</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP und ONTAP Select bieten die gleichen Vorteile in der Cloud bzw. im virtuellen Bereich.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service (AWS/GCP) und Azure NetApp Files bieten dateibasierten Storage in der Cloud.</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">Die Storage-Systeme von NetApp Element decken blockbasierte Anwendungsfälle (iSCSI) in hochskalierbarer Umgebung ab.</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">Jedes Storage-System im NetApp Portfolio kann das Datenmanagement und das Verschieben von Daten zwischen lokalen Standorten und der Cloud vereinfachen, sodass sich Ihre Daten dort befinden, wo sich Ihre Applikationen befinden.</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">Die folgenden Seiten enthalten zusätzliche Informationen zu den NetApp Storage-Systemen, die in der Lösung {Solution_Name} validiert wurden:</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="fcda5b98e8c212807dc088477e802757" category="inline-link-macro">NetApp Element</block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="9d312703c40c2d87b835076063682d59" category="paragraph">NetApp ONTAP ist ein leistungsstarkes Storage-Software-Tool mit Funktionen wie einer intuitiven GUI, REST-APIs mit Automatisierungsintegration, KI-informierte prädiktive Analysen und Korrekturmaßnahmen, unterbrechungsfreien Hardware-Upgrades und Storage-übergreifenden Import.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">NetApp ONTAP Website</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">Weitere Informationen zum NetApp ONTAP Storage-System finden Sie unter<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP bietet folgende Funktionen:</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">Ein Unified Storage-System mit gleichzeitigem Datenzugriff und Management von NFS, CIFS, iSCSI, FC, FCoE Und FC-NVMe-Protokolle unterstützt.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">Verschiedene Implementierungsmodelle umfassen lokale Konfigurationen auf All-Flash-, Hybrid- und rein HDD-basierten Hardware, VM-basierte Storage-Plattformen auf einem unterstützten Hypervisor wie ONTAP Select und in der Cloud als Cloud Volumes ONTAP.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">Erhöhte Storage-Effizienz auf ONTAP Systemen mit Unterstützung für automatisches Daten-Tiering, Inline-Datenkomprimierung, Deduplizierung und Data-Compaction</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">Workload-basierter QoS-gesteuerter Storage</block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">Nahtlose Integration in eine Public Cloud für Tiering und Datensicherung ONTAP bietet zudem robuste Datensicherungsfunktionen, die die Technologie in jeder Umgebung auszeichnet:</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">*NetApp Snapshot Kopien.* Ein schnelles, zeitpunktgenaues Backup von Daten mit minimalem Festplattenspeicher ohne zusätzlichen Performance Overhead.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">*NetApp SnapMirror.* spiegelt die Snapshot Kopien von Daten von einem Storage-System auf ein anderes. ONTAP unterstützt die Spiegelung von Daten auch auf andere physische Plattformen und Cloud-native Services.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">*NetApp SnapLock.* effiziente Verwaltung nicht wiederbeschreibbarer Daten durch Schreiben auf spezielle Volumes, die für einen vorgegebenen Zeitraum nicht überschrieben oder gelöscht werden können.</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">*NetApp SnapVault.* sichert Daten von mehreren Speichersystemen auf eine zentrale Snapshot Kopie, die als Backup auf allen designierten Systemen dient.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">*NetApp SyncMirror.* bietet Echtzeit-Spiegelung auf RAID-Ebene von Daten auf zwei verschiedenen Plexen von Festplatten, die physisch mit demselben Controller verbunden sind.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">*NetApp SnapRestore.* ermöglicht eine schnelle Wiederherstellung von gesicherten Daten bei Bedarf aus Snapshot-Kopien.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">*NetApp FlexClone.* ermöglicht die sofortige Bereitstellung einer vollständig lesbaren und schreibbaren Kopie eines NetApp Volumes auf Basis einer Snapshot Kopie.</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">Weitere Informationen zu ONTAP finden Sie im<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">NetApp ONTAP ist vor Ort, virtualisiert oder in der Cloud verfügbar.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp All Flash FAS/FAS</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp bietet robuste All-Flash (AFF) und horizontal skalierbare Hybrid (FAS) Storage-Plattformen, die auf latenzarme Performance, integrierte Datensicherung und Multiprotokoll-Unterstützung abgestimmt sind.</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">Beide Systeme werden durch die Datenmanagement-Software NetApp ONTAP unterstützt. Sie ist die fortschrittlichste Datenmanagement-Software der Branche für ein vereinfachtes, hochverfügbares Cloud-integriertes Storage-Management. Damit erhalten Sie die nötige Geschwindigkeit, Effizienz und Sicherheit der Enterprise-Klasse für Ihre Data-Fabric-Anforderungen.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">Weitere Informationen zu NETAPP All Flash FAS/FAS Plattformen finden Sie unter<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select ist eine softwaredefinierte Implementierung von NetApp ONTAP, die in einer Hypervisor-Umgebung implementiert werden kann. Es kann auf VMware vSphere oder KVM installiert werden und bietet den vollen Funktionsumfang und die Erfahrung eines hardwarebasierten ONTAP Systems.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">Weitere Informationen zu ONTAP Select finden Sie auf<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="section-title">Cloud Volumes ONTAP</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP ist eine Cloud-implementierte Version von NetApp ONTAP, die in einer Reihe von Public Clouds implementiert werden kann, wie z. B. Amazon AWS, Microsoft Azure und Google Cloud.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Weitere Informationen zu Cloud Volumes ONTAP finden Sie auf<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp bietet verschiedene Produkte, die Sie dabei unterstützen, zustandsorientierte Container-Applikationen und ihre Daten zu orchestrieren, zu managen, zu sichern und zu migrieren.</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Control bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für zustandsorientierte Kubernetes Workloads auf Basis der Datensicherungstechnologie von NetApp. Der Astra Control Service unterstützt statusorientierte Workloads in Cloud-nativen Kubernetes-Implementierungen. Das Astra Control Center unterstützt statusorientierte Workloads in On-Premises-Implementierungen von Kubernetes-Enterprise-Plattformen wie {k8s_Distribution_Name}. Weitere Informationen finden Sie auf der NetApp Astra Control Website<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen wie {k8s_Distribution_Name}. Weitere Informationen finden Sie auf der Astra Trident Website<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">Die folgenden Seiten enthalten zusätzliche Informationen zu den NetApp Produkten, die für das Management von Applikationen und persistentem Storage validiert wurden. Sie finden sie in der {Solution_Name} Lösung:</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="inline-link-macro">NetApp Astra Control Center</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">Das NetApp Astra Control Center bietet umfassende Storage- und applikationsorientierte Datenmanagement-Services für statusorientierte Kubernetes Workloads in einer On-Premises-Umgebung mit NetApp Datensicherungstechnologie.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra Control Center kann auf einem {k8s_Distribution_Name} Cluster installiert werden. Mit dem Astra Trident Storage-Orchestrator wurde der Server mit Storage-Klassen und Storage-Back-Ends für NetApp ONTAP Storage-Systeme implementiert und konfiguriert.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">Dieses Dokument hier einfügen</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Weitere Informationen zu Astra Trident finden Sie unter <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>.</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">In einer Umgebung mit Cloud-Anbindung sorgt Astra Control Center mithilfe von Cloud Insights für erweitertes Monitoring und Telemetrie. Liegt keine Cloud Insights-Verbindung vor, ist eingeschränktes Monitoring und Telemetrie (sieben Tage mit Kennzahlen) verfügbar und über offene metrische Endpunkte in die nativen Kubernetes-Monitoring-Tools (Prometheus und Grafana) exportiert.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center ist vollständig in das AutoSupport- und Active IQ-Ecosystem von NetApp integriert und bietet damit Support für Benutzer, Hilfestellung bei der Fehlerbehebung und Statistiken zur Anzeige der Nutzungsstatistik.</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">Neben der kostenpflichtigen Version des Astra Control Center ist auch eine 90-Tage-Evaluierungslizenz verfügbar. Die Evaluierungsversion wird durch E-Mail und den Slack Community-Kanal unterstützt. Kunden haben Zugriff auf diese Ressourcen, weitere Knowledge-Base-Artikel und Dokumentationen, die über das Produkt-Support-Dashboard verfügbar sind.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra-Website</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Mehr über das Astra Portfolio erfahren Sie auf der <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident ist ein vollständig unterstützter Open-Source-Storage-Orchestrator für Container und Kubernetes-Distributionen wie {k8s_Distribution_Name}. Trident kann mit dem gesamten NetApp Storage-Portfolio eingesetzt werden, einschließlich NetApp ONTAP und Element Storage-Systeme. Es unterstützt auch NFS- und iSCSI-Verbindungen. Trident beschleunigt den DevOps-Workflow, da Endbenutzer Storage über ihre NetApp Storage-Systeme bereitstellen und managen können, ohne dass ein Storage-Administrator eingreifen muss.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">Ein Administrator kann verschiedene Storage-Back-Ends basierend auf den Projektanforderungen und Storage-Systemmodellen konfigurieren, die erweiterte Storage-Funktionen wie Komprimierung, bestimmte Festplattentypen oder QoS-Level ermöglichen, die eine bestimmte Performance garantieren. Nach ihrer Definition können diese Back-Ends von Entwicklern in ihren Projekten verwendet werden, um persistente Volume Claims (PVCs) zu erstellen und persistenten Storage nach Bedarf an ihre Container anzubinden.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident führt einen schnellen Entwicklungszyklus durch, und, wie Kubernetes, wird viermal im Jahr veröffentlicht.</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">Die neueste Version von Astra Trident ist 22.04. April 2022. Eine Support-Matrix, in der die Version von Trident getestet wurde, mit der Kubernetes Distribution zu finden ist<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">Ab Version 20.04 wird die Trident-Einrichtung vom Trident Operator durchgeführt. Der Operator vereinfacht umfangreiche Implementierungen und bietet zusätzlichen Support. Durch die Selbstreparatur für Pods, die im Rahmen der Trident-Installation implementiert werden, wird damit das Selbstreparaturverfahren ermöglicht.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">In der Version 21.01 wurde ein Helm Chart zur Erleichterung der Installation des Trident Operators zur Verfügung gestellt.</block>
  <block id="662609908ab8e0f372d83dea3511370b" category="inline-link">Verfahren</block>
  <block id="8575c02ec176b0f64904bcbd79e81cba" category="list-text">Um die Ansible-Playbooks zu verwenden, die Astra Control Center implementieren, benötigen Sie eine Ubuntu/RHEL-Maschine, auf der Ansible installiert ist. Folgen Sie diesen Anweisungen<block ref="c1972c5d94c51919767b49f6cefbf6ba" category="inline-link-rx"></block> Für Ubuntu und dies<block ref="c4dab530b5bf152ded398881b8308451" category="inline-link-rx"></block> Für RHEL.</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Klonen Sie das GitHub Repository, das Ansible-Inhalte hostet.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">Melden Sie sich bei der NetApp Support-Website an und laden Sie die neueste Version des NetApp Astra Control Center herunter. Dazu ist eine Lizenz erforderlich, die an Ihr NetApp Konto angehängt ist. Nach dem Download des Tarballs, übertragen Sie es auf die Workstation.</block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Erstellen oder beziehen Sie die kubeconfg-Datei mit Administratorzugriff auf das {k8s_usercluster_Name}-Cluster, auf dem Astra Control Center installiert werden soll.</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">Ändern Sie das Verzeichnis in<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">Bearbeiten Sie das<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> Datei und füllen Sie die Variablen mit den erforderlichen Informationen aus.</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">Nutzen Sie das Playbook zur Implementierung des Astra Control Center. Für bestimmte Konfigurationen sind Root-Berechtigungen erforderlich.</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">Führen Sie den folgenden Befehl aus, um das Playbook auszuführen, wenn der Benutzer, der das Playbook ausführt, root ist oder passwortlose sudo konfiguriert ist.</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">Wenn der Benutzer passwortbasierten sudo-Zugriff konfiguriert hat, führen Sie den folgenden Befehl aus, um das Playbook auszuführen und geben Sie dann das sudo-Passwort ein.</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">Klicken Sie auf Vorlage bearbeiten auf der kopierten Vorlage, und ändern Sie den Namen in „Playbook wiederherstellen und wiederherstellen“.</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">Wählen Sie die ora_Recovery.yml als auszuführenden Playbook aus.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">Dieses Playbook wird erst ausgeführt, nachdem Sie bereit sind, Ihre Datenbank am Remote-Standort wiederherzustellen.</block>
  <block id="f1fc5bef6accc6d1fab4ab73142df7f3" category="list-text">Um Astra Control Center mit Ansible-Playbooks zu implementieren, benötigen Sie eine Ubuntu/RHEL-Maschine mit installiertem Ansible. Befolgen Sie die Anweisungen<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Für Ubuntu und das Verfahren<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Für RHEL.</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">Melden Sie sich bei der NetApp Support-Website an und laden Sie die neueste Version des NetApp Astra Control Center herunter. Dazu ist eine Lizenz erforderlich, die an Ihr NetApp Konto angehängt ist. Nach dem Download des Tarballs, übertragen Sie es auf die Workstation.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">Ändern Sie das Verzeichnis in die na_astra_control_Suite.</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">Bearbeiten Sie das<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> Datei, und füllen Sie die Variablen mit den erforderlichen Informationen.</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">Wenn der Benutzer, der das Playbook ausführt, root ist oder eine passwortlose sudo-Konfiguration hat, führen Sie den folgenden Befehl aus, um das Playbook auszuführen.</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">Wenn der Benutzer passwortbasierten sudo-Zugriff konfiguriert hat, führen Sie den folgenden Befehl aus, um das Playbook auszuführen, und geben Sie dann das sudo-Passwort ein.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="doc">Oracle-Installation validieren</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">Auf diese Weise werden die oracle-Prozesse aufgeführt, wenn die Installation wie erwartet abgeschlossen wurde und die oracle DB gestartet wurde</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost ~] USD/AS sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL*Plus: Release 19.0.0.0.0 - Produktion am Do Mai 6 12:52:51 2021 Version 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. Alle Rechte vorbehalten.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">Verbunden mit: Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Produktionsversion 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; Name auswählen, log_Mode von der V-Dollar-Datenbank; NAME LOG_MODE --------- -------------- CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; pdbs anzeigen</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname Form a30 SQL&gt; col dirname Form a30 SQL&gt; svrname, dirname, nfsversion von V€dnfs_Servers auswählen;</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME-NAME NFSVERSION ------------------------------------------ --------------------------------------- ------------------- 172.21.126.200 /rhelora03_u02 NFSv3.0 172.21.126.200 /rhelora03_u03 NFSv03 172.21.126.200 /rhelora03_u01 NFSv3.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle@localhost ~]@ System//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL*Plus: Release 19.0.0.0.0 - Produktion am Do Mai 6 13:19:57 2021 Version 19.8.0.0.0</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">Geben Sie das Passwort ein: Letzte erfolgreiche Anmeldung: Mi 05 2021 17:11:11 -04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show Benutzer is „SYSTEM“ SQL&gt; show con_Name CON_NAME CDB2_PDB1</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">Wo Hilfe benötigt wird?</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">NetApp Solution Automation Community Support Slack Channel</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">Wenn Sie Hilfe mit dem Toolkit benötigen, nehmen Sie bitte an der Teil <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> Und suchen Sie den Kanal zur Lösungsautomatisierung, um Ihre Fragen zu stellen oder zu fragen.</block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">Die Lösung wurde für eine Hybrid-Cloud-Einstellung entwickelt, um On-Premises-Produktionsdatenbanken zu unterstützen, die für Entwicklungs-/Test- und Disaster-Recovery-Vorgänge einen Burst in die gängigen Public Clouds ausführen können.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter-Anforderungen erfüllt</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">Früher: Lösungsarchitektur.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">Diese Lösung unterstützt alle Datenbanken, die derzeit von SnapCenter unterstützt werden, obwohl hier nur Oracle- und SQL Server-Datenbanken gezeigt werden. Diese Lösung wurde mit virtualisierten Datenbank-Workloads validiert, obwohl auch Bare-Metal-Workloads unterstützt werden.</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">Wir gehen davon aus, dass die produktiven Datenbankserver On-Premises mit DB-Volumes gehostet werden, die von einem ONTAP-Storage-Cluster an DB-Hosts präsentiert werden. SnapCenter Software wird lokal für Datenbank-Backups und Datenreplizierung in die Cloud installiert. Ein Ansible-Controller wird empfohlen, ist aber nicht für eine Automatisierung der Datenbankbereitstellung erforderlich, oder für eine Synchronisierung des OS-Kernels und der DB-Konfiguration mit einer Standby-DR-Instanz oder Entwicklungs-/Testinstanzen in der Public Cloud.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">Umgebung</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">*Auf dem Gelände*</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">Alle Datenbanken und Versionen, die von SnapCenter unterstützt werden</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter Version 4.4 oder höher</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible Version 2.09 oder höher</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP Cluster 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">Intercluster LIFs konfiguriert</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">Konnektivität von On-Premises zu einer Cloud-VPC (VPN, Interconnect usw.)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">Netzwerkports offen - ssh 22 - tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">*Cloud - AWS*</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager Connector</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">Zuordnen von DB-OS-EC2-Instanzen zu On-Premises</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">*Cloud - Azure*</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">Abgleich von DB OS Azure Virtual Machines mit On-Premises</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">*Cloud - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">Abgleich von DB OS Google Compute Engine Instanzen mit On-Premises</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">Als Nächstes: Konfiguration der Voraussetzungen.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">Auf dieser Seite wird die automatisierte Methode zur Implementierung von Oracle19c auf NetApp ONTAP Storage beschrieben.</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">Unternehmen automatisieren ihre Umgebungen, um die Effizienz zu steigern, Implementierungen zu beschleunigen und manuelle Aufgaben zu reduzieren. Konfigurationsmanagement-Tools wie Ansible werden zur Optimierung der Abläufe in Unternehmensdatenbanken eingesetzt. Diese Lösung zeigt, wie Sie mit Ansible die Datensicherung von Oracle mit NetApp ONTAP automatisieren können. Storage-Administratoren, Systemadministratoren und DBAs können die Datenreplizierung konsistent und schnell auf ein externes Datacenter oder in die Public Cloud einrichten. Sie profitieren von folgenden Vorteilen:</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">Vermeiden Sie Designkomplexität und menschliche Fehler und implementieren Sie eine wiederholbare, konsistente Implementierung und Best Practices</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">Verkürzung der Zeit für die Konfiguration von Intercluster-Replizierung, CVO Instanziation und Recovery von Oracle-Datenbanken</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">Erhöhen Sie die Produktivität von Datenbank-Administratoren, -Systemen und -Storage-Administratoren</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">Bietet Datenbank-Recovery-Workflow zum einfachen Testen eines DR-Szenarios.</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp bietet Kunden validierte Ansible-Module und -Rollen, um die Implementierung, Konfiguration und das Lifecycle-Management Ihrer Oracle-Datenbankumgebung zu beschleunigen. Diese Lösung bietet Anweisungen und Ansible-Playbook-Code, um Sie bei folgenden Aufgaben zu unterstützen:</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">Replizierung vor Ort und in On-Premises-Umgebungen</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">Erstellen von Intercluster-Libs an Quelle und Ziel</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">Cluster- und vServer-Peering einrichten</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">SnapMirror von Oracle Volumes erstellen und initialisieren</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Erstellen Sie einen Replikationszeitplan über AWX/Tower für Oracle-Binärdateien, -Datenbanken und -Protokolle</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">Stellen Sie Oracle DB auf dem Ziel wieder her und bringen Sie die Datenbank in den Online-Modus</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">Von On-Premises zu CVO in AWS</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">AWS Connector erstellen</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">CVO-Instanz in AWS erstellen</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Hinzufügen eines On-Premises-Clusters zu Cloud Manager</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">Erstellen von Intercluster-Libs auf der Quelle</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">Weitere Informationen erhalten Sie in den Übersichtsvideos unten.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX/Tower-Implementierungen</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">Teil 1: Noch ausstehend</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="list-text">Video</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">Teil 2: Noch ausstehend</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">Hier sind erste Schritte mit der Lösung</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">Klicken Sie anschließend auf <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">NetApp Enterprise Database Lösungen sind eine Reihe strategischer sowie technologischer Funktionen, die die Funktionen von NetApp Storage für die wichtigsten Enterprise-Datenbanken demonstrieren.</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">NetApp Lösungen für Enterprise Database</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">In diesem Dokument wird eine Echtzeit-Implementierung von SQL Server „Always On Availability Group“ (AOAG) auf Azure NetApp Files behandelt, die virtuelle Azure Maschinen nutzen.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897: SQL Server auf Azure NetApp Files - Real Deployment View</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT-Abteilungen stehen vor der ständigen Veränderung. Gartner meldet, dass bis 2022 fast 75 % aller Datenbanken Cloud-basierten Storage benötigen werden. Microsoft SQL Server ist eine führende Lösung für relationale Datenbanken-Managementsysteme (RDBMS) und eignet sich für Windows-Plattformen sowie Unternehmen, die sich von SQL Server für alles verlassen – von der Enterprise Resource Planning (ERP) über Big-Data-Analysen bis hin zum Content-Management. SQL Server hat dazu beigetragen, die Art und Weise zu revolutionieren, wie Unternehmen umfangreiche Datensätze managen und ihre Applikationen an die Anforderungen der Schemaschemen und Performance anpassen.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">Die meisten IT-Abteilungen verfolgen einen Ansatz, bei dem der „Cloud First“-Ansatz verfolgt. Kunden in einer Transformationsphase: Bewerten Sie ihre aktuelle IT-Umgebung und migrieren sie ihre Datenbank-Workloads anschließend anhand einer Analyse- und Bestandsaufnahme in die Cloud. Einige Faktoren, die Kunden für die Cloud-Migration antreibt, sind Flexibilität/Burst, Datacenter-Ausstieg, Datacenter-Konsolidierung, End-of-Life-Szenarien, Fusionen, Firmenübernahmen usw. Der Grund für die Migration kann je nach Unternehmen und ihren jeweiligen Geschäftsprioritäten variieren. Bei der Umstellung auf die Cloud ist die Wahl des richtigen Cloud-Storage sehr wichtig, um das Potenzial der Cloud-Implementierung von SQL Server Datenbanken auszuschöpfen.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">Anwendungsfall</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">Die Verlagerung der SQL Server-Daten in Azure und die Integration von SQL Server in die zahlreichen Plattform-als-Service-Funktionen (PaaS) von Azure wie Azure Data Factory, Azure IoT Hub und Azure Machine Learning schaffen einen enormen geschäftlichen Nutzen, um die digitale Transformation zu unterstützen. Durch die Einführung der Cloud kann sich auch der jeweilige Geschäftsbereich stärker auf die Produktivität konzentrieren und neue Funktionen und Verbesserungen schneller bereitstellen (DevTest Anwendungsfall), als auf das CAPEX- Modell oder herkömmliche Private Cloud-Modelle zurückgreifen zu müssen. In diesem Dokument wird eine Echtzeit-Implementierung von SQL Server „Always On Availability Group“ (AOAG) auf Azure NetApp Files behandelt, die virtuelle Azure Maschinen nutzen.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files bietet Storage der Enterprise-Klasse mit kontinuierlich verfügbaren Dateifreigaben. Kontinuierlich verfügbare Freigaben werden von SQL Server Produktionsdatenbanken auf SMB-Dateifreigaben benötigt, um sicherzustellen, dass der Node immer auf den Datenbank-Storage zugreifen kann, auch in störenden Szenarien wie Controller-Upgrades oder -Ausfälle. Dank kontinuierlich verfügbarer Dateifreigaben ist die Replizierung von Daten zwischen Storage-Nodes nicht mehr erforderlich. Azure NetApp Files nutzt horizontale Skalierbarkeit mit SMB 3.0, persistente Griffe und transparentes Failover zur Unterstützung von unterbrechungsfreiem Betrieb bei geplanten und ungeplanten Ausfallzeiten, einschließlich vieler administrativer Aufgaben.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">Wenn Sie Cloud-Migrationen planen, sollten Sie sich immer den besten Ansatz für deren Nutzung entscheiden. Der häufigste und einfachste Ansatz für die Applikationsmigration ist das Rehosting (auch bekannt als „Lift and Shift“). Das Beispielszenario in diesem Dokument verwendet die Methode zum Rehosting. SQL Server auf virtuellen Azure Machines mit Azure NetApp Files ermöglicht Ihnen die Verwendung vollständiger Versionen von SQL Server in der Cloud, ohne dass Sie Hardware vor Ort verwalten müssen. SQL Server Virtual Machines (VMs) vereinfachen außerdem die Lizenzkosten, wenn Sie für Kunden zahlen. Darüber hinaus bieten sie Elastizität und Bursting-Funktionen für Entwicklungs-, Test- und Immobilienaktualisierungen.</block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">Bestimmte Voraussetzungen müssen sowohl On-Premises als auch in der Cloud konfiguriert werden, bevor die Ausführung von Hybrid-Cloud-Datenbank-Workloads ausgeführt wird. Der folgende Abschnitt bietet einen allgemeinen Überblick über diesen Prozess und die folgenden Links führen zu weiteren Informationen über die erforderliche Systemkonfiguration.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">Konfiguration der Voraussetzungen</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">Früher: Lösungsanforderungen.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="list-text">Installation und Konfiguration von SnapCenter</block>
  <block id="df3fb602185c77a88bab186791d02636" category="list-text">Storage-Konfiguration des lokalen Datenbankservers</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="list-text">Lizenzierungsanforderungen</block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="list-text">Networking und Sicherheit</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central Anmeldung</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Netzwerkzugriff über einen Webbrowser zu mehreren Endpunkten</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">Ein Netzwerkspeicherort für einen Anschluss</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">Berechtigungen für Cloud-Provider</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">Vernetzung für einzelne Services</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">Wichtige Überlegungen:</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Wo wird der Cloud Manager Connector bereitgestellt?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Sizing und Architektur für Cloud Volume ONTAP</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">Single Node oder Hochverfügbarkeit?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">Die folgenden Links bieten weitere Einzelheiten:</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">On-Premises</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">Public Cloud</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">Als Nächstes: Vor Ort Voraussetzungen schaffen.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">Unternehmen automatisieren ihre Umgebungen, um die Effizienz zu steigern, Implementierungen zu beschleunigen und manuelle Aufgaben zu reduzieren. Konfigurationsmanagement-Tools wie Ansible werden zur Optimierung der Abläufe in Unternehmensdatenbanken eingesetzt. Diese Lösung zeigt, wie sich mit Ansible die Bereitstellung und Konfiguration von Oracle 19c mit NetApp ONTAP automatisieren lässt. Da Storage-Administratoren, Systemadministratoren und DBAs in der Lage sind, neuen Storage konsistent und schnell bereitzustellen, Datenbankserver zu konfigurieren und Oracle 19c Software zu installieren, profitieren Sie von folgenden Vorteilen:</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">Verkürzung der Zeit für Provisionierung von Speicher, Konfiguration von DB-Hosts sowie für Oracle-Installation</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">Vereinfachen Sie die Skalierung von Storage und Datenbanken</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Erstellen und Konfigurieren von ONTAP-NFS-Storage für Oracle-Datenbank</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Installation von Oracle 19c auf RedHat Enterprise Linux 7/8 oder Oracle Linux 7/8</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">Konfiguration von Oracle 19c auf ONTAP NFS Storage</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">Teil 1: Erste Schritte, Anforderungen, Automatisierungsdetails und erste AWX/Tower-Konfiguration</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">Teil 2: Variablen und Ausführen des Playbooks</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI-Implementierung</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">Teil 1: Erste Schritte, Anforderungen, Automatisierungsdetails und Ansible Control Host Setup</block>
  <block id="d76cffc02762fcf81c8bb85e5fe9e987" category="doc">TR-4764: Best Practices Guide für Microsoft SQL Server with NetApp EF-Series</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">Mitch Blackburn, Pat Sinthusan, NetApp</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">Dieser Best Practices-Leitfaden soll Storage-Administratoren und Datenbankadministratoren bei der erfolgreichen Implementierung von Microsoft SQL Server auf NetApp EF-Series Storage unterstützen.</block>
  <block id="d378412674e2e76ee3c7e245fd0aad9c" category="inline-link-macro"><block ref="d378412674e2e76ee3c7e245fd0aad9c" category="inline-link-rx"></block></block>
  <block id="855280cfa22ac6785edc7f9e23fa2cf7" category="paragraph"><block ref="855280cfa22ac6785edc7f9e23fa2cf7" category="inline-link-macro-rx"></block></block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794: Oracle Databases on NetApp EF-Series</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn, Ebin Kadavy, NetApp</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794 soll Storage-Administratoren und Datenbankadministratoren helfen, Oracle erfolgreich auf NetApp EF-Series Storage zu implementieren.</block>
  <block id="6ccd62bc352fd170c5fa9538c6fa84b1" category="inline-link-macro"><block ref="6ccd62bc352fd170c5fa9538c6fa84b1" category="inline-link-rx"></block></block>
  <block id="0d3b1c298c590bed5f16adc6a5e10809" category="paragraph"><block ref="0d3b1c298c590bed5f16adc6a5e10809" category="inline-link-macro-rx"></block></block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">TR-3633: Oracle Databases on ONTAP</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">Jeffrey Steiner, NetApp</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">Konsultieren Sie die <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> Um zu ermitteln, ob die Umgebung, die Konfigurationen und Versionen, die in TR-3633 angegeben wurden, Ihre Umgebung unterstützen.</block>
  <block id="76775d774363eb515c3954389bf96eb8" category="inline-link-macro"><block ref="76775d774363eb515c3954389bf96eb8" category="inline-link-rx"></block></block>
  <block id="ee47cd10fbc8d219225b06932059463a" category="paragraph"><block ref="ee47cd10fbc8d219225b06932059463a" category="inline-link-macro-rx"></block></block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Lösungsarchitekturen mit Azure NetApp Files nutzen</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Vorteile der Nutzung von Azure NetApp Files für die SQL Server-Implementierung</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">SQL Server auf Azure Deployment Guide Using Azure NetApp Files</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Fehlertoleranz, Hochverfügbarkeit und Ausfallsicherheit mit Azure NetApp Files</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">Ganz gleich, ob Sie mit Stretch-Datenbanken auf eine All-Cloud oder Hybrid Cloud setzen – Azure NetApp Files bietet Ihnen hervorragende Optionen für die Implementierung und das Management von Datenbank-Workloads und reduziert gleichzeitig die TCO, da die Datenanforderungen nahtlos auf die Applikationsebene reduziert werden.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">Dieses Dokument behandelt Empfehlungen für die Planung, Entwicklung, Optimierung und Skalierung von Microsoft SQL Server Implementierungen mit Azure NetApp Files, die zwischen Implementierungen stark variieren können. Die richtige Lösung hängt sowohl von den technischen Details der Implementierung als auch von den geschäftlichen Anforderungen ab, die für das Projekt ausschlaggebend sind.</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">Sie können nun Azure NetApp Files verwenden, um die Datenbank und den Dateifreigabenzeuge für das SQL Server Cluster zu hosten.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">Sie können die Reaktionszeiten von Applikationen verkürzen und eine Verfügbarkeit von 99.9999 % erzielen, um Zugriff auf SQL Server-Daten zu jeder Zeit und an jedem Ort zu ermöglichen.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">Sie können die Gesamtkomplexität der SQL Server-Bereitstellung und des fortlaufenden Managements, wie RAID-Striping, durch einfache und sofortige Anpassung vereinfachen.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">Mit intelligenten Funktionen lassen sich SQL Server Datenbanken in Minutenschnelle implementieren und Entwicklungszyklen verkürzen.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Wenn Azure Cloud Ziel ist, ist Azure NetApp Files die richtige Storage-Lösung für eine optimierte Implementierung.</block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Bevor wir den Cloud Manager Connector installieren und Cloud Volumes ONTAP konfigurieren und SnapMirror konfigurieren, müssen wir einige Vorbereitungen für unsere Cloud-Umgebung durchführen. Auf dieser Seite werden die erforderlichen Arbeiten sowie die Überlegungen bei der Implementierung von Cloud Volumes ONTAP beschrieben.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">Voraussetzungen für die Public Cloud</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">Zurück: Voraussetzungen vor Ort.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Checkliste zu den Implementierungsvoraussetzungen für Cloud Manager und Cloud Volumes ONTAP</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">Ein Netzwerkstandort für einen Konnektor</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">Cloud-Dokumentation</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">Weitere Informationen zu den ersten Schritten erhalten Sie auf unserer<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">Überlegungen</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. Was ist ein Cloud-Manager-Konnektor?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">In den meisten Fällen muss ein Cloud Central Account-Administrator einen Connector in Ihrer Cloud oder Ihrem On-Premises-Netzwerk bereitstellen. Über den Connector kann Cloud Manager Ressourcen und Prozesse in Ihrer Public-Cloud-Umgebung managen.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">Weitere Informationen zu Connectors finden Sie auf unserer<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Dimensionierung und Architektur von Cloud Volumes ONTAP</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Bei der Bereitstellung von Cloud Volumes ONTAP haben Sie die Wahl zwischen einem vordefinierten Paket oder der Erstellung Ihrer eigenen Konfiguration. Obwohl sich viele dieser Werte später unterbrechungsfrei ändern lassen, müssen vor der Implementierung auf der Grundlage der zu implementierenden Workloads in der Cloud einige wichtige Entscheidungen getroffen werden.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO-Sizing-Tool</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">Jeder Cloud-Provider verfügt über unterschiedliche Implementierungsmöglichkeiten, und fast jeder Workload verfügt über eigene einzigartige Eigenschaften. NetApp hat eine<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> Damit können Implementierungen auf der Basis von Kapazität und Performance korrekt ausgerichtet werden. Allerdings basieren sie auf einigen grundlegenden Konzepten, die sich lohnen:</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">Erforderliche Kapazität</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">Netzwerkfähigkeit der Cloud Virtual Machine</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">Performance-Merkmale von Cloud-Storage</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">Entscheidend ist dabei die Planung einer Konfiguration, die nicht nur die aktuellen Kapazitäts- und Performance-Anforderungen erfüllt, sondern auch das künftige Wachstum berücksichtigt. Dies wird im Allgemeinen als Kapazitätsreserve und Performance Reserve bezeichnet.</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">Wenn Sie weitere Informationen wünschen, lesen Sie die Dokumentation zur Planung richtig für<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, und<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. Single Node oder Hochverfügbarkeit?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">In allen Clouds besteht die Möglichkeit, CVO entweder in einem einzelnen Node oder in einem hochverfügbaren Cluster-Paar mit zwei Nodes zu implementieren. Je nach Anwendungsfall können Sie einen einzelnen Node implementieren, um Kosten zu sparen, oder ein HA-Paar, um weitere Verfügbarkeit und Redundanz zu ermöglichen.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">Einzelne Nodes sind für einen DR-Anwendungsfall oder das Aufsetzen von temporem Storage für Entwicklung und Tests häufig vorgängig, da die Auswirkungen eines plötzlichen zonalen beziehungsweise Infrastrukturausfalls geringer sind. Wenn sich die Daten jedoch in einem Produktionsfall nur an einem einzelnen Standort befinden oder wenn der Datensatz mehr Redundanz und Verfügbarkeit haben muss, wird Hochverfügbarkeit empfohlen.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">Weitere Informationen zur Architektur der Hochverfügbarkeit der einzelnen Cloud-Versionen finden Sie in der Dokumentation für<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> Und<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">Weiter: Erste Schritte – Übersicht</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">Dieser Abschnitt enthält detaillierte Informationen zu Faktoren, die bei der Migration von Oracle Datenbanken von lokalen zu AWS EC2 Instanzen und FSX Storage berücksichtigt werden müssen.</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">Datenbankmigration von lokalen Systemen in die Public Cloud</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">Früher: Datenbankmanagement.</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">Die Migration der Datenbank stellt auf jeden Fall eine Herausforderung dar. Die Migration einer Oracle Datenbank von On-Premises-Systemen in die Cloud ist keine Ausnahme.</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">In den folgenden Abschnitten werden die wichtigsten Faktoren aufgeführt, die Sie bei der Migration von Oracle Datenbanken in die AWS Public Cloud mit AWS EC2 Computing- und FSX Storage-Plattform berücksichtigen sollten.</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">ONTAP Storage ist vor Ort verfügbar</block>
  <block id="93336cb92f211f9ff347245c8559dd5e" category="paragraph">Wenn die lokale Oracle Datenbank auf einem ONTAP Storage Array liegt, lässt sich mit dem UI Tool NetApp SnapCenter einfacher die Replizierung für die Datenbankmigration einrichten.</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">Erstellung einer EC2 Ziel-Computing-Instanz, die zur lokalen Instanz passt</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">Stellen Sie passende Datenbank-Volumes gleicher Größe über die FSX-Konsole bereit.</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">Mounten Sie die FSX-Datenbank-Volumes in die EC2-Instanz.</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">Einrichten der SnapMirror Replizierung zwischen den lokalen Datenbank-Volumes und den FSX Ziel-Datenbank-Volumes Die erste Synchronisierung benötigt möglicherweise etwas Zeit, um die primären Quelldaten zu verschieben, aber die folgenden inkrementellen Updates sind viel schneller.</block>
  <block id="fda597a9ad18b763048653fa5e87e38c" category="list-text">Beenden Sie zum Zeitpunkt der Umschaltung die primäre Applikation, um alle Transaktionen zu beenden. Führen Sie in SnapCenter ein Protokoll-Backup aus, um die restlichen Transaktionen auf das Ziel zu bereinigen.</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">Untergliedern Sie die gespiegelten Volumes, führen Sie Oracle Recovery am Ziel aus und bringen Sie die Datenbank für den Service auf.</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">Weisen Sie Applikationen auf die Oracle Datenbank in der Cloud zu.</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">ONTAP Storage ist vor Ort nicht verfügbar</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">Wenn die lokale Oracle Datenbank auf Storage anderer Anbieter als ONTAP gehostet wird, basiert die Datenbankmigration auf dem Restore einer Backup-Kopie einer Oracle Datenbank. Sie müssen das Archivprotokoll wiedergeben, um es vor dem Umschalten aktuell zu machen.</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3 kann als Staging-Storage-Bereich für das Verschieben und Migrieren von Datenbanken verwendet werden. Für diese Methode sind die folgenden übergeordneten Schritte zu beachten:</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">Bereitstellung einer neuen, übereinstimmenden EC2 Instanz, die mit der lokalen Instanz vergleichbar ist</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">Stellen Sie gleich große Datenbank-Volumes vom FSX Storage bereit und mounten Sie die Volumes auf die EC2 Instanz.</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">Erstellen einer Oracle Backup-Kopie auf Festplattenebene</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">Die Backup-Kopie kann in AWS S3 Storage verschoben werden.</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">Stellen Sie die Oracle-Kontrolldatei wieder her und stellen Sie die Datenbank wieder her, indem Sie Daten und das Archivprotokoll aus dem S3-Storage ziehen.</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">Synchronisieren der Oracle Zieldatenbank mit der lokalen Quelldatenbank</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">Fahren Sie beim Switchover die Applikation und die Oracle Quelldatenbank herunter. Kopieren Sie die letzten paar Archivprotokolle und wenden Sie sie auf die Oracle Zieldatenbank an, um sie auf den neuesten Stand zu bringen.</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">Starten Sie die Zieldatenbank für den Benutzerzugriff.</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">Umleiten der Applikation zur Zieldatenbank, um die Umschaltung abzuschließen.</block>
  <block id="46c977a489a77ea3a7d6ff4a7fa6d556" category="section-title">Konsolidieren Sie Oracle Datenbanken in AWS mit der Oracle Mandantenfähigkeit CDB/PDB-Architektur</block>
  <block id="ea274b58537d36559ff3046cd5423083" category="list-text">CDB in der AWS Public Cloud erstellen.</block>
  <block id="12c774c8ec030e1d104719cf317b5ca2" category="list-text">Wenn die On-Premises-Datenbank auch für die CDB/PDB-Mandantenfähigkeit bereitgestellt wird, trennen Sie die zu migrierende PDB von der Stromversorgung.</block>
  <block id="6ee0eb9b1d29207b2ae6feda6428e2cc" category="list-text">Übertragen Sie Metadaten sowie unterstrichene Oracle-Datendateien auf die Ziel-CDB-Instanz.</block>
  <block id="4bb12c493b32940ff849ac100d727582" category="list-text">Validieren Sie die Kompatibilität mit Oracle Validierungsprojekten.</block>
  <block id="e7343c5c0db191b9c4841a6556ebc806" category="list-text">Wenn die Kompatibilitätsvalidierung besteht, schließen Sie die nicht eingesteckt PDB an den Ziel-CDB-Container an.</block>
  <block id="5bb0b3fe813867de21d25f37b58dc0fc" category="list-text">Aktualisieren Sie das Datenwörterbuch, falls erforderlich.</block>
  <block id="97b4c444678bacf256568fc4f7071634" category="list-text">Sichern und öffnen Sie die migrierte PDB für den Zugriff.</block>
  <block id="375116b8a4235f7fa12ebc4e2bddb3dc" category="admonition">Das Ausstecken und Plug-in von PDB erfordert Anwendungsausfallzeiten, die bei der Migrationsplanung berücksichtigt werden sollten.</block>
  <block id="0978a2ea1e5676c9e8f017f05e988475" category="paragraph">Das NetApp Automatisierungsteam stellt ein Migrations-Toolkit zur Verfügung, das die Migration von Oracle Datenbanken von lokalen Systemen in die AWS Cloud erleichtert. Die neuesten Datenbanktools finden Sie auf der öffentlichen NetApp GitHub Website.</block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">Dieser Abschnitt enthält Einzelheiten zum Management von AWS RDS Custom für Oracle Datenbanken als Ergänzung zur AWS RDS-Konsole über die UI von SnapCenter.</block>
  <block id="021f869e266a6eaa7e446e54dfc71149" category="doc">EC2/FSX Oracle Datenbankmanagement</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">Früher: Implementierungsverfahren</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">Neben der AWS EC2 und FSX Managementkonsole werden der Ansible-Steuerungsknoten und das SnapCenter UI-Tool für das Datenbankmanagement in dieser Oracle-Umgebung implementiert.</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Ein Ansible-Steuerungsknoten kann zum Management der Oracle Umgebungskonfiguration verwendet werden. Dabei stehen parallele Updates zur Verfügung, durch die primäre und Standby-Instanzen für Kernel- oder Patch-Updates synchronisiert werden. Failover, Resynchronisierung und Failback können mit dem NetApp Automation Toolkit automatisiert werden, um eine schnelle Wiederherstellung und Verfügbarkeit von Applikationen mit Ansible zu ermöglichen. Einige wiederholbare Aufgaben zum Datenbankmanagement können mithilfe eines Playbooks zur Reduzierung menschlicher Fehler ausgeführt werden.</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">SnapCenter Plug-in für Oracle Database – Übersicht</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">Das SnapCenter UI Tool kann Datenbank-Snapshot-Backups, zeitpunktgenaue Recovery, Klonen von Datenbanken usw. mit dem SnapCenter Plug-in für Oracle Datenbanken durchführen. Weitere Informationen zu Oracle-Plugin-Funktionen finden Sie im <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>.</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">Die folgenden Abschnitte erläutern, wie die wichtigsten Funktionen des Oracle Datenbankmanagements über die Benutzeroberfläche von SnapCenter erfüllt werden:</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">Datenbank-Snapshot-Backups</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">Zeitpunktgenaue Datenbank-Wiederherstellung</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">Erstellen von Datenbankklonen</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">Beim Klonen von Datenbanken wird ein Replikat einer primären Datenbank auf einem separaten EC2 Host zur Datenwiederherstellung im Falle eines logischen Datenfehlers oder einer Beschädigung erstellt. Klone können auch für Applikationstests, Fehlerbehebung, Patch-Validierung usw. verwendet werden.</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">Erstellen eines Snapshots</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">Eine EC2/FSX Oracle-Datenbank wird regelmäßig in vom Benutzer konfigurierten Intervallen gesichert. Ein Benutzer kann jederzeit auch ein einmalig durchzuführenden Snapshot Backup durchführen. Dies gilt sowohl für Volldatenbank-Snapshot-Backups als auch für Archiv-Log-only Snapshot-Backups.</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">Erstellen eines vollständigen Datenbank-Snapshots</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">Ein vollständiger Datenbank-Snapshot umfasst alle Oracle Dateien, einschließlich Datendateien, Steuerdateien und Archivprotokolldateien.</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">Melden Sie sich in der Benutzeroberfläche von SnapCenter an und klicken Sie im Menü auf der linken Seite auf „Ressourcen“. Wechseln Sie im Dropdown-Menü Ansicht in die Ansicht Ressourcengruppe.</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">Klicken Sie auf den Namen der vollständigen Backup-Ressource, und klicken Sie dann auf das Symbol Jetzt sichern, um ein Add-hoc-Backup zu starten.</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">Klicken Sie auf Backup und bestätigen Sie dann das Backup, um eine vollständige Datenbank-Sicherung zu starten.</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">Öffnen Sie in der Ansicht „Ressource“ für die Datenbank die Seite „verwaltete Backupkopien für die Datenbank“, um zu überprüfen, ob die einmalige Sicherung erfolgreich abgeschlossen wurde. Ein vollständiges Datenbank-Backup erstellt zwei Snapshots: Einen für das Daten-Volume und einen für das Log-Volume.</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">Erstellen eines Snapshot für Archivprotokolle</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">Ein Snapshot für das Archivprotokoll wird nur für das Oracle Archiv-Log-Volume erstellt.</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">Melden Sie sich in der Benutzeroberfläche von SnapCenter an und klicken Sie in der Menüleiste links auf die Registerkarte „Ressourcen“. Wechseln Sie im Dropdown-Menü Ansicht in die Ansicht Ressourcengruppe.</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">Klicken Sie auf den Namen der Backup-Ressource protokollieren und klicken Sie dann auf das Symbol Jetzt sichern, um eine zusätzliche Sicherung für Archivprotokolle zu starten.</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">Klicken Sie auf Backup und bestätigen Sie dann das Backup, um eine Archiv-Log-Sicherung zu starten.</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">Öffnen Sie in der Ansicht „Ressource“ für die Datenbank die Seite „verwaltete Backupkopien für die Datenbank“, um zu überprüfen, ob die Sicherungskopie für das einmalige Archivprotokoll erfolgreich abgeschlossen wurde. Ein Backup des Archivprotokolls erstellt einen Snapshot für das Protokollvolumen.</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">Wiederherstellung zu einem bestimmten Zeitpunkt</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">Eine zeitpunktgenaue SnapCenter Wiederherstellung wird auf demselben EC2 Instanzhost ausgeführt. Führen Sie die folgenden Schritte aus, um die Wiederherstellung durchzuführen:</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">Klicken Sie auf der Registerkarte SnapCenter-Ressourcen &gt; Datenbank auf den Datenbanknamen, um das Datenbank-Backup zu öffnen.</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">Wählen Sie die Datenbank-Backup-Kopie und den gewünschten Zeitpunkt für die Wiederherstellung aus. Markieren Sie auch die entsprechende SCN-Nummer für den Point-in-Time. Die Point-in-Time-Wiederherstellung kann entweder mit der Zeit oder mit dem SCN durchgeführt werden.</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">Markieren Sie den Snapshot des Protokollvolumens, und klicken Sie auf die Schaltfläche Mount, um das Volume zu mounten.</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">Wählen Sie die primäre EC2-Instanz, um das Protokoll-Volume zu mounten.</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">Vergewissern Sie sich, dass der Mount-Job erfolgreich abgeschlossen wurde. Überprüfen Sie auch auf dem EC2 Instance-Host, um das gemountete Protokoll-Volume und auch den Mount Point-Pfad zu sehen.</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">Kopieren Sie die Archivprotokolle vom gemounteten Protokollvolume in das aktuelle Archivprotokollverzeichnis.</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">Kehren Sie zur Registerkarte SnapCenter-Ressourcen &gt; Seite Datenbank-Backup zurück, markieren Sie die Daten-Snapshot-Kopie und klicken Sie auf die Schaltfläche Wiederherstellen, um den Workflow zur Datenbankwiederherstellung zu starten.</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">Überprüfen Sie „Alle Datendateien“ und „Datenbankstatus ändern, falls erforderlich für Restore und Recovery“, und klicken Sie auf Weiter.</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">Wählen Sie einen gewünschten Wiederherstellungsumfang mit SCN oder Time aus. Statt die gemounteten Archivprotokolle wie in Schritt 6 gezeigt in das aktuelle Logverzeichnis zu kopieren, kann der gemountete Archiv-Log-Pfad in "Geben Sie externe Archiv-Log-Dateien Speicherorte" zur Wiederherstellung aufgelistet werden.</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">Geben Sie bei Bedarf ein optionales Preskript an.</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">Geben Sie ggf. ein optionales Nachskript an, das ausgeführt werden soll. Überprüfen Sie die geöffnete Datenbank nach der Wiederherstellung.</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">Geben Sie einen SMTP-Server und eine E-Mail-Adresse an, wenn eine Jobbenachrichtigung erforderlich ist.</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">Stellen Sie die Jobübersicht wieder her. Klicken Sie auf Fertig stellen, um den Wiederherstellungsauftrag zu starten.</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">Validieren Sie die Wiederherstellung aus SnapCenter.</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">Validieren Sie die Wiederherstellung über den EC2 Instance Host.</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">Um die Bereitstellung des Wiederherstellungsprotokollvolumens aufzuheben, kehren Sie die Schritte in Schritt 4 um.</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">Erstellen eines Datenbankklons</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">Der folgende Abschnitt zeigt, wie der Workflow für SnapCenter-Klone zum Erstellen eines Datenbankklonen aus einer primären Datenbank auf eine Standby-EC2-Instanz verwendet wird.</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">Erstellen Sie mit der vollständigen Backup-Ressourcengruppe ein vollständiges Snapshot-Backup der primären Datenbank von SnapCenter.</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">Öffnen Sie auf der Registerkarte SnapCenter-Ressource &gt; Datenbank die Seite Datenbank-Backup-Verwaltung für die primäre Datenbank, aus der das Replikat erstellt werden soll.</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">Mounten Sie den in Schritt 4 erstellte Protokoll-Volume-Snapshot zum Standby-EC2-Instanz-Host.</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">Markieren Sie die für das Replikat zu klonenden Snapshot Kopie und klicken Sie auf die Schaltfläche Klonen, um das Klonverfahren zu starten.</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">Ändern Sie den Namen der Replikatkopie, damit sie sich vom Namen der primären Datenbank unterscheidet. Klicken Sie Auf Weiter.</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">Ändern Sie den Klon-Host auf den Standby-EC2-Host, akzeptieren Sie die Standardbenennung und klicken Sie auf Weiter.</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Ändern Sie Ihre Oracle-Starteinstellungen auf die für den Oracle-Zielserver-Host konfigurierten Einstellungen, und klicken Sie auf Weiter.</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">Geben Sie einen Wiederherstellungspunkt mit entweder Time oder dem SCN und dem angehängten Archivprotokollpfad an.</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">Senden Sie bei Bedarf die SMTP-E-Mail-Einstellungen.</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">Klonen Sie die Jobübersicht, und klicken Sie auf Fertig stellen, um den Klonauftrag zu starten.</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">Überprüfen Sie das Klon-Jobprotokoll, indem Sie das Klon-Jobprotokoll überprüfen.</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">Die geklonte Datenbank ist sofort in SnapCenter registriert.</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Deaktivieren Sie den Oracle Archivprotokollmodus. Melden Sie sich als oracle-Benutzer bei der EC2-Instanz an und führen Sie den folgenden Befehl aus:</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">Anstelle primärer Oracle Backup-Kopien kann ein Klon auch aus replizierten sekundären Backup-Kopien auf dem FSX Ziel-Cluster erstellt werden. Dies gilt gleichermaßen.</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">HA-Failover auf Standby und Resynchronisierung</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">Der Standby Oracle HA Cluster bietet Hochverfügbarkeit bei einem Ausfall am primären Standort, entweder in der Rechenschicht oder auf der Storage-Ebene. Ein wesentlicher Vorteil der Lösung besteht darin, dass Anwender die Infrastruktur jederzeit und beliebig oft testen und validieren können. Failover kann vom Benutzer simuliert oder durch wirklichen Ausfall ausgelöst werden. Die Failover-Prozesse sind identisch und können für ein schnelles Applikations-Recovery automatisiert werden.</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">Siehe folgende Liste der Failover-Verfahren:</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">Führen Sie bei einem simulierten Failover ein Protokoll-Snapshot-Backup aus, um die neuesten Transaktionen auf den Standby-Standort zu leeren, wie im Abschnitt dargestellt <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>. Bei einem durch einen tatsächlichen Ausfall ausgelösten Failover werden die letzten wiederherstellbaren Daten auf den Standby-Standort repliziert, wobei das letzte erfolgreiche Backup des geplanten Protokoll-Volumes erfolgt.</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">SnapMirror zwischen primärem und Standby FSX-Cluster unterbrechen</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">Mounten Sie die replizierten Standby-Datenbank-Volumes auf dem Standby-EC2 Instance-Host.</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">Verknüpfen Sie die Oracle-Binärdatei neu, wenn die replizierte Oracle-Binärdatei für die Oracle-Wiederherstellung verwendet wird.</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">Stellen Sie die Standby-Oracle-Datenbank auf das letzte verfügbare Archivprotokoll wieder her.</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">Öffnen Sie die Standby-Oracle-Datenbank für den Anwendungs- und Benutzerzugriff.</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">Bei einem tatsächlichen Ausfall des primären Standorts übernimmt die Standby-Oracle-Datenbank nun die Rolle des neuen primären Standorts und Datenbank-Volumes können dazu verwendet werden, den ausgefallenen primären Standort als neuen Standby-Standort mit der Reverse SnapMirror Methode wiederherzustellen.</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">Wenn ein simulierter Ausfall des primären Standorts im Rahmen des Tests oder der Validierung auftritt, fahren Sie nach Abschluss der Testdurchführung die Standby-Oracle-Datenbank herunter. Heben Sie dann die Standby-Datenbank-Volumes vom Standby-EC2-Instance-Host auf und synchronisieren Sie die Replikation vom primären Standort zum Standby-Standort neu.</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">Diese Verfahren können mit dem NetApp Automation Toolkit durchgeführt werden, das auf der öffentlichen NetApp GitHub Website heruntergeladen werden kann.</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">Lesen Sie die README-Anweisung sorgfältig, bevor Sie die Einrichtung und Failover-Tests durchführen.</block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">Als Nächstes geht es um die Datenbankmigration.</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">Dieser Abschnitt enthält Details zur Performance-Validierung und Benchmark-Ergebnissen eines simulierten OLTP-Workloads von Swingbank.</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">Performance-Validierung und Benchmark-Ergebnisse</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">Früher: Oracle Datenbankmanagement.</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">Das Ziel dieser Leistungsvalidierung ist es, keine Marken festzulegen. Wenn Sie die in diesem Dokument beschriebenen Implementierungsverfahren und Best Practices befolgen, können Sie von Ihrer Oracle-Datenbankimplementierung in einer Public Cloud ähnliche Performance-Kennzahlen erwarten.</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Wir haben einen OLTP-Workload mithilfe eines SwingBench Sales Order Entry (SOE)-Moduls simuliert und den Workload auf eine Oracle Datenbank angewendet, die auf eine M5 EC2 Instanz mit FSX Storage Volumes auf dem NFS-Protokoll implementiert wurde. Das Standard-SwingBench SOE I/O-Profil liegt in der Nähe eines Splitches mit Lese-/Schreibvorgängen von 80/20, das einem echten OLTP Oracle-Workload-Profil nahezu entspricht.</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">Der Workload wird erhöht, indem die Anzahl gleichzeitiger Benutzer auf der Client-Seite erhöht wird, die Auftragserfassung, Browsing, Bestandsanfragen usw. durchführen. Die getesteten Nummern waren 8, 16, 32, 64 und 128 gleichzeitige Benutzer. Der Algorithmus, den SwingBench verwendet, ist serverseitig sehr intensiv, um angemessene Transaktionsvolumen zu übertragen und Oracle-Servergrenzen zu testen. Wir beobachteten, dass bei 128 gleichzeitigen Benutzern die CPU-Auslastung von EC2 Instanzen ungefähr 80 bis 90 % erreichte.</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">Die folgenden Abschnitte enthalten Einzelheiten zu Einrichtung und Testergebnissen.</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">Einrichtung der Testumgebung</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">Wir implementierten eine EC2 M5 Instanz mit 8vCPU, 32 GB RAM und 10 GB/s Netzwerkbandbreite.</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">FSX-Storage</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">Wir haben drei Datenbank-Volumes erstellt und die Volumes mit NFS auf einer EC2 Instanz gemountet wie folgt:</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/U01 - Oracle binär</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/U02 - Oracle-Datendateien, Steuerdatei</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/U03 - Oracle-Protokolldateien, Steuerdatei</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">Aus Redundanzgründen haben wir zwei Kopien einer kritischen Kontrolldatei aufbewahrt.</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">Das FSX-Dateisystem ist mit einer Kapazität von 80,000 IOPS und einem I/O-Durchsatz von 2 GiBps konfiguriert.</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Oracle-Konfiguration</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Wir haben Oracle Version 19c mit RU Patch 19.8 installiert. DNFS wurde auf dem Server aktiviert.</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">Die Datenbank wurde als containerisierte Datenbank mit drei PDBs implementiert. Wir haben eine PDB-Instanz für Performance-Tests verwendet. Die folgende Abbildung zeigt die Größe von Oracle Storage auf den NFS-Mount-Punkten.</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Konfiguration von SwingBench</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">Wir haben SwingBench 2.6 (die neueste Version) auf einem Windows-Host mit 8vCPU und 32G RAM bereitgestellt. Für den Benchmark haben wir das SOE plsql-Testmodul Version 2 verwendet. Das Standard-Lastprofil bietet ein Verhältnis von 80/20 Lese-/Schreibvorgängen, um den tatsächlichen OLTP-Transaktionsarbeitslasten zu simulieren.</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">Der von uns verwendete Schemaskalierungsfaktor war 50, womit eine anfängliche Größe von 160 G und 30 G der temporären Speicherplatzzuweisung bereitgestellt wurde. Das SOE-Schema lieferte mit diesem Skalierungsfaktor 1000 Lagerhäuser und 50 Millionen Kunden für die Simulation der Online-Auftragsabwicklung.</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">Im folgenden Screenshot werden das Workload-Profil und die typischen Transaktionslaufkennzahlen der Swingbank Windows-Benutzeroberfläche gezeigt.</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">Wie diese Grafik zeigt, wurde die Transaktionsebene während des Testlaufs auf derselben Ebene beibehalten.</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">Analyse der Testergebnisse</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">Wir haben für jeden Testlauf die Ergebnisse von SwingBench erfasst und die entsprechenden Oracle AWR-Berichte für die Leistungsanalyse erhalten.</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">Auf Seiten des Endbenutzers haben wir uns wichtige Kennzahlen wie das Transaktionsvolumen und die Benutzerantwortzeit angesehen. Beide Metriken zeigen, wie viele Transaktionen Benutzer aus dem Eingabesystem für Bestellungen ausführen können, angesichts der Anzahl der gleichzeitigen Benutzer, die sich im System anmelden, sowie der Geschwindigkeit, mit der Benutzer Transaktionen abschließen und nach der Eingabe ihrer Bestellung eine Antwort erhalten können.</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">Vom Oracle Server-Ende haben wir den Oracle AWR-Bericht analysiert, um die wichtigsten Wartereignisse zu ermitteln, die möglicherweise die Benutzertransaktionen verlangsamt haben. Die Top 10 der Oracle-Warteereignisse gaben an, dass Oracle Server während simulierter Transaktionstests hauptsächlich I/O-gebunden sind und bis zu 50 bis 60 % der Datenbankzeit betragen<block ref="235591872ecf336383513d22098a1fa0" prefix=" " category="inline-code"></block>.<block ref="a249b22faad82bdea2a0930347b9e5ac" prefix=" " category="inline-code"></block> Dies ist auch ein Faktor, da die Transaktionsverpflichtung dazu führt, dass der Oracle-Protokollierungsprozess Log-I/O aus dem Puffer-Cache in die Protokolldatei auf der Festplatte schreibt, obwohl dies ein kleinerer Faktor auf der Datenbank-Zeit-Prozentebene ist.</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">Wir haben das Transaktionsvolumen für Benutzer, die Reaktionszeit der Benutzer und die häufigsten Oracle-Wartevents gegenüber der Anzahl der gleichzeitigen Benutzer während einer Transaktion dokumentiert. Die Ergebnisse sind nachfolgend aufgeführt:</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">Das Ergebnis zeigt, dass wir die Transaktions-Volumes für Benutzer mit einer höheren Anzahl gleichzeitiger Benutzer stetig erhöhen können, während gleichzeitig eine konsistent niedrige I/O-Latenz und Reaktionszeiten für Benutzer erhalten, was der richtigen Performance für eine Oracle Applikation entspricht.</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">Als wir 128 gleichzeitige Benutzer erreichten, begann sich die I/O-Latenz und die Reaktionszeit der Benutzer etwas zu erhöhen. Dies ist zu erwarten, da sich die EC2-Instanz der vollen Serverkapazität nähert, wie in der folgenden Abbildung dargestellt:</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">Auf ähnliche Weise zeigt die folgende Abbildung den entsprechenden FSX IOPS und den entsprechenden Durchsatz bei der Durchführung der zu diesem Zeitpunkt laufenden Benutzertransaktionsvolumes.</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Für die Implementierung von Oracle Database sind Faktoren zu berücksichtigen.</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">Wir haben die bereitgestellte FSX-Storage-Kapazität weder im IOPS-Bereich noch im Durchsatz erreicht, als die Oracle Server-EC2-Instanz den einschränkenden Faktor darstellt. Wie im Abschnitt gezeigt, müssen Sie die Computing- und Storage-Größe ordnungsgemäß basierend auf dem Transaktions-Volume auf Benutzerapplikationsebene festlegen <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="e848c28a0a485bcf645b0791381d9c89" category="doc">Modernisieren Ihrer Microsoft SQL Server Umgebung</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">Optimierter Betrieb und optimale Nutzung der Daten – vor Ort und in der Cloud</block>
  <block id="f867ac1965207b2211a876821d31d617" category="inline-link-macro"><block ref="f867ac1965207b2211a876821d31d617" category="inline-link-rx"></block></block>
  <block id="3f73fe1a14da103e822fb292c28f66df" category="paragraph"><block ref="3f73fe1a14da103e822fb292c28f66df" category="inline-link-macro-rx"></block></block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">Hybrid-Cloud-Datenbanklösungen mit SnapCenter DR-Workflow</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">Disaster-Recovery-Workflow</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">Früher: Workflow für Entwicklungs- und Test-Bursting in die Cloud.</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">Unternehmen nutzen die Public Cloud als praktikable Ressource und Ziel für die Disaster Recovery. SnapCenter macht diesen Prozess so nahtlos wie möglich. Dieser Disaster-Recovery-Workflow ähnelt dem Klon-Workflow sehr, doch die Datenbank-Recovery wird durch das letzte verfügbare Protokoll durchgeführt, das in die Cloud repliziert wurde, um alle möglichen Geschäftstransaktionen wiederherzustellen. Für Disaster Recovery gibt es jedoch noch weitere für die Konfiguration und die Nachbearbeitung ergänzende Schritte.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">Klonen einer lokalen Oracle-Produktionsdatenbank in die Cloud für DR</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">Um zu überprüfen, ob die Klonwiederherstellung das letzte verfügbare Protokoll durchlaufen hat, haben wir eine kleine Testtabelle erstellt und eine Zeile eingefügt. Die Testdaten würden nach einer vollständigen Wiederherstellung des letzten verfügbaren Protokolls wiederhergestellt.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Melden Sie sich bei SnapCenter als Benutzer-ID für das Datenbankmanagement für Oracle an. Öffnen Sie die Registerkarte Ressourcen, auf der die von SnapCenter geschützten Oracle-Datenbanken angezeigt werden.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Wählen Sie die Oracle-Protokollressourcengruppe aus, und klicken Sie auf Jetzt sichern, um manuell ein Oracle-Protokoll-Backup auszuführen, um die letzte Transaktion zum Ziel in der Cloud zu bereinigen. In einem echten DR-Szenario hängt die letzte wiederherstellbare Transaktion von der Replizierungshäufigkeit des Datenbank-Protokoll-Volumes in die Cloud ab, was wiederum von der RTO- oder RPO-Richtlinie des Unternehmens abhängt.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">Asynchronous SnapMirror verliert im Rahmen eines Disaster-Recovery-Szenarios Daten, die sie nicht zum Cloud-Ziel gemacht haben. Zur Minimierung von Datenverlusten können häufigere Protokoll-Backups geplant werden. Allerdings gibt es eine Begrenzung auf die technisch machbar Backup Log-Frequenz.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">Wählen Sie das letzte Protokoll-Backup auf den sekundären Spiegelsicherungs(s) aus, und mounten Sie das Protokoll-Backup.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">Wählen Sie das letzte vollständige Datenbank-Backup aus und klicken Sie auf Klonen, um den Klon-Workflow zu initiieren.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">Wählen Sie eine eindeutige Clone-DB-ID auf dem Host aus.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">Stellen Sie ein Protokoll-Volume bereit und mounten Sie es im Oracle Flash Recovery-Bereich und bei Online-Protokollen am Ziel-DR-Server.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Bei dem Klonverfahren von Oracle wird kein Protokoll-Volume erstellt, das vor dem Klonen auf dem DR-Server bereitgestellt werden muss.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">Wählen Sie den Host und den Speicherort des Zielklonen aus, um die Datendateien, Kontrolldateien und Wiederherstellungsprotokolle zu platzieren.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">Wählen Sie die Anmeldeinformationen für den Klon aus. Geben Sie die Details zur Oracle Home-Konfiguration auf dem Ziel-Server ein.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">Geben Sie die vor dem Klonen auszulaufenden Skripte an. Datenbankparameter können bei Bedarf angepasst werden.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">Wählen Sie als Recovery-Option bis Abbrechen aus, sodass die Recovery alle verfügbaren Archivprotokolle ausgeführt wird, um die letzte Transaktion, die am sekundären Cloud-Standort repliziert wurde, wiederzugewinnen.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">Konfigurieren Sie bei Bedarf den SMTP-Server für E-Mail-Benachrichtigungen.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">Zusammenfassung DES DR-Klons:</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">Geklonte DBs sind sofort nach Abschluss des Klons mit SnapCenter registriert und sind dann für den Backup-Schutz verfügbar.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Validierung und Konfiguration von Post-DR-Klonen für Oracle</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">Validierung der letzten Testtransaktion, die am DR-Standort in der Cloud gespeichert, repliziert und wiederhergestellt wurde</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">Konfigurieren Sie den Flash-Recovery-Bereich.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">Konfigurieren Sie den Oracle Listener für den Benutzerzugriff.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">Verteilen Sie das geklonte Volume vom replizierten Quell-Volume.</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">Die Replizierung wird von der Cloud in On-Premises-Systeme umkehren und der ausgefallene On-Premises-Datenbankserver neu erstellt.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">Durch die Aufteilung des Klons wird möglicherweise eine temporäre Storage-Auslastung verursacht, die deutlich höher ist als der normale Betrieb. Nach der rekonstruiert der lokalen DB-Server kann jedoch zusätzlicher Speicherplatz freigegeben werden.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">Klonen einer lokalen SQL-Produktionsdatenbank in die Cloud für DR</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">Um sicherzustellen, dass die SQL-Klon-Recovery durch das letzte verfügbare Protokoll ausgeführt wurde, haben wir eine kleine Testtabelle erstellt und eine Reihe eingefügt. Die Testdaten würden nach einer vollständigen Wiederherstellung des letzten verfügbaren Protokolls wiederhergestellt.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">Melden Sie sich mit einer Datenbank-Management-Benutzer-ID für SQL Server bei SnapCenter an. Navigieren Sie zur Registerkarte Ressourcen, auf der die SQL Server-Schutzressourcen-Gruppe angezeigt wird.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">Führen Sie ein Protokoll-Backup manuell aus, um die letzte Transaktion auszuführen, die in den sekundären Storage in der Public Cloud repliziert werden soll.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">Wählen Sie das letzte vollständige SQL Server-Backup für den Klon aus.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">Legen Sie die Kloneinstellung fest, z. B. den Klon-Server, die Kloninstanz, den Klonnamen und die Mount-Option. Der sekundäre Storage-Standort, an dem das Klonen durchgeführt wird, ist automatisch gefüllt.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">Wählen Sie alle anzuwendenden Protokollsicherungen aus.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">Geben Sie alle optionalen Skripte an, die vor oder nach dem Klonen ausgeführt werden sollen.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">Geben Sie einen SMTP-Server an, wenn eine E-Mail-Benachrichtigung gewünscht wird.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">Zusammenfassung DES DR-Klons: Geklonte Datenbanken werden sofort in SnapCenter registriert und stehen für den Backup-Schutz zur Verfügung.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">Validierung und Konfiguration von SQL-Klonen nach dem DR-Verfahren</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">Überwachen des Auftragsstatus von Klonen.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">Überprüfen Sie, ob die letzte Transaktion repliziert und mit allen Klonen von Protokolldateien und Recoverys wiederhergestellt wurde.</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">Konfigurieren Sie ein neues SnapCenter-Protokollverzeichnis auf dem DR-Server für die Sicherung der SQL Server-Protokolle.</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">NetApp Solution Automation Community unterstützt Slack-Channel</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">Wenn Sie Hilfe bei dieser Lösung und diesen Anwendungsbeispielen benötigen, nehmen Sie an der Teil <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> Und suchen Sie den Kanal zur Lösungsautomatisierung, um Ihre Fragen zu stellen oder zu fragen.</block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">In diesem Abschnitt wird der Bereitstellungsprozess von Cloud Manager und Cloud Volumes ONTAP in AWS beschrieben.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">Erste Schritte mit der AWS Public Cloud</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">Zurück: Erste Schritte vor Ort.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">AWS Public Cloud</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">Um die folgenden Elemente zu vereinfachen, haben wir dieses Dokument auf Basis einer Implementierung in AWS erstellt. Allerdings ist der Prozess für Azure und GCP sehr ähnlich.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. Scheck vor dem Flug</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">Stellen Sie vor der Implementierung sicher, dass die Infrastruktur vorhanden ist, die eine Implementierung in der nächsten Phase ermöglicht. Dazu gehört Folgendes:</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">AWS Konto</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">VPC in Ihrer bevorzugten Region</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">Subnetz mit Zugang zum öffentlichen Internet</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">Berechtigungen zum Hinzufügen von IAM-Rollen in Ihrem AWS-Konto</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">Ein geheimer Schlüssel und Zugriffsschlüssel für Ihren AWS-Benutzer</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. Schritte zur Implementierung von Cloud Manager und Cloud Volumes ONTAP in AWS</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">NetApp Cloud-Dokumentation</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Für die Implementierung von Cloud Manager und Cloud Volumes ONTAP gibt es viele Methoden. Diese Methode ist die einfachste, erfordert jedoch die meisten Berechtigungen. Falls diese Methode für Ihre AWS-Umgebung nicht geeignet ist, schlagen Sie bitte in nach<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Implementieren Sie den Cloud Manager Connector</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">Navigieren Sie zu<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> Und melden Sie sich an oder registrieren Sie sich.</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">Nach der Anmeldung sollten Sie auf den Bildschirm gebracht werden.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">Klicken Sie auf „Arbeitsumgebung hinzufügen“ und wählen Sie Cloud Volumes ONTAP in AWS. Hier haben Sie außerdem die Wahl, ob Sie ein Single Node-System oder ein Hochverfügbarkeitspaar implementieren möchten. Ich habe mich entschieden, ein Hochverfügbarkeitspaar bereitzustellen.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">Wenn kein Anschluss erstellt wurde, wird ein Popup-Fenster angezeigt, in dem Sie aufgefordert werden, einen Anschluss zu erstellen.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">Klicken Sie auf „Start“ und anschließend auf „AWS“.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">Die NetApp Richtlinien</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">Geben Sie Ihren geheimen Schlüssel und den Zugriffsschlüssel ein. Stellen Sie sicher, dass Ihr Benutzer über die auf dem angegebenen korrekten Berechtigungen verfügt<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">Geben Sie dem Konnektor einen Namen und verwenden Sie entweder eine vordefinierte Rolle, wie auf der beschrieben<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> Oder Fragen Sie Cloud Manager, welche Rolle Sie dabei spielen sollten.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">Geben Sie die für die Bereitstellung des Connectors erforderlichen Netzwerkinformationen an. Vergewissern Sie sich, dass der ausgehende Internetzugang aktiviert ist, indem Sie:</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">Geben der Verbindung eine öffentliche IP-Adresse</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">Dem Anschluss einen Proxy zur Verfügung stellen, der funktioniert</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">Dem Anschluss eine Route zum öffentlichen Internet über ein Internet-Gateway geben</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">Ermöglichen Sie die Kommunikation mit dem Connector über SSH, HTTP und HTTPS, indem Sie entweder eine Sicherheitsgruppe bereitstellen oder eine neue Sicherheitsgruppe erstellen. Ich habe nur von meiner IP-Adresse aus den Zugriff auf den Konnektor aktiviert.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">Überprüfen Sie die Informationen auf der Übersichtsseite, und klicken Sie auf Hinzufügen, um den Connector bereitzustellen.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">Der Connector wird nun mit einem Cloud-Formierung-Stack implementiert. Sie können den Fortschritt von Cloud Manager oder über AWS überwachen.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">Wenn die Bereitstellung abgeschlossen ist, wird eine Seite mit dem Erfolg angezeigt.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Implementieren Sie Cloud Volumes ONTAP</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">Wählen Sie AWS und die Art der Implementierung auf der Grundlage Ihrer Anforderungen aus.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">Wenn kein Abonnement zugewiesen wurde und Sie mit PAYGO kaufen möchten, wählen Sie Anmeldedaten bearbeiten.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">Wählen Sie Abonnement Hinzufügen.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">Wählen Sie den Vertrag aus, den Sie abonnieren möchten. Ich entschied mich für Pay-as-you-go.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">Sie werden zu AWS umgeleitet und wählen Sie „Weiter“, um sich Abonnieren zu öffnen.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">Melden Sie sich an und Sie werden zurück auf NetApp Cloud Central umgeleitet. Wenn Sie bereits abonniert haben und nicht umgeleitet werden, klicken Sie auf den Link "Hier klicken".</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Sie werden zu Cloud Central umgeleitet. Dort müssen Sie die Namen Ihres Abonnements benennen und es Ihrem Cloud Central Konto zuweisen.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">Wenn der Erfolg abgeschlossen ist, wird eine Seite mit den Häkchen angezeigt. Öffnen Sie die Registerkarte „Cloud Manager“.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">Das Abonnement wird jetzt in Cloud Central angezeigt. Klicken Sie auf Anwenden, um fortzufahren.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">Geben Sie die Angaben zur Arbeitsumgebung ein, z. B.:</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">Cluster-Name</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">Cluster-Passwort</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS Tags (optional)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">NetApp Cloud Homepage</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">Wählen Sie aus, welche zusätzlichen Services Sie bereitstellen möchten. Weitere Informationen zu diesen Services finden Sie auf der<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">Wählen Sie, ob die Implementierung in mehreren Verfügbarkeitszonen erfolgen soll (erfordert drei Subnetze, jede in einer anderen Verfügbarkeitszone) oder eine einzelne Verfügbarkeitszone. Ich habe mehrere AZS ausgewählt.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">Wählen Sie die Region, die VPC und die Sicherheitsgruppe für das zu implementierende Cluster aus. In diesem Abschnitt weisen Sie außerdem die Verfügbarkeitszonen pro Node (und Mediator) sowie die Subnetze zu, in denen sie tätig sind.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">Wählen Sie die Verbindungsmethoden für die Nodes und den Mediator.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">Der Mediator muss mit den AWS APIs kommunizieren. Es ist keine öffentliche IP-Adresse erforderlich, solange die APIs nach der Implementierung der Mediator EC2 Instanz erreichbar sind.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">NetApp Cloud Documentation</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">Mit fließenden IP-Adressen wird der Zugriff auf die verschiedenen von Cloud Volumes ONTAP verwendeten IP-Adressen ermöglicht, einschließlich Cluster-Management und DatenserverIPs. Diese Adressen müssen nicht bereits in Ihrem Netzwerk routingfähig sein und zu Routing-Tabellen in Ihrer AWS-Umgebung hinzugefügt werden. Sie sind erforderlich, um während des Failover konsistente IP-Adressen für ein HA-Paar zu aktivieren. Weitere Informationen zu schwimmenden IP-Adressen finden Sie im<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">Wählen Sie aus, zu welchen Routingtabellen die unverankerten IP-Adressen hinzugefügt werden sollen. Diese Routingtabellen werden von Clients für die Kommunikation mit Cloud Volumes ONTAP verwendet.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">Sie haben die Wahl, ob die von AWS gemanagte Verschlüsselung oder AWS KMS zur Verschlüsselung der ONTAP-Root-, Boot- und Datenfestplatten aktiviert werden sollen.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">Wählen Sie Ihr Lizenzmodell. Wenn Sie nicht wissen, welche Option Sie wählen sollten, wenden Sie sich an Ihren NetApp Ansprechpartner.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">Wählen Sie die Konfiguration aus, die am besten zu Ihrem Anwendungsfall passt. Dies bezieht sich auf die Überlegungen zur Dimensionierung, die auf der Seite Voraussetzungen behandelt werden.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">Erstellen Sie optional ein Volume. Dies ist nicht erforderlich, da in den nächsten Schritten SnapMirror verwendet wird, welches die Volumes für uns erstellt.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">Überprüfen Sie die getroffene Auswahl und aktivieren Sie die Kontrollkästchen, um zu überprüfen, ob Cloud Manager Ressourcen in Ihrer AWS-Umgebung implementiert. Klicken Sie abschließend auf „Go“.</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Cloud Volumes ONTAP startet jetzt mit der Implementierung. Cloud Manager verwendet für die Implementierung von Cloud Volumes ONTAP APIs und Cloud-Formations-Stacks von AWS. Anschließend wird das System gemäß Ihren Spezifikationen konfiguriert, sodass ein sofort einsatzbereites System verfügbar ist. Der Zeitpunkt für diesen Prozess variiert je nach getroffene Auswahl.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">Sie können den Fortschritt überwachen, indem Sie zur Zeitleiste navigieren.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">Die Zeitleiste dient als Audit aller in Cloud Manager ausgeführten Aktionen. Sie können alle API-Aufrufe anzeigen, die Cloud Manager bei der Einrichtung von AWS sowie dem ONTAP Cluster getätigt hat. Dies kann auch effektiv verwendet werden, um alle Probleme zu beheben, denen Sie gegenüberstehen.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">Nach Abschluss der Bereitstellung erscheint der CVO-Cluster auf dem Canvas, der aktuellen Kapazität. Das ONTAP Cluster ist im aktuellen Status vollständig konfiguriert, um ein echtes, out-of-the-box-Erlebnis zu ermöglichen.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">Konfigurieren Sie SnapMirror aus Ihrem lokalen Standort in die Cloud</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">Nachdem Sie nun ein ONTAP Quellsystem und ein implementierter Zielsystem von ONTAP haben, können Sie Volumes mit Datenbankdaten in die Cloud replizieren.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror Kompatibilitätsmatrix</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">Einen Leitfaden zu kompatiblen ONTAP-Versionen für SnapMirror finden Sie im<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">Klicken Sie auf das Quell-ONTAP-System (on-Premises), ziehen Sie es per Drag &amp; Drop zum Ziel, wählen Sie Replikation &gt; Aktivieren, oder wählen Sie Replikation &gt; Menü &gt; Replikation.</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Wählen Sie Aktivieren.</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">Oder Optionen.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">Replizierung:</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">Wenn Sie keine Drag-and-Drop-Option haben, wählen Sie das Ziel-Cluster aus, zu dem Sie replizieren möchten.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">Wählen Sie das Volume aus, das Sie replizieren möchten. Wir haben die Daten und alle Log-Volumes repliziert.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">Wählen Sie den Zieldatentyp und die Tiering-Richtlinie. Für Disaster Recovery empfehlen wir eine SSD als Festplattentyp und zur Aufrechterhaltung des Daten-Tiering. Mit Daten-Tiering werden die gespiegelten Daten in kostengünstigem Objekt-Storage verschoben und Kosten auf lokalen Festplatten eingespart. Wenn Sie die Beziehung unterbrechen oder das Volume klonen, verwenden die Daten den schnellen lokalen Storage.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">Wählen Sie den Zielvolumennamen: Wir haben ausgewählt<block ref="47456946fa180c1578446a0fa28fca75" prefix=" " category="inline-code"></block>.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">Wählen Sie die maximale Übertragungsrate für die Replikation aus. Dadurch sparen Sie Bandbreite, wenn Sie eine Verbindung mit einer niedrigen Bandbreite zur Cloud, wie zum Beispiel einem VPN, herstellen.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">Legen Sie die Replizierungsrichtlinie fest. Wir haben uns für einen Spiegel entschieden, der den letzten Datensatz aufnimmt und diesen in das Ziel-Volume repliziert. Sie können auch eine andere Richtlinie auf Basis Ihrer Anforderungen wählen.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">Wählen Sie den Zeitplan für das Auslösen der Replikation aus. NetApp empfiehlt die Festlegung eines „täglichen“ Zeitplans für das Daten-Volume und einen „stündlichen“ Zeitplan für die Log-Volumes, wobei diese jedoch je nach Anforderungen geändert werden können.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">Überprüfen Sie die eingegebenen Informationen, klicken Sie auf Go, um den Cluster Peer und SVM Peer auszulösen (wenn dies Ihr erstes Mal ist, wenn Sie zwischen den beiden Clustern replizieren) und implementieren und initialisieren Sie dann die SnapMirror Beziehung.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">Setzen Sie diesen Prozess für Datenvolumen und Protokoll-Volumes fort.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">Wenn Sie alle Beziehungen überprüfen möchten, wechseln Sie zur Registerkarte „Replikation“ in Cloud Manager. Hier können Sie Ihre Beziehungen verwalten und ihren Status überprüfen.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">Nachdem alle Volumes repliziert wurden, befinden Sie sich in einem stabilen Zustand und können zu den Workflows für Disaster Recovery und Entwicklung/Test wechseln.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. EC2 Computing-Instanz für Datenbank-Workload implementieren</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 Instanztyp</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS verfügt über vorkonfigurierte EC2 Computing-Instanzen für verschiedene Workloads. Die Wahl des Instanztyps bestimmt die Anzahl der CPU-Kerne, die Speicherkapazität, den Speichertyp und die Kapazität sowie die Netzwerk-Performance. In den Anwendungsfällen wird mit Ausnahme der Betriebssystempartition der Haupt-Storage für die Ausführung des Datenbank-Workloads von CVO oder der FSX ONTAP-Storage-Engine zugewiesen. Daher müssen die wichtigsten Faktoren die Wahl der CPU-Cores, des Arbeitsspeichers und der Netzwerk-Performance sein. Typische AWS EC2 Instanztypen sind hier zu finden:<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">Dimensionierung der Computing-Instanz</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">Wählen Sie den richtigen Instanztyp basierend auf dem erforderlichen Workload aus. Zu berücksichtigende Faktoren sind die Anzahl der zu unterstützenden Geschäftstransaktionen, die Anzahl gleichzeitiger Benutzer, die Größenbemessung von Datensätze usw.</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">Die Implementierung der EC2-Instanz kann über das EC2 Dashboard gestartet werden. Die genauen Implementierungsverfahren gehen über den Umfang dieser Lösung hinaus. Siehe<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> Entsprechende Details.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Konfiguration einer Linux-Instanz für Oracle-Workload</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">Dieser Abschnitt enthält weitere Konfigurationsschritte, nachdem eine EC2 Linux Instanz implementiert wurde.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">Fügen Sie eine Oracle-Standby-Instanz zum DNS-Server für die Namensauflösung in der SnapCenter-Managementdomäne hinzu.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">Fügen Sie als SnapCenter OS-Anmeldeinformationen eine Linux-Management-Benutzer-ID mit sudo-Berechtigungen ohne Kennwort hinzu. Aktivieren Sie die ID mit SSH-Passwort-Authentifizierung auf der EC2-Instanz. (Bei EC2-Instanzen ist die SSH-Kennwortauthentifizierung und passwortless sudo standardmäßig deaktiviert.)</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">Konfiguration der Oracle Installation entsprechend der lokalen Oracle Installation, z. B. Betriebssystem-Patches, Oracle Versionen und Patches usw.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Automatisierte Oracle 19c Implementierung</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">NetApp Ansible DB-Automatisierungsrollen können genutzt werden, um EC2 Instanzen für Anwendungsfälle in den Bereichen Entwicklung/Test und Disaster Recovery zu konfigurieren. Der Automatisierungscode kann auf der öffentlichen NetApp GitHub Website heruntergeladen werden:<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. Ziel ist es, einen Datenbank-Software-Stack auf einer EC2 Instanz zu installieren und zu konfigurieren, der an lokale OS- und Datenbankkonfigurationen angepasst wird.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">Windows-Instanzkonfiguration für den SQL Server-Workload</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">Dieser Abschnitt enthält zusätzliche Konfigurationsschritte, nachdem eine EC2 Windows-Instanz ursprünglich implementiert wurde.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">Rufen Sie das Windows-Administratorpasswort ab, um sich über RDP bei einer Instanz anzumelden.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Deaktivieren Sie die Windows-Firewall, treten Sie der Windows SnapCenter-Domäne des Hosts bei und fügen Sie die Instanz zum DNS-Server zur Namensauflösung hinzu.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">Bereitstellen eines SnapCenter-Protokollvolumens zum Speichern von SQL Server-Protokolldateien</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Konfigurieren Sie iSCSI auf dem Windows-Host, um das Volume zu mounten und das Festplattenlaufwerk zu formatieren.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp Automatisierung</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">Viele ihrer früheren Aufgaben können mit der NetApp Automatisierungslösung für SQL Server automatisiert werden. Informieren Sie sich auf der NetApp Public Automation GitHub Website über neu veröffentlichte Rollen und Lösungen:<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">Als Nächstes: Workflow für Entwicklungs- und Test-Bursting in die Cloud.</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="20da1f90c59ba57d043ded8994bb7619" category="summary">Dieser Abschnitt enthält einen Überblick über eine RDS-Architektur für die Oracle-Implementierungslösung mit individuell angepasster RDS- und FSX ONTAP-Storage.</block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">Das folgende Architekturdiagramm zeigt eine hochverfügbare Implementierung von Oracle Datenbanken auf einer AWS EC2 Instanz mit dem FSX Storage-Service. Ein ähnliches Bereitstellungsschema, jedoch mit Standby in einer anderen Region kann für das Disaster Recovery eingerichtet werden.</block>
  <block id="a0cdfa3b119f53b827ebc38a9519b32d" category="paragraph">In der Umgebung wird die Oracle Computing-Instanz über eine AWS EC2 Instance Console implementiert. Über die Konsole stehen mehrere EC2-Instanztypen zur Verfügung. NetApp empfiehlt die Implementierung eines datenbankorientierten EC2 Instanztyps wie ein m5 Ami Image mit RedHat Enterprise Linux 8 und eine Netzwerkbandbreite von bis zu 10 Gps.</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">Oracle Datenbank-Storage auf FSX Volumes hingegen wird mit der AWS FSX Konsole oder der CLI bereitgestellt. Die Oracle-Binärdateien, Daten oder Log-Volumes werden anschließend präsentiert und auf einem Linux-Host der EC2 Instanz gemountet. Jeder Daten- oder Protokoll-Volume kann abhängig vom verwendeten Storage-Protokoll mehrere LUNs zugewiesen sein.</block>
  <block id="736415956026dd8a803e8e2f7c5f0f42" category="paragraph"><block ref="736415956026dd8a803e8e2f7c5f0f42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0537fe1ac97a9f2e83612f0789e84585" category="paragraph">Ein FSX Storage-Cluster verfügt über doppelte Redundanz, sodass sowohl der primäre als auch der Standby-Storage-Cluster in zwei verschiedenen Verfügbarkeitszonen implementiert werden können. Datenbank-Volumes werden von einem primären FSX-Cluster auf ein Standby-FSX-Cluster in einem vom Benutzer konfigurierbaren Intervall für alle Oracle Binär-, Daten- und Protokoll-Volumes repliziert.</block>
  <block id="7a9829ab1a28b0d6ca9ddaee5874655a" category="paragraph">Diese hochverfügbare Oracle-Umgebung wird über einen Ansible-Controller-Node sowie einen SnapCenter-Backup-Server und ein UI-Tool verwaltet. Die Installation, Konfiguration und Replizierung von Oracle werden mithilfe von Playbook-basierten Ansible Toolkits automatisiert. Jedes Update auf dem Kernel-Betriebssystem der Oracle EC2 Instanz oder Oracle Patching kann parallel ausgeführt werden, um den Primär- und Standby-Modus synchron zu halten. So kann die Erstautomatisierung auch problemlos erweitert werden, um bei Bedarf einige sich wiederholende tägliche Oracle Aufgaben durchzuführen.</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter stellt Workflows für zeitpunktgenaue Oracle Database Recovery oder für das Datenbankklonen in den primären oder Standby-Zonen bereit, falls erforderlich. Über die Benutzeroberfläche von SnapCenter können Sie das Backup und die Replizierung von Oracle Datenbanken auf Standby FSX Storage konfigurieren, um für Hochverfügbarkeit oder Disaster Recovery entsprechend Ihrer RTO- oder RPO-Vorgaben zu sorgen.</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">Die Lösung stellt einen alternativen Prozess bereit, der Funktionen bietet, die denen von Oracle RAC und Data Guard Deployment ähnlich sind.</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">Als Nächstes: Implementierungsverfahren</block>
  <block id="6487ec60d16ab8bf4ce0aa7ebaf86b4f" category="paragraph"><block ref="6487ec60d16ab8bf4ce0aa7ebaf86b4f" category="inline-link-macro-rx"></block></block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">Auf dieser Seite wird die automatisierte Datensicherung von Oracle19c auf NetApp ONTAP Storage beschrieben.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">Schritt-für-Schritt-Anweisungen zur Implementierung</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/Tower Oracle Data Protection</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">Erstellen Sie Inventar, Gruppe, Hosts und Anmeldedaten für Ihre Umgebung</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">In diesem Abschnitt wird die Einrichtung von Inventar, Gruppen, Hosts und Zugangsdaten im AWX/Ansible Tower beschrieben, die die Umgebung für den Einsatz automatisierter NetApp Lösungen vorbereiten.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Navigieren Sie zu Ressourcen → Inventar → Hinzufügen, und klicken Sie auf Inventar hinzufügen.</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">Geben Sie den Namen und die Organisationsdetails ein, und klicken Sie auf Speichern.</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">Klicken Sie auf der Seite Inventar auf den erstellten Bestand.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Navigieren Sie zum Untermenü Gruppen, und klicken Sie auf Hinzufügen.</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">Geben Sie den Namen oracle für Ihre erste Gruppe ein, und klicken Sie auf Speichern.</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">Wiederholen Sie den Vorgang für eine zweite Gruppe namens dr_oracle.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">Wählen Sie die erstellte oracle-Gruppe aus, gehen Sie zum Untermenü Hosts und klicken Sie auf Neuen Host hinzufügen.</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">Geben Sie die IP-Adresse der Management-IP des Oracle Quell-Hosts an, und klicken Sie auf Speichern.</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">Dieser Prozess muss für die dr_oracle-Gruppe wiederholt werden und die Management-IP/den Host für DR/Ziel Oracle-Host hinzufügen.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">Im Folgenden werden die Typen und Anmeldedaten für Zugangsdaten, entweder für On-Premises mit ONTAP oder CVO in AWS, erstellt.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">Lokal</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">Erstellen Sie ein Projekt</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Gehen Sie zu Ressourcen → Projekte, und klicken Sie auf Hinzufügen.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Wählen Sie im Feld Quellenkontrolle Credential Type die Option Git aus.</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">Eingabe <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> Als URL für die Quellensteuerung.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">Das Projekt muss gelegentlich synchronisiert werden, wenn sich der Quellcode ändert.</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">Globale Variablen konfigurieren</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">Die in diesem Abschnitt definierten Variablen gelten für alle Oracle Hosts, Datenbanken und den ONTAP Cluster.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">Geben Sie Ihre umgebungsspezifischen Parameter in das folgende eingebettete globale Variablen oder Vars-Formular ein.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">Die blauen Elemente müssen an Ihre Umgebung angepasst werden.</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">Automation Playbooks</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">Es gibt vier separate Playbooks, die ausgeführt werden müssen.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">Playbook zur Einrichtung Ihrer Umgebung, vor Ort oder CVO</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Playbook für die Replizierung von Oracle Binaries und Datenbanken nach einem Zeitplan</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">Playbook für die Replizierung von Oracle Logs nach einem Zeitplan</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">Playbook für die Wiederherstellung Ihrer Datenbank auf einem Ziel-Host</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO Einrichtung</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">Replizierung für Binär- und Datenbank-Volumes</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">Replizierung für Protokoll-Volumes</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">Wiederherstellen und Wiederherstellen von Datenbanken</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Oracle Database Wird Wiederhergestellt</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">Daten-Volumes für Oracle-Produktionsdatenbanken vor Ort werden über NetApp SnapMirror Replizierung auf einen redundanten ONTAP Cluster im sekundären Datacenter oder Cloud Volume ONTAP in der Public Cloud gesichert. In einer vollständig konfigurierten Disaster-Recovery-Umgebung sind die Recovery von Computing-Instanzen im sekundären Datacenter oder in der Public Cloud Standby und im Notfall bereit, die Produktionsdatenbank wiederherzustellen. Die Standby-Computing-Instanzen werden mit On-Prem-Instanzen synchronisiert, indem paraellel-Updates auf OS-Kernel-Patch ausgeführt oder ein Upgrade in einem Lockstep durchgeführt wird.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">In dieser demonstrierten Lösung wird das Oracle Binary Volume zum Ziel repliziert und an einer Zielinstanz gemountet, um den Oracle Software Stack zu erstellen. Dieser Ansatz zur Wiederherstellung von Oracle hat den Vorteil, dass Oracle in letzter Minute bei einem Ausfall neu installiert wird. Es garantiert, dass die Oracle Installation vollständig mit der aktuellen Installation der On-Prem-Produktionssoftware und den Patch-Leveln synchronisiert ist. Dies kann jedoch je nach Struktur der Softwarelizenzierung mit Oracle für das replizierte Oracle Binary Volume am Recovery-Standort zusätzliche Konsequenzen haben oder diese nicht haben. Der Benutzer wird empfohlen, sich mit seinem Softwarelizenzierungspersonal zu erkundigen, um die potenziellen Lizenzierungsanforderungen für Oracle zu bewerten, bevor er sich für denselben Ansatz entscheidet.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">Der Standby-Oracle-Host am Ziel ist mit den Oracle-Vorbedingung-Konfigurationen konfiguriert.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">Die SnapMirror-Spiegelungen werden beschädigt und die Volumes werden beschreibbar gemacht und auf den Standby-Oracle Host eingebunden.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">Das Oracle Recovery-Modul führt die folgenden Aufgaben zur Wiederherstellung und dem Start von Oracle am Recovery-Standort aus, nachdem alle DB-Volumes auf der Standby-Compute-Instanz gemountet wurden.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">Sync the Control file: Wir haben duplizierte Oracle Steuerdateien auf verschiedenen Datenbank-Volumes implementiert, um die kritische Datenbankkontrolldatei zu schützen. Eine ist auf dem Daten-Volume und eine ist auf dem Log-Volume. Da Daten und Protokoll-Volumes unterschiedlich häufig repliziert werden, sind sie zum Zeitpunkt der Wiederherstellung nicht synchron.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Relink Oracle Binary: Da die Oracle-Binärdatei auf einen neuen Host verlagert wird, braucht es eine Relink.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Recovery von Oracle Datenbank: Der Recovery-Mechanismus ruft die letzte Systemänderungsnummer in der letzten verfügbaren archivierten Protokolldatei von Oracle ab und stellt die Oracle Datenbank wieder her, um alle Geschäftstransaktionen wiedergewonnen zu haben, die zum Zeitpunkt eines Ausfalls auf den DR-Standort repliziert werden konnten. Die Datenbank wird dann in einer neuen Inkarnation gestartet, um Benutzerverbindungen und Geschäftstransaktionen am Recovery-Standort durchzuführen.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Bevor Sie das Recovery-Playbook ausführen, stellen Sie sicher, dass Sie Folgendes haben: Vergewissern Sie sich, dass es über /etc/oratab und /etc/oraInst.loc vom Oracle-Quellhost zum Zielhost kopiert wird</block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">Die in diesem Abschnitt beschriebenen Aufgaben müssen vor Ort ausgeführt werden, um die SnapCenter Hybrid-Cloud-Datenbank-Workload-Umgebung vorzubereiten.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">Voraussetzungen vor Ort</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">Zurück: Konfiguration der Voraussetzungen.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">Die folgenden Aufgaben müssen vor Ort ausgeführt werden, um die SnapCenter Hybrid-Cloud-Datenbank-Workload-Umgebung vorzubereiten.</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">Das NetApp SnapCenter Tool ist eine auf Windows basierende Applikation, die normalerweise in einer Windows Domain-Umgebung ausgeführt wird, obwohl auch eine Implementierung von Arbeitsgruppen möglich ist. Sie basiert auf einer Multi-Tier-Architektur, die einen zentralen Management-Server (den SnapCenter Server) sowie ein SnapCenter-Plug-in auf den Datenbank-Server-Hosts für Datenbank-Workloads umfasst. Folgende wichtige Aspekte sollten bei der Implementierung der Hybrid Cloud beachtet werden:</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">*Single Instance oder HA-Bereitstellung.* HA-Bereitstellung bietet Redundanz bei Ausfall eines SnapCenter-Instanz-Servers.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">*Namensauflösung.* DNS muss auf dem SnapCenter-Server konfiguriert sein, um alle Datenbank-Hosts sowie auf der Speicher-SVM aufzulösen, damit die Suche vorwärts und rückwärts ausgeführt werden kann. DNS muss auch auf Datenbankservern konfiguriert werden, um den SnapCenter-Server und die Storage-SVM für die vorwärts und rückwärts Suche zu lösen.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">*Rollenbasierte Zugriffssteuerung (Role-Based Access Control, RBAC)-Konfiguration.* für gemischte Datenbank-Workloads sollten Sie die RBAC verwenden, um die Management-Verantwortung für verschiedene DB-Plattformen zu verteilen, z. B. einen Administrator für Oracle Database oder einen Administrator für SQL Server. Für den DB-Admin-Benutzer müssen die erforderlichen Berechtigungen erteilt werden.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">*Ermöglicht eine richtlinienbasierte Backup-Strategie.* zur Durchsetzung der Backup-Konsistenz und -Zuverlässigkeit.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">*Öffnen Sie erforderliche Netzwerkanschlüsse an der Firewall.* damit der On-Premise SnapCenter Server mit Agenten kommunizieren kann, die im Cloud DB-Host installiert sind.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">*Die Ports müssen offen sein, um SnapMirror Traffic zwischen On-Premises und Public Cloud zu ermöglichen.* der SnapCenter Server nutzt ONTAP SnapMirror zur Replizierung von Snapshot Backups vor Ort in Cloud-CVO Storage-SVMs.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter Installations-Workflow</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">Klicken Sie nach sorgfältiger Planung und Prüfung vor der Installation auf diese Schaltfläche <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> Einzelheiten zur Installation und Konfiguration von SnapCenter finden Sie im Dokument.</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">Die Storage-Performance spielt für die Gesamt-Performance von Datenbanken und Applikationen eine wichtige Rolle. Mit einem gut durchdachten Storage-Layout kann nicht nur die Datenbank-Performance verbessert werden, sondern auch das Management von Datenbank-Backup und -Recovery vereinfacht wird. Bei der Definition des Storage-Layouts sind mehrere Faktoren zu berücksichtigen. Dazu gehören die Größe der Datenbank, die erwartete Datenänderung der Datenbank und die Häufigkeit der Backups.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">Das direkte Anbinden von Storage-LUNs an die Gast-VM entweder über NFS oder iSCSI für virtualisierte Datenbank-Workloads liefert im Allgemeinen eine bessere Performance als über VMDK zugewiesener Storage. NetApp empfiehlt das Storage-Layout für eine große SQL Server Datenbank auf LUNs, die in der folgenden Abbildung dargestellt sind.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">Die folgende Abbildung zeigt das von NetApp empfohlene Storage-Layout für kleine oder mittlere SQL Server-Datenbank auf LUNs.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">Das Log-Verzeichnis ist SnapCenter dediziert, um Transaktions-Log-Rollup für Datenbank-Recovery durchzuführen. Für eine besonders große Datenbank können einem Volume mehrere LUNs zugewiesen werden, um eine bessere Performance zu erzielen.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Bei Oracle-Datenbank-Workloads unterstützt SnapCenter Datenbankumgebungen, die über ONTAP Storage gesichert sind, die als physische oder virtuelle Geräte auf dem Host gemountet werden. Je nach Wichtigkeit der Umgebung können Sie die gesamte Datenbank auf einem einzigen oder mehreren Storage-Geräten hosten. In der Regel isolieren Kunden Datendateien im dedizierten Storage von allen anderen Dateien, z. B. Kontrolldateien, Wiederherstellungsdateien und Archivprotokolldateien. So sind Administratoren in ONTAP der Lage, in wenigen Sekunden oder Minuten eine große kritische Datenbank (Petabyte-Größe) mit Snapshot Technologie wiederherzustellen (Single-File SnapRestore) oder zu klonen.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">Für geschäftskritische Workloads, die von der Latenz abhängig sind, sollte ein dediziertes Storage Volume auf verschiedene Arten von Oracle Dateien implementiert werden, um die bestmögliche Latenz zu erzielen. Bei einer großen Datenbank sollten mehrere LUNs (NetApp empfiehlt bis zu acht) pro Volume Datendateien zugewiesen werden.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">Bei kleineren Oracle Datenbanken unterstützt SnapCenter Shared-Storage-Layouts, in denen mehrere Datenbanken oder Teile einer Datenbank auf demselben Storage-Volume oder derselben LUN gehostet werden können. Als Beispiel für dieses Layout können Sie Datendateien für alle Datenbanken auf einer +DATA ASM Laufwerksgruppe oder einer Volume-Gruppe hosten. Der Rest der Dateien (Redo-, Archivprotokoll- und Kontrolldateien) kann auf einer anderen dedizierten Laufwerksgruppe oder Volume-Gruppe (LVM) gehostet werden. Ein solches Implementierungsszenario wird im Folgenden dargestellt.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Um die Verschiebung von Oracle Datenbanken zu erleichtern, sollte Oracle-Binärdatei auf einer separaten LUN installiert werden, die in der regelmäßigen Backup-Richtlinie enthalten ist. So wird sichergestellt, dass bei der Datenbankverschiebung zu einem neuen Serverhost der Oracle Stack für eine Recovery ohne potenzielle Probleme aufgrund einer aus der Synchronisierung bestehenden Oracle-Binärdatei gestartet werden kann.</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter ist eine lizenzierte Software von NetApp. Sie ist im Allgemeinen in einer ONTAP Lizenz vor Ort enthalten. Bei der Hybrid-Cloud-Implementierung ist jedoch auch eine Cloud-Lizenz für SnapCenter erforderlich, um CVO zu SnapCenter als Ziel-Datenreplizierungsziel zu hinzufügen. Weitere Informationen erhalten Sie unter folgenden Links zu der kapazitätsbasierten SnapCenter Standardlizenz:</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">SnapCenter-Standard-kapazitätsbasierte Lizenzen</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">Wenn ein hybrider Datenbankbetrieb eine lokale Produktionsdatenbank benötigt, die nicht stabil in der Cloud für Entwicklung/Test und Disaster Recovery ist, müssen Netzwerke und Sicherheit beim Einrichten der Umgebung sowie die Verbindung zur Public Cloud aus einem lokalen Datacenter berücksichtigt werden.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">Public Clouds verwenden in der Regel eine Virtual Private Cloud (VPC), um verschiedene Benutzer innerhalb einer Public-Cloud-Plattform zu isolieren. Innerhalb eines individuellen VPC wird die Sicherheit mithilfe von Maßnahmen wie Sicherheitsgruppen gesteuert, die je nach Benutzeranforderungen für die Sperrung eines VPC konfiguriert werden können.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">Die Konnektivität vom lokalen Datacenter zur VPC kann über einen VPN-Tunnel gesichert werden. Auf dem VPN-Gateway kann die Sicherheit durch NAT- und Firewall-Regeln, die Versuche blockieren, Netzwerkverbindungen von Hosts im Internet zu Hosts im unternehmenseigenen Rechenzentrum herzustellen, abgehärtet werden.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">Networking- und Sicherheitsaspekte finden Sie in den relevanten ein- und ausgehenden CVO-Regeln für die beliebige Public Cloud:</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">Regeln für Sicherheitsgruppen für CVO – AWS</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">Regeln für Sicherheitsgruppen für CVO – Azure</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">Firewall-Regeln für CVO - GCP</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Nutzung von Ansible-Automatisierung zur Synchronisierung von DB-Instanzen zwischen On-Premises und der Cloud – optional</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">Um das Management einer Hybrid-Cloud-Datenbankumgebung zu vereinfachen, empfiehlt NetApp unbedingt den Einsatz eines Ansible-Controllers, um einige Managementaufgaben zu automatisieren, z. B. um Computing-Instanzen lokal und in der Cloud synchron zu halten. Dies ist besonders wichtig, da eine Out-of-Sync-Computing-Instanz in der Cloud die wiederhergestellte Datenbank im Cloud-Fehler aufgrund fehlender Kernel-Pakete und anderer Probleme anfällig machen könnte.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">Mit den Automatisierungsfunktionen eines Ansible-Controllers lässt sich SnapCenter für bestimmte Aufgaben erweitern, beispielsweise durch Aufbrechen der SnapMirror Instanz zur Aktivierung der DR-Datenkopie für die Produktion.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">Redhat/CentOS Ansible Controller-Setup</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu/Debian Ansible-Controller-Setup</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">Folgen Sie diesen Anweisungen, um Ihren Ansible-Steuerungsknoten für RedHat- oder CentOS-Maschinen einzurichten: <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. Befolgen Sie diese Anweisungen, um Ihren Ansible-Steuerungsknoten für Ubuntu oder Debian-Maschinen einzurichten: <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">In der nächsten Richtung: Public Cloud.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250: SAP with Oracle on UNIX and NFS with NetApp Clustered Data ONTAP and SnapManager for SAP 3.4</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">Nils Bauer, NetApp</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">TR-4250 erläutert die Herausforderungen bei der Entwicklung von Storage-Lösungen zur Unterstützung von SAP Business Suite Produkten unter Verwendung einer Oracle Database. Das Hauptaugenmerk dieses Dokuments liegt auf dem allgemeinen Bedarf an Storage-Infrastruktur-Design, -Implementierung, -Betrieb und -Management-Herausforderungen. Geschäftliche und IT-Führungskräfte stehen dabei vor der Herausforderung, die auf der neuesten Generation von SAP-Lösungen basieren. Die Empfehlungen in diesem Dokument sind allgemein, nicht spezifisch für eine SAP-Anwendung oder Größe und Umfang der SAP-Implementierung. TR-4250 geht davon aus, dass der Leser über die grundlegenden Kenntnisse der Technologie und des Betriebs der NetApp- und SAP-Produkte verfügt. TR-4250 wurde entwickelt nach dem Zusammenspiel des technischen Personals von NetApp, SAP, Oracle und unseren Kunden.</block>
  <block id="72b1d38d81a57d1482ce5708d98653f1" category="inline-link-macro"><block ref="72b1d38d81a57d1482ce5708d98653f1" category="inline-link-rx"></block></block>
  <block id="9661c205dc29ba33fe04212e23a675a7" category="paragraph"><block ref="9661c205dc29ba33fe04212e23a675a7" category="inline-link-macro-rx"></block></block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155: Oracle 19c RAC-Datenbanken on FlexPod Datacenter with Cisco UCS and NetApp AFF A800 over FC - Design and Deployment Guide</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">Allen Cao, NetApp</block>
  <block id="a42a54d915f9cd474841cab349e2de5e" category="paragraph">Dieser Design- und Implementierungsleitfaden für Oracle 19c RAC-Datenbanken unter FlexPod Datacenter mit Cisco UCS und NetApp AFF A800 über FC bietet Details zum Lösungsdesign und schrittweise Implementierungsprozesse für das Hosting von Oracle RAC-Datenbanken auf der neuesten FlexPod Datacenter-Infrastruktur mit Oracle Linux 8.2 Betriebssystem und einen Red hat kompatiblen Kernel.</block>
  <block id="26536a9e695c3724c27d8ef7d7297f41" category="inline-link-macro"><block ref="26536a9e695c3724c27d8ef7d7297f41" category="inline-link-rx"></block></block>
  <block id="6e0751d9d8cd023132b0afea3073c96d" category="paragraph"><block ref="6e0751d9d8cd023132b0afea3073c96d" category="inline-link-macro-rx"></block></block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">Diese Seite beschreibt die automatisierte Methode zur Implementierung von Oracle-Datensicherung auf NetApp ONTAP Storage.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">Erste Schritte</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">Diese Lösung wurde für den Betrieb in einer AWX/Tower-Umgebung entwickelt.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/Tower</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">Für AWX-/Tower-Umgebungen werden Sie geleitet durch das Erstellen einer Bestandsaufnahme für das ONTAP Cluster-Management und den Oracle Server (IPs und Hostnamen), das Erstellen von Anmeldeinformationen, das Konfigurieren eines Projekts, das den Ansible-Code aus NetApp Automation Github zieht, und durch die Jobvorlage, die die Automatisierung startet.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">Die Lösung wurde für die Ausführung in einem Private-Cloud-Szenario (vor Ort und lokal) und in einer Hybrid Cloud (On-Premises zu Public-Cloud-Cloud Volumes ONTAP [CVO]) entwickelt.</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">Füllen Sie die Variablen aus, die für Ihre Umgebung spezifisch sind, und kopieren Sie sie in die Felder Extra Vars in Ihrer Job-Vorlage.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">Nachdem die zusätzlichen Vars zu Ihrer Job-Vorlage hinzugefügt wurden, können Sie die Automatisierung starten.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">Die Automatisierung umfasst drei Phasen (Setup, Replizierungsplan für Oracle Binaries, Database, Logs und Replication Schedule nur für Logs) und einen vierten Schritt zur Wiederherstellung der Datenbank an einem DR-Standort.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">Sammeln von Voraussetzungen für CVO- und Connector-Implementierungen</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">Detaillierte Anweisungen zum Abrufen der für den CVO-Datenschutz erforderlichen Schlüssel und Token finden Sie unter <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;starke Klasse=„groß“&gt;On-Prem&lt;/strong&gt; &lt;stark&gt;&lt;/strong&gt;</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">*Ansible-Umgebung*</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 und höher</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python Libraries - netapp-lib - xmltodict - jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">*ONTAP*</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP Version 9.8 +</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">Zwei Datenaggregate</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS vlan und iffrp wurden erstellt</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">*Oracle Server*</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">Netzwerkschnittstellen für das NFS-, öffentlichen und optionalen Management</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">Vorhandene Oracle Umgebung auf Quelle und das entsprechende Linux Betriebssystem am Zielort (DR-Standort oder Public Cloud)</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;Strong class=„big“&gt;CVO&lt;/strong&gt;</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Legen Sie auf der Oracle EC2-Instanz angemessenen Swap-Speicherplatz fest. Standardmäßig sind einige EC2-Instanzen mit 0-Swap bereitgestellt</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">*Cloud Manager/AWS*</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS Zugriff/geheimer Schlüssel</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager Konto</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager – Token für die Aktualisierung</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">Automatisierungsdetails</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">Diese automatisierte Implementierung basiert auf einem einzigen Ansible-Playbook, das aus drei separaten Rollen besteht. Rollen sind Konfigurationen von ONTAP, Linux und Oracle. In der folgenden Tabelle werden die automatisierten Aufgaben beschrieben.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Playbook</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">Aufgaben</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">*ontap_Setup*</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">Vorabprüfung der ONTAP-Umgebung</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">Erstellung von Intercluster LIFs am Quell-Cluster (OPTIONAL)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">Erstellung von Intercluster LIFs am Ziel-Cluster (OPTIONAL)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">Erstellung von Cluster- und SVM-Peering</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">Erstellung des Ziel-SnapMirror und Initialisierung designierter Oracle Volumes</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">*Ora_Replication_cg*</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">Aktivieren Sie den Backup-Modus für jede Datenbank in /etc/oratab</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Snapshot von Oracle Binary und Datenbank-Volumes erstellt</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">Snapmirror Aktualisiert</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">Deaktivieren Sie den Backup-Modus für jede Datenbank in /etc/oratab</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">*Ora_Replication_log*</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">Schalten Sie das aktuelle Protokoll für jede Datenbank in /etc/oratab um</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Snapshot vom Oracle Log Volume erstellt</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">*Ora_Erholung*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">SnapMirror unterbrechen</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">Aktivieren Sie NFS und erstellen Sie Verbindungspfad für Oracle Volumes auf dem Ziel</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">Konfigurieren Sie den Oracle-Host für DR</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Mounten und überprüfen Sie Oracle Volumes</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Stellen Sie die Oracle Datenbank wieder her und starten Sie sie</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">*cvo_Setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">Vorabprüfung der Umgebung</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS konfigurieren/AWS Zugriffsschlüssel-ID/geheimer Schlüssel/Standardregion</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">Erstellung der AWS Rolle</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">Erstellung der NetApp Cloud Manager Connector-Instanz in AWS</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">Erstellung der Cloud Volumes ONTAP-Instanz (CVO) in AWS</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">Fügen Sie ein On-Premises-Quell-ONTAP-Cluster zu NetApp Cloud Manager hinzu</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">Aktivieren Sie NFS und erstellen Sie den Verbindungspfad für Oracle Volumes auf dem Ziel-CVO</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">Standardparameter</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">Um die Automatisierung zu vereinfachen, haben wir viele erforderliche Oracle Parameter mit Standardwerten voreingestellt. In der Regel ist es nicht erforderlich, die Standardparameter für die meisten Implementierungen zu ändern. Ein fortgeschrittener Benutzer kann mit Vorsicht Änderungen an den Standardparametern vornehmen. Die Standardparameter befinden sich in jedem Rollenordner unter dem Standardverzeichnis.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">Lizenz</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Sie sollten die Lizenzinformationen wie im Github-Repository angegeben lesen. Durch Zugriff, Herunterladen, Installation oder Nutzung des Inhalts in diesem Repository stimmen Sie den Bedingungen der Lizenz zu <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">Beachten Sie, dass es bestimmte Beschränkungen bezüglich der Erstellung und/oder Freigabe abgeleiteter Werke mit dem Inhalt in diesem Repository gibt. Bitte lesen Sie die Bedingungen des <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> Vor der Verwendung des Inhalts. Wenn Sie nicht mit allen Bedingungen einverstanden sind, dürfen Sie den Inhalt in diesem Repository nicht aufrufen, herunterladen oder verwenden.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">Hier finden Sie ausführliche AWX/Tower-Verfahren</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">Klicken Sie anschließend auf <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">In diesem Abschnitt wird die Echtzeit-Implementierung einer SQL-Datenbank in einer AOAG-Konfiguration unter Verwendung eines Azure NetApp Files SMB Volume behandelt.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">High-Level-Referenzdesign in Echtzeit</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">Anzahl der Knoten: 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">Anzahl der Datenbanken: 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">Anzahl der Verfügbarkeitsgruppen: 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">Backup-Aufbewahrung: 7 Tage</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">Backup-Archiv: 365 Tage</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Durch die Implementierung von FCI mit SQL Server auf Azure Virtual Machines mit einer Azure NetApp Files-Freigabe wird ein kostengünstiges Modell mit einer einzigen Kopie der Daten bereitgestellt. Mit dieser Lösung können Probleme beim Betrieb von Add-Dateien vermieden werden, wenn sich der Dateipfad vom sekundären Replikat unterscheidet.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">Das folgende Bild zeigt die Datenbanken in AOAG, die über die Knoten verteilt sind.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Datenlayout</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">Die Benutzerdatenbank-Dateien (.mdf) und Transaktions-Log-Dateien der Benutzerdatenbank (.ldf) zusammen mit tempdb werden auf demselben Volume gespeichert. Der Service-Level ist Ultra.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">Die Konfiguration besteht aus vier Knoten und vier AGs. Alle 21 Datenbanken (Teil von Dynamic AX, SharePoint, RDS Connection Broker und Indizierungsdienste) werden auf den Azure NetApp Files Volumes gespeichert. Die Datenbanken sind zwischen den AOAG-Knoten ausgeglichen, um die Ressourcen auf den Knoten effektiv zu nutzen. Vier D32 v3-Instanzen werden im WSFC hinzugefügt, der an der AOAG-Konfiguration beteiligt ist. Diese vier Nodes werden im virtuellen Azure-Netzwerk bereitgestellt und nicht von On-Premises-Systemen migriert.</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">Wenn die Protokolle abhängig von der Art der Anwendung und den ausgeführten Abfragen mehr Performance und Durchsatz benötigen, können die Datenbankdateien auf dem Premium-Service-Level platziert werden und die Protokolle können auf dem Ultra-Service-Level gespeichert werden.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">Wenn die tempdb-Dateien auf Azure NetApp Files abgelegt wurden, sollte das Azure NetApp Files-Volume von den Benutzerdatenbankdateien getrennt werden. Hier ist eine Beispielverteilung der Datenbankdateien in AOAG.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Um die Vorteile der auf Snapshot Kopien basierenden Datensicherung weiterhin nutzen zu können, empfiehlt NetApp, Daten und Log-Daten nicht in ein einziges Volume zu kombinieren.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">Ein auf dem primären Replikat durchgef?rter Add-File-Vorgang kann auf den sekundären Datenbanken fehlschlagen, wenn sich der Dateipfad einer sekundären Datenbank vom Pfad der entsprechenden primären Datenbank unterscheidet. Dies kann passieren, wenn der Freigabepfad auf primären und sekundären Knoten unterschiedlich ist (aufgrund verschiedener Computerkonten). Der Ausfall kann dazu führen, dass die sekundären Datenbanken ausgesetzt werden. Wenn das Wachstum oder das Performance-Muster nicht vorhergesagt werden kann und der Plan darin besteht, später Dateien hinzuzufügen, ist ein SQL Server Failover-Cluster mit Azure NetApp Files eine akzeptable Lösung. Bei den meisten Implementierungen erfüllt Azure NetApp Files die Performance-Anforderungen.</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">Es gibt verschiedene Möglichkeiten, eine lokale SQL Server Benutzerdatenbank zu SQL Server in einer Azure Virtual Machine zu migrieren. Die Migration kann online oder offline sein. Die ausgewählten Optionen hängen von der SQL Server-Version, den geschäftlichen Anforderungen und den im Unternehmen definierten SLAs ab. Um Ausfallzeiten während des Datenbankmigrationsprozesses zu minimieren, empfiehlt NetApp, entweder die AlwaysOn Option oder die Option zur transaktionsorientierten Replizierung zu verwenden. Wenn es nicht möglich ist, diese Methoden zu verwenden, können Sie die Datenbank manuell migrieren.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">Der einfachste und am genauesten getestete Ansatz zum Verschieben von Datenbanken zwischen Maschinen ist Backup und Restore. In der Regel können Sie mit einem Datenbank-Backup und einer Kopie des Datenbank-Backups in Azure beginnen. Anschließend können Sie die Datenbank wiederherstellen. Um die optimale Datentransferleistung zu erzielen, migrieren Sie die Datenbankdateien mithilfe einer komprimierten Backup-Datei in die Azure VM. Das in diesem Dokument erwähnte High-Level-Design verwendet den Backup-Ansatz beim Azure-File-Storage mit Azure File Sync und stellt dann die Wiederherstellung auf Azure NetApp Files her.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Mit Azure Migrate können SQL Server-Workloads ermittelt, bewertet und migriert werden.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">Führen Sie die folgenden grundlegenden Schritte aus, um eine Migration durchzuführen:</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">Richten Sie je nach Ihren Anforderungen Konnektivität ein.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">Ein vollständiges Datenbank-Backup an einem lokalen File-Share-Speicherort</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Backup-Dateien werden mit Azure-Dateisynchronisation in eine Azure-Dateifreigabe kopiert.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">Stellen Sie die VM mit der gewünschten Version von SQL Server bereit.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">Kopieren Sie die Backup-Dateien mit der in die VM<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Befehl an einer Eingabeaufforderung.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">Stellen Sie die vollständigen Datenbanken auf SQL Server auf Azure Virtual Machines wieder her.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">Zur Wiederherstellung von 21 Datenbanken dauerte der Einsatz ungefähr neun Stunden. Dieser Ansatz ist spezifisch für dieses Szenario. Die unten aufgeführten Migrationstechniken können jedoch basierend auf Ihrer Situation und Ihren Anforderungen verwendet werden.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">Zu den anderen Migrationsoptionen, die Daten von einem lokalen SQL Server auf Azure NetApp Files verschieben, zählen:</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">Trennen Sie die Daten- und Protokolldateien, kopieren Sie sie in den Azure Blob Storage und verbinden Sie sie anschließend über die URL mit SQL Server in der Azure VM. Dabei wird eine ANF-Dateifreigabe angehängt.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Assistent Zum Hinzufügen Von Azure Replikaten</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Wenn Sie eine lokale Implementierung von Always-On-Verfügbarkeitsgruppen verwenden, verwenden Sie das<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> Um ein Replikat in Azure zu erstellen und dann Failover auszuführen.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">Transaktionsorientierte Replizierung</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">Verwenden Sie SQL Server<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Um die Azure SQL Server-Instanz als Abonnent zu konfigurieren, deaktivieren Sie die Replikation und weisen Sie Benutzer auf die Azure-Datenbankinstanz zu.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Senden Sie die Festplatte mithilfe des Windows Import/Export-Dienstes.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">Backup und Recovery</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">Backup und Recovery sind ein wichtiger Aspekt jeder SQL Server-Implementierung. Es ist zwingend erforderlich, dass das entsprechende Sicherheitsnetz in Verbindung mit Hochverfügbarkeitslösungen wie AOAG schnell von verschiedenen Datenversagen- und -Verlustszenarien wiederhergestellt wird. Zum Ausführen eines applikationskonsistenten Backups der Datenbanken können SQL Server Database Quiesce Tool, Azure Backup (Streaming) oder ein Backup-Tool eines Drittanbieters wie beispielsweise CommVault verwendet werden.</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI-Tool</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">Mit der Azure NetApp Files Snapshot Technologie können Sie ganz einfach eine zeitpunktgenaue Kopie der Benutzerdatenbanken erstellen, ohne die Performance oder Netzwerkauslastung zu beeinträchtigen. Mit dieser Technologie können Sie außerdem eine Snapshot Kopie auf einem neuen Volume wiederherstellen oder das betroffene Volume schnell auf den Zustand zurücksetzen, in dem es sich zum Zeitpunkt der Erstellung der Snapshot Kopie mithilfe der Funktion zum Zurücksetzen des Volumes befand. Der Azure NetApp Files-Snapshot-Prozess ist sehr schnell und effizient, wodurch mehrere tägliche Backups möglich sind, im Gegensatz zum Streaming Backup des Azure-Backup. Da mehrere Snapshot Kopien an einem bestimmten Tag möglich sind, lassen sich die RPO- und RTO-Zeiten erheblich reduzieren. Um die Applikationskonsistenz der intakten Daten und vor dem Erstellen der Snapshot-Kopie ordnungsgemäß auf der Festplatte zu speichern, nutzen Sie das Quiesce-Tool für die SQL Server-Datenbank <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; Für den Zugriff auf diesen Link sind NetApp SSO Login-Anmeldedaten erforderlich). Dieses Tool kann in PowerShell ausgeführt werden, das die SQL Server Datenbank enthält und wiederum die applikationskonsistente Storage Snapshot Kopie für Backups erstellen kann.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">*Hinweise: *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">Das SCSQLAPI-Tool unterstützt nur die SQL Server 2016- und 2017-Versionen.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">Das SCSQLAPI-Tool funktioniert jeweils nur mit einer Datenbank.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">Isolieren Sie die Dateien von der jeweiligen Datenbank, indem Sie sie auf einem separaten Azure NetApp Files Volume ablegen.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure Backup</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">Wegen der großen Einschränkungen der SCSQL API,<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> Wurde für die Datensicherung zur Erfüllung der SLA-Anforderungen eingesetzt. Sie bietet ein Stream-basiertes Backup von SQL Server, das in Azure Virtual Machines und Azure NetApp Files ausgeführt wird. Azure Backup ermöglicht einen RPO von 15 Minuten mit häufigen Protokoll-Backups und zeitpunktgenauer Recovery von bis zu einer Sekunde.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">Monitoring</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files ist für die Zeitreihendaten in Azure Monitor integriert und bietet Metriken zu zugewiesenem Storage, tatsächlicher Storage-Auslastung, Volume-IOPS, Durchsatz, Lesebytes/s für Festplatten, Schreibbytes/s der Festplatte, Lesen/s der Festplatte und Schreiben/s der Festplatte sowie zugehörige Latenz. Diese Daten können zur Identifizierung von Engpässen mit Alarmfunktionen und zur Durchführung von Systemprüfungen eingesetzt werden, um zu überprüfen, ob Ihre SQL Server Implementierung in einer optimalen Konfiguration ausgeführt wird.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">In dieser HLD wird ScienceLogic zur Überwachung von Azure NetApp Files verwendet, indem die Kennzahlen unter Verwendung des entsprechenden Service-Principal offengelegt werden. Das folgende Bild ist ein Beispiel für die Option Azure NetApp Files Metric.</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">DevTest mit Thick Clones</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Mit Azure NetApp Files können Sie sofortige Kopien von Datenbanken erstellen, um die Funktionalität zu testen, die mithilfe der aktuellen Datenbankstruktur und des Inhalts während der Applikationsentwicklungszyklen implementiert werden sollte. So können Sie beim Befüllen von Data Warehouses die Tools zur Datenextraktion und -Bearbeitung verwenden. Oder sogar um Daten wiederherzustellen, die versehentlich gelöscht oder geändert wurden. Bei diesem Prozess müssen Daten nicht aus Azure Blob Containern kopiert werden, was sie sehr effizient macht. Nach der Wiederherstellung des Volumes können Lese-/Schreibvorgänge genutzt werden, was die Validierung und die Produkteinführungszeit erheblich verkürzt. Dies muss in Verbindung mit SCSQLAPI verwendet werden, um die Anwendungskonsistenz zu gewährleisten. Dieser Ansatz stellt zusammen mit Azure NetApp Files eine weitere kontinuierliche Kostenoptimierung dar, die die Option „auf neues Volume wiederherstellen“ nutzt.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">Das mit der Option Neues Volume wiederherstellen erstellte Volume nutzt Kapazität aus dem Kapazitäts-Pool.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">Die geklonten Volumes können über DIE REST- oder Azure CLI gelöscht werden, um zusätzliche Kosten zu vermeiden (falls der Kapazitäts-Pool erhöht werden muss).</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">Hybrid Storage-Optionen</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">Obwohl NetApp empfiehlt, in SQL Server Verfügbarkeitsgruppen denselben Storage für alle Nodes zu verwenden, gibt es Szenarien, in denen mehrere Storage-Optionen verwendet werden können. Das Szenario ist für Azure NetApp Files möglich, bei dem ein Node in AOAG mit einer Azure NetApp Files SMB-Dateifreigabe verbunden ist und der zweite Node mit einer Azure Premium-Festplatte verbunden wird. Vergewissern Sie sich in diesen Fällen, dass die Azure NetApp Files SMB-Freigabe die primäre Kopie der Benutzerdatenbanken enthält und die Premium-Festplatte als sekundäre Kopie verwendet wird.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">In diesen Implementierungen zur Vermeidung von Failover-Problemen muss sichergestellt werden, dass die kontinuierliche Verfügbarkeit auf dem SMB Volume aktiviert ist. Ohne kontinuierlich verfügbares Attribut kann die Datenbank ausfallen, wenn Hintergrundwartung auf der Speicherebene durchgeführt wird.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">Bewahren Sie die primäre Kopie der Datenbank auf der Azure NetApp Files SMB-Dateifreigabe auf.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">Business Continuity Remote replizieren</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">Disaster Recovery ist bei jeder Implementierung im Allgemeinen ein Nebensache. Disaster Recovery muss jedoch während der ersten Design- und Implementierungsphase berücksichtigt werden, um Auswirkungen auf Ihr Geschäft zu vermeiden. Mit Azure NetApp Files kann die CRR-Funktion (Cross-Region Replication) verwendet werden, um die Volume-Daten auf Blockebene in die gepaarte Region zu replizieren, um unerwartete regionale Ausfälle zu bewältigen. Das CRR-fähige Ziel-Volume kann für Lesevorgänge verwendet werden, was es zu einem idealen Kandidaten für Disaster-Recovery-Simulationen macht. Darüber hinaus kann das CRR-Ziel mit dem niedrigsten Service-Level (z. B. Standard) zugewiesen werden, um die Gesamtbetriebskosten zu senken. Im Falle eines Failover kann die Replizierung beschädigt werden, sodass das entsprechende Volume Lese-/Schreibzugriff möglich ist. Durch dynamische Service Level-Funktionalität kann darüber hinaus der Service-Level des Volumes angepasst werden, was die Disaster Recovery-Kosten erheblich senkt. Dies ist eine weitere einzigartige Funktion von Azure NetApp Files mit Blockreplizierung in Azure.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">Langfristiges Archiv der Snapshot-Kopien</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">Viele Unternehmen müssen ihre Snapshot Daten langfristig aus Datenbankdateien aufbewahren, um Compliance-Anforderungen zu erfüllen. Obwohl dieser Prozess in dieser HLD nicht verwendet wird, kann er einfach mit einem einfachen Batch-Skript mit durchgeführt werden<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> Um das Snapshot-Verzeichnis in den Azure Blob-Container zu kopieren. Das Batch-Skript kann unter Verwendung geplanter Aufgaben nach einem bestimmten Zeitplan ausgelöst werden. Der Prozess ist unkompliziert und beinhaltet folgende Schritte:</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">Laden Sie die ausführbare Datei AzCopy V10 herunter. Es gibt nichts zu installieren, weil es ein ist<block ref="98e83379d45538379c2ac4e47c3be81d" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">Autorisieren Sie AzCopy, indem Sie ein SAS-Token auf der Containerebene mit den entsprechenden Berechtigungen verwenden.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">Nach der Autorisierung von AzCopy beginnt die Datenübertragung.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">Stellen Sie in Batch-Dateien sicher, dass die in SAS-Token angezeigten %-Zeichen nicht mehr verwendet werden. Dies kann durch Hinzufügen eines zusätzlichen %-Zeichens neben vorhandenen %-Zeichen in der SAS-Token-Zeichenfolge erreicht werden.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">Sichere Übertragung Erforderlich</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">Der<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> Die Einrichtung eines Speicherkontos bestimmt, ob die Verbindung zu einem Speicherkonto mit Transport Layer Security (TLS) gesichert ist. Diese Einstellung ist standardmäßig aktiviert. Das folgende Batch-Skript-Beispiel kopiert rekursiv Daten aus dem Verzeichnis der Snapshot-Kopie in einen festgelegten Blob-Container:</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">Das folgende Beispiel cmd wird in PowerShell ausgeführt:</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Eine ähnliche Backup-Funktion zur langfristigen Aufbewahrung wird in Kürze in Azure NetApp Files verfügbar sein.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">Das Batch-Skript kann in jedem Szenario verwendet werden, in dem Daten in den Blob-Container einer beliebigen Region kopiert werden müssen.</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">Kostenoptimierung</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">Mit Volume-Umgestaltung und der dynamischen Service Level-Änderung, die für die Datenbank vollständig transparent ist, ermöglicht Azure NetApp Files eine kontinuierliche Kostenoptimierung in Azure. Diese Funktion wird in dieser HLD umfassend eingesetzt, um eine Überprovisionierung von zusätzlichem Storage zu vermeiden, um Workload-Spitzen auszugleichen.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">Die Größe des Volumes kann einfach angepasst werden, indem eine Azure Funktion in Verbindung mit den Azure Alarmprotokollen erstellt wird.</block>
  <block id="954dcd3322a22ffd4d24f94c2d40abfc" category="doc">TR-4467: SAP with Microsoft SQL Server on Windows – Best Practices Using NetApp Clustered Data ONTAP and SnapCenter</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen, NetApp</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467 bietet Kunden und Partnern Best Practices für die Implementierung von Clustered NetApp Data ONTAP zur Unterstützung von SAP Business Suite Lösungen, die in einem Microsoft SQL Server auf Windows-Umgebungen ausgeführt werden.</block>
  <block id="39929f96a57edd550a6cb67e9fd82f26" category="inline-link-macro"><block ref="39929f96a57edd550a6cb67e9fd82f26" category="inline-link-rx"></block></block>
  <block id="e1373a4ef25d8a3dcebe3b2cff4b90b2" category="paragraph"><block ref="e1373a4ef25d8a3dcebe3b2cff4b90b2" category="inline-link-macro-rx"></block></block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">Die Agilität der Public Cloud, die Amortisierung und die Kosteneinsparungen sind sinnvolle Vorteile für Unternehmen, die sich für die Entwicklung von Datenbankapplikationen und für Tests zur Public Cloud entscheiden. Es gibt kein besseres Werkzeug als SnapCenter, um dies in Eile Realität zu machen. Mit SnapCenter können Sie Ihre Produktionsdatenbank nicht nur lokal sichern, sondern auch schnell eine Kopie für die Entwicklung von Applikationen oder Code-Tests in der Public Cloud klonen und dabei nur sehr wenig zusätzlichen Storage belegen. Im Folgenden finden Sie Details zu Schritt-für-Schritt-Prozessen mit dem Tool.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">Workflow für Entwicklungs- und Test-Bursting in die Cloud</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">Zurück: Erste Schritte mit der AWS Public Cloud</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">Die Agilität der Public Cloud, die Amortisierung und die Kosteneinsparungen sind sinnvolle Vorteile für Unternehmen, die sich für die Entwicklung und das Testen von Datenbankapplikationen durch die Public Cloud entscheiden. Es gibt kein besseres Werkzeug als SnapCenter, um dies Wirklichkeit werden zu lassen. Mit SnapCenter können Sie Ihre Produktionsdatenbank nicht nur vor Ort schützen, sondern auch schnell eine Kopie für Applikationsentwicklung oder Code-Tests in der Public Cloud klonen und belegen gleichzeitig nur sehr wenig zusätzlichen Storage. Im Folgenden finden Sie Details zu den Schritt-für-Schritt-Prozessen für dieses Tool.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">Klonen einer Oracle Datenbank für Entwicklungs- und Testzwecke aus einem replizierten Snapshot Backup</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Melden Sie sich mit einer Datenbank-Management-Benutzer-ID für Oracle bei SnapCenter an. Öffnen Sie die Registerkarte Ressourcen, auf der die von SnapCenter geschützten Oracle-Datenbanken angezeigt werden.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">Klicken Sie auf den gewünschten Namen der lokalen Datenbank für die Backup-Topologie und die detaillierte Ansicht. Wenn ein sekundärer replizierter Standort aktiviert ist, werden verknüpfte Spiegelsicherungen angezeigt.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">Klicken Sie auf „gespiegelte Backups“, um zur Ansicht „gespiegelte Backups“ zu gelangen. Anschließend werden die Backup(s) der sekundären Spiegelung angezeigt.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">Wählen Sie eine gespiegelte sekundäre Datenbank-Backup-Kopie, die geklont werden soll, und legen Sie einen Recovery-Zeitpunkt entweder nach Zeit- und Systemänderungsnummer oder nach SCN fest. Im Allgemeinen sollte der Recovery-Zeitpunkt hinter der vollständigen Datenbank-Backup-Zeit zurückliegen oder SCN zum Klonen stehen. Nach der Entscheidung für einen Wiederherstellungspunkt muss die erforderliche Protokolldatei-Sicherung für die Wiederherstellung eingebunden werden. Die Sicherung der Protokolldatei sollte auf dem Ziel-DB-Server gemountet werden, auf dem die Klondatenbank gehostet werden soll.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">Wenn die Protokollbeschneidung aktiviert ist und der Wiederherstellungspunkt über den letzten Protokollschnitt hinaus erweitert wird, müssen möglicherweise mehrere Archiv-Log-Backups eingebunden werden.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">Markieren Sie die vollständige Datenbank-Backup-Kopie, die geklont werden soll, und klicken Sie dann auf die Schaltfläche Klonen, um den DB-Klon-Workflow zu starten.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">Wählen Sie eine geeignete Klon-DB-SID für eine vollständige Container-Datenbank oder einen CDB-Klon.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">Wählen Sie den Zielklonhost in der Cloud aus, und Datendatei, Kontrolldatei und Wiederherstellungsprotokolle werden vom Klon-Workflow erstellt.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">Der Name für keine Anmeldeinformationen wird für die BS-basierte Authentifizierung verwendet, wodurch der Datenbankport irrelevant wird. Geben Sie die korrekte Oracle Home, Oracle OS User und Oracle OS Group ein, wie im Klon-DB-Server konfiguriert.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">Geben Sie die vor dem Klonvorgang zu ausführenden Skripte an. Vor allem kann hier der Parameter der Datenbankinstanz angepasst oder definiert werden.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">Geben Sie den Wiederherstellungspunkt entweder mit Datum und Uhrzeit oder mit SCN an. Bis Abbrechen die Datenbank bis zu den verfügbaren Archivprotokollen wiederherstellt. Geben Sie den externen Speicherort für das Archivprotokoll vom Zielhost an, auf dem das Archiv-Protokoll-Volume angehängt ist. Wenn sich der Oracle-Eigentümer des Zielservers von dem lokalen Produktionsserver unterscheidet, überprüfen Sie, ob das Archivprotokollverzeichnis vom Oracle Eigentümer des Zielservers lesbar ist.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">Konfigurieren Sie bei Bedarf den SMTP-Server für E-Mail-Benachrichtigungen.</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">Zusammenfassung des Klons:</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">Sie sollten nach dem Klonen validieren, um sicherzustellen, dass die geklonte Datenbank funktionsfähig ist. Einige zusätzliche Aufgaben, wie z. B. das Starten des Listeners oder das Deaktivieren des DB-Log-Archivmodus, können an der Entwicklungs-/Testdatenbank ausgeführt werden.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">Klonen einer SQL Datenbank für Entwicklungs- und Testzwecke aus einem replizierten Snapshot Backup</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">Melden Sie sich mit einer Datenbank-Management-Benutzer-ID für SQL Server bei SnapCenter an. Navigieren Sie zur Registerkarte Ressourcen, die die SQL Server-Benutzerdatenbanken anzeigt, die durch SnapCenter geschützt sind, und eine Ziel-Standby-SQL-Instanz in der Public Cloud.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">Klicken Sie auf den gewünschten lokalen Namen der SQL Server-Benutzerdatenbank für die Backup-Topologie und die detaillierte Ansicht. Wenn ein sekundärer replizierter Standort aktiviert ist, werden verknüpfte Spiegelsicherungen angezeigt.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">Wechseln Sie zur Ansicht gespiegelte Backups, indem Sie auf gespiegelte Backups klicken. Sekundäre Spiegelsicherung(en) werden angezeigt. Da SnapCenter das Transaktions-Log von SQL Server auf einem dedizierten Laufwerk für die Wiederherstellung sichert, werden hier nur vollständige Datenbank-Backups angezeigt.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">Wählen Sie eine Backup-Kopie aus, und klicken Sie dann auf die Schaltfläche Klonen, um den Klon aus dem Backup-Workflow zu starten.</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">Wählen Sie einen Cloud-Server als Ziel-Klonserver, als Kloninstanz und als Name der Klondatenbank aus. Wählen Sie entweder einen Mount-Punkt für die automatische Zuweisung oder einen benutzerdefinierten Mount-Point-Pfad.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">Legen Sie einen Recovery-Zeitpunkt entweder um eine Backup-Zeit für das Protokoll oder um ein bestimmtes Datum und eine bestimmte Uhrzeit fest.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">Legen Sie optionale Skripte fest, die vor und nach dem Klonvorgang ausgeführt werden sollen.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">Konfigurieren Sie einen SMTP-Server, wenn eine E-Mail-Benachrichtigung gewünscht wird.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">Zusammenfassung Klonen.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">Überwachen Sie den Job-Status und überprüfen Sie, ob die vorgesehene Benutzerdatenbank mit einer Ziel-SQL-Instanz im Cloud-Klon-Server verbunden wurde.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">Konfiguration nach dem Klonen</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">Eine lokale Oracle Produktionsdatenbank wird normalerweise im Protokollarchivierungsmodus ausgeführt. Dieser Modus ist für eine Entwicklungs- oder Testdatenbank nicht erforderlich. Um den Protokollarchivmodus zu deaktivieren, melden Sie sich als sysdba in der Oracle DB an, führen Sie einen Änderungsbefehl für den Protokollmodus aus, und starten Sie die Datenbank für den Zugriff.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Konfigurieren Sie einen Oracle-Listener oder registrieren Sie die neu geklonte DB für den Benutzerzugriff mit einem vorhandenen Listener.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">Ändern Sie für SQL Server den Protokollmodus von „voll“ in „einfach“, sodass die SQL Server Entwicklungs-/Test-Protokolldatei problemlos verkleinert werden kann, wenn sie das Protokoll-Volume füllt.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">Klondatenbank aktualisieren</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">Ablegen geklonter Datenbanken und Bereinigen der Serverumgebung der Cloud-Datenbanken. Anschließend sollten Sie eine neue DB mit frischen Daten klonen. Das Klonen einer neuen Datenbank dauert nur wenige Minuten.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">Aktualisieren Sie einen Klon</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">Fahren Sie die Klondatenbank herunter, führen Sie mit der CLI einen Befehl zur Klonaktualisierung aus. Einzelheiten finden Sie in der folgenden SnapCenter-Dokumentation: <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">Wenn Sie Hilfe bei dieser Lösung und bei den Anwendungsfällen benötigen, treten Sie dem bei <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> Und suchen Sie den Kanal zur Lösungsautomatisierung, um Ihre Fragen zu stellen oder zu fragen.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">Weiter: Disaster-Recovery-Workflow.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">Das NetApp SnapCenter Tool verwendet die rollenbasierte Zugriffssteuerung (RBAC) zum Management der Benutzerressourcen für den Zugriff und die Berechtigungszuschüsse. SnapCenter Installationen erstellen vorbestückte Rollen. Sie können auch benutzerdefinierte Rollen erstellen, die Ihren Anforderungen oder Applikationen entsprechen.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">Erste Schritte vor Ort</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">Zurück: Erste Schritte Übersicht.</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. Einrichten Datenbank Admin Benutzer in SnapCenter</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">Das NetApp SnapCenter Tool verwendet eine rollenbasierte Zugriffssteuerung (RBAC) zum Managen der Benutzerressourcen-Zuschüsse und Berechtigungszuschüsse. SnapCenter Installationen erstellen vorbestückte Rollen. Sie können auch benutzerdefinierte Rollen erstellen, die Ihren Anforderungen oder Applikationen entsprechen. Es ist sinnvoll, eine dedizierte Admin-Benutzer-ID für jede von SnapCenter unterstützte Datenbankplattform zur Sicherung, Wiederherstellung und/oder Disaster Recovery von Datenbanken zu haben. Sie können auch eine einzige ID zum Managen aller Datenbanken verwenden. In unseren Test-Cases und Demos haben wir für Oracle und SQL Server einen dedizierten Admin-Benutzer erstellt.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">Bestimmte SnapCenter Ressourcen können nur mit der Funktion „SnapCenterAdmin“ bereitgestellt werden. Ressourcen können dann anderen Benutzer-IDs für den Zugriff zugewiesen werden.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">In einer vorkonfigurierten und konfigurierten lokalen SnapCenter-Umgebung wurden möglicherweise die folgenden Aufgaben bereits ausgeführt. Wenn nicht, erstellen Sie mit den folgenden Schritten einen Datenbank-Admin-Benutzer:</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Fügen Sie den Admin-Benutzer zu Windows Active Directory hinzu.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">Melden SnapCenter Sie sich mit einer ID an, die mit der SnapCenterAdmin-Rolle erteilt wurde.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">Navigieren Sie zur Registerkarte Zugriff unter Einstellungen und Benutzer, und klicken Sie auf Hinzufügen, um einen neuen Benutzer hinzuzufügen. Die neue Benutzer-ID ist mit dem in Windows Active Directory in Schritt 1 erstellten Admin-Benutzer verknüpft. . Weisen Sie dem Benutzer nach Bedarf die richtige Rolle zu. Weisen Sie dem Admin-Benutzer nach Bedarf Ressourcen zu.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. Installationsvoraussetzungen für das SnapCenter Plugin</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter führt Backup, Wiederherstellung, Klonen und weitere Funktionen mithilfe eines Plug-in-Agenten aus, der auf den DB-Hosts ausgeführt wird. Er verbindet sich mit dem Datenbank-Host und der Datenbank über Anmeldeinformationen, die unter der Registerkarte Einstellungen und Anmeldeinformationen für die Plugin-Installation und andere Verwaltungsfunktionen konfiguriert sind. Es gibt spezielle Berechtigungsanforderungen auf der Grundlage des Ziel-Host-Typs, wie Linux oder Windows, sowie der Datenbanktyp.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">DB Hosts die Zugangsdaten müssen vor der SnapCenter Plugin-Installation konfiguriert werden. In der Regel möchten Sie ein Administrator-Benutzerkonto auf dem DB-Host als Ihre Host-Verbindungsdaten für die Plugin-Installation verwenden. Sie können auch dieselbe Benutzer-ID für den Datenbankzugriff über die BS-basierte Authentifizierung gewähren. Auf der anderen Seite können Sie auch Datenbank-Authentifizierung mit verschiedenen Datenbank-Benutzer-IDs für DB-Management-Zugriff. Wenn Sie sich für die Verwendung der OS-basierten Authentifizierung entscheiden, muss der BS-Admin-Benutzer-ID DB-Zugriff gewährt werden. Für die Windows-domänenbasierte SQL Server-Installation kann ein Domain-Administratorkonto verwendet werden, um alle SQL-Server innerhalb der Domäne zu verwalten.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">Windows Host für SQL Server:</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">Wenn Sie Windows-Anmeldeinformationen zur Authentifizierung verwenden, müssen Sie die Anmeldedaten vor dem Installieren von Plug-ins einrichten.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">Wenn Sie eine SQL Server-Instanz zur Authentifizierung verwenden, müssen Sie die Anmeldeinformationen nach der Installation von Plugins hinzufügen.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">Wenn Sie die SQL-Authentifizierung beim Einrichten der Anmeldeinformationen aktiviert haben, wird die erkannte Instanz oder Datenbank mit einem roten Sperrsymbol angezeigt. Wenn das Sperrsymbol angezeigt wird, müssen Sie die Instanz oder die Datenbankanmeldeinformationen angeben, um die Instanz oder Datenbank einer Ressourcengruppe erfolgreich hinzuzufügen.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">Sie müssen die Anmeldedaten einem RBAC-Benutzer ohne sysadmin-Zugriff zuweisen, wenn die folgenden Bedingungen erfüllt sind:</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">Die Anmeldeinformationen werden einer SQL-Instanz zugewiesen.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">Die SQL Instanz oder der Host wird einem RBAC-Benutzer zugewiesen.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">Der RBAC-DB-Admin-Benutzer muss sowohl die Gruppen- als auch die Backup-Rechte besitzen.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">UNIX Host für Oracle:</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">Sie müssen die passwortbasierte SSH-Verbindung für den Root- oder nicht-Root-Benutzer aktiviert haben, indem Sie sshd.conf bearbeiten und den sshd-Dienst neu starten. Die passwortbasierte SSH-Authentifizierung für die AWS-Instanz ist standardmäßig deaktiviert.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">Konfigurieren Sie die Sudo-Berechtigungen für den nicht-Root-Benutzer, um den Plug-in-Prozess zu installieren und zu starten. Nach der Installation des Plugins werden die Prozesse als effektiver Root-Benutzer ausgeführt.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">Erstellen Sie Anmeldedaten im Linux-Authentifizierungsmodus für den Installationsbenutzer.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Sie müssen Java 1.8.x (64-bit) auf Ihrem Linux-Host installieren.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">Die Installation des Oracle Database Plugins installiert auch das SnapCenter Plugin für Unix.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. SnapCenter Host Plugin Installation</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">Bevor Sie versuchen, SnapCenter-Plugins auf Cloud-DB-Serverinstanzen zu installieren, stellen Sie sicher, dass alle Konfigurationsschritte wie im entsprechenden Cloud-Abschnitt für die Bereitstellung von Computing-Instanzen aufgeführt abgeschlossen wurden.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">Die folgenden Schritte veranschaulichen, wie ein Datenbank-Host zu SnapCenter hinzugefügt wird, während ein SnapCenter-Plugin auf dem Host installiert ist. Das Verfahren gilt für das Hinzufügen von On-Premises-Hosts und Cloud-Hosts. Die folgende Demonstration führt zu einem Windows- oder Linux-Host in AWS.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">Konfigurieren Sie die globalen Einstellungen von SnapCenter VMware</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">Navigieren Sie zu Einstellungen &gt; Globale Einstellungen. Wählen Sie unter Hypervisor-Einstellungen „VMs verfügen über direkt verbundene iSCSI-Festplatten oder NFS für alle Hosts“ aus und klicken Sie auf „Update“.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Fügen Sie den Windows-Host und die Installation des Plugins auf dem Host hinzu</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">Melden Sie sich mit einer Benutzer-ID mit SnapCenterAdmin-Berechtigungen beim SnapCenter an.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">Klicken Sie im linken Menü auf die Registerkarte Hosts und dann auf Hinzufügen, um den Host-Workflow hinzufügen zu öffnen.</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">Wählen Sie Windows für den Hosttyp. Der Hostname kann entweder ein Hostname oder eine IP-Adresse sein. Der Hostname muss vom SnapCenter-Host auf die richtige Host-IP-Adresse aufgelöst werden. Wählen Sie die in Schritt 2 erstellten Hostanmeldeinformationen aus. Wählen Sie Microsoft Windows und Microsoft SQL Server als die zu installierenden Plugin-Pakete.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Nach der Installation des Plug-ins auf einem Windows-Host wird sein Gesamtstatus als „Protokollverzeichnis konfigurieren“ angezeigt.</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">Klicken Sie auf den Hostnamen, um die Konfiguration des SQL Server-Protokollverzeichnisses zu öffnen.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">Klicken Sie auf „Protokollverzeichnis konfigurieren“, um „Plug-in für SQL Server konfigurieren“ zu öffnen.</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">Klicken Sie auf Browse, um NetApp Storage zu entdecken, so dass ein Log-Verzeichnis eingestellt werden kann; SnapCenter verwendet dieses Log-Verzeichnis, um die Transaktions-Log-Dateien für SQL Server zu öffnen. Klicken Sie dann auf Speichern.</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">Wenn NetApp Storage, der einem DB-Host zur Ermittlung bereitgestellt wird, hinzugefügt werden soll, muss der Storage (On-Prem oder CVO) zum SnapCenter hinzugefügt werden, wie in Schritt 6 für CVO als Beispiel dargestellt.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">Nach der Konfiguration des Protokollverzeichnisses wird der Gesamtstatus des Windows-Host-Plug-ins in „Ausführen“ geändert.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">Um den Host der Benutzer-ID der Datenbankverwaltung zuzuweisen, navigieren Sie zur Registerkarte Zugriff unter Einstellungen und Benutzer, klicken Sie auf die Datenbank-Management-Benutzer-ID (in unserem Fall der sqldba, dem der Host zugewiesen werden muss), und klicken Sie auf Speichern, um die Host-Ressourcenzuweisung abzuschließen.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Fügen Sie den Unix-Host hinzu und installieren Sie das Plugin auf dem Host</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">Klicken Sie im linken Menü auf die Registerkarte Hosts, und klicken Sie auf Hinzufügen, um den Host-Workflow hinzufügen zu öffnen.</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">Wählen Sie Linux als Host-Typ. Der Hostname kann entweder der Hostname oder eine IP-Adresse sein. Der Host-Name muss jedoch aufgelöst werden, um die Host-IP-Adresse vom SnapCenter-Host zu korrigieren. Wählen Sie die in Schritt 2 erstellten Hostanmeldeinformationen aus. Die Hostanmeldeinformationen erfordern Sudo-Berechtigungen. Überprüfen Sie Oracle Database als das zu installierende Plug-in, das sowohl Oracle- als auch Linux-Host-Plug-ins installiert.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">Klicken Sie auf Weitere Optionen und wählen Sie „Prüfung vor der Installation überspringen“. Sie werden aufgefordert, das Überspringen der Vorinstallationsüberprüfung zu bestätigen. Klicken Sie auf Ja und dann auf Speichern.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Klicken Sie auf Senden, um die Plugin-Installation zu starten. Sie werden wie unten gezeigt aufgefordert, den Fingerabdruck zu bestätigen.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter führt die Host-Validierung und -Registrierung durch, anschließend wird das Plug-in auf dem Linux Host installiert. Der Status wird von Plugin installieren auf Ausführen geändert.</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">Weisen Sie den neu hinzugefügten Host der korrekten Datenbank-Management-Benutzer-ID zu (in unserem Fall oradba).</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. Ermittlung von Datenbankressourcen</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">Bei erfolgreicher Plugin-Installation können die Datenbankressourcen auf dem Host sofort erkannt werden. Klicken Sie im linken Menü auf die Registerkarte Ressourcen. Je nach Typ der Datenbankplattform stehen verschiedene Ansichten zur Verfügung, z. B. die Datenbank, die Ressourcengruppe usw. Möglicherweise müssen Sie auf die Registerkarte Ressourcen aktualisieren klicken, wenn die Ressourcen auf dem Host nicht erkannt und angezeigt werden.</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">Wenn die Datenbank zunächst erkannt wird, wird der Gesamtstatus als „nicht geschützt“ angezeigt. Der vorherige Screenshot zeigt eine Oracle Datenbank, die noch nicht durch eine Sicherungsrichtlinie geschützt ist.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">Wenn eine Backup-Konfiguration oder -Richtlinie eingerichtet und ein Backup ausgeführt wurde, zeigt der Gesamtstatus der Datenbank den Backup-Status als „Backup erfolgreich“ und den Zeitstempel des letzten Backups an. Der folgende Screenshot zeigt den Sicherungsstatus einer SQL Server Benutzerdatenbank.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">Wenn die Anmeldeinformationen für den Datenbankzugriff nicht ordnungsgemäß eingerichtet sind, zeigt eine rote Sperrtaste an, dass auf die Datenbank nicht zugegriffen werden kann. Wenn beispielsweise Windows-Anmeldeinformationen keinen sysadmin-Zugriff auf eine Datenbankinstanz haben, müssen die Datenbankanmeldeinformationen neu konfiguriert werden, um die rote Sperre zu entsperren.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Nachdem die entsprechenden Anmeldeinformationen entweder auf Windows-Ebene oder auf Datenbankebene konfiguriert wurden, wird das rote Schloss ausgeblendet und Informationen zum SQL Server-Typ gesammelt und überprüft.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. Storage Cluster-Peering und DB Volumes Replication einrichten</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">Um Ihre On-Premises-Datenbankdaten mithilfe einer Public Cloud als Ziel zu schützen, werden On-Premises ONTAP Cluster-Datenbank-Volumes mithilfe von NetApp SnapMirror Technologie in die Cloud-CVO repliziert. Die replizierten Ziel-Volumes können dann für ENTWICKLUNG/Betrieb oder Disaster Recovery geklont werden. Mit den folgenden grundlegenden Schritten können Sie Cluster-Peering und DB-Volumes-Replikation einrichten.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">Konfigurieren Sie Intercluster LIFs für Cluster-Peering sowohl auf dem On-Premises-Cluster als auch auf der CVO-Cluster-Instanz. Dieser Schritt kann mit ONTAP System Manager ausgeführt werden. In einer CVO-Standardimplementierung werden automatisch Inter-Cluster-LIFs konfiguriert.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">On-Premises-Cluster:</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">Ziel-CVO-Cluster:</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">Erste Schritte – AWS Public Cloud</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">Bei konfigurierten Intercluster LIFs können Cluster-Peering und Volume-Replizierung mithilfe von Drag-and-Drop in NetApp Cloud Manager eingerichtet werden. Siehe <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> Entsprechende Details.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">Alternativ können Cluster-Peering und die Replizierung von DB-Volumes mithilfe von ONTAP System Manager wie folgt durchgeführt werden:</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">Melden Sie sich bei ONTAP System Manager an. Navigieren Sie zu Cluster &gt; Einstellungen, und klicken Sie auf Peer Cluster, um Cluster-Peering mit der CVO-Instanz in der Cloud einzurichten.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Wechseln Sie zur Registerkarte Volumes. Wählen Sie das zu replizierende Datenbank-Volume aus, und klicken Sie auf „Schützen“.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">Legen Sie die Schutzrichtlinie auf Asynchronous fest. Wählen Sie das Ziel-Cluster und die Storage-SVM aus.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">Überprüfen Sie, ob das Volume zwischen Quelle und Ziel synchronisiert wird und ob die Replikationsbeziehung ordnungsgemäß ist.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. CVO Datenbank-Storage-SVM zu SnapCenter hinzufügen</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">Klicken Sie im Menü auf die Registerkarte Storage-System und dann auf Neu, um eine CVO-Storage-SVM hinzuzufügen, die replizierte Ziel-Datenbank-Volumes als Host für SnapCenter hostet. Geben Sie im Feld Storage-System die Cluster-Management-IP ein, und geben Sie den entsprechenden Benutzernamen und das entsprechende Passwort ein.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">Klicken Sie auf Mehr Optionen, um weitere Storage-Konfigurationsoptionen zu öffnen. Wählen Sie im Feld Plattform die Option Cloud Volumes ONTAP aus, aktivieren Sie Sekundär und klicken Sie dann auf Speichern.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">Weisen Sie die Storage-Systeme den Benutzer-IDs der SnapCenter-Datenbankverwaltung zu, wie in dargestellt <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. Einrichten der Datenbank Backup Policy in SnapCenter</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">Die folgenden Verfahren zeigen, wie eine vollständige Datenbank oder Backup-Richtlinie für Protokolldateien erstellt wird. Die Richtlinie kann dann zum Schutz von Datenbankressourcen implementiert werden. Der Recovery Point Objective (RPO) oder das Recovery Time Objective (RTO) bestimmt die Häufigkeit der Datenbank- und/oder Protokoll-Backups.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Erstellen einer vollständigen Datenbank-Backup-Richtlinie für Oracle</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">Melden Sie sich bei SnapCenter als Benutzer-ID für die Datenbankverwaltung an, klicken Sie auf Einstellungen und klicken Sie dann auf Richtlinien.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">Klicken Sie auf Neu, um einen Workflow für die Erstellung einer neuen Backup-Richtlinie zu starten oder eine vorhandene Richtlinie zur Änderung auszuwählen.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">Wählen Sie den Sicherungstyp und die Zeitplanfrequenz aus.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">Legen Sie die Einstellung für die Backup-Aufbewahrung fest. Dies definiert, wie viele vollständige Datenbank-Backup-Kopien aufzubewahren sind.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">Wählen Sie die sekundären Replizierungsoptionen aus, um lokale primäre Snapshots zu verschieben, die an einen sekundären Standort in der Cloud repliziert werden sollen.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">Geben Sie ein optionales Skript an, das vor und nach einer Sicherungsfahrt ausgeführt werden soll.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">Führen Sie bei Bedarf eine Backup-Überprüfung durch.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">Zusammenfassung.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Erstellen Sie eine Backup-Richtlinie für Datenbankprotokolle für Oracle</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">Melden Sie sich mit einer Benutzer-ID für die Datenbankverwaltung bei SnapCenter an, klicken Sie auf Einstellungen und klicken Sie dann auf Richtlinien.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">Klicken Sie auf Neu, um einen Workflow für die Erstellung einer neuen Backup-Richtlinie zu starten, oder wählen Sie eine vorhandene Richtlinie zur Änderung aus.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">Legen Sie den Aufbewahrungszeitraum für das Protokoll fest.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">Aktivieren Sie die Replizierung an einen sekundären Standort in der Public Cloud.</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">Geben Sie alle optionalen Skripts an, die vor und nach der Protokollsicherung ausgeführt werden sollen.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">Geben Sie alle Skripts für die Backup-Überprüfung an.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">Erstellen einer vollständigen Datenbank-Backup-Richtlinie für SQL</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">Legen Sie die Backup-Option fest und planen Sie die Häufigkeit. Für SQL Server, der mit einer Verfügbarkeitsgruppe konfiguriert ist, kann ein bevorzugtes Backup-Replikat festgelegt werden.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">Legen Sie den Aufbewahrungszeitraum für Backups fest.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">Replizierung von Backup-Kopien an einen sekundären Standort in der Cloud aktivieren</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">Geben Sie alle optionalen Skripts an, die vor oder nach einem Backupjob ausgeführt werden sollen.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">Geben Sie die Optionen für die Ausführung der Backup-Überprüfung an.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">Erstellen Sie eine Backup-Richtlinie für Datenbankprotokolle für SQL.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">Melden Sie sich mit einer Benutzer-ID für die Datenbankverwaltung bei SnapCenter an, klicken Sie auf Einstellungen &gt; Richtlinien und dann auf Neu, um einen Workflow zur Erstellung neuer Richtlinien zu starten.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">Legen Sie die Option zur Protokollsicherung fest und planen Sie die Häufigkeit. Für SQL Server, der mit einer Verfügbarkeitsgruppe konfiguriert ist, kann ein bevorzugtes Backup-Replikat festgelegt werden.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">Die SQL Server Daten-Backup-Richtlinie definiert die Backup-Aufbewahrung für Protokolle. Akzeptieren Sie hier die Standardeinstellungen.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">Aktivierung der Backup-Replizierung für Protokolle in der sekundären Umgebung in der Cloud</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. Backup Policy implementieren, um Datenbank zu schützen</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter verwendet eine Ressourcengruppe, um eine Datenbank in einer logischen Gruppierung von Datenbankressourcen zu sichern, z. B. mehrere Datenbanken, die auf einem Server gehostet werden, eine Datenbank, die dieselben Storage Volumes nutzt, mehrere Datenbanken zur Unterstützung einer Business-Applikation usw. Durch den Schutz einer einzigen Datenbank wird eine eigene Ressourcengruppen erzeugt. Die folgenden Verfahren veranschaulichen die Implementierung einer in Abschnitt 7 erstellten Backup-Richtlinie zum Schutz von Oracle- und SQL Server-Datenbanken.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Erstellen Sie eine Ressourcengruppe für vollständige Oracle-Backups</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">Melden Sie sich mit einer Benutzer-ID für die Datenbankverwaltung bei SnapCenter an und navigieren Sie zur Registerkarte „Ressourcen“. Wählen Sie in der Dropdown-Liste Ansicht entweder Datenbank oder Ressourcengruppe aus, um den Arbeitsablauf für die Erstellung von Ressourcengruppen zu starten.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">Geben Sie einen Namen und Tags für die Ressourcengruppe an. Sie können ein Benennungsformat für die Snapshot Kopie definieren und, falls konfiguriert, das redundante Archivprotokollziel umgehen.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">Fügen Sie der Ressourcengruppe Datenbankressourcen hinzu.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">Wählen Sie aus der Dropdown-Liste eine vollständige Backup Policy aus, die in Abschnitt 7 erstellt wurde.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">Klicken Sie auf das Pluszeichen (+), um den gewünschten Backup-Zeitplan zu konfigurieren.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Klicken Sie auf Lokatoren laden, um das Quell- und Zielvolume zu laden.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Erstellen Sie eine Ressourcengruppen für das Protokoll-Backup von Oracle</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">Wählen Sie aus der Dropdown-Liste eine Protokoll-Backup-Richtlinie aus, die in Abschnitt 7 erstellt wurde.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">Klicken Sie auf das Pluszeichen (+), um den gewünschten Backup-Zeitplan zu konfigurieren.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">Wenn die Backup-Überprüfung konfiguriert ist, wird sie hier angezeigt.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">Konfigurieren Sie bei Bedarf einen SMTP-Server für E-Mail-Benachrichtigungen.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">Erstellen Sie eine Ressourcengruppe für die vollständige Sicherung von SQL Server</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">Melden Sie sich mit einer Benutzer-ID für die Datenbankverwaltung bei SnapCenter an und navigieren Sie zur Registerkarte „Ressourcen“. Wählen Sie in der Dropdown-Liste Ansicht entweder eine Datenbank oder eine Ressourcengruppe aus, um den Arbeitsablauf für die Erstellung von Ressourcengruppen zu starten. Geben Sie einen Namen und Tags für die Ressourcengruppe an. Sie können ein Benennungsformat für die Snapshot Kopie definieren.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">Wählen Sie die zu sichernden Datenbankressourcen aus.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">Wählen Sie eine vollständige SQL-Backup-Richtlinie aus, die in Abschnitt 7 erstellt wurde.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">Fügen Sie sowohl den genauen Zeitpunkt für Backups als auch die Häufigkeit hinzu.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">Wählen Sie den Verifizierungsserver für das Backup auf dem sekundären aus, wenn eine Backup-Überprüfung durchgeführt werden soll. Klicken Sie auf Load Locator, um den sekundären Speicherort zu füllen.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">Erstellen Sie eine Ressourcengruppe für die Protokollsicherung von SQL Server</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">Melden Sie sich mit einer Benutzer-ID für die Datenbankverwaltung bei SnapCenter an und navigieren Sie zur Registerkarte „Ressourcen“. Wählen Sie in der Dropdown-Liste Ansicht entweder eine Datenbank oder eine Ressourcengruppe aus, um den Arbeitsablauf für die Erstellung von Ressourcengruppen zu starten. Geben Sie den Namen und die Tags für die Ressourcengruppe an. Sie können ein Benennungsformat für die Snapshot Kopie definieren.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">Wählen Sie eine in Abschnitt 7 erstellte SQL-Protokoll-Backup-Richtlinie aus.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">Fügen Sie den genauen Zeitpunkt für das Backup sowie die Häufigkeit hinzu.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">Wählen Sie den Verifizierungsserver für das Backup auf dem sekundären aus, wenn eine Backup-Überprüfung durchgeführt werden soll. Klicken Sie auf Load Locator, um den sekundären Speicherort zu füllen.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. Sicherung validieren</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">Nachdem Datenbanksicherungsressourcengruppen zum Schutz von Datenbankressourcen erstellt wurden, werden die Backupjobs gemäß dem vordefinierten Zeitplan ausgeführt. Überprüfen Sie den Status der Auftragsausführung auf der Registerkarte Überwachung.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">Wechseln Sie zur Registerkarte Ressourcen, klicken Sie auf den Datenbanknamen, um Details zum Datenbank-Backup anzuzeigen, und wechseln Sie zwischen lokalen Kopien und gespiegelten Kopien. So überprüfen Sie, ob Snapshot Backups an einem sekundären Standort in der Public Cloud repliziert werden.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">Zu diesem Zeitpunkt sind Datenbank-Backup-Kopien in der Cloud bereit für das Klonen, um Entwicklungs-/Testprozesse auszuführen oder um bei einem primären Ausfall eine Disaster Recovery durchzuführen.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">Weiter: Erste Schritte mit der AWS Public Cloud</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">Diese Lösung wurde für die Ausführung in einer AWX/Tower-Umgebung oder über CLI auf einem Ansible-Kontroll-Host entwickelt.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">Die Job-Vorlage wird in drei Phasen ausgeführt, indem Tags für ontap_config, linux_config und oracle_config angegeben werden.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">CLI über den Ansible-Steuerhost</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">Klicken Sie hier für RHEL 7/8 oder CentOS 7/8</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Hier für Ubuntu/Debian</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Konfigurieren des Linux-Hosts, sodass er als Ansible-Steuerhost verwendet werden kann<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>, Oder<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Nach der Konfiguration des Ansible-Steuerhosts können Sie das Ansible Automation-Repository git klonen.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">Bearbeiten Sie die Hostdatei mit den IPs und/oder Hostnamen Ihrer ONTAP-Clusterverwaltung und der Management-IPs des Oracle-Servers.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">Geben Sie die Variablen ein, die für Ihre Umgebung spezifisch sind, und kopieren Sie sie in die<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">Jeder Oracle Host verfügt über eine variable Datei, die über einen Hostnamen mit Host-spezifischen Variablen identifiziert wird.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">Nachdem alle variablen Dateien abgeschlossen wurden, können Sie das Playbook in drei Phasen ausführen, indem Sie Tags für angeben<block ref="0aadb2735557202c6ab978c489e2b6e9" prefix=" " category="inline-code"></block>,<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block>, und<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block>.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">AWX/Tower- oder Linux-Host, um der Ansible-Steuerungshost zu sein</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP Version 9.3 - 9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle Installationsdateien auf Oracle Servern</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Rolle</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">*ontap_config*</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Erstellung NFS-basierter SVM für Oracle</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">Erstellung einer Exportrichtlinie</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Erstellung von Volumes für Oracle</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">Erstellung von NFS LIFs</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">Erstellen von Bereitstellungspunkten und Mounten von NFS Volumes</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">Überprüfen Sie die NFS-Mounts</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">OS-spezifische Konfiguration</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Erstellen von Oracle Verzeichnissen</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">konfigurieren Sie hugepages</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">Deaktivieren Sie SELinux und den Firewall-Daemon</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">Aktivieren und starten Sie den Chronyd-Dienst</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">Erhöhen Sie die harte Grenze für den Dateideskriptor</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">Erstellen Sie eine pam.d-Sitzungsdatei</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">*oracle_config*</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle Software-Installation</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Oracle Listener erstellen</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Erstellen Sie Oracle Datenbanken</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Konfiguration der Oracle Umgebung</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">PDB-Status speichern</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">Aktivieren Sie den Instanzarchivierungsmodus</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">Aktivieren Sie den DNFS-Client</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">Aktivieren Sie das automatische Starten und Herunterfahren der Datenbank zwischen einem Neustart des Betriebssystems</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">Um die Automatisierung zu vereinfachen, haben wir viele erforderliche Oracle Implementierungsparameter mit Standardwerten voreingestellt. In der Regel ist es nicht erforderlich, die Standardparameter für die meisten Implementierungen zu ändern. Ein fortgeschrittener Benutzer kann mit Vorsicht Änderungen an den Standardparametern vornehmen. Die Standardparameter befinden sich in jedem Rollenordner unter dem Standardverzeichnis.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">Implementierungsanleitungen</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">Laden Sie vor dem Start die folgenden Oracle-Installations- und Patch-Dateien herunter, und legen Sie sie in den ein<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> Verzeichnis mit Lese-, Schreib- und Lesezugriff für alle Benutzer auf jedem zu implementierenden DB-Server Die Automatisierungsaufgaben suchen nach den benannten Installationsdateien in diesem speziellen Verzeichnis für die Installation und Konfiguration von Oracle.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">Hier finden Sie ausführliche AWX/Tower-Implementierungsverfahren</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">Hier geht es zur CLI-Implementierung</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">Klicken Sie anschließend auf <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> Oder <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower-Implementierung der Oracle 19c-Datenbank</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. Erstellen Sie das Inventar, die Gruppe, die Hosts und die Anmeldeinformationen für Ihre Umgebung</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">Wenn es Bestandsvariablen gibt, fügen Sie diese in das Feld Variablen ein.</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">Geben Sie den Namen der Gruppe für ONTAP ein, fügen Sie die Gruppenvariablen ein (falls vorhanden) und klicken Sie auf Speichern.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Wiederholen Sie den Vorgang für eine andere Gruppe für Oracle.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">Wählen Sie die erstellte ONTAP-Gruppe aus, gehen Sie zum Untermenü Hosts und klicken Sie auf Neuen Host hinzufügen.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">Geben Sie die IP-Adresse der ONTAP-Cluster-Management-IP an, fügen Sie die Host-Variablen ein (falls vorhanden), und klicken Sie auf Speichern.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Dieser Prozess muss für die Oracle-Gruppe und für Oracle-Host(s)-Management-IP/Hostname wiederholt werden.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">Erstellen von Anmeldungstypen. Bei Lösungen, die ONTAP verwenden, müssen Sie den Anmeldeinformationstyp so konfigurieren, dass er mit den Einträgen für Benutzernamen und Kennwort übereinstimmt.</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">Fügen Sie folgenden Inhalt in die Konfiguration des Injektors ein:</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">Geben Sie den Namen und die Organisationsdetails für ONTAP ein.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">Wählen Sie den benutzerdefinierten Anmeldungstyp aus, den Sie für ONTAP erstellt haben.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">Geben Sie unter „Type Details“ den Benutzernamen, das Passwort und das vsadmin_password ein.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">Klicken Sie auf Zurück zur Anmeldeinformation, und klicken Sie auf Hinzufügen.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Geben Sie den Namen und die Organisationsdetails für Oracle ein.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. Erstellen Sie ein Projekt</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">Eingabe <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> Als URL für die Quellensteuerung.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Oracle Host_vars konfigurieren</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">Die in diesem Abschnitt definierten Variablen werden auf jeden einzelnen Oracle Server und jede Datenbank angewendet.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">Geben Sie Ihre umgebungsspezifischen Parameter in das folgende eingebettete Oracle-Hosts-Variablen oder Host_vars-Formular ein.</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">Füllen Sie alle Variablen in die blauen Felder ein.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">Klicken Sie nach Abschluss der Variablen auf die Schaltfläche Kopieren im Formular, um alle Variablen zu kopieren, die an AWX oder Tower übertragen werden sollen.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">Navigieren Sie zurück zu AWX oder Tower, und gehen Sie zu Ressourcen → Hosts, und wählen Sie und öffnen Sie die Konfigurationsseite für den Oracle-Server.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">Klicken Sie auf der Registerkarte Details auf Bearbeiten und fügen Sie die kopierten Variablen aus Schritt 1 in das Feld Variablen unter der Registerkarte YAML ein.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">Wiederholen Sie diesen Vorgang für alle weiteren Oracle Server im System.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. Globale Variablen konfigurieren</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">Alle Variablen in blaue Felder eintragen.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">Klicken Sie nach Abschluss der Variablen auf die Schaltfläche Kopieren im Formular, um alle Variablen zu kopieren, die an AWX oder Tower übertragen werden sollen, in die folgende Jobvorlage.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. Konfigurieren und starten Sie die Jobvorlage.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">Geben Sie den Namen und die Beschreibung ein</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">Wählen Sie den Jobtyp aus. Führen Sie die Konfiguration des Systems anhand eines Playbooks aus, und prüfen Sie, ob ein Playbook trocken ausgeführt wird, ohne das System tatsächlich zu konfigurieren.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">Wählen Sie all_Playbook.yml als Standard-Playbook aus, das ausgeführt werden soll.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">Aktivieren Sie das Kontrollkästchen Aufforderung zum Starten im Feld Job-Tags.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">Wenn Sie beim Start nach Job-Tags gefragt werden, geben Sie Anforderungen_config ein. Möglicherweise müssen Sie unter Requirements_config auf die Zeile Job-Tag erstellen klicken, um die Job-Tag-Nummer einzugeben.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">Requirements_config stellt sicher, dass Sie über die richtigen Bibliotheken verfügen, um die anderen Rollen auszuführen.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">Klicken Sie auf Weiter und dann auf Start, um den Job zu starten.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">Klicken Sie auf Ansicht → Jobs, um die Jobausgabe und den Fortschritt zu überwachen.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">Wenn Sie zur Einführung von Job-Tags aufgefordert werden, geben sie ontap_config ein. Sie müssen möglicherweise direkt unter ontap_config auf die Zeile „Job Tag erstellen“ klicken, um das Job-Tag einzugeben.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">Klicken Sie auf Ansicht → Jobs, um die Jobausgabe und den Fortschritt zu überwachen</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">Führen Sie nach Abschluss der rolle ontap_config den Prozess für linux_config erneut aus.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">Wählen Sie die gewünschte Vorlage aus, und klicken Sie dann auf Starten.</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Wenn Sie beim Start aufgefordert werden, geben Sie die Job-Tags in linux_config ein, müssen Sie möglicherweise die Zeile „Job-Tag erstellen“ direkt unter linux_config auswählen, um das Job-Tag einzugeben.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">Wählen Sie Ansicht → Jobs, um die Jobausgabe und den Fortschritt zu überwachen.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Führen Sie nach Abschluss der rolle linux_config den Prozess für oracle_config erneut aus.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">Gehen Sie zu Ressourcen → Vorlagen.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">Wenn Sie beim Start nach Job-Tags gefragt werden, geben sie oracle_config ein. Sie müssen möglicherweise die Zeile „Job Tag erstellen“ direkt unter oracle_config auswählen, um das Job-Tag einzugeben.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. Implementieren Sie zusätzliche Datenbank auf demselben Oracle Host</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">Der Oracle Teil des Playbook erstellt pro Ausführung eine einzelne Oracle-Container-Datenbank auf einem Oracle-Server. Führen Sie die folgenden Schritte aus, um zusätzliche Container-Datenbanken auf demselben Server zu erstellen.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">Host_Vars-Variablen überarbeiten.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">Zurück zu Schritt 2 - Oracle Host_Vars konfigurieren.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Ändern Sie Oracle SID zu einer anderen Namenskonvention.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">Ändern Sie den Listener-Port in eine andere Zahl.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">Ändern Sie den EM Express-Port in eine andere Nummer, wenn Sie EM Express installieren.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">Kopieren Sie die überarbeiteten Hostvariablen in das Feld Oracle Host Variables auf der Registerkarte Host Configuration Detail.</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">Starten Sie die Jobvorlage für die Bereitstellung nur mit dem tag oracle_config.</block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">Dieses Whitepaper enthält einen Überblick und eine Validierung der Lösung für AWS angepasste Oracle RDS Datenbank-HA und -DR unter Nutzung des AWS FSX Storage-Service in einer Implementierung mit mehreren Verfügbarkeitszonen.</block>
  <block id="9ae9d82ee587bffe09c5b3c745d93c1c" category="doc">WP-7357: Einführung zu Oracle Database Deployment auf EC2/FSX Best Practices</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">Allen Cao, Niyaz Mohamed, Jeffrey Steiner, NetApp</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">Viele geschäftskritische Oracle Datenbanken der Enterprise-Klasse werden nach wie vor lokal gehostet, und viele Unternehmen möchten diese Oracle Datenbanken in eine Public Cloud migrieren. Häufig sind diese Oracle-Datenbanken Applikationsorientierung vorhanden und benötigen daher benutzerspezifische Konfigurationen. Diese Funktionen fehlen bei vielen Public-Cloud-Angeboten für Datenbanken als Service. Aus diesem Grund erfordert die aktuelle Datenbanklandschaft eine Public-Cloud-basierte Oracle Datenbanklösung, die auf einem hochperformanten, skalierbaren Computing- und Storage-Service aufbaut und individuelle Anforderungen erfüllt. AWS EC2 Computing-Instanzen und der AWS FSX Storage-Service sind möglicherweise die fehlenden Bestandteile dieses Puzzles, das Sie zum Erstellen und Migrieren Ihrer geschäftskritischen Oracle Datenbank-Workloads in eine Public Cloud nutzen können.</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud (Amazon EC2) ist ein Web-Service, der eine sichere, anpassbare Computing-Kapazität in der Cloud bietet. Es wurde entwickelt, um Unternehmen das webbasierte Cloud-Computing zu erleichtern. Über die einfache Amazon EC2 Web-Service-Schnittstelle erhalten und konfigurieren Sie Kapazitäten mit minimalem Reibungsaufwand. Es bietet Ihnen die vollständige Kontrolle über Ihre Computing-Ressourcen und ermöglicht Ihnen, auf Amazon bewährten Computing-Umgebung laufen.</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX für ONTAP ist ein AWS Storage-Service, der branchenführende NetApp ONTAP Block- und File-Storage verwendet, der NFS, SMB und iSCSI aufdeckt. Dank einer derart leistungsstarken Storage Engine war es noch nie einfacher, geschäftskritische Oracle Datenbankapplikationen mit Reaktionszeiten von unter einer Millisekunde, einem Durchsatz von mehreren GBit/s und mehr als 100,000 IOPS pro Datenbankinstanz in AWS zu verschieben. Der FSX Storage-Service verfügt außerdem über native Replizierungsfunktionen, mit denen Sie Ihre Oracle Datenbanken problemlos zu AWS migrieren oder Ihre geschäftskritische Oracle Datenbank zu einer sekundären AWS Verfügbarkeitszone für HA oder DR zu replizieren.</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">Ziel dieser Dokumentation ist es, Schritt-für-Schritt-Prozesse, Verfahren und Best Practice-Anleitungen zur Implementierung und Konfiguration einer Oracle Datenbank mit FSX Storage und einer EC2 Instanz zu liefern, die eine Performance ähnlich wie ein lokales System bietet. NetApp stellt zudem ein Automatisierungs-Toolkit bereit, das die meisten Aufgaben für die Implementierung, Konfiguration und das Management Ihres Oracle Datenbank-Workloads in der AWS Public Cloud automatisiert.</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">Als Nächstes: Lösungsarchitektur.</block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI-Implementierung einer Oracle 19c Datenbank</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">Erste Schritte und Abschnitt zu den Anforderungen</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">In diesem Abschnitt werden die Schritte beschrieben, die für die Vorbereitung und Implementierung der Oracle19c-Datenbank mit der CLI erforderlich sind. Stellen Sie sicher, dass Sie den geprüft haben <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> Und Ihre Umgebung entsprechend vorbereitet.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Oracle19c repo herunterladen</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">Bearbeiten Sie die Host-Datei</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">Vor der Bereitstellung Folgendes abschließen:</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">Bearbeiten Sie die Host-Datei na_oracle19c_Deploy.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">Ändern Sie unter [ONTAP] die IP-Adresse in Ihre Cluster-Management-IP.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">Fügen Sie unter der Gruppe [oracle] die namen der oracle-Hosts hinzu. Der Host-Name muss für seine IP-Adresse entweder über DNS oder über die Hosts-Datei aufgelöst werden, oder er muss im Host angegeben werden.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">Speichern Sie nach Abschluss dieser Schritte alle Änderungen.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">Im folgenden Beispiel wird eine Host-Datei dargestellt:</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">Dieses Beispiel führt das Playbook aus und implementiert oracle 19c gleichzeitig auf zwei oracle DB Servern. Sie können auch mit nur einem DB-Server testen. In diesem Fall müssen Sie nur eine Host-Variablendatei konfigurieren.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">Das Playbook wird unabhängig davon, wie viele Oracle Hosts und Datenbanken Sie implementieren, auf dieselbe Weise ausgeführt.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">Bearbeiten Sie die Datei Host_Name.yml unter Host_vars</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">Jeder Oracle Host verfügt über seine Host-Variablendatei, die durch den Hostnamen identifiziert wird, der Host-spezifische Variablen enthält. Sie können einen beliebigen Namen für Ihren Host angeben. Bearbeiten und kopieren Sie die<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Fügen Sie sie im Abschnitt Host VARS Config in Ihre gewünschte ein<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">Bearbeiten Sie die Datei Vars.yml</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">Der<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Die Datei konsolidiert alle umgebungsspezifischen Variablen (ONTAP, Linux oder Oracle) für die Implementierung von Oracle.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">Bearbeiten und kopieren Sie die Variablen aus dem Abschnitt VARS und fügen Sie diese Variablen in Ihr ein<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Datei:</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">Führen Sie das Playbook aus</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">Nach Abschluss der erforderlichen Umgebungsvoraussetzungen und Kopieren der Variablen in<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Und<block ref="97513b66e909abfd622924972387a816" prefix=" " category="inline-code"></block>, Sie sind jetzt bereit, die Playbooks zu implementieren.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">&lt;username&gt; muss an Ihre Umgebung angepasst werden.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">Implementieren Sie zusätzliche Datenbanken auf demselben Oracle Host</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">Der Oracle Teil des Playbook erstellt pro Ausführung eine einzelne Oracle-Container-Datenbank auf einem Oracle-Server. Gehen Sie wie folgt vor, um eine zusätzliche Container-Datenbank auf demselben Server zu erstellen:</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">Ändern der Variablen Host_Vars.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">Gehen Sie zurück zu Schritt 3 - Bearbeiten Sie den<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Datei unter<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">Ändern Sie den EM Express-Port in eine andere Nummer, wenn Sie EM Express installiert haben.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">Kopieren Sie die überarbeiteten Hostvariablen in die Oracle-Host-Variablendatei unter<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">Führen Sie das Playbook mit dem aus<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block> Tag wie oben in dargestellt <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">Dieser Abschnitt enthält eine Zusammenfassung der Aufgaben, die erfüllt werden müssen, um die Anforderungen zu erfüllen, wie im vorherigen Abschnitt beschrieben. Der folgende Abschnitt enthält eine allgemeine Aufgabenliste für den Betrieb am Standort sowie in der Public Cloud. Auf die detaillierten Prozesse und Verfahren kann durch Anklicken der entsprechenden Links zugegriffen werden.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">Erste Schritte – Übersicht</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">Früher: Voraussetzungen für die Public Cloud.</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">Einrichten des Datenbank-Admin-Benutzers in SnapCenter</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">Installationsvoraussetzungen für das SnapCenter Plug-in</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter Host Plug-in-Installation</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">DB-Ressourcenerkennung</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">Storage-Cluster-Peering und DB-Volume-Replizierung einrichten</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">Fügen Sie die CVO Datenbank-Storage-SVM zu SnapCenter hinzu</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">Backup-Richtlinie für Datenbanken in SnapCenter einrichten</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">Backup-Richtlinie zum Schutz der Datenbank implementieren</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">Backup validieren</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">Scheck vor dem Flug</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">Schritte zur Implementierung von Cloud Manager und Cloud Volumes ONTAP in AWS</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">Implementieren Sie EC2 Computing-Instanz für Datenbank-Workloads</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">Details finden Sie unter folgenden Links:</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">Public Cloud – AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">Diese Lösung bietet Außendienstmitarbeiter und Kunden von NetApp Anweisungen und Anleitungen für die Konfiguration, den Betrieb und die Migration von Datenbanken in eine Hybrid-Cloud-Umgebung mithilfe des GUI-basierten NetApp SnapCenter Tools und des NetApp Storage-Service CVO in Public Clouds.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908: Übersicht zu Hybrid-Cloud-Datenbanklösungen mit SnapCenter</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">Alan Cao, Felix Melligan, NetApp</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">Diese Lösung bietet Außendienstmitarbeiter und Kunden Anweisungen und Anleitungen für die Konfiguration, den Betrieb und die Migration von Datenbanken in eine Hybrid-Cloud-Umgebung mithilfe des GUI-basierten NetApp SnapCenter Tools und des NetApp Storage-Service CVO in Public Clouds, um in folgenden Fällen verfügbar zu machen:</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">Entwicklungs-/Testprozesse für Datenbanken in der Hybrid Cloud</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">Datenbank-Disaster-Recovery in der Hybrid Cloud</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">Heute befinden sich viele Enterprise-Datenbanken aus Performance-, Sicherheits- und anderen Gründen immer noch in privaten Datacentern eines Unternehmens. Diese Hybrid-Cloud-Datenbanklösung ermöglicht Unternehmen, ihre primären Datenbanken vor Ort zu betreiben und gleichzeitig eine Public Cloud für Test- und Entwicklungsdatenbanken zu nutzen sowie Disaster Recovery zu nutzen, um die Lizenz- und Betriebskosten zu senken.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Viele Enterprise-Datenbanken wie Oracle, SQL Server, SAP HANA usw. Hohe Lizenz- und Betriebskosten Viele Kunden zahlen eine einmalige Lizenzgebühr sowie jährliche Support-Kosten, die auf der Anzahl der Computing-Kerne in ihrer Datenbankumgebung basieren und unabhängig davon, ob die Kerne für Entwicklung, Tests, Produktion oder Disaster Recovery verwendet werden. Viele dieser Umgebungen sind möglicherweise nicht während des gesamten Applikationslebenszyklus vollständig ausgelastet.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">Die Lösungen bieten Kunden die Möglichkeit, die Anzahl ihrer lizenzierbaren Kerne zu reduzieren, indem sie ihre Datenbankumgebungen für Entwicklung, Tests oder Disaster Recovery in die Cloud verschieben. Durch den Einsatz von Skalierbarkeit, Redundanz, Hochverfügbarkeit und einer nutzungsbasierten Abrechnung auf Basis von Public Clouds können Lizenzgebühren und Betriebsabläufe erheblich gesenkt werden, ohne dabei die Benutzerfreundlichkeit oder Verfügbarkeit der Applikationen zu beeinträchtigen.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">Neben den potenziellen Einsparungen bei Datenbanklizenzkosten ermöglicht das kapazitätsbasierte CVO Lizenzmodell von NetApp Kunden, Storage-Kosten pro GB zu sparen. Gleichzeitig profitieren sie von einem hohen Maß an Datenbankverwaltung, das in den Storage-Services anderer Anbieter nicht möglich ist. Das folgende Diagramm zeigt einen Storage-Kostenvergleich für gängige Storage-Services, die in der Public Cloud verfügbar sind.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">Die Lösung zeigt, dass mithilfe des GUI-basierten Software-Tools SnapCenter und der NetApp SnapMirror Technologie Hybrid-Cloud-Datenbankvorgänge einfach eingerichtet, implementiert und betrieben werden können.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">SnapCenter wird in der Praxis in den folgenden Videos gezeigt:</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">Backup einer Oracle-Datenbank in einer Hybrid Cloud mit SnapCenter</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter – KLONEN SIE ENTWICKLUNG/TEST für eine Oracle Datenbank in AWS Cloud</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">Zwar zeigen die Abbildungen in diesem Dokument zeigen CVO als Ziel-Storage-Instanz in der Public Cloud, doch ist die Lösung auch für die neue Version der FSX ONTAP Storage-Engine für AWS vollständig validiert.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">Ein NetApp Lab-on-Demand SL10680 kann über folgenden Link angefordert werden: https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD: AWS - NW, SnapCenter (OnPrem)^].</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">Dieser Abschnitt enthält Details zu den Faktoren, die bei der Implementierung einer Oracle Datenbank auf AWS EC2 Instance und FSX-Storage zu berücksichtigen sind.</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Für die Implementierung von Oracle Database sind Faktoren zu berücksichtigen</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">Früher: Lösungsarchitektur.</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">Eine Public Cloud bietet eine große Auswahl an Computing- und Storage-Ressourcen. Der Einsatz der richtigen Computing-Instanz und der richtigen Storage Engine ist ein guter Ausgangspunkt für die Datenbankimplementierung. Wählen Sie außerdem Computing- und Storage-Konfigurationen aus, die für Oracle Datenbanken optimiert sind.</block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">In den folgenden Abschnitten werden die wichtigsten Aspekte bei der Implementierung von Oracle Datenbanken in einer AWS Public Cloud auf einer EC2 Instanz mit FSX Storage beschrieben.</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">VM-Performance</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">Für die optimale Performance einer relationalen Datenbank in einer Public Cloud ist die Auswahl der richtigen VM-Größe wichtig. Um eine bessere Performance zu erzielen, empfiehlt NetApp die Verwendung einer EC2 M5 Series Instanz für die Oracle Implementierung, die für Datenbank-Workloads optimiert ist. Derselbe Instanztyp wird auch verwendet, um eine RDS-Instanz für Oracle von AWS zu versorgen.</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">Wählen Sie basierend auf Workload-Merkmalen die richtige vCPU- und RAM-Kombination aus.</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">Fügen Sie Swap-Speicherplatz zu einer VM hinzu. Die Standard-Implementierung der EC2-Instanz erstellt keinen Swap-Speicherplatz, der nicht optimal für eine Datenbank ist.</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">Storage-Layout und -Einstellungen</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">NetApp empfiehlt das folgende Storage Layout:</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">Für NFS-Storage besteht das empfohlene Volume-Layout aus drei Volumes: Eines für die Oracle-Binärdatei, eines für Oracle-Daten und einer doppelten Kontrolldatei und eines für das aktive Protokoll, archiviertes Protokoll und die Kontrolldatei von Oracle.</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">Für iSCSI-Storage empfiehlt sich das Volume-Layout aus drei Volumes: Eines für die Oracle-Binärdatei, eines für Oracle-Daten und einer doppelten Kontrolldatei und eines für das aktive Protokoll, Archivprotokoll und die Kontrolldatei von Oracle. Allerdings sollte jede Daten- und Protokoll-Volume idealerweise vier LUNs enthalten. Die LUNs sind idealerweise auf den HA Cluster Nodes ausgeglichen.</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">Für Storage-IOPS und -Durchsatz können Sie den Schwellenwert für bereitgestellte IOPS und Durchsatz für den FSX Storage-Cluster festlegen. Die Parameter können spontan angepasst werden, wann sich der Workload ändert.</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">Die automatische IOPS-Einstellung beträgt drei IOPS pro gib der zugewiesenen Storage-Kapazität oder den benutzerdefinierten Storage bis zu 80,000.</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">Der Durchsatz wird wie folgt erhöht: 128, 256, 512, 1024, 2045 Mbps.</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">Überprüfen Sie die <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> Dokumentation bei der Größenbestimmung von Durchsatz und IOPS.</block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">NFS-Konfiguration</block>
  <block id="b6e1b7fd7aad364a8ad758d8ae8ba50d" category="paragraph">Linux, das gängigste Betriebssystem, umfasst native NFS-Funktionen. Oracle bietet den direkten NFS-Client (dNFS), der nativ in Oracle integriert ist. Oracle unterstützt NFSv3 seit über 20 Jahren, und NFSv4 wird mit Oracle 12.1.0.2 und höher unterstützt. Die automatisierte Oracle-Implementierung mit dem NetApp Automatisierungs-Toolkit konfiguriert dNFS auf NFSv3 automatisch.</block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">Weitere Faktoren, die berücksichtigt werden sollten:</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">TCP-Slot-Tabellen entsprechen dem NFS-Äquivalent zur Warteschlangentiefe des Host-Bus-Adapters (HBA). Diese Tabellen steuern die Anzahl der NFS-Vorgänge, die zu einem beliebigen Zeitpunkt ausstehen können. Der Standardwert ist normalerweise 16, was für eine optimale Performance viel zu niedrig ist. Das entgegengesetzte Problem tritt auf neueren Linux-Kerneln auf, die automatisch die Begrenzung der TCP-Slot-Tabelle auf ein Niveau erhöhen können, das den NFS-Server mit Anforderungen sättigt.</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">Um eine optimale Performance zu erzielen und Performance-Probleme zu vermeiden, passen Sie die Kernel-Parameter an, die die TCP-Slot-Tabellen steuern, auf 128 an.</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">Die folgende Tabelle enthält die empfohlenen NFS-Mount-Optionen für Linux NFSv3 – Single-Instance.</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">Überprüfen Sie vor der Verwendung von dNFS, ob die in Oracle Doc 1495104.1 beschriebenen Patches installiert sind. DNFS unterstützt ab Oracle 12c NFSv3, NFSv4 und NFSv4.1. NetApp Support-Richtlinien decken v3 und v4 für alle Clients ab. Zum Zeitpunkt der Erstellung dieses Berichts wurde NFSv4.1 jedoch nicht für die Verwendung mit Oracle dNFS unterstützt.</block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">Wie in der Lösungsarchitektur angegeben, wird HA auf der Replizierung auf Storage-Ebene aufgebaut. Somit sind Start und Verfügbarkeit von Oracle davon abhängig, wie schnell Computing- und Storage-Ressourcen aufgerufen und wiederhergestellt werden können. Die folgenden wichtigen Faktoren sind wichtig:</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">Eine Standby-Computing-Instanz ist bereit und mit dem primären über das parallele Ansible-Update zu beiden Hosts synchronisiert.</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">Replizieren Sie das Binärvolumen aus dem primären Standby-Modus, damit Sie Oracle in letzter Minute nicht installieren und herausfinden müssen, was installiert und gepatcht werden muss.</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">Die Replizierungsfrequenz bestimmt, wie schnell die Oracle-Datenbank wiederhergestellt werden kann, damit der Service verfügbar ist. Zwischen der Replizierungshäufigkeit und dem Storage-Verbrauch besteht ein Kompromiss.</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">Nutzen Sie die Automatisierung, um das Recovery zu beschleunigen und den Wechsel auf Standby schnell und frei von menschlichen Fehlern zu machen. NetApp stellt zu diesem Zweck ein Automatisierungs-Toolkit zur Verfügung.</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">In diesem Abschnitt werden die Implementierungsverfahren für die Implementierung von Oracle RDS Custom Database mit FSX Storage beschrieben.</block>
  <block id="b8a2bfa78779af1958bed97119657167" category="doc">Schritt-für-Schritt-Anweisungen zur Oracle-Implementierung auf AWS EC2/FSX</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">Implementieren Sie eine EC2 Linux-Instanz für Oracle über die EC2-Konsole</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">Für neue AWS-Lösungen müssen Sie zunächst eine AWS-Umgebung einrichten. Die Registerkarte Dokumentation auf der Landing Page der AWS-Website enthält EC2-Anweisungslinks zur Implementierung einer Linux-EC2-Instanz, die zum Hosten Ihrer Oracle-Datenbank über die AWS-EC2-Konsole verwendet werden kann. Der folgende Abschnitt enthält eine Zusammenfassung dieser Schritte. Weitere Informationen finden Sie in der zugehörigen AWS EC2-spezifischen Dokumentation.</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">Einrichten der AWS EC2-Umgebung</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">Sie müssen ein AWS-Konto erstellen, um die erforderlichen Ressourcen bereitzustellen, um Ihre Oracle Umgebung auf dem EC2 und FSX Service auszuführen. Die folgende AWS-Dokumentation enthält die erforderlichen Details:</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Einrichten zur Verwendung von Amazon EC2</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">Hauptthemen:</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">Melden Sie sich für AWS an.</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">Erstellen Sie ein Schlüsselpaar.</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">Erstellen Sie eine Sicherheitsgruppe.</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">Aktivierung mehrerer Verfügbarkeitszonen in AWS-Kontoattributen</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">Für eine Oracle-Hochverfügbarkeitskonfiguration, wie im Architekturdiagramm gezeigt, müssen Sie mindestens vier Verfügbarkeitszonen in einer Region aktivieren. Die verschiedenen Verfügbarkeitszonen können auch in verschiedenen Regionen aufgestellt werden, um die für das Disaster Recovery erforderlichen Entfernungen zu erfüllen.</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">Erstellen und Verbinden mit einer EC2-Instanz zum Hosten von Oracle-Datenbank</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Erste Schritte mit Amazon EC2 Linux Instanzen</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">Siehe Lernprogramm <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> Für Schritt-für-Schritt-Anweisungen und Best Practices bei der Implementierung.</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">Überblick.</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">Voraussetzungen.</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">Schritt 1: Eine Instanz starten.</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">Schritt 2: Stellen Sie eine Verbindung zu Ihrer Instanz her.</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">Schritt 3: Reinigen Sie Ihre Instanz.</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">Die folgenden Screenshots zeigen die Bereitstellung einer m5-Typ Linux-Instanz mit der EC2-Konsole für die Ausführung von Oracle.</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">Klicken Sie im EC2-Dashboard auf die gelbe Schaltfläche Instanz starten, um den Implementierungs-Workflow für EC2 Instanzen zu starten.</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">Wählen Sie in Schritt 1 „Red hat Enterprise Linux 8 (HVM), SSD Volume Type - ami-0b0af3577fe5e3532 (64-bit x86) / ami-01fc429821bf1f4b4 (64-bit ARM)“ aus.</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">Wählen Sie in Schritt 2 einen m5-Instanztyp mit der entsprechenden CPU- und Speicherzuweisung basierend auf Ihrem Oracle-Datenbank-Workload aus. Klicken Sie Auf „Weiter: Instanzdetails Konfigurieren“.</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">Wählen Sie in Schritt 3 die VPC und das Subnetz aus, in dem die Instanz platziert werden soll, und aktivieren Sie die öffentliche IP-Zuweisung. Klicken Sie Auf „Next: Add Storage“ (Weiter).</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">Weisen Sie in Schritt 4 genügend Speicherplatz für die Root-Festplatte zu. Möglicherweise benötigen Sie den Speicherplatz, um einen Swap hinzuzufügen. Standardmäßig weist EC2-Instanz keinen Swap-Speicherplatz zu, was nicht optimal für die Ausführung von Oracle ist.</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">Fügen Sie in Schritt 5 bei Bedarf ein Tag für die Instanzidentifikation hinzu.</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">Wählen Sie in Schritt 6 eine vorhandene Sicherheitsgruppe aus oder erstellen Sie eine neue mit der gewünschten ein- und ausgehenden Richtlinie für die Instanz.</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">Überprüfen Sie in Schritt 7 die Zusammenfassung der Instanzkonfiguration, und klicken Sie auf Starten, um die Instanzbereitstellung zu starten. Sie werden aufgefordert, ein Schlüsselpaar zu erstellen oder ein Schlüsselpaar für den Zugriff auf die Instanz auszuwählen.</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">Melden Sie sich über ein SSH-Schlüsselpaar bei der EC2-Instanz an. Nehmen Sie ggf. Änderungen an Ihrem Schlüsselnamen und Ihrer Instanz-IP-Adresse vor.</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">Sie müssen zwei EC2-Instanzen als primäre und Standby-Oracle-Server in ihrer festgelegten Verfügbarkeitszone erstellen, wie im Architekturdiagramm dargestellt.</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Stellen Sie FSX für ONTAP File-Systeme für Oracle Datenbank-Storage bereit</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">Die Implementierung der EC2-Instanz weist ein EBS Root Volume für das Betriebssystem zu. FSX für ONTAP stellt Oracle Datenbank-Storage-Volumes bereit, einschließlich der Oracle Binär-, Daten- und Protokoll-Volumes. Die FSX-Storage-NFS-Volumes können entweder über die AWS FSX Konsole oder über die Oracle-Installation bereitgestellt werden und durch Konfigurationsautomatisierung, die die Volumes dem Benutzer in einer Automatisierungsparameter-Datei zuweist.</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="section-title">Erstellen von FSX für ONTAP-Dateisysteme</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">Verwalten von FSX für ONTAP-Dateisysteme</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">Habe auf diese Dokumentation verwiesen<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> Zur Erstellung von FSX für ONTAP-Dateisysteme.</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">Wichtige Überlegungen:</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">SSD-Storage-Kapazität: Mindestens 1024 gib, maximal 192 tib.</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">Provisionierter SSD-IOPS: Maximal 80,000 SSD-IOPS pro Filesystem, basierend auf Workload-Anforderungen.</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">Durchsatzkapazität.</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">Legen Sie das Administratorpasswort fsxadmin/vsadmin fest. Erforderlich für FSX-Konfigurationsautomatisierung</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">Backup und Wartung. Automatische tägliche Backups deaktivieren; Datenbank-Storage-Backups werden durch SnapCenter-Planung durchgeführt.</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">Rufen Sie die SVM Management-IP-Adresse und protokollspezifische Zugriffadressen auf der SVM Detailseite ab. Erforderlich für FSX-Konfigurationsautomatisierung</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">Sehen Sie sich die folgenden Schritt-für-Schritt-Anweisungen zum Einrichten eines primären oder Standby HA FSX-Clusters an.</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">Klicken Sie auf der FSX-Konsole auf Dateisystem erstellen, um den FSX-Bereitstellungsprozess zu starten.</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">Wählen Sie Amazon FSX für NetApp ONTAP aus. Klicken Sie anschließend auf Weiter.</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">Wählen Sie Standard Erstellen und benennen Sie unter Dateisystemdetails Ihr Dateisystem, Multi-AZ HA. Wählen Sie je nach Datenbank-Workload entweder automatisch oder vom Benutzer bereitgestellte IOPS bis zu 80,000 SSD-IOPS. FSX Storage verfügt über bis zu 2 tib NVMe-Caching im Backend, das noch höhere gemessene IOPS liefern kann.</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">Wählen Sie im Abschnitt Netzwerk &amp; Sicherheit die VPC, die Sicherheitsgruppe und die Subnetze aus. Diese sollten vor der Bereitstellung von FSX erstellt werden. Platzieren Sie die FSX-Storage-Nodes auf Basis der Rolle des FSX-Clusters (primär oder Standby) in die entsprechenden Zonen.</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">Akzeptieren Sie im Abschnitt Sicherheit &amp; Verschlüsselung die Standardeinstellung, und geben Sie das fsxadmin-Passwort ein.</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">Geben Sie den SVM-Namen und das vsadmin-Passwort ein.</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">Behalten Sie die Volume-Konfiguration leer. Sie müssen derzeit kein Volume erstellen.</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Prüfen Sie die Seite Zusammenfassung, und klicken Sie auf Dateisystem erstellen, um die Bereitstellung des FSX-Dateisystems abzuschließen.</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Bereitstellung von Datenbank-Volumes für Oracle Database</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">Management von FSX für ONTAP-Volumes – Erstellen eines Volumes</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">Siehe <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> Entsprechende Details.</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">Dimensionierung der Datenbank-Volumes entsprechend.</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">Deaktivieren der Kapazitäts-Pool Tiering-Richtlinie für eine Performance-Konfiguration</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">Oracle dNFS für NFS Storage Volumes aktivieren.</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">Multipath-Einrichtung für iSCSI-Storage-Volumes</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">Erstellen Sie Datenbank-Volume über die FSX Konsole</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">Über die AWS FSX-Konsole können Sie drei Volumes für Oracle-Datenbank-File-Storage erstellen: Eines für die Oracle-Binärdatei, eines für die Oracle-Daten und eines für das Oracle-Protokoll. Stellen Sie sicher, dass die Volume-Benennung mit dem Oracle Host-Namen (definiert in der Hosts-Datei im Automatisierungs-Toolkit) übereinstimmt, um die ordnungsgemäße Identifizierung zu finden. In diesem Beispiel verwenden wir db1 als Oracle-Hostname von EC2 anstelle eines typischen IP-Adressenbasierten Hostnamens für eine EC2-Instanz.</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">Das Erstellen von iSCSI-LUNs wird derzeit nicht von der FSX-Konsole unterstützt. Für die Implementierung von iSCSI-LUNs bei Oracle können die Volumes und LUNs mithilfe von Automatisierung für ONTAP mit dem NetApp Automatisierungs-Toolkit erstellt werden.</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">Installation und Konfiguration von Oracle auf einer EC2-Instanz mit FSX Datenbank-Volumes</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">Das Automatisierungsteam von NetApp stellt ein Automatisierungs-Kit bereit, um Oracle Installation und Konfiguration auf EC2 Instanzen gemäß den Best Practices auszuführen. Die aktuelle Version des Automatisierungs-Kits unterstützt Oracle 19c on NFS mit dem Standard RU Patch 19.8. Das Automationskit kann bei Bedarf problemlos an andere RU-Patches angepasst werden.</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">Ansible-Controller vorbereiten, um die Automatisierung auszuführen</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">Befolgen Sie die Anweisungen im Abschnitt „<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>„ “ Bezeichnet, um eine kleine EC2 Linux-Instanz zum Ausführen des Ansible-Controllers bereitzustellen. Anstatt RedHat zu verwenden, sollte Amazon Linux t2.Large mit 2vCPU und 8G RAM ausreichend sein.</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">Rufen Sie das NetApp Oracle Deployment Automation Toolkit ab</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">Melden Sie sich bei der EC2-Ansible-Controller-Instanz an, die von Schritt 1 als ec2-Benutzer bereitgestellt wird, und führen Sie das aus, wenn sie das ec2-User-Home-Verzeichnis verwenden<block ref="aebfab4ae394171a00d2e86fff2ff38b" prefix=" " category="inline-code"></block> Befehl zum Klonen einer Kopie des Automatisierungscodes.</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">Führen Sie die automatisierte Oracle 19c-Implementierung mit dem Automatisierungs-Toolkit aus</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">Siehe diese detaillierte Anweisung <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> Um Oracle 19c mit CLI-Automatisierung zu implementieren. Die Befehlssyntax für die Ausführung des Playbook-Befehls ändert sich klein, da Sie ein SSH-Schlüsselpaar anstelle eines Passworts für die Host-Zugriffs-Authentifizierung verwenden. Die folgende Liste enthält eine allgemeine Zusammenfassung:</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">Standardmäßig verwendet eine EC2-Instanz ein SSH-Schlüsselpaar für die Zugriffsauthentisierung. Über Ansible-Root-Verzeichnisse zur Controller-Automatisierung<block ref="4a1bfa90833e8fe6c82ca6f61f31d147" prefix=" " category="inline-code"></block>, und<block ref="a1d1fcb426260f0fdb7febffa690e21c" prefix=" " category="inline-code"></block>Erstellen Sie eine Kopie des SSH-Schlüssels<block ref="956c187b3d0c7dcff5b113900e032874" prefix=" " category="inline-code"></block> Für den im Schritt implementierten Oracle Host „<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>.“</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">Melden Sie sich als ec2-User beim DB-Host der EC2-Instanz an, und installieren Sie die python3-Bibliothek.</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">Wie weisen ich Speicher zu, um durch Verwendung einer Auslagerungsdatei als Auslagerungsspeicher in einer Amazon EC2 Instanz zu arbeiten?</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">Erstellen Sie einen 16G-Swap-Speicherplatz vom Root-Festplattenlaufwerk. Standardmäßig erstellt eine EC2-Instanz keinen Swap-Speicherplatz. Folgen Sie der folgenden AWS Dokumentation: <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>.</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Zurück zum Ansible-Controller <block ref="e97a9e3bee0cbfb89ba75f3695725fba" prefix="(" category="inline-code"></block>), und führen Sie das Pre-Clone-Playbook mit den entsprechenden Anforderungen und aus<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block> tags:</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">Wechseln Sie zum<block ref="127b3ddd6eac38dd05a00b88b9348ff5" prefix=" " category="inline-code"></block> Lesen Sie die README-Datei, und füllen Sie den globalen Ordner aus<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Datei mit den relevanten globalen Parametern.</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">Füllen Sie das aus<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Datei mit den entsprechenden Parametern im<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Verzeichnis.</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Führen Sie das Playbook für Linux aus, und drücken Sie die Eingabetaste, wenn Sie zur Eingabe des vsadmin-Passworts aufgefordert werden.</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Führen Sie das Playbook für Oracle aus, und drücken Sie die Eingabetaste, wenn Sie zur Eingabe des vsadmin-Passworts aufgefordert werden.</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">Ändern Sie ggf. das Berechtigungsbit für die SSH-Schlüsseldatei in 400. Ändern Sie den Oracle-Host <block ref="e15cba2a55d1c830968665125de5abf6" prefix="(" category="inline-code"></block> Im<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Datei) IP-Adresse an die öffentliche Adresse Ihrer EC2 Instanz.</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">Einrichten von SnapMirror zwischen primärem und Standby FSX HA-Cluster</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">Für Hochverfügbarkeit und Disaster Recovery kann SnapMirror Replizierung zwischen dem primären und Standby FSX Storage-Cluster eingerichtet werden. Im Gegensatz zu anderen Cloud-Storage-Services ermöglicht FSX Benutzern die Steuerung und das Management der Storage-Replizierung mit der gewünschten Häufigkeit und dem Replizierungsdurchsatz. Außerdem können Benutzer HA/DR ohne Auswirkungen auf die Verfügbarkeit testen.</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">Die folgenden Schritte zeigen, wie die Replikation zwischen einem primären und Standby FSX-Storage-Cluster eingerichtet wird.</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">Primären und Standby-Cluster-Peering einrichten. Melden Sie sich als fsxadmin-Benutzer im primären Cluster an, und führen Sie den folgenden Befehl aus. Bei dieser gegenseitigen Erstellung wird der Befehl create sowohl auf dem primären Cluster als auch auf dem Standby-Cluster ausgeführt. Austausch<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> Mit dem entsprechenden Namen für Ihre Umgebung einfügen.</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">Einrichten von Vserver Peering zwischen dem primären und dem Standby-Cluster Melden Sie sich als vsadmin-Benutzer im primären Cluster an, und führen Sie den folgenden Befehl aus. Austausch<block ref="f826cd2f4a01fe594ea3f06fc8e9a764" prefix=" " category="inline-code"></block>,<block ref="73483be5a30a2604d22183209c74149e" prefix=" " category="inline-code"></block>,<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> Den entsprechenden Namen für Ihre Umgebung bereit.</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">Überprüfen Sie, ob die Cluster- und vserver-Peerings korrekt eingerichtet sind.</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">Erstellung von Ziel-NFS-Volumes im Standby-FSX Cluster für jedes Quell-Volume im primären FSX-Cluster Ersetzen Sie den für Ihre Umgebung geeigneten Volume-Namen.</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">Sie können auch iSCSI Volumes und LUNs für die Oracle-Binärdatei, Oracle Daten und das Oracle-Protokoll erstellen, wenn das iSCSI-Protokoll für den Datenzugriff verwendet wird. Lassen Sie ungefähr 10% freien Platz in den Volumes für Schnappschüsse.</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">vol create -Volume dr_db1_log -aggregate aggr1 -size 250G -State online -Policy Standard -unix-Berechtigungen ---rwxr-xr-x -type RW</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">Erstellen Sie bei iSCSI LUNs eine Zuordnung für den Oracle-Host-Initiator für jede LUN, wobei die binäre LUN als Beispiel verwendet wird. Ersetzen Sie die Initiatorgruppe durch einen entsprechenden Namen für Ihre Umgebung und erhöhen Sie die LUN-id für jede zusätzliche LUN.</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">Erstellen einer SnapMirror Beziehung zwischen dem primären und dem Standby-Datenbank-Volume Ersetzen Sie den entsprechenden SVM-Namen für Ihre Umgebung.s</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">Die SnapMirror Einrichtung kann mit einem NetApp Automation Toolkit für NFS-Datenbank-Volumes automatisiert werden. Das Toolkit kann auf der öffentlichen NetApp GitHub Website heruntergeladen werden.</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">Lesen Sie die README-Anweisungen sorgfältig durch, bevor Sie die Einrichtung und Failover-Tests durchführen.</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">Bei der Replizierung der Oracle Binary vom primären zu einem Standby-Cluster können sich Auswirkungen auf die Oracle Lizenz ergeben. Weitere Informationen erhalten Sie bei Ihrem Oracle-Lizenzvertreter. Als Alternative könnte Oracle zum Zeitpunkt der Recovery und des Failover installiert und konfiguriert werden.</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">SnapCenter Deployment</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">SnapCenter Installation</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">Installieren des SnapCenter-Servers</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">Folgen <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> So installieren Sie den SnapCenter-Server: In dieser Dokumentation wird die Installation eines eigenständigen SnapCenter-Servers erläutert. Eine SaaS-Version von SnapCenter ist derzeit in der Beta-Überprüfung und könnte in Kürze verfügbar sein. Wenden Sie sich bei Bedarf an Ihren NetApp Vertriebsmitarbeiter, um Informationen zur Verfügbarkeit zu erhalten.</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">Konfiguration des SnapCenter Plug-ins für den EC2 Oracle Host</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">Melden SnapCenter Sie sich nach der automatisierten SnapCenter-Installation als administrativer Benutzer für den Windows-Host an, auf dem der SnapCenter-Server installiert ist.</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">Klicken Sie im linken Menü auf Einstellungen und dann Credential und New, um ec2-User-Anmeldeinformationen für die SnapCenter-Plugin-Installation hinzuzufügen.</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">Setzen Sie das ec2-User-Passwort zurück und aktivieren Sie die SSH-Passwort-Authentifizierung, indem Sie den bearbeiten<block ref="07b421e5f5e0300b1a0fd6cc22745306" prefix=" " category="inline-code"></block> Datei auf dem EC2 Instance Host.</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">Vergewissern Sie sich, dass das Kontrollkästchen „Sudo-Berechtigungen verwenden“ aktiviert ist. Im vorherigen Schritt setzen Sie einfach das ec2-User-Passwort zurück.</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">Fügen Sie zur Namensauflösung den SnapCenter-Servernamen und die IP-Adresse zur Host-Datei der EC2-Instanz hinzu.</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">Fügen Sie auf dem Windows-Host des SnapCenter-Servers der Windows-Hostdatei die Host-IP-Adresse der EC2-Instanz hinzu<block ref="803976de87f6862821bd3c4d94e0ff2b" prefix=" " category="inline-code"></block>.</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">Wählen Sie im linken Menü Hosts &gt; Managed Hosts aus und klicken Sie dann auf Hinzufügen, um den EC2 Instance Host zu SnapCenter hinzuzufügen.</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">Aktivieren Sie Oracle Database, und klicken Sie vor dem Senden auf More Options.</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">Aktivieren Sie Prüfungen Vor Der Installation Überspringen. Bestätigen Sie die Überprüfung der Vorinstallation überspringen, und klicken Sie dann auf nach Speichern senden.</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">Sie werden mit Fingerabdruck bestätigen aufgefordert und dann auf Bestätigen und Senden klicken.</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">Nach erfolgreicher Plugin-Konfiguration wird der Gesamtstatus des verwalteten Hosts als aktiv angezeigt.</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Konfigurieren der Backup-Richtlinie für Oracle-Datenbank</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">Siehe diesen Abschnitt <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Weitere Informationen zur Konfiguration der Backup-Richtlinie für Oracle Datenbanken finden Sie unter.</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">Im Allgemeinen müssen Sie eine Politik für das vollständige Snapshot-Backup der Oracle-Datenbank und eine Politik für das Oracle Archiv-Log-only Snapshot-Backup erstellen.</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">Sie können Oracle Archivprotokoll-Beschneidung in der Backup-Richtlinie aktivieren, um den Protokollarchiv-Speicherplatz zu steuern. Aktivieren Sie „Update SnapMirror nach dem Erstellen einer lokalen Snapshot Kopie“ in der „Select secondary Replication Option“, da Sie die Replizierung zu einem Standby-Standort für HA oder DR benötigen.</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Konfigurieren Sie Backup und Planung von Oracle Datenbanken</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">Das Datenbank-Backup in SnapCenter ist benutzerkonfigurierbar und kann entweder einzeln oder als Gruppe in einer Ressourcengruppe eingerichtet werden. Das Backup-Intervall hängt von den RTO- und RPO-Zielen ab. NetApp empfiehlt, alle paar Stunden ein komplettes Datenbank-Backup auszuführen und das Protokoll-Backup mit einer höheren Frequenz, z. B. 10-15 Minuten, zu archivieren, um eine schnelle Recovery zu ermöglichen.</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">Weitere Informationen finden Sie im Abschnitt Oracle von <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> Für detaillierte Schritt-für-Schritt-Prozesse zur Implementierung der im Abschnitt erstellten Backup-Richtlinie <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> Und für die Backup-Jobplanung.</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">Das folgende Bild zeigt ein Beispiel für die Ressourcengruppen, die zum Backup einer Oracle-Datenbank eingerichtet wurden.</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">Als Nächstes: Datenbankmanagement.</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">In diesem Abschnitt ist eine typische Hybrid-Cloud-Architektur für Entwicklungs- und Testzwecke sowie DR-Vorgänge dargestellt.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">Das folgende Architekturdiagramm zeigt eine typische Implementierung von Unternehmensdatenbankvorgängen in einer Hybrid Cloud für Entwicklungs-/Test- und Disaster-Recovery-Vorgänge.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">Im normalen Geschäftsbetrieb können synchronisierte Datenbank-Volumes in der Cloud geklont und in Entwicklungs-/Testdatenbankinstanzen für Applikationen zum entwickeln oder Testen gemountet werden. Bei einem Ausfall können die synchronisierten Datenbank-Volumes in der Cloud dann für die Disaster Recovery aktiviert werden.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">Als Nächstes: Lösungsanforderungen.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">In diesem Abschnitt werden die verschiedenen Probleme beschrieben, die bei Azure NetApp Files mit SQL Server in der Cloud zu berücksichtigen sind.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">Zu berücksichtigende Faktoren</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">Speicheroptimierung</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">Für die optimale Performance einer relationalen Datenbank in einer Public Cloud ist die Auswahl der richtigen VM-Größe wichtig. Microsoft empfiehlt, weiterhin dieselben Optionen zur Verbesserung der Datenbank-Performance zu verwenden, die für SQL Server in lokalen Serverumgebungen relevant sind. Nutzung<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> VM-Größen für die beste Performance von SQL Server Workloads Sammeln der Performance-Daten einer vorhandenen Bereitstellung, um die RAM- und CPU-Auslastung zu identifizieren und gleichzeitig die richtigen Instanzen auszuwählen Die meisten Implementierungen wählen zwischen der D-, E- oder M-Serie.</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">Verwenden Sie für die beste Performance von SQL Server Workloads eine speicheroptimierte VM-Größe.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp und Microsoft empfehlen, die Anforderungen an die Storage-Performance zu identifizieren, bevor Sie den Instanztyp mit dem entsprechenden Speicher-zu-Vcore-Verhältnis auswählen. Dadurch ist auch die Auswahl eines Instanztyps mit der richtigen Netzwerkbandbreite möglich, um die Storage-Durchsatzbegrenzungen der VM zu überwinden.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM-Redundanz</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">Verfügbarkeitsgruppe</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">Verfügbarkeitszonen</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">Um Redundanz und Hochverfügbarkeit zu erhöhen, sollten SQL Server VMs sich entweder in derselben befinden<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> Oder anders<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Bei der Erstellung von Azure VMs müssen Sie zwischen der Konfiguration von Verfügbarkeitsgruppen und den Verfügbarkeitszonen wählen. Eine Azure VM kann nicht an beiden teilnehmen.</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">Für hohe Verfügbarkeit ist die Konfiguration von SQL Server AOAG oder Always On Failover Cluster Instance (FCI) die beste Option. Bei AOAG werden mehrere Instanzen von SQL Server auf Azure Virtual Machines in einem virtuellen Netzwerk durchgeführt. Wenn auf Datenbankebene eine hohe Verfügbarkeit erforderlich ist, sollten Sie die Konfiguration von SQL Server-Verfügbarkeitsgruppen in Betracht ziehen.</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server kann mit SMB-Dateifreigaben als Storage-Option implementiert werden. Beginnend mit SQL Server 2012, Systemdatenbanken (Master, Model, msdb oder tempdb), Zudem können Benutzerdatenbanken mit dem Server Message Block (SMB)-Dateiserver als Storage-Option installiert werden. Dies gilt sowohl für Standalone-SQL Server als auch für SQL Server FCI.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">File Share Storage für SQL Server-Datenbanken sollte kontinuierlich verfügbare Eigenschaft unterstützen. Dadurch ist unterbrechungsfreier Zugriff auf die Dateifreigabedaten möglich.</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files bietet hochperformanten File-Storage für jeden anspruchsvollen Workload und reduziert die TCO von SQL Server im Vergleich zu Block-Storage-Lösungen. Bei Block-Storage haben VMs Beschränkungen für I/O und Bandbreite für Festplattenoperationen festgelegt. Beschränkungen der Netzwerkbandbreite allein werden auf Azure NetApp Files angewendet. Das heißt, auf Azure NetApp Files werden keine I/O-Limits auf VM-Ebene angewendet. Ohne diese I/O-Limits kann SQL Server auf kleineren, mit Azure NetApp Files verbundenen VMs ihre Performance ebenso wie SQL Server auf wesentlich größeren VMs liefern. Azure NetApp Files senken die Implementierungskosten für SQL Server durch niedrigere Computing- und Softwarelizenzkosten. Detaillierte Kostenanalysen und Performance-Vorteile der Verwendung von Azure NetApp Files für SQL Server-Implementierungen finden Sie im<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">Die Verwendung von Azure NetApp Files für SQL Server bietet u. a. folgende Vorteile:</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Durch den Einsatz von Azure NetApp Files können kleinere Instanzen verwendet und somit die Computing-Kosten gesenkt werden.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">Azure NetApp Files reduziert auch die Kosten für Softwarelizenzen und dadurch die TCO insgesamt.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">Die Volume-Umgestaltung und die dynamische Service Level-Funktion optimieren die Kosten, indem sie für stabile Workloads angepasst werden und eine Überprovisionierung vermieden wird.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">Um Redundanz und Hochverfügbarkeit zu erhöhen, sollten SQL Server VMs sich entweder in derselben befinden<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> Oder in einem anderen<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Beachten Sie die Dateipfadanforderungen, wenn benutzerdefinierte Datendateien erforderlich sind; wählen Sie in diesem Fall SQL FCI über SQL AOAG aus.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.Test\SQLDB und \\ANFSMB-b4ca.anf.Test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">Der folgende UNC-Pfad wird unterstützt:<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">Der Loopback UNC-Pfad wird nicht unterstützt.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">Verwenden Sie für die Dimensionierung historische Daten aus Ihrer lokalen Umgebung. Bei OLTP-Workloads passen Sie die Ziel-IOPS den Performance-Anforderungen an, wobei Workloads mit durchschnittlichen und Spitzenzeiten sowie den Leistungszählern für Festplattenzugriffe/s und Festplattenschreibvorgänge/s verwendet werden. Bei Data Warehouse- und Reporting-Workloads wird der Zieldurchsatz anhand von Workloads mit durchschnittlichen und Spitzenzeiten sowie den Byte/s der Festplattenschreibdaten und den Byte/Sek. des Festplattenschreibvorgangs angepasst Die Durchschnittswerte können zusammen mit den Funktionen zur Volumenumformung verwendet werden.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">Kontinuierlich verfügbare Shares erstellen</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">Erstellen einer kontinuierlich verfügbaren Freigabe</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Kontinuierlich verfügbare Shares erstellen mit dem Azure Portal oder der Azure CLI Wählen Sie im Portal die Option Eigenschaft kontinuierliche Verfügbarkeit aktivieren aus. Geben Sie bei der Azure-CLI die Freigabe als kontinuierlich verfügbare Freigabe über das an<block ref="0be8c8a92e4fe4621be30aa11942bc4d" prefix=" " category="inline-code"></block> Die Option ist auf eingestellt<block ref="91da4c74e2fced40755d4d3997af3488" prefix=" " category="inline-code"></block>. Weitere Informationen zum Erstellen eines neuen, für kontinuierliche Verfügbarkeit bestimmten Volumes finden Sie unter<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">Sorgen Sie für eine kontinuierliche Verfügbarkeit des SMB Volume, wie in der folgenden Abbildung dargestellt.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">Wenn ein Domain-Konto ohne Administrator verwendet wird, stellen Sie sicher, dass dem Konto die erforderliche Sicherheitsberechtigung zugewiesen ist.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">Legen Sie die entsprechenden Berechtigungen auf Share-Ebene und die entsprechenden Berechtigungen auf Dateiebene fest.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">Vorhandene SMB Volumes werden konvertiert, um kontinuierliche Verfügbarkeit zu nutzen</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">Eine kontinuierlich verfügbare Eigenschaft kann auf vorhandenen SMB Volumes nicht aktiviert werden. Um ein vorhandenes Volume zu konvertieren, wird ein kontinuierlich verfügbarer Share verwendet. Nutzen Sie die NetApp Snapshot Technologie. Weitere Informationen finden Sie unter<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files unterstützt drei Service-Level: Standard (16 Mbit/s pro Terabyte), Premium (64 Mbit/s pro Terabyte) und Ultra (128 Mbit/s pro Terabyte). Die Bereitstellung der passenden Volume-Größe ist für eine optimale Performance des Datenbank-Workloads wichtig. Bei Azure NetApp Files basieren die Volume-Performance und die Durchsatzbegrenzung auf einer Kombination der folgenden Faktoren:</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Performance-Validierung</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server Storage Benchmark-Tool (SB)</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">Wie bei jeder Implementierung sind auch VM- und Storage-Tests entscheidend. Für die Storage-Validierung Tools wie HammerDB, Apploader, die<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>, Oder jedes benutzerdefinierte Skript oder FIO mit der entsprechenden Lese-Schreib-Mischung verwendet werden sollte. Man sollte jedoch daran denken, dass die meisten SQL Server Workloads, selbst überlastete OLTP-Workloads, näher bei 80–90 % Lese- und 10–20 % Schreibvorgängen liegen.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">Um die Performance zu demonstrieren, wurde für ein Volume ein kurzer Test mithilfe von Premium-Service-Leveln durchgeführt. In diesem Test wurde die Volume-Größe spontan von 100 GB auf 2 TB erhöht, ohne dass der Applikationszugriff unterbrochen wird und keine Datenmigration erforderlich ist.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">Hier sehen Sie ein weiteres Beispiel für Echtzeit-Performance-Tests mit HammerDB für die in diesem Dokument behandelte Implementierung. Für diese Tests haben wir eine kleine Instanz mit acht vCPUs, einer 500 GB Premium SSD und einem 500 GB SMB Azure NetApp Files Volume verwendet. HammerDB wurde mit 80 Lagerhäusern und acht Anwendern konfiguriert.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">Das folgende Diagramm zeigt, dass Azure NetApp Files bei einem Volume einer vergleichbaren Größe (500 GB) eine 2,6-mal so viele Transaktionen pro Minute liefern konnte.</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">Ein zusätzlicher Test wurde durchgeführt, indem die Größe auf eine größere Instanz mit 32x vCPUs und einem 16-TB-Azure NetApp Files Volume angepasst wurde. Die Anzahl der Transaktionen pro Minute wurde mit einer konsistenten Latenz von 1 ms deutlich erhöht. HammerDB wurde für diesen Test mit 80 Lagerhäusern und 64 Anwendern konfiguriert.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files ermöglicht eine unterbrechungsfreie, transparente Volume-Anpassung und das Ändern der Service Level ohne Ausfallzeiten und Beeinträchtigung von Applikationen. Dies ist eine einzigartige Funktion für ein dynamisches Kostenmanagement, das die Datenbankdimensionierung mit Metriken nicht mehr erfordert. Sie können stattdessen stabile Workloads verwenden, wodurch Vorlaufkosten vermieden werden. Durch die Volume-Umgestaltung und die dynamische Service Level-Änderung können Sie die Bandbreite und das Service Level von Azure NetApp Files Volumes nahezu sofort und ohne Unterbrechung des I/O-Zugriffs anpassen und den Datenzugriff erhalten.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">Mit Azure PaaS-Angeboten wie LogicApp oder Funktionen kann die Volume-Größe anhand eines bestimmten Web-Hook- oder Alarm-Regelauslösens problemlos angepasst werden, um die Workload-Anforderungen zu erfüllen und gleichzeitig die Kosten dynamisch zu bewältigen.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">Nehmen wir beispielsweise an, eine Datenbank, die 250 MB/s für den stabilen Betrieb benötigt, benötigt jedoch auch einen Spitzendurchsatz von 400 MB/s. In diesem Fall sollte die Implementierung mit einem 4-TB-Volume innerhalb des Premium Service-Levels durchgeführt werden, um die Performance-Anforderungen in stabilem Zustand zu erfüllen. Um Spitzenlasten zu kompensieren, erhöhen Sie die Volume-Größe mithilfe von Azure Funktionen für diesen speziellen Zeitraum auf 7 TB und verkleinern Sie das Volume, um die Bereitstellung kostengünstig zu gestalten. Bei dieser Konfiguration wird eine Überprovisionierung des Storage vermieden.</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">Informationen zu diesem Repository</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">Kurze Einführung in das NetApp Solutions-Repository: Wo finden Sie weitere Lösungen und wie Sie dieses Repository nutzen können.</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">Navigation des Repository</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">Die Navigation des Projektarchivs wird über die Hauptleiste verwaltet, die auf der linken Seite angezeigt wird. Lösungen werden in übergeordnete technische Bereiche unterteilt, die als „Technologietürme“ für NetApp Lösungen definiert sind.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Überblick über Technology Towers</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">*Abschnitt*</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*Content Landing Page*</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">KI-basierte Lösungen sammeln. Die KI-Landing Page bietet beliebte Inhalte, die in Content-spezifischen „Tiles“ präsentiert werden.</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">KI-Inhalte</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">Sammlung moderner Data Analytics Lösungen (z.B. Splunk SmartStore, Apache Spark etc.) Die Landing Page Modern Data Analytics bietet beliebte Inhalte, die in Content-spezifischen „Tiles“ präsentiert werden.</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">Inhalte zu modernen Datenanalysen</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">Definiert NetApp in einem hybriden Multi Cloud-Modell – einschließlich VMware in der Public Cloud und NetApp Storage-Optionen in jedem Hyperscaler. Die Hybrid-Multi-Cloud-Landing Page bietet beliebte Inhalte, die in inhaltlichen „Tiles“ präsentiert werden.</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">Hybrid-Multi-Cloud mit VMware Inhalten</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">Reihe zentraler Virtualisierungslösungen, einschließlich Desktop-Virtualisierung Die Landing Page für Virtualisierung bietet beliebte Inhalte, die im Content-spezifischen „Tiles“ dargestellt sind.</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">Virtualisierungsinhalte</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">Sammlung containerbasierter Lösungen Die Landing Page für Virtualisierung bietet beliebte Inhalte, die im Content-spezifischen „Tiles“ dargestellt sind.</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">Container-Inhalte</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">Business-Applikationen und Datenbanken</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">Sammlung von Business-Applikationen und Datenbanklösungen. Die SAP und SAP HANA Landing Page bietet beliebte Inhalte, die in Content-spezifischen „Tiles“ präsentiert werden. Auch Oracle und SQL Server Datenbanklösungen werden in diesem Abschnitt behandelt.</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">Inhalte für SAP und SAP HANA</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="cell">Datenmigration und Datensicherung</block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">Sammlung von Lösungen für Datenmigration, Datensicherung und Datensicherheit.</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Überblick über die ersten Schritte mit der Lösungsautomatisierung mit Red hat Ansible</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Änderungsprotokoll</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">Änderungsprotokoll</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">Alle wesentlichen Änderungen an dem Repository (neue Lösungen, größere Updates, neue Videos / Demos, etc.) werden im verfolgt <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>.</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">Feedback Geben</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">Verwenden Sie bitte <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> Um Änderungen an Inhalten anzufordern oder Feedback zu den Inhalten zu geben. Bitte machen Sie so präzise wie möglich, damit Ihr Feedback entsprechend adressiert wird.</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">Die neuesten Ergänzungen des Begleitmaterials für Hybrid-Cloud-, Desktop-Virtualisierung und Container-Lösungen</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">Neuerungen bei Hybrid Cloud-, Desktop-Virtualisierungs- und Container-Lösungen</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">Überblick über das neueste Begleitmaterial zu Hybrid Cloud, Desktop-Virtualisierung und Container-Lösungen und -Lösungen.</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">*Hybrid / Private Cloud*</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">*Virtualisierung*</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere für ONTAP</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">*Desktop-Virtualisierung*</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">Hybrid Cloud VDI mit NetApp Virtual Desktop Service (VDS)</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">*Behälter*</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">DevOps mit NetApp Astra</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">Video: Schnellere Software-Entwicklung mit Astra Control und NetApp FlexClone Technologie</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Automatische Installation von Astra Control Center über Ansible</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">Video: Nutzen Sie NetApp Astra Control, um Post-Mortem-Analysen durchzuführen und Ihre Anwendung wiederherstellen zu können</block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">Video: Datensicherung in der CI/CD-Pipeline mit Astra Control</block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">Video: Workload-Migration mit Astra Control Center – Red hat OpenShift mit NetApp</block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">NetApp Astra Control Center auf Red hat OpenShift</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">Video: Workload-Migration mit Astra Trident und SnapMirror - Red hat OpenShift mit NetApp</block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="inline-link-macro">Erweitertes Cluster Management für Kubernetes auf Red hat OpenShift mit NetApp</block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">Red hat OpenShift Virtualisierung mit NetApp ONTAP</block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">Video: Installation von OpenShift Virtualization – Red hat OpenShift mit NetApp</block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">Video: Bereitstellung einer Virtual Machine mit OpenShift Virtualization – Red hat OpenShift mit NetApp</block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">Mandantenfähigkeit auf Red hat OpenShift mit NetApp ONTAP</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 – Red hat OpenShift mit NetApp</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">Anthos auf Bare Metal mit NetApp</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">Videos und Demos: Red hat OpenShift mit NetApp</block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">Das folgende Video zeigt einige der in diesem Dokument dokumentierten Funktionen:</block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="list-text"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="list-text"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="list-text"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="list-text"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="list-text"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="list-text"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">Video: NetApp HCI for Red hat OpenShift on Red hat Virtualization Deployment</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">Weiter: Weitere Informationen: Red hat OpenShift mit NetApp</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">Weitere Informationen: Red hat OpenShift mit NetApp</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">Sehen Sie sich die folgenden Websites an, um mehr über die in diesem Dokument beschriebenen Daten zu erfahren:</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp Dokumentation</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident – Dokumentation</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra Control Center - Dokumentation</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red hat OpenShift-Dokumentation</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Dokumentation der Red hat OpenStack Platform</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat Virtualization Documentation</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">Dokumentation zu VMware vSphere</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">Gleichzeitige Ausführung virtualisierter und Container-Workloads</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">Unabhängige Skalierung der Infrastruktur je nach Workload-Anforderungen</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">Weitere Informationen finden Sie auf der OpenShift Website<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">Weitere Informationen finden Sie auf der NetApp Website<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">Das NetApp Astra Control Center bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für zustandsorientierte Kubernetes Workloads, die in einer On-Premises-Umgebung implementiert und mit der bewährten NetApp Datensicherungstechnologie unterstützt werden.</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">NetApp verfügt über mehrere Storage-Plattformen, die für die Bereitstellung, Sicherung und das Management von Daten für Container-Applikationen mit Astra und Astra Control qualifiziert sind.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">NetApp Element Storage-Systeme bieten für blockbasierte (iSCSI-)Anwendungsfälle in hochskalierbarer Umgebung.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">Jedes Storage-System im NetApp Portfolio kann das Datenmanagement und das Verschieben von Daten zwischen lokalen Standorten und der Cloud vereinfachen. Damit befinden sich Ihre Daten genau dort, wo sich Ihre Applikationen befinden.</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">Nahtlose Integration in eine Public Cloud für Tiering und Datensicherung ONTAP bietet zudem robuste Datensicherungsfunktionen, die die Technologie in jeder Umgebung auszeichnet:</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">Beide Systeme werden durch die Datenmanagement-Software NetApp ONTAP unterstützt. Sie ist eine der fortschrittlichsten Datenmanagement-Software der Branche für das hochverfügbare, Cloud-integrierte und vereinfachte Storage-Management. So erhalten Sie die Geschwindigkeit, Effizienz und Sicherheit Ihrer Data-Fabric-Infrastruktur der Enterprise-Klasse.</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select ist eine softwaredefinierte Implementierung von NetApp ONTAP, die in einer Hypervisor-Umgebung implementiert werden kann. Es kann auf VMware vSphere oder KVM installiert werden und bietet den vollen Funktionsumfang und die Erfahrung eines hardwarebasierten ONTAP Systems.</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP ist eine Cloud-implementierte Version von NetApp ONTAP, die in einer Reihe von Public Clouds implementiert werden kann, darunter Amazon AWS, Microsoft Azure und Google Cloud.</block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">NetApp bietet Ihnen eine Reihe von Produkten, die Sie bei der Orchestrierung, dem Management, dem Schutz und der Migration zustandsorientierte containerisierte Applikationen und deren Daten unterstützen.</block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">NetApp Astra Control bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für zustandsorientierte Kubernetes Workloads auf Basis der NetApp Datensicherungstechnologie. Der Astra Control Service unterstützt statusorientierte Workloads in Cloud-nativen Kubernetes-Implementierungen. Das Astra Control Center unterstützt statusorientierte Workloads in On-Premises-Implementierungen von Kubernetes-Enterprise-Plattformen wie {k8s_Distribution_Name}. Weitere Informationen finden Sie auf der NetApp Astra Control Website<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">In einer Umgebung mit Cloud-Anbindung sorgt Astra Control Center mithilfe von Cloud Insights für erweitertes Monitoring und Telemetrie. Liegt keine Cloud Insights-Verbindung vor, ist eingeschränktes Monitoring und Telemetrie (7 Tage mit Kennzahlen) verfügbar und über offene metrische Endpunkte in native Kubernetes-Monitoring-Tools (Prometheus und Grafana) exportiert.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Zusätzlich zur kostenpflichtigen Version des Astra Control Center ist eine 90-Tage-Evaluierungslizenz verfügbar. Die Evaluierungsversion wird durch die E-Mail und die Community (Slack-Kanal) unterstützt. Kunden haben Zugriff auf diese und andere Knowledge-Base-Artikel sowie auf die Dokumentation, die über das Produkt-Support-Dashboard verfügbar sind.</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen wie {k8s_Distribution_Name}. Trident kann mit dem gesamten NetApp Storage-Portfolio eingesetzt werden, einschließlich NetApp ONTAP und Element Storage-Systeme. Es unterstützt auch NFS- und iSCSI-Verbindungen. Trident beschleunigt den DevOps-Workflow, da Endbenutzer Storage über ihre NetApp Storage-Systeme bereitstellen und managen können, ohne dass ein Storage-Administrator eingreifen muss.</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident verfügt über einen schnellen Entwicklungszyklus, und genau wie Kubernetes bereits viermal im Jahr veröffentlicht.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">Ab Version 20.04 wird die Trident-Einrichtung vom Trident Operator durchgeführt. Der Operator vereinfacht umfangreiche Implementierungen und bietet zusätzlichen Support einschließlich Selbstreparatur für Pods, die im Rahmen der Trident-Installation bereitgestellt werden.</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">Merkmale: Erweitertes Cluster Management für Kubernetes auf Red hat OpenShift mit NetApp</block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">Beobachtbarkeit</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Advanced Cluster Management für Kubernetes bietet eine Möglichkeit, Nodes, Pods und Applikationen sowie Workloads über alle Cluster hinweg zu überwachen.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">Navigieren Sie zu Umgebungen beobachten &gt; Übersicht.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">Beobachtbarkeit Homepage</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">Alle Pods und Workloads über alle Cluster hinweg werden überwacht und basierend auf verschiedenen Filtern sortiert. Klicken Sie auf Pods, um die entsprechenden Daten anzuzeigen.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">Pods Beobachten</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">Alle Nodes in den Clustern werden auf Basis verschiedener Datenpunkte überwacht und analysiert. Klicken Sie auf Knoten, um mehr Informationen zu den entsprechenden Details zu erhalten.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">Beobachten Sie Nodes</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">Alle Cluster werden basierend auf unterschiedlichen Cluster-Ressourcen und -Parametern überwacht und organisiert. Klicken Sie auf Cluster, um Cluster-Details anzuzeigen.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">Cluster Beobachten</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">Weiter: Features - Ressourcen Erstellen.</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">Konfiguration der Mandantenfähigkeit auf Red hat OpenShift mit NetApp</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">Skalierung: Mehr Projekte hinzufügen</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">In einer mandantenfähigen Konfiguration erfordert das Hinzufügen neuer Projekte mit Storage-Ressourcen eine zusätzliche Konfiguration, um sicherzustellen, dass Mandantenfähigkeit nicht verletzt wird. Gehen Sie wie folgt vor, um weitere Projekte in einem mandantenfähigen Cluster hinzuzufügen:</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">Melden Sie sich als Storage-Administrator beim NetApp ONTAP Cluster an.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">Navigieren Sie zu<block ref="ba7ff8660fabd8daa8e7fbd0c74dd990" prefix=" " category="inline-code"></block> Und klicken<block ref="ec211f7c20af43e742bf2570c3cb84f9" prefix=" " category="inline-code"></block>. Erstellen Sie eine neue SVM für Projekt-3. Erstellen Sie außerdem ein vsadmin-Konto, um die SVM und ihre Ressourcen zu managen.</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">SVM zur Skalierung erstellen</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Melden Sie sich als Clusteradministrator beim Red hat OpenShift Cluster an.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">Erstellen Sie ein neues Projekt.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">Stellen Sie sicher, dass die Benutzergruppe für Projekt-3 auf IdP erstellt und mit dem OpenShift-Cluster synchronisiert wird.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">Die Entwicklerrolle für Project-3 erstellen.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">Die in diesem Abschnitt angegebene Rollendefinition ist nur ein Beispiel. Die Entwicklerrolle muss basierend auf den Anforderungen des Endbenutzers definiert werden.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">Erstellen Sie RoleBending für Entwickler in Project-3, um die Rolle Developer-project-3 an die entsprechende Gruppe (ocp-project-3) in Projekt-3 zu binden.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Melden Sie sich als Storage-Administrator beim Red hat OpenShift-Cluster an</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Erstellen Sie ein Trident-Back-End und ordnen Sie es der für Projekt-3 dedizierten SVM zu. NetApp empfiehlt, das vsadmin Konto des SVM zu verwenden, um das Backend mit der SVM zu verbinden, anstatt den ONTAP-Cluster-Administrator zu verwenden.</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">In diesem Beispiel verwenden wir den ontap-nas-Treiber. Verwenden Sie den entsprechenden Treiber, um das Backend basierend auf dem Anwendungsfall zu erstellen.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Wir gehen davon aus, dass Trident im Projekt Trident installiert wird.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">Erstellen Sie die Storage-Klasse für Projekt-3, und konfigurieren Sie sie so, dass die Speicherpools vom Back-End für Projekt-3 verwendet werden.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">Erstellen Sie ein ResourceQuota zur Einschränkung von Ressourcen im Projekt-3, in dem Storage aus Storage-Speicherageclasses für andere Projekte angefordert wird.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">Patchen Sie die ResourceQuotas in anderen Projekten, um Ressourcen in diesen Projekten vom Zugriff auf den Speicher aus der für Projekt-3 vorgesehenen Speicherklasse zu beschränken.</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">Je nach Anwendungsfall können sowohl Container als auch Virtual Machines (VMs) als optimale Plattformen für verschiedene Applikationstypen dienen. Daher führen viele Unternehmen einige ihrer Workloads auf Containern und einige auf VMs aus. Dies führt häufig dazu, dass Unternehmen zusätzliche Herausforderungen meistern müssen, indem sie separate Plattformen managen müssen: Einen Hypervisor für VMs und einen Container-Orchestrator für Applikationen.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">Um diese Herausforderung zu bewältigen, hat Red hat die OpenShift Virtualization (früher bekannt als Container Native Virtualization) eingeführt – angefangen bei OpenShift Version 4.6. Mit der OpenShift Virtualization-Funktion können Sie virtuelle Maschinen parallel mit Containern auf derselben OpenShift Container Platform-Installation ausführen und verwalten. Sie bieten Hybrid-Managementfunktionen für die Automatisierung der Bereitstellung und des Managements von VMs durch Betreiber. Neben der Erstellung von VMs in OpenShift unterstützt Red hat mit OpenShift Virtualization auch den Import von VMs aus VMware vSphere, Red hat Virtualization und Red hat OpenStack Platform-Implementierungen.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift Virtualisierung</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">Bestimmte Funktionen wie Live VM-Migration, Klonen von VMs-Festplatten, VM-Snapshots usw. werden auch von der OpenShift Virtualization mit Unterstützung von Astra Trident unterstützt, wenn die NetApp ONTAP unterstützt wird. Beispiele für jeden dieser Workflows werden im weiteren Verlauf dieses Dokuments im jeweiligen Abschnitt erläutert.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Weitere Informationen zu Red hat OpenShift Virtualization finden Sie in der Dokumentation<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">Danach: Voraussetzungen Für Die Implementierung.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">Dieses Referenzdokument validiert die Red hat OpenShift-Lösung, die über IPI (Installer Provisioned Infrastructure) in verschiedenen Datacenter-Umgebungen bereitgestellt wird, wie von NetApp validiert. Sie Details zur Storage-Integration mit NetApp Storage-Systemen dank des Astra Trident Storage-Orchestrators für das Management von persistentem Storage sowie des NetApp Astra Control Center für das Management und die Sicherung statusbehafteter Applikationen. Abschließend werden eine Reihe von Validierungen von Lösungen und Anwendungsbeispiele aus der Praxis untersucht und dokumentiert.</block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">Erstellen Sie Ressourcen auf mehreren Clustern</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Dank erweitertem Cluster Management für Kubernetes können Benutzer Ressourcen auf einem oder mehreren gemanagten Clustern gleichzeitig über die Konsole erstellen. Wenn Sie beispielsweise OpenShift-Cluster an verschiedenen Standorten mit unterschiedlichen NetApp ONTAP-Clustern haben und an beiden Standorten PVC bereitstellen möchten, können Sie in der oberen Leiste auf das (+)-Zeichen klicken. Wählen Sie dann die Cluster aus, auf denen Sie die PVC erstellen möchten, fügen Sie die Ressource YAML ein und klicken Sie auf Erstellen.</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">Erstellen von Ressourcen</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">NetApp Container Solutions sind validierte Implementierungen vieler gängiger Kubernetes-basierter Container-Orchestrierungssysteme und ihre Integration in NetApp Storage-Managementsysteme und -Software.</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">Container-Lösungen von NetApp</block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">Installation von OpenShift Virtualization: Red hat OpenShift mit NetApp</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">Weiter: Weitere Informationen: Red hat OpenShift mit NetApp</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">Bereitstellung einer Virtual Machine mit OpenShift Virtualisierung: Red hat OpenShift mit NetApp</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Red hat OpenShift.</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident – Überblick</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Red hat OpenShift. Trident kann mit dem gesamten NetApp Storage-Portfolio eingesetzt werden, einschließlich NetApp ONTAP und Element Storage-Systeme. Es unterstützt auch NFS- und iSCSI-Verbindungen. Trident beschleunigt den DevOps-Workflow, da Endbenutzer Storage über ihre NetApp Storage-Systeme bereitstellen und managen können, ohne dass ein Storage-Administrator eingreifen muss.</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">Die neueste Version von Astra Trident ist die 22.01 Version von Januar 2022. Eine Support-Matrix, in der die Version von Trident getestet wurde, mit der Kubernetes Distribution zu finden ist<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Laden Sie Astra Trident Herunter</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">Um Trident auf dem implementierten Benutzer-Cluster zu installieren und ein persistentes Volume bereitzustellen, gehen Sie die folgenden Schritte durch:</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">Laden Sie das Installationsarchiv auf die Admin-Arbeitsstation herunter und extrahieren Sie den Inhalt. Die aktuelle Version von Trident ist 22.01, die heruntergeladen werden kann<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">Extrahieren Sie die Trident Installation aus dem heruntergeladenen Paket.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Installieren Sie den Trident Operator mit Helm</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">Legen Sie zunächst den Speicherort des Benutzer-Clusters fest<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Datei als Umgebungsvariable, damit Sie nicht darauf verweisen müssen, weil Trident keine Option hat, diese Datei zu übergeben.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Führen Sie den Helm-Befehl aus, um den Trident-Operator aus dem Tarball im Steuerverzeichnis zu installieren, während der Dreizack-Namespace in Ihrem Benutzer-Cluster erstellt wird.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">Sie können überprüfen, ob Trident erfolgreich installiert wurde, indem Sie die Pods prüfen, die im Namespace ausgeführt werden, oder die tridentctl-Binärdatei verwenden, um die installierte Version zu überprüfen.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">In einigen Fällen müssen die Kundenumgebungen möglicherweise die Anpassungen der Trident Implementierung erfordern. In diesen Fällen kann der Trident-Operator manuell installiert und die enthaltenen Manifeste aktualisiert werden, um die Implementierung anzupassen.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Trident Operator kann manuell installiert werden</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Legen Sie zunächst den Speicherort des Benutzer-Clusters fest<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Datei als Umgebungsvariable, damit Sie nicht darauf verweisen müssen, weil Trident keine Option hat, diese Datei zu übergeben.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">Der<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block> Das Verzeichnis enthält Manifeste für die Definition aller erforderlichen Ressourcen. Erstellen Sie mithilfe der entsprechenden Manifeste das<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block> Benutzerdefinierte Ressourcendefinition.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Wenn nicht vorhanden ist, erstellen Sie mithilfe des angegebenen Manifests einen Trident Namespace im Cluster.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">Erstellen Sie die Ressourcen, die für die Trident-Operator, wie z. B. ein, erforderlich sind<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block> Für den Operator A<block ref="d7d354d0f9d0780e168c895c92a32c24" prefix=" " category="inline-code"></block> Und<block ref="e866afd8290d5c73cda6260e04e6eef0" prefix=" " category="inline-code"></block> Bis zum<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block>, Eine engagierte<block ref="316707d12484dd3afede08839dee49bc" prefix=" " category="inline-code"></block>, Oder der Operator selbst.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">Sie können den Status des Bedieners überprüfen, nachdem er mit den folgenden Befehlen bereitgestellt wurde:</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">Mit dem implementierten Operator können wir nun Trident installieren. Dazu muss ein erstellt werden<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block>.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">Worker-Nodes für Storage vorbereiten</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">Bei den meisten Kubernetes-Distributionen kommen Pakete und Utilities zur standardmäßig installierten NFS-Back-Ends einschließlich Red hat OpenShift zum Einsatz.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">Bei NFSv3 gibt es jedoch keinen Mechanismus, um die Parallelität zwischen dem Client und dem Server auszuhandeln. Daher muss die maximale Anzahl der clientseitigen sunrpc-Slot-Tabelleneinträge manuell mit dem unterstützten Wert auf dem Server synchronisiert werden, um die beste Leistung für die NFS-Verbindung zu gewährleisten, ohne dass der Server die Fenstergröße der Verbindung verringern muss.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">Bei ONTAP ist die unterstützte maximale Anzahl von sunrpc-Slot-Tabelleneinträgen 128, d.h. ONTAP kann 128 gleichzeitige NFS-Anfragen gleichzeitig verarbeiten. Standardmäßig hat Red hat CoreOS/Red hat Enterprise Linux jedoch maximal 65,536 Sunrpc Slot-Tabelleneinträge pro Verbindung. Dieser Wert muss auf 128 gesetzt werden. Dies kann mit Machine Config Operator (MCO) in OpenShift geschehen.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">Gehen Sie wie folgt vor, um die maximalen Einträge in den OpenShift Worker Nodes zu ändern:</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">Melden Sie sich bei der OCP-Webkonsole an, und navigieren Sie zu „Compute“ &gt; „Machine Configs“. Klicken Sie Auf Maschinenkonfiguration Erstellen. Kopieren Sie die YAML-Datei und fügen Sie sie ein, und klicken Sie auf Erstellen.</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">Nach der Erstellung des MCO muss die Konfiguration auf alle Arbeitsknoten angewendet und nacheinander neu gestartet werden. Der gesamte Vorgang dauert etwa 20 bis 30 Minuten. Überprüfen Sie, ob die Maschinenkonfiguration mit angewendet wird<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> Und stellen Sie sicher, dass der Konfigurationspool für die Maschinenkonfiguration für die Arbeitnehmer aktualisiert wird.</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">Um die Worker-Knoten vorzubereiten, die die Zuordnung von Block-Speicher-Volumes über das iSCSI-Protokoll ermöglichen, müssen Sie die erforderlichen Pakete installieren, um diese Funktionalität zu unterstützen.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">In Red hat OpenShift wird dieser Vorgang durch Anwendung eines MCO (Machine Config Operator) auf das Cluster durchgeführt, nachdem es bereitgestellt wurde.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">Führen Sie die folgenden Schritte aus, um die Worker-Knoten für die Ausführung von iSCSI-Diensten zu konfigurieren:</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">Wenn Sie kein Multipathing verwenden:</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">Bei Verwendung von Multipathing:</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">Nach der Erstellung der Konfiguration dauert es etwa 20 bis 30 Minuten, die Konfiguration auf die Worker-Nodes anzuwenden und erneut zu laden. Überprüfen Sie, ob die Maschinenkonfiguration mit angewendet wird<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> Und stellen Sie sicher, dass der Konfigurationspool für die Maschinenkonfiguration für die Arbeitnehmer aktualisiert wird. Sie können sich auch bei den Worker-Nodes anmelden, um zu bestätigen, dass der iscsid-Service ausgeführt wird (und der Multipathd-Dienst wird ausgeführt, wenn Multipathing verwendet wird).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">Es ist auch möglich zu bestätigen, dass die MachineConfig erfolgreich angewendet wurde und die Dienste wie erwartet durch Ausführen der gestartet wurden<block ref="5c237bbde25a8cf47cdca465191a6c1d" prefix=" " category="inline-code"></block> Befehl mit den entsprechenden Flags.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">Erstellen von Storage-System-Back-Ends</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Nach Abschluss der Installation des Astra Trident Operator müssen Sie das Backend für die spezifische NetApp Storage-Plattform konfigurieren, die Sie verwenden. Folgen Sie den Links unten, um mit der Einrichtung und Konfiguration von Astra Trident fortzufahren.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">Als Nächstes: Lösungsvalidierung/-Anwendungsfälle: Red hat OpenShift mit NetApp</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">In diesem Abschnitt werden Optionen zur Lastverteilung für Benutzer untersucht, die ihre Red hat OpenShift mit NetApp Implementierung anpassen möchten.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">Load Balancer-Optionen: Red hat OpenShift mit NetApp</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">In den meisten Fällen stellt Red hat OpenShift Anwendungen für die Außenwelt über Routen zur Verfügung. Ein Service wird durch die Angabe eines extern zugänglichen Host-Namens zugänglich gemacht. Die definierte Route und die vom Dienst identifizierten Endpunkte können von einem OpenShift-Router genutzt werden, um diese benannte Verbindung externen Clients bereitzustellen.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">In einigen Fällen müssen jedoch Applikationen zum Einsatz kommen und eine Konfiguration von angepassten Lastausgleich erforderlich sein, um die entsprechenden Services bereitzustellen. Ein Beispiel hierfür ist das NetApp Astra Control Center. Um diesem Bedarf gerecht zu werden, haben wir eine Reihe von benutzerdefinierten Load Balancer-Optionen evaluiert. Die Installation und Konfiguration der Lösung wird in diesem Abschnitt beschrieben.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">Auf den folgenden Seiten sind zusätzliche Informationen zu den in Red hat OpenShift mit NetApp validierten Load Balancer-Optionen verfügbar:</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">Als Nächstes: Lösungsvalidierung/-Anwendungsfälle: Red hat OpenShift mit NetApp</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">Weitere Informationen zu ONTAP finden Sie im<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">Als Nächstes: Übersicht zu NetApp Storage-Integrationen</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="doc">OpenShift auf Bare Metal</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">OpenShift auf Bare Metal ermöglicht eine automatisierte Bereitstellung der OpenShift Container Platform auf Standard-Servern.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">OpenShift auf Bare Metal ähnelt den virtuellen OpenShift-Implementierungen, die eine einfache Implementierung, schnelle Provisionierung und Skalierung von OpenShift-Clustern ermöglichen. Gleichzeitig werden virtualisierte Workloads für Applikationen unterstützt, die nicht containerisiert werden können. Durch die Implementierung auf Bare Metal-Servern ist neben der OpenShift-Umgebung kein zusätzlicher Overhead für das Management der Host-Hypervisor-Umgebung erforderlich. Durch die direkte Bereitstellung auf Bare Metal-Servern sind zudem weniger physische Overhead-Einschränkungen möglich, wenn Ressourcen zwischen dem Host und der OpenShift-Umgebung gemeinsam genutzt werden müssen.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">OpenShift auf Bare Metal bietet folgende Funktionen:</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">*IPI oder Assisted Installer-Bereitstellung.* mit einem OpenShift-Cluster, der von Installer Provisioned Infrastructure (IPI) auf Bare-Metal-Servern bereitgestellt wird, können Kunden eine vielseitig skalierbare OpenShift-Umgebung direkt auf herkömmlichen Servern bereitstellen, ohne eine Hypervisor-Ebene verwalten zu müssen.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">*Kompaktes Cluster-Design.* um die Hardwareanforderungen zu minimieren, ermöglicht OpenShift auf Bare Metal den Benutzern die Bereitstellung von Clustern mit nur 3 Knoten, indem die OpenShift Control Plane Nodes auch als Worker Nodes und Host Container fungieren können.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">* OpenShift Virtualisierung.* OpenShift kann virtuelle Maschinen innerhalb von Containern mit OpenShift Virtualization ausführen. Bei dieser Container-nativen Virtualisierung wird der KVM-Hypervisor innerhalb eines Containers ausgeführt und persistente Volumes für den VM-Storage angebunden.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">*KI/ML-optimierte Infrastruktur.* Einsatz von Anwendungen wie Kubeflow für Machine-Learning-Anwendungen durch die Integration GPU-basierter Worker-Nodes in Ihre OpenShift-Umgebung und Nutzung von OpenShift Advanced Scheduling.</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Netzwerkdesign</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">Die Red hat OpenShift on NetApp Lösung verwendet zwei Daten-Switches für die primäre Datenkonnektivität mit 25 Gbit/s. Zudem werden zwei Management-Switches mit 1 Gbit/s für in-Band-Management der Storage-Nodes und bandexternen Management für IPMI-Funktionen verwendet.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">Für eine Bare-Metal-IPI-Bereitstellung mit OpenShift müssen Sie einen bereitstellungsknoten erstellen, einen Red hat Enterprise Linux 8-Rechner, für den Netzwerkschnittstellen mit separaten Netzwerken verbunden sein müssen.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">*Provisioning-Netzwerk.* Dieses Netzwerk wird verwendet, um die Bare-Metal-Knoten zu booten und die notwendigen Images und Pakete zu installieren, um den OpenShift-Cluster bereitzustellen.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">*Bare-Metal-Netzwerk.* Dieses Netzwerk wird nach seiner Bereitstellung für die Kommunikation mit öffentlichen Einrichtungen des Clusters verwendet.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">Für das Setup des bereitstellungsknoten erstellt der Kunde Bridge-Schnittstellen, die es dem Traffic ermöglichen, auf dem Node selbst und auf der Bootstrap-VM, die für Bereitstellungszwecke bereitgestellt wird, ordnungsgemäß zu leiten. Nach der Bereitstellung des Clusters werden die API- und Ingress-VIP-Adressen vom Bootstrap-Node zum neu implementierten Cluster migriert.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">Die folgenden Bilder zeigen die Umgebung sowohl während der IPI-Bereitstellung als auch nach Abschluss der Bereitstellung.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN-Anforderungen</block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">Die Lösung Red hat OpenShift mit NetApp wurde speziell zur logischen Trennung des Netzwerk-Traffic für unterschiedliche Zwecke mithilfe von Virtual Local Area Networks (VLANs) entwickelt.</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLANs</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN-ID</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">Out-of-Band-Managementnetzwerk</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">Management für Bare-Metal-Nodes und IPMI</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">Bare-Metal-Netzwerk</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">Netzwerk für OpenShift-Services, sobald Cluster verfügbar ist</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">Bereitstellung von Netzwerken</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Netzwerk für PXE-Boot und Installation von Bare Metal-Knoten über IPI</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">Obwohl jedes dieser Netzwerke virtuell durch VLANs getrennt ist, muss jeder physische Port im Zugriffsmodus mit dem zugewiesenen primären VLAN eingerichtet werden, da es während einer PXE-Startsequenz keine Möglichkeit gibt, ein VLAN-Tag zu übergeben.</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">Support-Ressourcen für die Netzwerkinfrastruktur</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">Vor der Bereitstellung der OpenShift-Container-Plattform sollte die folgende Infrastruktur vorhanden sein:</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">Mindestens ein DNS-Server, der eine vollständige Host-Name-Auflösung bietet, auf die über das bandinterne Managementnetzwerk und das VM-Netzwerk zugegriffen werden kann.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">Mindestens ein NTP-Server, auf den über das bandinterne Managementnetzwerk und das VM-Netzwerk zugegriffen werden kann.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(Optional) ausgehende Internetverbindung sowohl für das bandinterne Managementnetzwerk als auch für das VM-Netzwerk.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">Als Nächstes: NetApp Storage – Überblick</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI-Konfiguration</block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">Um die Trident Integration mit dem NetApp ONTAP Storage-System zu aktivieren, müssen Sie ein Back-End erstellen, das die Kommunikation mit dem Storage-System ermöglicht.</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">Im heruntergeladenen Installationsarchiv stehen Beispiele für Backend-Dateien zur Verfügung<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> Ordnerhierarchie. Kopieren Sie bei NetApp ONTAP-Systemen, die iSCSI bereitstellen, das<block ref="684351d8ace6c8daa15d6a5ec881647e" prefix=" " category="inline-code"></block> Datei in Ihr Arbeitsverzeichnis und bearbeiten Sie die Datei.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">Bearbeiten Sie die Werte ManagementLIF, dataLIF, svm, Benutzername und Passwort in dieser Datei.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">Führen Sie mit dieser Backend-Datei den folgenden Befehl aus, um Ihr erstes Backend zu erstellen.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">Wenn das Back-End erstellt wird, müssen Sie als nächstes eine Storage-Klasse erstellen. Wie beim Backend gibt es auch eine Beispiel-Speicherklassendatei, die für die im Ordner Sample-Inputs verfügbare Umgebung bearbeitet werden kann. Kopieren Sie ihn in das Arbeitsverzeichnis und nehmen Sie die erforderlichen Änderungen an dem erstellten Backend vor.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">Die einzige Bearbeitung, die zu dieser Datei gemacht werden muss, ist das zu definieren<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Wert für den Namen des Speichertreibers aus dem neu erstellten Back-End. Notieren Sie auch den Wert des Namensfelds, auf den in einem späteren Schritt verwiesen werden muss.</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">Es gibt ein optionales Feld mit dem Namen<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> Das ist in dieser Datei definiert. In iSCSI-Back-Ends kann dieser Wert auf einen bestimmten Linux-Dateisystem-Typ (XFS, ext4 usw.) gesetzt oder gelöscht werden, damit OpenShift entscheiden kann, welches Dateisystem verwendet werden soll.</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">Führen Sie die aus<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> Befehl zum Erstellen der Storage-Klasse.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">Nach Erstellung der Storage-Klasse müssen Sie dann die erste Forderung für ein persistentes Volume (PVC) erstellen. Es gibt ein Beispiel<block ref="a46b72c0e3ff39640d78567a663da1aa" prefix=" " category="inline-code"></block> Datei, mit der diese Aktion ausgeführt werden kann, die sich auch in Sample-Inputs befindet.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">Die einzige Bearbeitung, die zu dieser Datei gemacht werden muss, ist sicherzustellen, dass die<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> Feld entspricht dem gerade erstellten. Die PVC-Definition kann je nach Bedarf des bereitzustellenden Workloads weiter angepasst werden.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">Erstellen Sie das PVC, indem Sie die ausstellen<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> Befehl. Die Erstellung kann je nach Größe des erstellten Sicherungsvolumens einige Zeit in Anspruch nehmen, sodass Sie den Prozess nach Abschluss beobachten können.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">Weiter: Lösungsvalidierung/-Anwendungsfälle.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">Bei mandantenfähigen Lösungen kann der Benutzer nicht auf mehr Cluster-Ressourcen zugreifen, als erforderlich ist. So sind alle Ressourcen, die als Teil der mandantenfähige Konfiguration konfiguriert werden müssen, in die Bereiche Cluster-Admin, Storage-Admin und Entwickler unterteilt, die an den einzelnen Projekten arbeiten.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">In der folgenden Tabelle sind die verschiedenen Aufgaben aufgeführt, die von verschiedenen Benutzern ausgeführt werden müssen:</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* Cluster-Admin*</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">Erstellung von Projekten für verschiedene Applikationen oder Workloads</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">ClusterRoles and Roles Bindings für Storage-Admin erstellen</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">Erstellen Sie Rollen und RolleBindungen für Entwickler, die bestimmten Projekten Zugriff zuweisen</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[Optional] Konfigurieren Sie Projekte, um PODs für bestimmte Nodes zu planen</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* Storage-Admin*</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">SVMs auf NetApp ONTAP erstellen</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Erstellen von Trident Back-Ends</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">Erstellen von StorageClasses</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">Erstellen von Storage-RessourcenQuotas</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">*Entwickler*</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">Validieren des Zugriffs zum Erstellen oder Patchen von PVCs oder Pods im zugewiesenen Projekt</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">Validieren des Zugriffs zum Erstellen oder Patchen von PVCs oder Pods in einem anderen Projekt</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">Validieren des Zugriffs zum Anzeigen oder Bearbeiten von Projekten, ResourceQuotas und StorageClasses</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">Weiter: Voraussetzungen.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">Mandantenfähigkeit auf Red hat OpenShift mit NetApp konfigurieren</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">Viele Unternehmen, die mehrere Anwendungen oder Workloads in Containern ausführen, implementieren meist ein Red hat OpenShift-Cluster pro Applikation oder Workload. Auf diese Weise können sie eine strenge Isolation für die Applikation oder den Workload implementieren, die Performance optimieren und Sicherheitsschwachstellen reduzieren. Die Bereitstellung eines separaten Red hat OpenShift-Clusters für jede Applikation stellt jedoch eigene Probleme dar. Es erhöht den betrieblichen Overhead, der jedes Cluster einzeln überwachen und managen muss. Außerdem erhöht es die Kosten, die durch dedizierte Ressourcen für verschiedene Applikationen entstehen, und behindert die effiziente Skalierbarkeit.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">Um diese Probleme zu beheben, kann man in Betracht ziehen, alle Anwendungen oder Workloads in einem einzigen Red hat OpenShift-Cluster auszuführen. In einer solchen Architektur stellen jedoch die Schwachstellen bei der Ressourcen-Isolierung und Applikationssicherheit eine der größten Herausforderungen dar. Sicherheitsschwachstellen bei einem Workload können natürlich auf einen anderen Workload überlaufen, wodurch die Aufprallzone erhöht wird. Darüber hinaus kann jede abrupte, unkontrollierte Ressourcenauslastung einer Applikation die Performance einer anderen Applikation beeinträchtigen, da standardmäßig keine Ressourcenzuordnungsrichtlinie vorhanden ist.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">Daher interessieren sich Unternehmen für Lösungen, die sich in beiden Welten optimal einsetzen lassen: Sie können dadurch beispielsweise alle Workloads in einem einzelnen Cluster ausführen und dennoch die Vorteile eines dedizierten Clusters für jeden Workload bieten.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">Eine solche effektive Lösung ist die Konfiguration der Mandantenfähigkeit auf Red hat OpenShift. Mandantenfähigkeit ist eine Architektur, in der mehrere Mandanten gleichzeitig im selben Cluster nebeneinander existieren können, wobei Ressourcen, Sicherheit usw. voneinander isoliert werden. In diesem Zusammenhang kann ein Mandant als Teilbereich der Cluster-Ressourcen angesehen werden, die so konfiguriert sind, dass er für einen exklusiven Zweck von einer bestimmten Benutzergruppe verwendet werden kann. Die Konfiguration der Mandantenfähigkeit auf einem Red hat OpenShift-Cluster bietet folgende Vorteile:</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">A - Verringerung von Investitions- und Betriebskosten durch gemeinsame Nutzung von Cluster-Ressourcen</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">Geringerer Betriebs- und Managementaufwand</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">Schutz der Workloads vor Kreuzkontamination von Sicherheitsverletzungen</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">Schutz von Workloads vor unerwarteter Performance-Verschlechterung aufgrund von Ressourcenkonflikten</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">Für einen vollständig realisierten, mandantenfähigen OpenShift-Cluster müssen Quoten und Einschränkungen für Cluster-Ressourcen konfiguriert werden, die zu verschiedenen Ressourcen-Buckets gehören: computing, Storage, Netzwerk, Sicherheit usw. Obwohl wir in dieser Lösung bestimmte Aspekte aller Ressourcen-Buckets abdecken, Die Best Practices für die Isolierung und Sicherung von Daten, die von mehreren Workloads bereitgestellt oder genutzt werden, stehen im selben Red hat OpenShift Cluster im Mittelpunkt. Dazu müssen Mandantenfähigkeit auf Storage-Ressourcen konfiguriert werden, die durch Astra Trident und NetApp ONTAP dynamisch zugewiesen werden.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Damit das Astra Control Center Ihre Workloads managen kann, müssen Sie zunächst Ihren Red hat OpenShift-Cluster registrieren.</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Registrieren Sie Ihre Red hat OpenShift-Cluster mit dem Astra Control Center</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Red hat OpenShift-Cluster registrieren</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">Der erste Schritt besteht darin, die OpenShift Cluster zum Astra Control Center hinzuzufügen und zu verwalten. Wechseln Sie zu Cluster und klicken Sie auf Cluster hinzufügen, laden Sie die kubeconffig-Datei für den OpenShift-Cluster hoch, und klicken Sie auf Storage auswählen.</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center erstellt ein Cluster</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">Die kubeconfig-Datei kann zur Authentifizierung mit einem Benutzernamen und Passwort oder einem Token erzeugt werden. Token laufen nach begrenzter Zeit ab und lassen das registrierte Cluster möglicherweise nicht mehr erreichbar. NetApp empfiehlt, eine kubeconfig-Datei mit einem Benutzernamen und einem Passwort zu verwenden, um Ihre OpenShift-Cluster beim Astra Control Center zu registrieren.</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center erkennt geeignete Storage-Klassen. Wählen Sie jetzt aus, wie Storage Volumes mithilfe von Trident durch eine SVM auf NetApp ONTAP bereitgestellt werden, und klicken Sie auf „Review“ (prüfen). Überprüfen Sie im nächsten Teilfenster die Details, und klicken Sie auf Cluster hinzufügen.</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center Erstellen Sie Cluster Select Storage</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">Registrieren Sie beide OpenShift-Cluster wie in Schritt 1 beschrieben. Wenn sie hinzugefügt werden, wechseln die Cluster zum Status Erkennung, während das Astra Control Center sie überprüft und die erforderlichen Agenten installiert. Der Cluster-Status ändert sich auf „ausgeführt“, nachdem sie erfolgreich registriert wurden.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Astra Control Center Cluster verfügbar</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Alle von Astra Control Center zu verwaltenden Red hat OpenShift-Cluster sollten Zugriff auf die Bildregistrierung haben, die für die Installation verwendet wurde, da die auf den verwalteten Clustern installierten Agenten die Bilder aus dieser Registrierung ziehen.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Importieren Sie ONTAP-Cluster als Storage-Ressourcen, die vom Astra Control Center als Back-Ends gemanagt werden sollen. Wenn dem Astra OpenShift-Cluster hinzugefügt und ein Storage-glass konfiguriert ist, erkennt und inspiziert er den ONTAP-Cluster automatisch auf der Basis der Storage-glass, importiert ihn aber nicht in das zu verwaltende Astra-Control-Center.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Backend-Discovery für Astra Control Center</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">Um die ONTAP-Cluster zu importieren, gehen Sie zu Backend, klicken Sie auf das Dropdown-Menü und wählen Sie Verwalten neben dem zu verwaltenden ONTAP-Cluster aus. Geben Sie die ONTAP-Cluster-Anmeldeinformationen ein, klicken Sie auf Informationen überprüfen und klicken Sie dann auf Speicher-Backend importieren.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center erstellen Backend</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">Nach dem Hinzufügen der Back-Ends ändert sich der Status in „verfügbar“. Diese Back-Ends enthalten jetzt Informationen über die persistenten Volumes im OpenShift-Cluster und die entsprechenden Volumes im ONTAP-System.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Astra Control Center Back-Ends verfügbar</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Für Backups und Restores in OpenShift-Clustern mit Astra Control Center müssen Sie einen Objekt-Storage-Bucket bereitstellen, der das S3-Protokoll unterstützt. Aktuell werden ONTAP S3, StorageGRID und AWS S3 unterstützt. Im Rahmen dieser Installation wird ein AWS S3-Bucket konfiguriert. Wechseln Sie zu Buckets, klicken Sie auf „Bucket hinzufügen“ und wählen Sie „Allgemeines S3“ aus. Geben Sie die Details zum S3-Bucket ein und erhalten Sie Zugangsdaten, um darauf zuzugreifen. Aktivieren Sie das Kontrollkästchen „Machen Sie diesen Bucket zum Standard-Bucket für die Cloud“ und klicken Sie dann auf Hinzufügen.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center Bucket erstellen</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">Wählen Sie dann die zu schützenden Anwendungen aus.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="d7b2cdc877c7db996d45c651b4e7834a" category="paragraph">In diesem Dokument werden die Konfiguration und Validierung der NetApp ONTAP-Storage-Plattform mit Google Cloud Anthos auf Bare-Metal-Plattform erläutert. Sie verwenden NetApp Astra Trident, den Open-Source-Storage-Orchestrator für Kubernetes, um persistenten Storage für zustandsorientierte Applikations-Container zu implementieren und zu managen.</block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">Während die aktuelle Implementierung dieser Lösung mithilfe von Tools des Google Cloud-Teams zwei strenge Validierungsprozesse durchgeführt wurde.</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">Lösungsvalidierung</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">Während die aktuelle Implementierung dieser Lösung mithilfe von Tools des Google Cloud-Teams zwei strenge Validierungsprozesse durchgeführt wurde. Diese Validierungen umfassen eine Auswahl der folgenden Tests:</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Partnervalidierung der Anthos-fähigen Plattform:</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">Vergewissern Sie sich, dass alle Anthos auf Bare-Metal-Plattform-Services installiert sind und ausgeführt werden.</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">Skalieren Sie die physischen Anthos auf Bare-Metal-Cluster von vier Worker-Nodes auf drei und dann zurück auf vier.</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">Erstellen und Löschen eines benutzerdefinierten Namespace</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Erstellen Sie eine Bereitstellung des Nginx-Webservers, indem Sie die Bereitstellung durch Erhöhung der Anzahl der Replikate skalieren.</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Erstellen Sie einen Ingress für die Nginx-Anwendung, und überprüfen Sie die Konnektivität durch Curling des Index.HTML.</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">Alle Test-Suite-Aktivitäten erfolgreich bereinigen und das Cluster in einen Pre-Test-Status versetzen.</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Partnervalidierung für Anthos-fähigen Storage:</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">Bereitstellung mit einem persistenten Volume erstellen</block>
  <block id="2b9593caebc55ca069d98dcb7a3473c8" category="list-text">Mit dem NetApp Astra Trident können Sie das angeforderte persistente Volume von NetApp ONTAP bereitstellen und anhängen.</block>
  <block id="c0724935c9b9fa3acfd0441317cac5e4" category="list-text">Validieren der Trennen und Wiederanbinden von persistenten Volumes</block>
  <block id="05053a6eeca3d00f1ffdaead4d65118f" category="list-text">Validieren Sie den schreibgeschützten, Multi-Attached Storage-Zugriff auf persistente Volumes von anderen Pods auf dem Node.</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">Validieren Sie die Größenanpassung des Offline-Volumes.</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">Überprüfung, ob das persistente Volume einen Cluster-Scale-Vorgang überlebt.</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">Dank der hardwareunabhängigen Funktionen von Anthos auf Bare Metal können Sie eine Compute-Plattform auswählen, die für Ihren Anwendungsfall optimiert ist. Somit können Sie die Anpassung Ihrer bestehenden Infrastruktur vornehmen und Ihre Kapitalausgaben senken.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">Anforderungen der Lösung erfüllen</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">Computing: Eigenen Server verwenden</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">Dank der hardwareunabhängigen Funktionen von Anthos auf Bare Metal können Sie eine Compute-Plattform auswählen, die für Ihren Anwendungsfall optimiert ist. Somit können Sie die Anpassung Ihrer bestehenden Infrastruktur vornehmen und Ihre Kapitalausgaben senken.</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">In der folgenden Tabelle ist die Mindestanzahl an Computing-Hardwarekomponenten aufgeführt, die für die Implementierung dieser Lösung erforderlich sind. Die verwendeten Hardwaremodelle können jedoch je nach Anforderungen des Kunden variieren.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">Zu Verwenden</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">Hardware und Modell</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">Admin-Nodes</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">Worker-Nodes</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">NetApp ONTAP</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">In der folgenden Tabelle ist die Mindestanzahl an Storage-Hardware-Komponenten aufgeführt, die für die Implementierung der Lösung erforderlich sind. Die verwendeten Hardware-Modelle können jedoch je nach Anforderungen des Kunden variieren.</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 (1 HA-Paar)</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">Die in der folgenden Tabelle aufgeführten Softwareversionen wurden von NetApp und unseren Partnern zur Validierung der Lösung mit NetApp verwendet. Die verwendeten Software-Komponenten können jedoch je nach Anforderungen des Kunden variieren.</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">OS auf 3 Administratoren</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">OS auf Worker4</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">OS auf Worker3</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">OS auf Worker2</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">OS auf Worker1</block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="cell">Anthos auf Bare Metal</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">Container-Orchestrierung</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">Storage-Betriebssystem</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Container-Storage-Management</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">Diese Multi-OS-Umgebung zeigt die Interoperabilität mit unterstützten Betriebssystemversionen der Anthos auf Bare Metal-Lösung. Wir gehen davon aus, dass Kunden für die Implementierung ein oder mehrere Betriebssysteme standardisieren werden.</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Anthos auf Bare-Metal-Dokumentation</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">Weitere Informationen zu Anthos für Bare-Metal-Hardware- und -Software-Anforderungen finden Sie im<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> Seite.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">Als Nächstes: Zusammenfassung der Implementierung</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">Anthos auf Bare Metal mit NetApp bietet eine robuste Plattform zur effizienten Ausführung containerbasierter Workloads durch die Anpassung der implementierten Infrastruktur.</block>
  <block id="65ffe919dd9568cce4454508d8e543bd" category="paragraph">Anthos auf Bare Metal mit NetApp bietet eine robuste Plattform zur effizienten Ausführung containerbasierter Workloads durch die Anpassung der implementierten Infrastruktur. Kunden können die Server-Infrastruktur und ein unterstütztes Betriebssystem ihrer Wahl nutzen oder die Lösung sogar in ihrer vorhandenen Infrastruktur implementieren. Die Leistung und Flexibilität dieser Umgebungen steigt erheblich durch die Integration von NetApp ONTAP und NetApp Astra Trident. Sie unterstützt statusorientierte Applikations-Workloads durch eine effiziente Bereitstellung und das effiziente Management von persistentem Storage für Container. Wenn Kunden das Potenzial von Google Cloud auf der Basis von NetApp Systemen ihrem Datacenter ausschöpfen, profitieren sie von den Vorteilen einer vollständig unterstützten, hochverfügbaren, einfach skalierbaren und vollständig gemanagten Kubernetes-Lösung zur Entwicklung und Produktion ihrer Applikations-Workloads.</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">NetApp ONTAP Documentation Center</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="list-text">Google Cloud Anthos</block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="c8a326f53d0d33a113452a303c243987" category="summary">NetApp und Google Cloud arbeiten seit mehreren Jahren eng zusammen: NetApp stellt gemeinsam mit Cloud Volumes ONTAP und Cloud Volumes Service Cloud-Datenservices vor, die erstmals in Google Cloud verfügbar sind. Anschließend wird die On-Premises-NetApp HCI-Plattform für Google Cloud Anthos validiert – eine Hypervisor-basierte Kubernetes-Lösung für Multi-Cloud-Umgebungen auf VMware vSphere. NetApp hat Anthos Ready Qualification für NetApp Astra Trident, ONTAP und das NFS-Protokoll bestanden, um dynamischen persistenten Storage für Container bereitzustellen.</block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337: Anthos auf Bare Metal</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">Alan Cowles und Nikhil M Kulkarni, NetApp</block>
  <block id="f989491ea62ea4778f84ec6b21a68adf" category="paragraph">NetApp und Google Cloud arbeiten seit mehreren Jahren eng zusammen: NetApp stellt gemeinsam mit Cloud Volumes ONTAP und Cloud Volumes Service Cloud-Datenservices für Google Cloud vor. Anschließend wird die On-Premises-NetApp HCI-Plattform für Google Cloud Anthos validiert – eine Hypervisor-basierte Kubernetes-Lösung für Multi-Cloud-Umgebungen auf VMware vSphere. NetApp hat Anthos Ready Qualification für NetApp Astra Trident, ONTAP und das NFS-Protokoll bestanden, um dynamischen persistenten Storage für Container bereitzustellen.</block>
  <block id="1349318f8c0f3a02420c7453ca5cda7d" category="paragraph">Anthos kann jetzt direkt auf Bare-Metal-Servern in der Kundenumgebung installiert werden, was eine zusätzliche Option für Kunden zur Erweiterung von Google Cloud in ihre lokalen Rechenzentren ohne Hypervisor bietet. Durch die Nutzung der Funktionen des Storage-Betriebssystems NetApp ONTAP und des NetApp Astra Trident können Sie die Funktionen Ihrer Plattform erweitern, indem Sie persistenten Storage für Container integrieren.</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">Mit dieser Kombination können Sie das volle Potenzial Ihrer Server, Ihres Storage und Ihres Netzwerks ausschöpfen sowie Support, Service Level, monatliche Abrechnung und bedarfsgerechte Flexibilität wie Google Cloud bieten. Da Sie Ihre eigene Hardware, Ihr Netzwerk und Ihren eigenen Storage verwenden, haben Sie die direkte Kontrolle über Applikationsskala, Sicherheit und Netzwerklatenz sowie die Vorteile von gemanagten und containerisierten Applikationen mit Anthos auf Bare Metal.</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">Zur ersten Validierung dieser Lösung arbeitete NetApp mit World Wide Technology (WWT) zusammen, um eine Umgebung im Advanced Technology Center (ATC) von WWT aufzubauen. Anthos wurde auf einer Bare-Metal-Infrastruktur mithilfe des bmctl-Tools von Google Cloud implementiert. Der folgende Abschnitt beschreibt die Implementierung, die für Validierungszwecke verwendet wird.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">Zusammenfassung der Implementierung</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">Anthos auf Bare Metal mit NetApp Lösung wurde als hochverfügbares Hybrid-Cluster mit drei Anthos Control Plane-Nodes und vier Anthos-Worker-Nodes konzipiert.</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">Es wurden die Knoten für die Kontrollebene verwendet, die Cisco UCS B200M3 Blade-Server waren, die in einem Chassis gehostet und mit einer einzigen Virtual Network Interface Card (vNIC) auf jedem konfiguriert wurden. Dies ermöglichte Ein Failover Auf Ebene der Cisco UCS Plattform zur Fehlertoleranz. Das Cisco UCS-Gehäuse ist vorgelagerte an ein Paar Cisco UCS 6248 Fabric Interconnects angeschlossen, wodurch getrennte Pfade für die Trennung des Datenverkehrs entlang Fabric A und Fabric B bereitgestellt werden Diese Fabric Interconnects sind über ein vorgelagertes Cisco Nexus 5548 Datacenter-Switch-Paar verbunden, die an das Kernnetzwerk im WWT gebunden sind.</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">Die Worker-Knoten waren HP ProLiant DL360-Knoten, auf denen jeweils eine der unterstützten Linux-Distributionen für Anthos auf Bare Metal ausgeführt wurde: Red hat Enterprise Linux 8.2, CentOS 8.2, Ubuntu 20.04 LTS oder Ubuntu 18.04 LTS. Die Knoten Red hat Enterprise Linux 8 und CentOS 8 wurden mit NIC-Teams konfiguriert, die im LACP-Modus ausgeführt wurden und für Fehlertoleranz mit zwei Nexus 9k C93180YC-FX Switches verkabelt wurden. Die Ubuntu Server wurden für das Netzwerk-Bonding im LACP-Modus konfiguriert und für Fehlertoleranz mit demselben Paar Nexus 9k Switches verkabelt.</block>
  <block id="4ed7e16612fd7090efc8d89c68421b74" category="paragraph">Das NetApp AFF A300 Storage-System mit ONTAP 9.7 wurde installiert und physisch mit demselben Paar Nexus 9k-Switches verbunden, wie die Anthos-Worker-Nodes. Diese Netzwerk-Uplinks wurden in einer Interface Group (a0a) aggregiert und das entsprechende Datennetzwerk VLAN wurde markiert, damit die Worker Nodes mit dem Storage-System interagieren können. Eine Storage Virtual Machine (SVM) wurde mit Daten-LIFs erstellt, die das NFS-Protokoll unterstützen, und für Storage-Abläufe von Trident dediziert ist. Damit können die Container in Anthos auf Bare-Metal-Cluster persistenten Storage bereitstellen. Diese persistenten Volumes wurden durch NetApp Astra Trident 20.10 bereitgestellt, die neueste Version des vollständig unterstützten Open Source Storage Orchestrator von NetApp für Kubernetes.</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">Die folgende Abbildung zeigt ein Diagramm zur physischen Verkabelung der Lösung über die oberen Bereiche des Rack Datacenter Switches.</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">Die nächste Abbildung zeigt eine logische Ansicht der Lösung, die auf der Hardware im Lab des NetApp Partners WWT implementiert und validiert wurde.</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">Weiter: Lösungsvalidierung.</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF ist eine robuste All-Flash-Storage-Plattform mit latenzarmer Performance, integrierter Datensicherung, Multiprotokoll-Support und unterbrechungsfreiem Betrieb. Mit der Datenmanagement-Software NetApp ONTAP sorgt NetApp AFF für einen unterbrechungsfreien Betrieb – von der Wartung über Upgrades bis hin zum kompletten Ersatz Ihres Storage-Systems.</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp ONTAP auf NetApp All Flash FAS/FAS</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP ist ein leistungsstarkes Storage-Software-Tool mit Funktionen wie einer intuitiven GUI, REST-APIs mit Automatisierungsintegration, KI-fundierte prädiktive Analysen und Korrekturmaßnahmen, unterbrechungsfreien Hardware-Upgrades und Storage-Import.</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">*NetApp FlexClone.* ermöglicht die sofortige Bereitstellung einer vollständig lesbaren und schreibbaren Kopie eines NetApp Volumes auf Basis einer Snapshot Kopie. Weitere Informationen zu ONTAP finden Sie im<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a5e993e443aa30456050e2589b6e1a7" category="paragraph">NetApp Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Google Cloud Anthos. Kompatibel mit dem gesamten NetApp Storage-Portfolio einschließlich NetApp ONTAP Software Trident ist vollständig CSI-konform und beschleunigt den DevOps-Workflow, da Sie Storage von Ihren NetApp Storage-Systemen bereitstellen und managen können, ohne dass ein Storage-Administrator eingreifen muss. Trident wird als Operator implementiert, der direkt mit dem Kubernetes API-Endpunkt kommuniziert, um Storage-Anfragen von Containern in Form von PVCs (Persistent Volume Claims) zu bedienen, indem Volumes auf dem NetApp Storage-System erstellt und gemanagt werden.</block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">Persistente Volumes (PVS) werden auf Basis von Storage-Klassen bereitgestellt, die in der Kubernetes-Umgebung definiert sind. Sie verwenden Storage-Back-Ends, die von einem Storage-Administrator erstellt wurden (die an die Projektanforderungen angepasst werden können) und Storage-Systemmodelle für eine beliebige Anzahl an erweiterten Storage-Funktionen, wie Komprimierung, bestimmte Festplattentypen oder QoS-Level, die die Performance garantieren.</block>
  <block id="eb3bc37ad07db70234f55e02bb4fa499" category="paragraph">Weitere Informationen zu NetApp Astra Trident finden Sie im<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> Seite.</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident orchestriert Storage von jedem System und jedem Service im NetApp Portfolio.</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Google Cloud Anthos ist eine Cloud-basierte Kubernetes Datacenter-Lösung, mit der Unternehmen moderne Hybrid-Cloud-Infrastrukturen aufbauen und managen und gleichzeitig flexible Workflows einführen können, die sich auf die Applikationsentwicklung konzentrieren. Anthos auf Bare Metal erweitert die Fähigkeit von Anthos, On-Premises direkt auf physischen Servern ohne Hypervisor-Ebene auszuführen und ohne die Kompatibilität mit Anthos GKE-Clustern in der Google Cloud zu nutzen.</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">Die Einführung von Containern, Mesh-Diensten und anderen Transformationstechnologien ermöglicht Unternehmen konsistente Applikationsentwicklungszyklen und produktionsbereite Workloads in lokalen und Cloud-basierten Umgebungen.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos bietet die folgenden Funktionen:</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">*Anthos Konfigurationsmanagement.* automatisiert die Richtlinie und Sicherheit von hybriden Kubernetes-Implementierungen.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">*Anthos Service Mesh.* verbessert die Beobachtbarkeit, Sicherheit und Kontrolle von Anwendungen mit einem Istio-betriebenen Service-Mesh.</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">*Google Cloud Marketplace für Kubernetes-Anwendungen.* ein Katalog von kuratierten Container-Anwendungen zur einfachen Bereitstellung verfügbar.</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">* Migrieren Sie nach Anthos.* Automatische Migration von physischen Services und VMs von lokalen Systemen in die Cloud. Abbildung 3 zeigt die Anthos Lösung und die Art und Weise, wie eine Implementierung in einem On-Premises-Datacenter mit Infrastruktur in der Cloud verbindet.</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Anthos-Website</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Weitere Informationen zu Anthos finden Sie im<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>.</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">Die folgende Abbildung zeigt die Google Cloud Anthos Architektur.</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">Anthos auf Bare Metal ist eine Erweiterung von GKE, die im privaten Rechenzentrum eines Kunden eingesetzt wird. Ein Unternehmen kann dieselben Applikationen implementieren, die für die Ausführung in Containern in Google Cloud in Anthos Clustern vor Ort entwickelt wurden. Anthos auf Bare Metal läuft direkt auf physischen Servern mit der Wahl des Benutzers zugrunde liegenden Linux-Betriebssystems und bietet Kunden eine vollwertige Hybrid Cloud-Umgebung mit der Möglichkeit, im Kern oder am Rand ihrer Rechenzentren zu laufen.</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">Anthos auf Bare Metal bietet folgende Vorteile:</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">*Hardwareunabhängig.* Kunden können Anthos auf einer optimierten Hardware-Plattform ihrer Wahl in ihren bestehenden Rechenzentren einsetzen.</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">*Kosteneinsparungen.* Sie können deutliche Kosteneinsparungen erzielen, indem Sie Ihre eigenen physischen Ressourcen für Applikationsimplementierungen verwenden, anstatt Ressourcen in der Google Cloud-Umgebung bereitzustellen.</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">*Entwickeln und veröffentlichen.* Sie können On-Premises-Bereitstellungen während der Entwicklung von Anwendungen nutzen, die das Testen von Anwendungen in der Privatsphäre Ihres lokalen Rechenzentrums ermöglichen, bevor Sie sie in der Cloud öffentlich zur Verfügung stellen.</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">*Bessere Performance.* intensive Applikationen, die eine geringe Latenz und höchste Performance erfordern, laufen näher an der Hardware.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">*Sicherheitsanforderungen.* Kunden mit erhöhten Sicherheitsbedenken oder vertraulichen Datensätzen, die nicht in der Public Cloud gespeichert werden können, können ihre Anwendungen von der Sicherheit ihrer eigenen Rechenzentren aus ausführen und damit die organisatorischen Anforderungen erfüllen.</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">*Management und Betrieb.* Anthos on Bare Metal verfügt über eine breite Palette von Einrichtungen, die die betriebliche Effizienz erhöhen, wie integrierte Netzwerke, Lifecycle Management, Diagnose, Health Checks, Protokollierung, Und Monitoring:</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">Als Nächstes: Lösungsanforderungen.</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">Damit die Trident Integration mit dem NetApp ONTAP Storage-System aktiviert werden kann, muss ein Backend erstellt werden, das die Kommunikation zum Storage-System ermöglicht.</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">Konfiguration von NetApp ONTAP NFS</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">Im heruntergeladenen Installationsarchiv stehen Beispiele für Backend-Dateien zur Verfügung<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> Ordnerhierarchie. Kopieren Sie für NetApp ONTAP-Systeme, die NFS bereitstellen, den<block ref="d897e4d05156cbf9998e98200d6190aa" prefix=" " category="inline-code"></block> Datei in Ihr Arbeitsverzeichnis und bearbeiten Sie die Datei.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">BackendName, Management LIF, Daten LIF, svm, Benutzername, bearbeiten Und Kennwortwerte in dieser Datei.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">Als Best Practice empfiehlt es sich, den benutzerdefinierten BackendName-Wert als Kombination aus storageDriverName und der DatenLIF zu definieren, die NFS bedienen, um die einfache Identifizierung zu erleichtern.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">Es gibt ein optionales Feld mit dem Namen<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> Das ist in dieser Datei definiert. Diese Zeile kann in NFS-Back-Ends gelöscht werden.</block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere ist eine Virtualisierungsplattform zur zentralen Verwaltung einer großen Anzahl virtualisierter Server und Netzwerke, die auf dem ESXi Hypervisor ausgeführt werden.</block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="doc">OpenShift auf VMware vSphere</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere Website</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">Weitere Informationen zu VMware vSphere finden Sie im<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere bietet folgende Funktionen:</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">*VMware vCenter Server.* VMware vCenter Server bietet ein einheitliches Management aller Hosts und VMs von einer einzigen Konsole aus und aggregiert die Performance-Überwachung von Clustern, Hosts und VMs.</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">*VMware vSphere vMotion.* VMware vCenter ermöglicht die unterbrechungsfreie Migration von VMs zwischen Knoten des Clusters bei Anfrage.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">*VSphere High Availability.* um Unterbrechungen bei Host-Ausfällen zu vermeiden, ermöglicht VMware vSphere die Clusterkonfiguration und Konfiguration von Hosts für Hochverfügbarkeit. VMs, die durch einen Host-Ausfall unterbrochen werden, werden in Kürze auf anderen Hosts im Cluster neu gestartet, wodurch die Services wiederhergestellt werden.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">*Distributed Resource Scheduler (DRS).* Ein VMware vSphere Cluster kann konfiguriert werden, um den Ressourcenbedarf der von ihm gehosteten VMs auszugleichen. VMs mit Ressourceninhaltungen können Hot-to-andere Nodes im Cluster migriert werden, um sicherzustellen, dass genügend Ressourcen verfügbar sind.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">Die Red hat OpenShift on NetApp Lösung verwendet zwei Daten-Switches für die primäre Datenkonnektivität mit 25 Gbit/s. Zudem werden zwei zusätzliche Management-Switches verwendet, die mit 1 Gbit/s Konnektivität für in-Band-Management der Storage-Nodes und Out-of-Band-Management-Funktionen für IPMI-Funktionalität bieten. OCP verwendet für das Cluster-Management das logische VM-Netzwerk auf VMware vSphere. Dieser Abschnitt beschreibt die Anordnung und der Zweck jedes in der Lösung verwendeten virtuellen Netzwerksegments und beschreibt die Voraussetzungen für die Implementierung der Lösung.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">Red hat OpenShift auf VMware vSphere wurde entwickelt, um den Netzwerkverkehr für verschiedene Zwecke durch die Verwendung von Virtual Local Area Networks (VLANs) logisch zu trennen. Diese Konfiguration kann entsprechend den Kundenanforderungen skaliert werden oder um eine weitere Isolierung für spezifische Netzwerkservices zu bieten. In der folgenden Tabelle werden die für die Implementierung der Lösung erforderlichen VLANs bei der Validierung der Lösung bei NetApp aufgeführt.</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">Management für physische Knoten und IPMI</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM Network</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">Zugriff auf das virtuelle Gastnetzwerk</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">Datennetzwerk Storage-Netzwerk</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">Storage-Netzwerk für ONTAP NFS</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">Storage-Netzwerk für ONTAP iSCSI</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">In-Band-Managementnetzwerk</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">Management für ESXi Knoten, vCenter Server, ONTAP Select</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">Storage-Netzwerk für NetApp Element iSCSI</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">Migrationsnetzwerk</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">Netzwerk für die Migration von virtuellen Gastnetzvorgängen</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">Die folgende Infrastruktur sollte vor der Bereitstellung der OpenShift Container Platform vorhanden sein:</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">Mindestens ein DNS-Server bietet vollständige Host-Name-Auflösung, auf die über das bandinterne Managementnetzwerk und das VM-Netzwerk zugegriffen werden kann.</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">Best Practices für Produktionsimplementierungen</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">In diesem Abschnitt werden verschiedene Best Practices aufgeführt, die ein Unternehmen vor der Implementierung dieser Lösung in der Produktion berücksichtigen sollte.</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">OpenShift in ein ESXi-Cluster mit mindestens drei Nodes implementieren</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">Die in diesem Dokument beschriebene Architektur behandelt die minimale Hardwarebereitstellung für HA-Vorgänge durch Implementierung von zwei ESXi Hypervisor-Nodes und die Gewährleistung einer fehlertoleranten Konfiguration durch die Unterstützung von VMware vSphere HA und VMware vMotion. Mit dieser Konfiguration können implementierte VMs zwischen den beiden Hypervisoren migriert und neu gestartet werden, sollte ein Host nicht mehr verfügbar sein.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Da Red hat OpenShift zunächst mit drei Master-Nodes implementiert wird, können unter bestimmten Umständen mindestens zwei Master-Master-Konfigurationen mit zwei Nodes denselben Node belegen. Dies kann zu einem möglichen Ausfall von OpenShift führen, wenn dieser bestimmte Node nicht mehr verfügbar ist. Daher ist es eine Best Practice von Red hat, dass mindestens drei ESXi-Hypervisor-Nodes bereitgestellt werden müssen, damit die OpenShift-Master gleichmäßig verteilt werden können, was eine zusätzliche Fehlertoleranz bietet.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">Konfiguration der virtuellen Maschine und der Host-Affinität</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">Durch die Unterstützung der VM- und Host-Affinität kann sichergestellt werden, dass die OpenShift-Master-Verteilung über mehrere Hypervisor-Nodes hinweg erreicht werden kann.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">Affinität oder Antiaffinität ist eine Möglichkeit, Regeln für eine Gruppe von VMs und/oder Hosts zu definieren, die festlegen, ob die VMs auf demselben Host oder denselben Hosts in der Gruppe oder auf verschiedenen Hosts ausgeführt werden. Wird auf die VMs angewendet, indem Gruppen von Affinitätsgruppen erstellt werden, die aus VMs und/oder Hosts mit einer Reihe identischer Parameter und Bedingungen bestehen. Je nachdem, ob die VMs einer Affinitätsgruppe auf demselben Host oder Hosts der Gruppe oder separat auf verschiedenen Hosts ausgeführt werden, können die Parameter der Affinitätsgruppe entweder eine positive oder eine negative Affinität definieren.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">VSphere 6.7 Dokumentation: Nutzung von DRS Affinity Rules</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">Informationen zum Konfigurieren von Affinitätsgruppen finden Sie im<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">Verwenden Sie eine benutzerdefinierte Installationsdatei für die OpenShift-Bereitstellung</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI vereinfacht die Bereitstellung von OpenShift-Clustern durch den interaktiven Assistenten, den bereits in diesem Dokument erläutert wurde. Es ist jedoch möglich, dass Sie einige Standardwerte im Rahmen einer Cluster-Bereitstellung ändern müssen.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red hat OpenShift Installieren eines Clusters auf vSphere mit Anpassungen</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">In diesen Fällen können Sie den Assistenten ausführen und ausführen, ohne sofort einen Cluster bereitzustellen. Stattdessen erstellt der Assistent eine Konfigurationsdatei, aus der das Cluster später bereitgestellt werden kann. Dies ist sehr nützlich, wenn Sie IPI-Standards ändern müssen oder wenn Sie mehrere identische Cluster in Ihrer Umgebung für andere Zwecke wie Mandantenfähigkeit implementieren möchten. Weitere Informationen zum Erstellen einer benutzerdefinierten Installationskonfiguration für OpenShift finden Sie unter<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">Weiter: NetApp Storage Überblick</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">Erweitertes Cluster Management für Kubernetes auf Red hat OpenShift mit NetApp</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Implementieren Sie Advanced Cluster Management für Kubernetes</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">So installieren Sie Advanced Cluster Management für Kubernetes auf einem OpenShift-Cluster:</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">Wählen Sie einen OpenShift-Cluster als Hub-Cluster aus und melden Sie sich mit Clusteradministratorrechten an.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Navigieren Sie zu Operators &gt; Operators Hub, und suchen Sie nach Advanced Cluster Management für Kubernetes.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM-Kachel</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Wählen Sie Advanced Cluster Management für Kubernetes aus, und klicken Sie auf Installieren.</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM-Details</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Geben Sie im Bildschirm „Install Operator“ die erforderlichen Details ein (NetApp empfiehlt, die Standardparameter zu behalten), und klicken Sie auf Install.</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">Installieren Sie die ACM-Bedienfliese</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">ACM-Bedienerinstallation läuft</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">Klicken Sie nach der Installation des Operators auf MultiClusterHub erstellen.</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM Operator Multiclusterhub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Klicken Sie auf dem Bildschirm MultiClusterHub erstellen nach Einrichtung der Details auf Erstellen. Hierdurch wird die Installation eines Multi-Cluster-Hubs initiiert.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">Bildschirm Multicluster Hub erstellen</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">Nachdem alle Pods im Open-Cluster-Management Namespace in den aktiven Status verschoben und der Operator in den Status „erfolgreich“ verlagert wurde, wird Advanced Cluster Management für Kubernetes installiert.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM-Operator installiert</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">Es dauert einige Zeit, bis die Hub-Installation abgeschlossen ist, und anschließend wechselt der Multicluster-Hub in den laufenden Zustand.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">Multicluster Hub bereit</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">Der Service erstellt eine Route im Open-Cluster-Management Namespace. Stellen Sie eine Verbindung mit der URL auf der Route her, um auf die Konsole für die erweiterte Cluster-Verwaltung zuzugreifen.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM-Konsolenroute</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">Weiter: Funktionen - Cluster Lifecycle Management.</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Nachdem die Applikations-Workloads vom Astra Control Center gemanagt wurden, können Sie die Sicherungseinstellungen für diese Workloads konfigurieren.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">Sichern Sie Ihre Applikationen</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">Erstellen eines Anwendungs-Snapshots</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">Ein Snapshot einer Applikation erstellt eine ONTAP Snapshot Kopie, mit der die Applikation auf Basis dieser Snapshot Kopie einem bestimmten Zeitpunkt wiederhergestellt oder geklont werden kann.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">Um einen Snapshot der Anwendung zu erstellen, navigieren Sie zur Registerkarte Apps &gt; Managed und klicken Sie auf die Anwendung, von der Sie eine Snapshot Kopie erstellen möchten. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf Snapshot.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra Control Center: Snapshot-Schaltfläche</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">Geben Sie die Snapshot-Details ein, klicken Sie auf Weiter und klicken Sie dann auf Snapshot. Es dauert etwa eine Minute, um den Snapshot zu erstellen, und der Status wird verfügbar, nachdem der Snapshot erfolgreich erstellt wurde.</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center erstellt eine Momentaufnahme</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">Erstellen eines Applikations-Backups</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">Ein Backup einer Applikation erfasst den aktiven Status der Applikation und die Konfiguration der Ressourcen des IT-Systems, deckt sie in Dateien ab und speichert sie in einem Remote-Objekt-Storage-Bucket.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Für die Sicherung und Wiederherstellung von verwalteten Anwendungen im Astra Control Center müssen Sie die Superuser-Einstellungen für die ONTAP-Systeme als Voraussetzung konfigurieren. Geben Sie dazu die folgenden Befehle ein.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Um ein Backup der verwalteten Anwendung im Astra Control Center zu erstellen, navigieren Sie zur Registerkarte Apps &gt; Managed und klicken Sie auf die Anwendung, von der Sie ein Backup durchführen möchten. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf Backup.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra Control Center Backup-Schaltfläche</block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">Geben Sie die Backup-Details ein, wählen Sie den Objekt-Storage-Bucket aus, der die Backup-Dateien enthält, klicken Sie auf Weiter und klicken Sie nach Überprüfung der Details auf Backup. Abhängig von der Größe der Applikation und den Daten kann das Backup mehrere Minuten dauern und der Status des Backups wird nach erfolgreichem Abschluss des Backups wieder verfügbar.</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center erstellen Backup</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">Wiederherstellen einer Anwendung</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">Auf Knopfdruck können Sie eine Applikation zum Zwecke der Applikationssicherung und Disaster Recovery im selben Cluster oder zu einem Remote-Cluster wiederherstellen, was den Namespace Ursprung im selben Cluster hat.</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">Um eine Anwendung wiederherzustellen, navigieren Sie zu „Apps“ &gt; „Managed“, und klicken Sie auf die betreffende Anwendung. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block>.</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center Clone-Schaltfläche</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">Geben Sie den Namen des Restore Namespace ein, wählen Sie den Cluster aus, in dem Sie ihn wiederherstellen möchten, und wählen Sie aus einem vorhandenen Snapshot oder aus einem Backup der Applikation aus, ob Sie ihn wiederherstellen möchten. Klicken Sie Auf Weiter.</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra Control Center Restore</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">Geben Sie im Prüfungsfenster ein<block ref="bb2ac0b8da1f64a3498af147ba43fc10" prefix=" " category="inline-code"></block> Und klicken Sie auf Wiederherstellen, nachdem Sie die Details geprüft haben.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra Control Center – Wiederherstellungsüberprüfung</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">Die neue Applikation geht in den Status Wiederherstellen, während Astra Control Center die Anwendung auf dem ausgewählten Cluster wiederherstellt. Nachdem alle Ressourcen der Anwendung installiert und von Astra erkannt wurden, geht die Anwendung in den verfügbaren Zustand.</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Astra Control Center hat eine neue App entdeckt</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">Klonen einer Applikation</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">Sie können eine Applikation zu Entwicklungs-/Testzwecken oder zur Sicherung von Applikationen und Disaster Recovery in einem entfernten Cluster klonen. Das Klonen einer Applikation im selben Cluster im selben Storage-Back-End nutzt die NetApp FlexClone Technologie, die VES sofort klont und Storage-Platz einspart.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">Um eine Anwendung zu klonen, navigieren Sie zur Registerkarte Apps &gt; Managed und klicken Sie auf die betreffende Anwendung. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen und klicken Sie auf Klonen.</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">Geben Sie die Details zum neuen Namespace ein, wählen Sie den Cluster aus, in dem Sie ihn klonen möchten, und legen Sie fest, ob er aus einem vorhandenen Snapshot oder einem Backup oder dem aktuellen Status der Applikation geklont werden soll. Klicken Sie dann auf Weiter, und klicken Sie auf den Fensterbereich Klonen im Überprüfungsbereich, sobald Sie die Details geprüft haben.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">Die neue Applikation geht in den Entdeckungszustand, während Astra Control Center die Anwendung im ausgewählten Cluster erstellt. Nachdem alle Ressourcen der Anwendung installiert und von Astra erkannt wurden, geht die Anwendung in den verfügbaren Zustand.</block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">Weiter: Lösungsvalidierung/Anwendungsfälle.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Die Red hat OpenStack Platform bietet eine integrierte Grundlage zur Erstellung, Implementierung und Skalierung einer sicheren und zuverlässigen OpenStack Private Cloud.</block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="doc">OpenShift auf der Red hat OpenStack Platform</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP ist eine IaaS-Cloud (Infrastruktur als Service), die durch eine Sammlung von Kontroll-Services implementiert wird und Computing-, Storage- und Netzwerkressourcen managt. Die Umgebung wird über eine webbasierte Schnittstelle gemanagt, die es Administratoren und Benutzern ermöglicht, OpenStack Ressourcen zu kontrollieren, bereitzustellen und zu automatisieren. Darüber hinaus wird die OpenStack Infrastruktur durch eine umfangreiche Befehlszeilenschnittstelle und API erleichtert, die umfassende Automatisierungsfunktionen für Administratoren und Endbenutzer ermöglichen.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">Das OpenStack Projekt ist ein schnell entwickeltes Community-Projekt, das alle sechs Monate aktualisierte Versionen bereitstellt. Zunächst hat Red hat OpenStack Platform mit diesem Release-Zyklus Schritt gehalten, indem es eine neue Version zusammen mit jeder Upstream-Version veröffentlichte und für jede dritte Version langfristige Unterstützung bietet. In jüngster Zeit hat Red hat mit der OSP 16.0-Version (auf OpenStack Train) entschieden, nicht mit den Versionsnummern Schritt zu halten, sondern neue Funktionen in Unterversionen zu portieren. Die neueste Version ist Red hat OpenStack Platform 16.1, die erweiterte Funktionalitäten der Upstream-Versionen Ussuri und Victoria unterstützt.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red hat OpenStack Platform Website</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">Weitere Informationen zu OSP finden Sie im<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack Services</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack Platform Services werden als Container implementiert. Dadurch werden Services voneinander isoliert, einfache Upgrades ermöglicht. Die OpenStack Plattform nutzt eine Reihe von Containern, die mit einer Kolla erstellt und gemanagt werden. Die Bereitstellung von Services erfolgt durch Ziehen von Container-Images aus dem Red hat Custom Portal. Diese Service-Container werden über den Podman-Befehl gemanagt und mit Red hat OpenStack Director implementiert, konfiguriert und gewartet.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">Service</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">Projektname</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">Dashboard</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">Horizont</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">Webbrowser-basiertes Dashboard für das Management von OpenStack Services.</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">Identität</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">Zentraler Service zur Authentifizierung und Autorisierung von OpenStack Services sowie zur Verwaltung von Benutzern, Projekten und Rollen.</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack Networking</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">Neutron</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">Bietet Konnektivität zwischen den Schnittstellen von OpenStack Services.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">Block-Storage</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">Managt persistente Block-Storage-Volumes für Virtual Machines (VMs)</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">Nova</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">Management und Bereitstellung von VMs, die auf Computing-Nodes ausgeführt werden</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">Überblick</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">Registry-Service zur Speicherung von Ressourcen wie VM Images und Volume Snapshots</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">Objekt-Storage</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">Swift</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">Benutzer können Storage-Ressourcen speichern und Dateien sowie beliebige Daten abrufen.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">Telemetrie</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Decken</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">Erlaubt Messungen der Nutzung von Cloud-Ressourcen</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">Orchestrierung</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">Wärme</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">Vorlagenbasierte Orchestrierungs-Engine zur automatischen Erstellung von Ressourcen-Stacks.</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">Die Red hat OpenShift mit NetApp Lösung verwendet zwei Daten-Switches für die primäre Datenkonnektivität mit 25 Gbit/s. Zudem werden zwei zusätzliche Management-Switches verwendet, die mit 1 Gbit/s Konnektivität für in-Band-Management der Storage-Nodes und Out-of-Band-Management-Funktionen für IPMI-Funktionalität bieten.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Die IPMI-Funktionalität ist von Red hat OpenStack Director für die Implementierung der Red hat OpenStack Plattform unter Verwendung des ironischen Bare-Metal-Bereitstellungsservice erforderlich.</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">Red hat OpenShift mit NetApp wurde entwickelt, um den Netzwerk-Traffic für verschiedene Zwecke durch die Verwendung von Virtual Local Area Networks (VLANs) logisch voneinander zu trennen. Diese Konfiguration kann entsprechend den Kundenanforderungen skaliert werden oder um eine weitere Isolierung für spezifische Netzwerkservices zu bieten. In der folgenden Tabelle werden die für die Implementierung der Lösung erforderlichen VLANs bei der Validierung der Lösung bei NetApp aufgeführt.</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">Das Netzwerk, das für das Management physischer Nodes und den IPMI-Service verwendet wird, dient zur ironischen Ironie.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">Storage-Infrastruktur bereit</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Netzwerk, das für Controller Nodes verwendet wird, um Volumes direkt zuzuweisen, um Infrastrukturservices wie Swift zu unterstützen.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">Storage Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">Netzwerk, das verwendet wird, um Block-Volumes direkt an virtuelle Instanzen in der Umgebung zuzuordnen und anzubinden.</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">Interne API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">Ein Netzwerk, das für die Kommunikation zwischen den OpenStack-Diensten unter Verwendung von API-Kommunikation, RPC-Meldungen und Datenbankkommunikation verwendet wird.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">Mandant</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron stellt jedem Mieter über VXLAN sein eigenes Netzwerk zur Verfügung. Der Netzwerkverkehr wird innerhalb jedes Mandantennetzwerks isoliert. Jedem Mandantennetzwerk ist ein IP-Subnetz zugewiesen. Netzwerknamenpaces bedeuten, dass mehrere Mandantennetzwerke denselben Adressbereich verwenden können, ohne dass Konflikte verursacht werden.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">Storage-Management</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage (Swift) verwendet dieses Netzwerk zur Synchronisierung von Datenobjekten zwischen den teilnehmenden Replikationsknoten. Der Proxy-Dienst fungiert als Schnittstelle zwischen Benutzeranfragen und der zugrunde liegenden Speicherebene. Der Proxy empfängt eingehende Anforderungen und lokalisiert das erforderliche Replikat, um die angeforderten Daten abzurufen.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">Der OpenStack Director bietet PXE-Boot als Bestandteil des ironischen Bare Metal-Bereitstellungsservice und ermöglicht so die Orchestrierung der Installation von OSP OverCloud.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">Extern</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">Ein öffentlich verfügbares Netzwerk, das das OpenStack Dashboard (Horizon) für das grafische Management hostet und öffentliche API-Aufrufe zur Verwaltung von OpenStack Services ermöglicht.</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">Bietet Zugriff auf Systemverwaltungsfunktionen wie SSH-Zugriff, DNS-Traffic und NTP-Datenverkehr (Network Time Protocol). Dieses Netzwerk fungiert auch als Gateway für Nodes ohne Controller.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">Mindestens ein DNS-Server, der eine vollständige Namensauflösung bietet.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">Mindestens drei NTP-Server, die die Zeit für die Server in der Lösung synchronisiert halten können.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(Optional) ausgehende Internetverbindung für die OpenShift-Umgebung.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">OpenShift in eine Private Cloud mit mindestens drei Computing-Nodes auf einem OSP-System implementieren</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">Die in diesem Dokument beschriebene Architektur enthält die minimale Hardwareimplementierung, die durch Implementierung von drei OSP-Controller-Nodes und zwei OSP-Computing-Nodes für HA-Vorgänge geeignet ist. Diese Architektur sorgt für eine fehlertolerante Konfiguration, bei der beide Computing-Nodes virtuelle Instanzen starten und implementierte VMs zwischen den beiden Hypervisoren migrieren können.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Da Red hat OpenShift zunächst mit drei Master-Nodes implementiert wird, kann es vorkommen, dass mindestens zwei Master-Konfigurationen denselben Node belegen, was zu einem möglichen Ausfall für OpenShift führen kann, wenn dieser bestimmte Node nicht mehr verfügbar ist. Daher ist es eine Best Practice von Red hat, mindestens drei OSP-Computing-Nodes bereitzustellen, damit die OpenShift-Master gleichmäßig verteilt werden können und die Lösung eine zusätzliche Fehlertoleranz erhält.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">Konfiguration der virtuellen Maschine/Host-Affinität</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">OpenShift-Master kann durch Unterstützung der VM-/Host-Affinität auf mehrere Hypervisor-Nodes verteilt werden.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">Affinity ermöglicht die Definition von Regeln für eine Gruppe von VMs und/oder Hosts, anhand derer bestimmt wird, ob die VMs auf demselben Host oder denselben Hosts in der Gruppe oder auf verschiedenen Hosts ausgeführt werden. Wird auf die VMs angewendet, indem Gruppen von Affinitätsgruppen erstellt werden, die aus VMs und/oder Hosts mit einer Reihe identischer Parameter und Bedingungen bestehen. Je nachdem, ob die VMs einer Affinitätsgruppe auf demselben Host oder Hosts der Gruppe oder separat auf verschiedenen Hosts ausgeführt werden, können die Parameter der Affinitätsgruppe entweder eine positive oder eine negative Affinität definieren. In der Red hat OpenStack Platform können Host-Affinität und Anti-Affinität-Regeln erstellt und durchgesetzt werden, indem Servergruppen erstellt und Filter konfiguriert werden, damit Instanzen von Nova in einer Servergruppe auf unterschiedlichen Computing-Nodes bereitgestellt werden.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">Eine Servergruppe verfügt standardmäßig über maximal 10 virtuelle Instanzen, für die sie die Platzierung managen kann. Dies kann durch Aktualisierung der Standardkontingente für Nova geändert werden.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">Es gibt ein bestimmtes Limit für die Hardinität/Antiaffinität für OSP-Servergruppen. Wenn nicht genügend Ressourcen für die Bereitstellung auf separaten Nodes vorhanden sind oder nicht genügend Ressourcen zur gemeinsamen Nutzung von Nodes vorhanden sind, wird die VM nicht gestartet.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">Wie konfiguriere ich Affinität und Antiaffinität für OpenStack Instanzen?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">Informationen zum Konfigurieren von Affinitätsgruppen finden Sie unter<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red hat OpenShift – Installation eines Clusters auf OpenStack mit Anpassungen</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">In diesen Fällen können Sie die Anwendung erst ausführen und ausführen, ohne gleich einen Cluster implementieren zu müssen. Stattdessen erstellt es eine Konfigurationsdatei, aus der das Cluster später implementiert werden kann. Dies ist sehr nützlich, wenn Sie IPI-Standards ändern müssen oder mehrere identische Cluster in Ihrer Umgebung für andere Zwecke wie Mandantenfähigkeit implementieren möchten. Weitere Informationen zum Erstellen einer benutzerdefinierten Installationskonfiguration für OpenShift finden Sie unter<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV ist eine virtuelle Rechenzentrumsplattform für Unternehmen, die auf Red hat Enterprise Linux (RHEL) ausgeführt wird und den KVM-Hypervisor verwendet.</block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="doc">OpenShift auf Red hat Virtualization</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red hat Virtualization (RHV) ist eine virtuelle Rechenzentrumsplattform für Unternehmen, die auf Red hat Enterprise Linux (RHEL) ausgeführt wird und den KVM-Hypervisor verwendet.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red hat Virtualization Website</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">Weitere Informationen zu RHV finden Sie im<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV bietet die folgenden Funktionen:</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">*Zentrales Management von VMs und Hosts.* der RHV-Manager läuft als physische oder virtuelle Maschine (VM) in der Bereitstellung und bietet eine webbasierte Benutzeroberfläche für die Verwaltung der Lösung über eine zentrale Schnittstelle.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">*Self-Hosted Engine.* um die Hardwareanforderungen zu minimieren, ermöglicht RHV Manager (RHV-M) die Bereitstellung als VM auf denselben Hosts, auf denen Gast-VMs ausgeführt werden.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">*Hohe Verfügbarkeit.* um Unterbrechungen bei Host-Ausfällen zu vermeiden, ermöglicht RHV die Konfiguration von VMs für hohe Verfügbarkeit. Die hochverfügbaren VMs werden auf Cluster-Ebene mithilfe von Resiliency-Richtlinien gesteuert.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">*Hohe Skalierbarkeit.* Ein einziger RHV-Cluster kann bis zu 200 Hypervisor-Hosts haben, wodurch IT-Abteilungen Anforderungen großer VMs unterstützen können, um ressourcenschonende Workloads der Enterprise-Klasse zu hosten.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">*Erhöhte Sicherheit.* die Technologien Secure Virtualization (sVirt) und Security Enhanced Linux (SELinux) werden von RHV zum Zweck einer erhöhten Sicherheit und Härtung für Hosts und VMs eingesetzt. Der wichtigste Vorteil dieser Funktionen ist die logische Isolierung einer VM und der damit verbundenen Ressourcen.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">Die Red hat OpenShift on NetApp Lösung verwendet zwei Daten-Switches für die primäre Datenkonnektivität mit 25 Gbit/s. Zudem werden zwei zusätzliche Management-Switches eingesetzt, die mit 1 Gbit/s Konnektivität für das in-Band-Management der Storage-Nodes und das Out-of-Band-Management für IPMI-Funktionen bereitstellen. OCP verwendet das logische Netzwerk der virtuellen Maschine auf RHV für die Clusterverwaltung. Dieser Abschnitt beschreibt die Anordnung und der Zweck jedes in der Lösung verwendeten virtuellen Netzwerksegments und beschreibt die Voraussetzungen für die Implementierung der Lösung.</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">Red hat OpenShift auf RHV wurde entwickelt, um den Netzwerkverkehr für verschiedene Zwecke durch die Verwendung von Virtual Local Area Networks (VLANs) logisch zu trennen. Diese Konfiguration kann entsprechend den Kundenanforderungen skaliert werden oder um eine weitere Isolierung für spezifische Netzwerkservices zu bieten. In der folgenden Tabelle werden die für die Implementierung der Lösung erforderlichen VLANs bei der Validierung der Lösung bei NetApp aufgeführt.</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">Management für RHV-H-Knoten, RHV-Manager und ovirtmgmt-Netzwerk</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">OpenShift wird in einem RHV-Cluster mit mindestens drei Nodes bereitgestellt</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">Die in diesem Dokument beschriebene verifizierte Architektur stellt die minimale Hardwareimplementierung dar, die für HA-Vorgänge geeignet ist. Sie stellt zwei RHV-H-Hypervisor-Knoten bereit und sorgt für eine fehlertolerante Konfiguration, bei der beide Hosts die gehostete Engine und implementierte VMs zwischen den beiden Hypervisoren migrieren können.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Da Red hat OpenShift zunächst mit drei Master-Nodes implementiert wird, wird in einer Konfiguration mit zwei Nodes sichergestellt, dass mindestens zwei Master denselben Node belegen. Dies kann zu einem möglichen Ausfall von OpenShift führen, wenn dieser bestimmte Node nicht mehr verfügbar ist. Daher ist es eine Best Practice von Red hat, dass mindestens drei RHV-H-Hypervisor-Nodes als Teil der Lösung eingesetzt werden, damit die OpenShift-Master gleichmäßig verteilt werden können und die Lösung eine zusätzliche Fehlertoleranz erhält.</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">Sie können die OpenShift-Master durch Unterstützung der VM-/Host-Affinität auf mehrere Hypervisor-Nodes verteilen.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">Affinity ermöglicht die Definition von Regeln für eine Gruppe von VMs und/oder Hosts, anhand derer bestimmt wird, ob die VMs auf demselben Host oder denselben Hosts in der Gruppe oder auf verschiedenen Hosts ausgeführt werden. Wird auf die VMs angewendet, indem Gruppen von Affinitätsgruppen erstellt werden, die aus VMs und/oder Hosts mit einer Reihe identischer Parameter und Bedingungen bestehen. Je nachdem, ob die VMs einer Affinitätsgruppe auf demselben Host oder Hosts der Gruppe oder separat auf verschiedenen Hosts ausgeführt werden, können die Parameter der Affinitätsgruppe entweder eine positive oder eine negative Affinität definieren.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">Die für die Parameter definierten Bedingungen können eine harte Durchsetzung oder eine weiche Durchsetzung sein. Harte Durchsetzung stellt sicher, dass die VMs in einer Affinitätsgruppe immer die positive oder negative Affinität streng ohne Berücksichtigung von externen Bedingungen folgen. Die weiche Durchsetzung sorgt dafür, dass die VMs in einer Affinitätsgruppe, sofern dies möglich ist, eine höhere Vorliebe für die VMs festgelegt werden, um nach Möglichkeit eine positive oder negative Affinität zu verfolgen. In der in diesem Dokument beschriebenen zwei- oder drei-Hypervisor-Konfiguration ist die weiche Affinität die empfohlene Einstellung. In größeren Clustern kann die Verteilung von OpenShift-Nodes durch Hard-Affinität korrekt erfolgen.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11 Dokumentation von Affinitätsgruppen</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">Informationen zum Konfigurieren von Affinitätsgruppen finden Sie im<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI vereinfacht die Bereitstellung von OpenShift-Clustern durch den interaktiven Assistenten, den bereits in diesem Dokument erläutert wurde. Es ist jedoch möglich, dass es einige Standardwerte gibt, die im Rahmen der Cluster-Implementierung geändert werden müssen.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red hat OpenShift Installieren eines Clusters auf RHV mit Anpassungen</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">In diesen Fällen können Sie den Assistenten ausführen und ausführen, ohne sofort ein Cluster bereitzustellen. Stattdessen wird eine Konfigurationsdatei erstellt, aus der der Cluster später bereitgestellt werden kann. Dies ist sehr nützlich, wenn Sie IPI-Standards ändern möchten oder mehrere identische Cluster in Ihrer Umgebung für andere Zwecke wie Mandantenfähigkeit implementieren möchten. Weitere Informationen zum Erstellen einer benutzerdefinierten Installationskonfiguration für OpenShift finden Sie unter<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">Installation von F5 BIG-IP Load Balancer</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP ist ein Application Delivery Controller (ADC), der ein breites Spektrum erweiterter Traffic Management und Sicherheitsservices wie L4-L7 Load Balancing, SSL/TLS-Entlastung, DNS, Firewall und vieles mehr in Produktionsqualität bietet. Diese Services sorgen für eine signifikante Steigerung der Verfügbarkeit, Sicherheit und Performance der Applikationen.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP kann auf verschiedene Arten implementiert und genutzt werden: Auf dedizierter Hardware, in der Cloud oder als virtuelle Appliance vor Ort. In der Dokumentation finden Sie Informationen zur Nutzung und Implementierung von F5 BIG-IP nach Bedarf.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">Für eine effiziente Integration von F5 BIG-IP-Diensten in Red hat OpenShift bietet F5 den BIG-IP Container Ingress Service (CIS) an. CIS wird als Controller-Pod installiert, der die OpenShift API für bestimmte Custom Resource Definitions (CRDs) überwacht und die F5 BIG-IP-Systemkonfiguration verwaltet. F5 BIG-IP CIS kann für die Steuerung von Servicetypen für Loadbalancer und Routen in OpenShift konfiguriert werden.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">Für die automatische IP-Adresszuweisung zur Wartung des Typs loadbalancer können Sie außerdem den F5 IPAM-Controller nutzen. Der F5 IPAM-Controller wird als Controller-Pod installiert, der OpenShift API für Load Balancer-Dienste mit einer ipamLabel-Anmerkung überwacht, um die IP-Adresse aus einem vorkonfigurierten Pool zuzuweisen.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">Auf dieser Seite sind die Installations- und Konfigurationsanweisungen für die F5 BIG-IP CIS- und IPAM-Controller aufgeführt. Voraussetzung ist, dass ein F5 BIG-IP-System implementiert und lizenziert werden muss. Es muss auch für SDN-Dienste lizenziert sein, die standardmäßig in DER BIG-IP VE-Basislizenz enthalten sind.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP kann im Standalone- oder Cluster-Modus implementiert werden. Im Rahmen dieser Validierung wurde F5 BIG-IP im Standalone-Modus implementiert, jedoch wird es für Produktionszwecke bevorzugt, ein Cluster VON BIG-IPs zu verwenden, um Single Point of Failure zu vermeiden.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">Ein F5 BIG-IP System kann auf dedizierter Hardware, in der Cloud oder als virtuelle Appliance on-Premises mit Versionen über 12.x bereitgestellt werden, damit es mit F5 CIS integriert werden kann. Für dieses Dokument wurde das F5 BIG-IP System als virtuelle Appliance validiert, beispielsweise mit DER BIG-IP VE Edition.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">Validierte Versionen</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Softwareversion</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red hat OpenShift</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE EDITION</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 Container Ingress Service</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM Controller</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">Installation</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub-Repository</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">Installieren Sie die Erweiterung F5 Application Services 3, damit BIG-IP-Systeme Konfigurationen in JSON anstelle von Imperativ-Befehlen akzeptieren können. Gehen Sie zu<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>, Und laden Sie die neueste RPM-Datei.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">Melden Sie sich bei F5 BIG-IP-System an, navigieren Sie zu iApps &gt; Package Management LX, und klicken Sie auf Importieren.</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">Klicken Sie auf Datei auswählen und wählen Sie die heruntergeladene AS3 RPM-Datei aus, klicken Sie auf OK und anschließend auf Hochladen.</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">IApps hochladen</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">Vergewissern Sie sich, dass die AS3-Erweiterung erfolgreich installiert wurde.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3-Installationsprüfung</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">Konfigurieren Sie dann die Ressourcen, die für die Kommunikation zwischen OpenShift- und BIG-IP-Systemen benötigt werden. Erstellen Sie zunächst einen Tunnel zwischen OpenShift und DEM BIG-IP-Server, indem Sie eine VXLAN-Tunnelschnittstelle auf dem BIG-IP-System für OpenShift SDN erstellen. Navigieren Sie zu Netzwerk &gt; Tunnel &gt; Profile, klicken Sie auf Erstellen, und legen Sie das übergeordnete Profil auf vxlan und den Hochwassertyp auf Multicast fest. Geben Sie einen Namen für das Profil ein und klicken Sie auf Fertig.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">VXLAN-Profil erstellen</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Navigieren Sie zu Netzwerk &gt; Tunnel &gt; Tunnelliste, klicken Sie auf Erstellen, und geben Sie den Namen und die lokale IP-Adresse für den Tunnel ein. Wählen Sie das Tunnelprofil aus, das im vorherigen Schritt erstellt wurde, und klicken Sie auf Fertig.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">VXLAN-Tunnel erstellen</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">Melden Sie sich beim Red hat OpenShift-Cluster mit Clusteradministratorrechten an.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">Erstellen Sie auf OpenShift ein Hostsubnetz für den F5 BIG-IP-Server, der das Subnetz vom OpenShift-Cluster auf den F5 BIG-IP-Server erweitert. Laden Sie die YAML-Hostsubnet-Definition herunter.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">Bearbeiten Sie die Hostsubnet-Datei und fügen Sie die BIG-IP-VTEP-IP (VXLAN-Tunnel)-IP für das SDN OpenShift hinzu.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">Ändern Sie HostIP und andere Details, je nach Ihrer Umgebung.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">Hostsubnet-Ressource erstellen.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">Abrufen des Cluster-IP-Subnetzes für das für den F5 BIG-IP-Server erstellte Host-Subnetz.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">Erstellen Sie auf OpenShift VXLAN mit einer IP im Host-Subnetz-Bereich von OpenShift eine eigene IP-Adresse, die dem F5 BIG-IP-Server entspricht. Melden Sie sich beim F5 BIG-IP-System an, navigieren Sie zu Netzwerk &gt; selbst-IPs, und klicken Sie auf Erstellen. Geben Sie eine IP aus dem Cluster-IP-Subnetz ein, das für das F5 BIG-IP Host-Subnetz erstellt wurde, wählen Sie den VXLAN-Tunnel aus, und geben Sie die anderen Details ein. Klicken Sie anschließend auf Fertig.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">Erstellen Sie Self-IP für VXLAN</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">Erstellen Sie eine Partition im F5 BIG-IP-System, die mit CIS konfiguriert und verwendet werden soll. Navigieren Sie zu System &gt; Users &gt; Partitionsliste, klicken Sie auf Create, und geben Sie die Details ein. Klicken Sie anschließend auf Fertig.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">BIG-IP-Partition erstellen</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5 empfiehlt, auf der von CIS verwalteten Partition keine manuelle Konfiguration durchzuführen.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">Installieren Sie die F5 BIG-IP CIS mit dem Operator von OperatorHub. Melden Sie sich mit Clusteradministratorrechten beim Red hat OpenShift-Cluster an und erstellen Sie mit den Anmeldedaten des F5 BIG-IP-Systems ein Geheimnis, das Voraussetzung für den Operator ist.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">Installieren Sie die F5 CIS CRDs.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Navigieren Sie zu Operators &gt; OperatorHub, suchen Sie nach dem Schlüsselwort F5 und klicken Sie auf die Kachel F5 Container Ingress Service.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">F5 CIS im OperatorHub</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">Lesen Sie die Bedienerinformationen, und klicken Sie auf Installieren.</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">F5 CIS-Info-Kachel im OperatorHub</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Lassen Sie auf dem Bildschirm Install Operator alle Standardparameter stehen, und klicken Sie auf Install.</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">Installieren Sie den F5 CIS-Operator</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">Es dauert eine Weile, bis der Bediener installiert wird.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">Fortschritt der Installation durch F5 CIS Operator</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">Nach der Installation des Bedieners wird die Meldung Installation erfolgreich angezeigt.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Navigieren Sie zu Operatoren &gt; Installed Operators, klicken Sie auf F5 Container Ingress Service und klicken Sie dann unter der Kachel F5BigIpCtlr auf Create Instance.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">F5BigIpCtlr erstellen</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">Klicken Sie auf YAML View und fügen Sie den folgenden Inhalt ein, nachdem Sie die erforderlichen Parameter aktualisiert haben.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">Aktualisieren Sie die Parameter<block ref="9117e80b6a6843f23b631387abeed925" prefix=" " category="inline-code"></block>, ` openshift_sdn_Name`,<block ref="957c32cdfcd5fb9c99f7a4e3311e7768" prefix=" " category="inline-code"></block> Und<block ref="1155b6812ea5125b3144173aaaad6205" prefix=" " category="inline-code"></block> Geben Sie unten die Werte für Ihr Setup vor dem Kopieren des Inhalts an.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">Klicken Sie nach dem Einfügen dieses Inhalts auf Erstellen. Damit werden die CIS-Pods im Namespace des kube-Systems installiert.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">Validieren Sie F5 CIS-Pods</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Red hat OpenShift bietet standardmäßig eine Möglichkeit, die Dienste über Routen für L7-Lastenausgleich zur Verfügung zu stellen. Ein eingebauter OpenShift-Router ist für die Werbung und den Umgang mit dem Verkehr auf diesen Routen verantwortlich. Sie können die F5 CIS jedoch auch so konfigurieren, dass sie die Routen über ein externes F5 BIG-IP-System unterstützen, das entweder als Hilfrouter oder als Ersatz für den selbst gehosteten OpenShift-Router ausgeführt werden kann. CIS erstellt einen virtuellen Server im BIG-IP-System, der als Router für die OpenShift-Routen fungiert, und BIG-IP übernimmt das Werbe- und Traffic-Routing. Informationen zu Parametern, die diese Funktion aktivieren, finden Sie in der Dokumentation hier. Beachten Sie, dass diese Parameter für die OpenShift Deployment-Ressource in der Apps/v1-API definiert sind. Wenn Sie diese also mit der F5BigIpCtlr Resource cis.f5.com/v1 API verwenden, ersetzen Sie die Bindestriche (-) durch Unterstriche (_) für die Parameternamen.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">Die Argumente, die an die Erstellung von CIS-Ressourcen übergeben werden, umfassen<block ref="49dcf57b3a065d02c9969c595e32ea50" prefix=" " category="inline-code"></block> Und<block ref="5d0d2663dc7f08b0183abaddf17f8307" prefix=" " category="inline-code"></block>. Diese Parameter sind für die CIS-Integration mit einem IPAM-Controller erforderlich. Überprüfen Sie, ob die CIS die IPAM-Integration aktiviert hat, indem Sie die F5 IPAM-Ressource erstellen.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">Erstellen Sie das Servicekonto, die Rolle und die Einbindung, die für den F5 IPAM-Controller erforderlich sind. Erstellen Sie eine YAML-Datei, und fügen Sie den folgenden Inhalt ein.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">Erstellen Sie die Ressourcen.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">Erstellen Sie eine YAML-Datei, und fügen Sie die nachfolgend angegebene F5 IPAM-Bereitstellungsdefinition ein.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">Aktualisieren Sie den ip-Bereich-Parameter in spec.template.spec.Containers[0].args unten, um die ipamLabels und IP-Adressbereiche zu berücksichtigen, die Ihrem Setup entsprechen.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IpamLabels <block ref="4795fc86aa645b109548974bcffefe07" prefix="[" category="inline-code"></block> Und<block ref="0ce75607b46ab2a9cc08eab9ade2a24d" prefix=" " category="inline-code"></block> Im folgenden Beispiel] müssen für die Dienste des Typs loadbalancer Anmerkungen gemacht werden, damit der IPAM-Controller eine IP-Adresse aus dem definierten Bereich erkennt und zuweist.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">Erstellen Sie die F5 IPAM Controller-Implementierung.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">Überprüfen Sie, ob die F5 IPAM-Controller-Pods ausgeführt werden.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">Erstellen Sie das F5 IPAM-Schema.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">Verifizierung</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">Erstellen Sie einen Service vom Typ Load Balancer</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">Überprüfen Sie, ob der IPAM-Controller ihm eine externe IP zuweist.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">Erstellen Sie eine Implementierung, und verwenden Sie den erstellten Load Balancer Service.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Prüfen Sie, ob die Pods ausgeführt werden.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">Prüfen Sie, ob der entsprechende virtuelle Server im BIG-IP-System für den Dienst vom Typ loadbalancer in OpenShift erstellt wird. Navigieren Sie zu lokalem Verkehr &gt; Virtuelle Server &gt; Liste virtueller Server.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">Überprüfen Sie die Erstellung VON BIG-IP virtuellen Servern für den entsprechenden Servicetyp loadbalancer</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">Das NetApp Astra Control Center bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für zustandsorientierte Kubernetes-Workloads, die in einer On-Premises-Umgebung implementiert werden und auf der Basis der bewährten NetApp Datensicherungstechnologie eingesetzt werden.</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="doc">Sicherung in CI/CD-Pipelines mit NetApp Astra Control integrieren</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">Eine der häufigsten Nutzungsmöglichkeiten von DevOps-Workflows ist die Continuous Integration und CI/CD-Pipelines (Continuous Deployment), die während der Entwickler neuen Code erstellen, integrieren und auf Applikationen automatisierte Test-Suites ausführen. DevOps-Engineers und Site-Reliability Engineers (SREs) verfügen in der Regel über Pipelines, die verschiedenen Workflows für die Entwicklung von neuen Funktionen, für Regressionstests, Bug Fixes, Qualitätstechnik und andere Funktionen im Entwicklungsprozess gewidmet sind.</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">Mit dem zunehmenden Automatisierungsgrad von Teams fühlen sich die Veränderungen bei Produktionsapplikationen als unübersichtlich. Daher bevorzugen einige Teams den Schutz von Produktionsapplikationen oder Services in ihrer Produktion. Neben dem Schutz von Code- und Container-Images möchten sie auch den Applikationsstatus, Konfigurationsdaten (wie Kubernetes-Objekte und Ressourcen, die mit der Applikation verknüpft sind) und die persistenten Daten einer Applikation schützen.</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">In diesem Anwendungsfall schauen wir uns eine Pipeline für die Förderung bis zur Produktion genauer an, die eine neue Version einer Applikation implementiert: Zuerst in eine Staging-Umgebung und dann in eine Produktionsumgebung. Dieses Beispiel gilt gleichermaßen für die großen Public Clouds und auch für eine On-Premises-Umgebung. Obwohl wir die Bereitstellung einer Version der App zeigen, kann die Pipeline auch mit anderen Strategien wie blau/grün oder canary Deployment verwendet werden. Als Teil der CI/CD-Pipeline werden wir die Anwendung durch ein komplettes Applikations-Backup schützen. Ein applikationsgerechtes Backup der Applikation in der Produktion mit seinen Daten, Zustand und Konfiguration kann für zahlreiche DevOps-Workflows nützlich sein.</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">DevOps mit NetApp Astra: Anwendungsfall 1-Architektur</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">NetApp Astra Control Python SDK</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">Die Anwendung zur Validierung dieses Anwendungsfalls war<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>, Eine E-Commerce-Lösung mit webbasiertem Frontend, eine Elasticsearch-Instanz für Such- und Analysefunktionen sowie eine MariaDB-Datenbank, die alle Shopping-Bestands- und Transaktionsdetails erfasst. Diese Container-Applikation wurde in einem Red hat OpenShift-Cluster installiert. Jeder POD in der Applikation verwendete persistente Volumes zum Speichern von Daten. Die persistenten Volumes wurden automatisch durch NetApp Astra Trident erstellt, den Container-Storage Interface-konformen Storage-Orchestrator für Kubernetes. Er ermöglicht die Bereitstellung von Storage auf NetApp Storage-Systemen. Darüber hinaus wurde die betreffende Applikation durch Astra Control Center verwaltet, mit der anschließend Applikations-Backups ausgelöst werden konnten, die den Zustand der Applikation zusammen mit den in persistenten Volumes gespeicherten Daten speicherten. Wir haben das verwendet<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> Um den Prozess der Auslösung von Applikations-Backups zu automatisieren, der dann in eine CI/CD-Pipeline eingeführt wurde. Diese Pipeline wurde mit dem beliebten CI/CD-Tool namens erstellt und ausgeführt <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>] Zum Automatisieren des Ablaufes zum Erstellen, Sichern und Implementieren der Applikation</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">Gehen wir die Voraussetzungen und Verfahren durch, um Schutz in eine CI/CD-Pipeline einzuführen.</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">Voraussetzungen für die Validierung von Anwendungsfällen</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">Folgende Tools oder Plattformen wurden implementiert und als Voraussetzungen konfiguriert:</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="list-text">Red hat OpenShift Container Platform</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">NetApp Astra Trident wird auf OpenShift mit konfiguriertem NetApp ONTAP System per Backend installiert</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">Eine Standardspeicherklasse mit Verweis auf ein NetApp ONTAP-Back-End ist konfiguriert</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">NetApp Astra Control Center wird auf einem OpenShift-Cluster installiert</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">OpenShift-Cluster wurde dem Astra Control Center als gemanagter Cluster hinzugefügt</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins wird auf einem OpenShift-Cluster installiert und mit einem Agent-Node konfiguriert, auf dem eine Docker Engine installiert ist</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">Installieren der Anwendung</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">Beginnen wir mit der Erstinstallation der Applikation in den Staging- und Produktionsumgebungen. Für diesen Anwendungsfall ist dieser Schritt eine Voraussetzung, daher wird er manuell durchgeführt. Die CI/CD-Pipeline kommt für nachfolgende Builds und Implementierungen von Workflows als Folge neuer Versionsversionen der Applikation zum Einsatz.</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">Die Produktionsumgebung ist in diesem Anwendungsbeispiel ein Namespace genannt<block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix=" " category="inline-code"></block>, Und die entsprechende Staging-Umgebung ist ein Namespace genannt<block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix=" " category="inline-code"></block> Konfiguration auf dem Red hat OpenShift-Cluster Gehen Sie wie folgt vor, um die Anwendung zu infüllen:</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">Installieren Sie die Magento-Anwendung mit dem bitnami-Steuerkarton in der Produktionsumgebung. Wir verwenden RWX PVS für Magento- und MariaDB-Pods.</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Magento bitnami Steueround erfordert einen Load Balancer Service, um den Magento GUI Service auszusetzen. Wir haben genutzt <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> Für die Bereitstellung eines On-Premises-Load-Balancer-Service in diesem Beispiel.</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">Stellen Sie nach wenigen Minuten sicher, dass alle Pods und Services ausgeführt werden.</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">Wiederholen Sie den gleichen Vorgang für die Staging-Umgebung.</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Verwalten Sie die Anwendung Magento im Astra Control Center</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">Navigieren Sie zu Anwendungen, und wählen Sie die Registerkarte ermittelte Anwendungen aus.</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">Klicken Sie in der Produktionsumgebung auf die Ellipse gegenüber der Magento-Anwendung <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>Und klicken Sie auf Verwalten.</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">Die Anwendung Magento wird nun vom Astra Control Center verwaltet. Alle von Astra Control unterstützten Vorgänge können auf der Anwendung ausgeführt werden. Beachten Sie auch die Version der Anwendung.</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">Magento-Version vor dem Upgrade prüfen</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">Wiederholen Sie die Schritte für die Verwaltung der Magento-Anwendung in der Staging-Umgebung <block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix="(" category="inline-code"></block>).</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">CI/CD-Pipeline mit integriertem Schutz</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">Bei der Arbeit mit neuen Applikationsversionen verwenden wir eine CI/CD-Pipeline zum Erstellen des Container-Images, Erstellen von Backups sowohl der Staging- als auch der Produktionsumgebung, Bereitstellen der neuen Version der Applikation in der Staging-Umgebung, Warten auf Genehmigung der Beförderung in die Produktion. Anschließend können Sie die neue Version der Applikation in der Produktionsumgebung implementieren. Gehen Sie wie folgt vor, um eine CI/CD-Pipeline zu verwenden:</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Melden Sie sich bei Jenkins an, und erstellen Sie die erforderlichen Anmeldedaten: Eine für Magento-Credo, eine für MariaDB-Admin-Credo und die dritte für MariaDB-Root-Creds.</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Navigieren Sie zu verwalten Jenkins &gt; Anmeldeinformationen verwalten, und klicken Sie auf die entsprechende Domäne.</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">Klicken Sie auf Anmeldeinformationen hinzufügen, und legen Sie den Benutzernamen fest, der das Passwort und den Umfang auf „Global“ gesetzt hat. Geben Sie den Benutzernamen, das Passwort und eine ID für die Anmeldeinformationen ein, und klicken Sie auf OK.</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">Anmeldedaten Erstellen</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">Wiederholen Sie das gleiche Verfahren für die anderen beiden Anmeldedaten.</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">Gehen Sie zurück zum Dashboard, erstellen Sie eine Pipeline, indem Sie auf Neues Element klicken und dann auf Pipeline klicken.</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Kopieren Sie die Pipeline aus der Jenkinsdatei<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>.</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">Fügen Sie die Pipeline in den Jenkins-Pipeline-Abschnitt ein, und klicken Sie dann auf Speichern.</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Füllen Sie die Parameter der Jenkins-Pipeline mit den entsprechenden Details aus, einschließlich der Ruderdiagrammversion, der zu aktualisierenden Magento-Anwendungsversion, der Astra-Toolkit-Version, dem FQDN des Astra Control Center, dem API-Token und der Instanz-ID. Geben Sie die Docker-Registrierung, den Namespace und die Magento-IP sowohl in Produktions- als auch in Staging-Umgebungen an, und geben Sie auch die Anmeldeinformationen für die erstellten Anmeldeinformationen an.</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">Klicken Sie Auf Jetzt Erstellen. Die Pipeline beginnt mit der Ausführung und führt die einzelnen Schritte durch. Das Anwendungsabbild wird zuerst erstellt und in die Container-Registrierung hochgeladen.</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">Fortschritt Der Verkaufskanäle</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">Die Applikations-Backups werden über Astra Control initiiert.</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">Backup initiiert</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">Nachdem die Backup-Phasen erfolgreich abgeschlossen sind, überprüfen Sie die Backups aus dem Astra Control Center.</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">Backup erfolgreich</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">Anschließend wird die neue Version der Applikation in der Staging-Umgebung bereitgestellt.</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">Staging-Implementierung gestartet</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">Nach Abschluss dieses Schritts wartet das Programm, bis der Benutzer die Bereitstellung in der Produktion genehmigt. Nehmen Sie in dieser Phase an, dass das QA-Team einige manuelle Tests durchführt und die Produktion genehmigt. Sie können dann auf Genehmigen klicken, um die neue Version der Anwendung in der Produktionsumgebung zu implementieren.</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">Warten auf die Werbeaktion</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">Überprüfen Sie, ob die Produktionsanwendung auch auf die gewünschte Version aktualisiert wird.</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">Prod-App aktualisiert</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">Als Teil der CI/CD-Pipeline haben wir demonstriert, dass sich die Applikation durch ein vollständiges applikationsgerechtes Backup schützen lässt. Da die gesamte Applikation im Rahmen der Pipeline-zwischen den Produktionsförderungen gesichert wurde, können Sie sich sicher in Bezug auf die hochgradig automatisierten Applikationsimplementierungen fühlen. Dieses applikationsgerechte Backup mit Daten, Zustand und Konfiguration der Applikation kann für zahlreiche DevOps-Workflows nützlich sein. Ein wichtiger Workflow wäre ein Rollback zur vorherigen Version der Applikation im Falle unvorhergesehener Probleme.</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Obwohl wir einen CI/CD-Workflow durch das Jenkins Tool demonstriert haben, kann das Konzept einfach und effizient auf verschiedene Tools und Strategien hochgerechnet werden. Sehen Sie sich das Video an, um diesen Anwendungsfall in Aktion zu sehen <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>.</block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">Als Nächstes: Videos und Demos – DevOps mit NetApp Astra.</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">Schnelle Implementierung mithilfe von FlexClone Technologie</block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">Beschleunigte Softwareentwicklung mit NetApp FlexClone Technologie</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">Das Klonen einer in einem Kubernetes Cluster implementierten Applikation ist ein sehr nützliches Tool für Entwickler, das ihre Workflows beschleunigen möchte, indem Umgebungen mit Partnern gemeinsam genutzt oder neue Code-Versionen in einer Entwicklungsumgebung getestet werden, ohne die aktuelle Version zu beeinträchtigen. Das statusorientierte und applikationskonsistente Klonen einer Kubernetes Applikation ist eine wichtige Funktion, die in NetApp Astra Control enthalten ist und zusätzlich die Backup- und Restore-Vorgänge von Applikationen übernimmt. Wenn eine Applikation innerhalb desselben Kubernetes Clusters über dasselbe Storage-Backend geklont wird, nutzt Astra Control standardmäßig die NetApp FlexClone Technologie zur Duplizierung persistenter Daten-Volumes, wodurch der Prozess erheblich beschleunigt wird. Durch Beschleunigung dieses Prozesses wird die geklonte Umgebung in wenigen Augenblicken bereitgestellt und verfügbar. So können Entwickler die Arbeit im Vergleich zur Neuimplementierung ihrer Test- oder Entwicklungsumgebung mit nur einer kurzen Pause wiederaufnehmen. Darüber hinaus können alle Funktionen von NetApp Astra Control mit einer API aufgerufen werden, die die einfache Integration in Automatisierungs-Frameworks wie Ansible ermöglicht. Daher können Umgebungen noch schneller bereitgestellt werden, da für das Klonen nur geringfügige Änderungen in einem Playbook oder einer Rolle erforderlich sind.</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">Was ist NetApp FlexClone Technologie?</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">Die NetApp FlexClone Technologie ist eine beschreibbare, zeitpunktgenaue Snapshot-basierte Kopie einer NetApp FlexVol. Sie werden nahezu sofort bereitgestellt, enthalten alle Daten vom Quell-Volume und verbrauchen keinen zusätzlichen Speicherplatz, bis die Daten im neuen Volume vom Quellspeicherort abweichen. Sie werden häufig in Entwicklungs- oder vorlagenbasierten Umgebungen verwendet, wenn mehrere Datenkopien für Staging-Zwecke nützlich sind und Storage-Systeme nur über begrenzte Ressourcen zur Bereitstellung dieser Volumes verfügen. Im Vergleich zu einem herkömmlichen Storage-System, bei dem Daten mehrfach kopiert werden müssen, wodurch viel Speicherplatz und Zeit in Anspruch genommen werden, beschleunigt die NetApp FlexClone Technologie die speicherabhängige Aufgabe.</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">Bild zu FlexClone</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">NetApp Dokumente</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">Um mehr über die NetApp FlexClone Technologie zu erfahren, besuchen Sie die Seite auf<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>.</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Eine unterstützte Kubernetes-Distribution, z. B. Red hat OpenShift 4.6.8+, Rancher 2.5+ oder Kubernetes 1.19+.</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra Control Center 21.12 oder höher</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">Ein NetApp ONTAP System mit einem über NetApp Astra Trident konfigurierten Storage-Backend.</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible, 2.9 Oder Höher</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">Vorlagen für die Umgebungen, die Sie als gemanagte Applikationen in NetApp Astra Control klonen möchten.</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">Anwendungsfallvorstellung</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">Für diesen Anwendungsfall betrachten wir etwas, das dem folgenden Workflow ähnelt:</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">Workflow-Bild</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">Ein Benutzer führt das ansible-Playbook aus, um eine neue Staging-Umgebung zu erstellen.</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible verwendet das URI-API-Modul, um Astra Control zum Ausführen des Klonvorgangs aufzurufen.</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control führt einen Klonvorgang in einer vorab bereitgestellten Vorlagenumgebung aus und erstellt auf diese Weise eine neue, gemanagte Applikation.</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">Diese Umgebung kann es sich um eine einzelne Standalone-Applikation in der Entwicklung oder um eine gesamte Entwicklungsumgebung wie eine Jenkins CI/CD-Pipeline handeln.</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">Der Benutzer zieht dann eine Codeversion von einem Online-Repository wie Gitea in die geklonte Entwicklungsumgebung ein.</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">Die neue Version der Applikation wird von NetApp Astra Control implementiert und gemanagt.</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">Beide Prozesse können automatisiert werden.</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">In dieser geklonten Umgebung kann der Benutzer neuen Code entwickeln.</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">Wenn der Benutzer mit seinen Entwicklungsbemühungen zufrieden ist, kann er den Code zurück in das gehostete Repository übertragen.</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">Der hier vorgestellte Anwendungsfall hängt von dem Vorhandensein von goldenen Vorlagen für die speziellen Umgebungen oder Applikationen ab, die geklont werden sollen. In unserer Umgebung haben wir drei solche Vorlagen erstellt, eine für eine WordPress-Bereitstellung, eine für eine Magento-Bereitstellung und eine für eine Jenkins CI/CD-Umgebung mit Gitea, die wir mit DevTools betitelt haben.</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">Vorlagen Bild</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">Jede dieser Umgebungen wird durch den NetApp Astra Control gemanagt, wobei persistente Volumes auf einem NetApp ONTAP Storage-System mit einem durch NetApp Astra Trident bereitgestellten NFS-Back-End gespeichert sind.</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">Validierung von Anwendungsfällen</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">das netapp Solutions Engineering Team klont das ansible Toolkit, das die Klonrolle und das Playbook für Applikations-Updates enthält.</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">Bearbeiten<block ref="c4fe4210b1a8cc125caf1d344db07732" prefix=" " category="inline-code"></block> Und füllen Sie die globalen Werte aus, die zu Ihrer Astra Control-Umgebung passen.</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">Die erforderlichen globalen Umgebungswerte sind im NetApp Astra Control über das API Access-Menü unter dem Benutzerprofilsymbol verfügbar.</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">API-Zugriffsbild</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">Wenn die globalen Variablen abgeschlossen sind, können Sie die Werte für die spezifische Applikation auswählen, die Sie klonen möchten. Um die devTools-Umgebung in einer persönlichen Umgebung namens zu klonen<block ref="2ab4557e919d8388e34d63b073eb0704" prefix=" " category="inline-code"></block>, Sie würden Folgendes tun:</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">Um beim Klonprozess die NetApp FlexClone Technologie zu nutzen,<block ref="4235aba0b7240b55d6c0b4e16f2b0c9a" prefix=" " category="inline-code"></block> Und<block ref="57d3fb1ffc6c61e8386a14142cad2cfe" prefix=" " category="inline-code"></block> Muss gleich sein.</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">Sie können nun das Playbook ausführen, um die Applikation zu klonen.</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">Das Playbook muss vom Root-Benutzer oder einer Person ausgeführt werden, die den Sudo-Prozess durchlaufen kann, indem es das Argument „-K“ gibt.</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">Nach Abschluss des Playbooks wird die geklonte Applikation in der Astra Control Center-Konsole angezeigt.</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">Geklontes App-Image</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">Ein Benutzer kann sich anschließend in der Kubernetes-Umgebung, in der die Applikation implementiert wurde, überprüfen, ob die Applikation mit einer neuen IP-Adresse konfrontiert ist, und seine Entwicklungsarbeiten starten.</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">Eine Demonstration dieses Anwendungsfalls und eines Beispiels zum Aktualisieren einer Anwendung finden Sie unter <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>.</block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">Klonen Sie die Applikation für die Post-Mortem-Analyse und stellen Sie Ihre Applikation in der CI/CD-Pipeline mit Astra Control Center wieder her</block>
  <block id="8b682694b3e16be71600ae19c5a6e2fe" category="doc">Nutzen Sie NetApp Astra Control, um eine Analyse nach der Sterblichen durchzuführen und Ihre Applikation wiederherzustellen</block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">Als Nächstes: Weitere Informationen: DevOps mit NetApp Astra.</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">Eine Übersicht über devops und potenzielle Anwendungsfälle in diesem technischen Bericht.</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">DevOps-Übersicht</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">In den vergangenen Jahren haben Softwareunternehmen die Konzepte von DevOps umgesetzt. DevOps-Praktiken machen die organisatorischen Barrieren aus und bringen die Entwicklungs- und Betriebsteams näher. DevOps-Praktiken ermöglichen es den Teams zudem, Bereitstellungen zu beschleunigen, die Verfügbarkeit zu erhöhen und Services und Applikationen stabiler zu machen, was die Produktivität des Teams erhöht. Darüber hinaus ist die Einführung eines Automatisierungs-Frameworks auch ein wichtiger Erfolgsfaktor – vom Erstellen, Testen und Betrieb skalierbarer Applikationen bis hin zum Management einer voll automatisierten Infrastrukturplattform oder eines Stack. Im Folgenden werden einige primäre Anwendungsfälle für DevOps erläutert, in denen NetApp Lösungen implementiert werden können, um die Erfahrung zu verbessern, die DevOps-Fachleute im täglichen Geschäft erleben.</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">DevOps-Anwendungsfälle</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">Auch wenn DevOps keine einheitliche, allgemein anerkannte Definition bietet, enthalten Lösungen für DevOps-Praktiken normalerweise ähnliche Konstrukte oder Ideologien, die eine einfache Implementierung, Wiederholung und einfaches Management im großen Maßstab ermöglichen. In den folgenden Abschnitten werden potenzielle Anwendungsfälle für DevOps-Workflows, die mithilfe von NetApp Lösungen möglich sind, beschrieben.</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">Continuous Integration, Continuous Delivery und Continuous Deployment (CI/CD)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">Continuous Integration, Continuous Delivery und Continuous Deployment (CI/CD) ist eine Codierungsphilosophie, die Entwickler dazu ermutigt, ihre Codierungsverfahren zu implementieren und zu transformieren, indem eine Methode eingerichtet wird, mit der sie ihren Code konsistent automatisch aktualisieren, testen und implementieren können. Die beliebteste Methode zur Implementierung von CI/CD in den meisten DevOps-Workflows ist die CI/CD-Pipeline. Darüber hinaus gibt es verschiedene Softwareapplikationen von Drittanbietern.</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">CI/CD-Image</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">Die folgenden Beispiele sind beliebte Anwendungen, die bei CI/CD-Workflows helfen können:</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ArgoCD</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">Tekton</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">Einige der später in diesem technischen Bericht enthaltenen Anwendungsfälle wurden in Jenkins demonstriert, aber die primären CI/CD-Prinzipien können für jedes Tool angewendet werden, das ein Unternehmen in seinen eigenen Methoden implementiert hat.</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">Infrastruktur als Code</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">Infrastruktur als Code unterstützt die Bereitstellung und das Management VON IT-Ressourcen mithilfe automatisierter Befehle, APIs und Software Development Kits (SDK). Dieses Konzept sorgt für eine deutlich bessere DevOps-Erfahrung, da die Einschränkungen des physischen Datacenters oder der Ressourcen beseitigt werden, die verhindern könnten, dass Entwickler ihre Ziele erreichen.</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">Bild: Infrastruktur als Code</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">Puppet</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">Endbenutzer verwenden häufig Programmiersprachen wie z. B.<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> Oder Automatisierungs-Tools wie<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> Oder<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> Um automatisierte und wiederholbare Aktionen zur Infrastrukturskalierung zu erstellen, die von Entwicklern jederzeit aufgerufen werden können.</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">Sowohl NetApp ONTAP als auch Astra Control enthalten öffentliche APIs und ansible-Module oder Software-Entwicklungs-Toolkits, die die Einführung und Integration von automatisierten Abläufen sehr einfach in DevOps-Prozesse vereinfachen.</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">Weiter: NetApp Storage-Systeme: Überblick</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp verfügt über mehrere Storage-Plattformen, die für Astra Trident und Astra Control qualifiziert sind, um Daten für Container-Applikationen bereitzustellen, zu sichern und zu managen und so den DevOps-Durchsatz zu definieren und zu maximieren.</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">NetApp Storage-Systeme: Überblick</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">Weiter: Übersicht über NetApp Storage-Integrationen</block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">Dieser technische Bericht erläutert, wie NetApp DevOps im Einsatz von Container-Applikationen einfach und effizient in diversen Bereichen unterstützt. Am Anfang werden die NetApp Storage-Systeme und ihre Integration mit Kubernetes-Plattformen mithilfe des Astra Portfolios detailliert erläutert. Abschließend werden eine Reihe von Validierungen von Lösungen und Anwendungsbeispiele aus der Praxis untersucht und dokumentiert.</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919: DevOps mit NetApp Astra</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">Die Architektur von DevOps mit NetApp Astra bietet Kunden mit den folgenden Anwendungsfällen einen hervorragenden Mehrwert:</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">Einfaches Implementieren und Managen von Applikationen und Entwicklungsumgebungen, die auf unterstützten Kubernetes-Distributionen ausgeführt werden.</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">Diskussion über reale Anwendungsfälle für DevOps-Workflows und Beispiele für Tools und Methoden, die NetApp bereitstellen kann, um die Einführung und Nutzung dieser Methoden zu vereinfachen</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">Die Untersuchung, wie applikationskonsistente Snapshots, Backups und Klone verwendet werden können, um die DevOps-Erfahrung zu verbessern</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">Geschäftlicher Nutzen</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">Hochverfügbarkeit auf allen Ebenen im Stack, damit Workflows nie unterbrochen werden.</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">Einfache Implementierung und einfaches Management für Endbenutzer.</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">API-gestützte, programmierbare Infrastruktur, um mit Microservices und Entwicklerflexibilität Schritt zu halten</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">Möglichkeit, Infrastruktur unabhängig und automatisiert zu skalieren, um sie an Workload-Anforderungen anzupassen</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">Durch den Schutz von Applikationen und die Sicherung persistenter Datensätze für DevOps-Workflows wird die Markteinführung beschleunigt, da keine Reimplementierungen oder manuelles Kopieren von Daten erforderlich sind.</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">In diesem technischen Bericht werden diese Funktionen und Herausforderungen erkannt und erläutert, wie sich DevOps-Anwendungsfälle für Container-Applikationen mithilfe des umfassenden Portfolios von NetApp Produkten verbessern und vereinfachen lassen.</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">Die Lösung DevOps mit NetApp umfasst die folgenden Hauptkomponenten:</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">DevOps-Praktiken</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">DevOps-Praktiken konzentrieren sich auf automatisierte, wiederholbare und leicht zu verwaltende Vorgänge, die den Entwicklungs-Workflow verbessern, da Endbenutzer die Umgebung steuern können, in der sie ihren Code entwickeln. Diese Lösung enthält mehrere Beispiele und Anwendungsfälle, in denen sich NetApp Technologie für einen solchen Betrieb am meisten eignet.</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="section-title">Container-Orchestrierung</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">Derzeit sind zahlreiche Container-Orchestrierungsplattformen im Einsatz. Obwohl die meisten dieser Plattformen auf Kubernetes basieren, besitzen beide vor- und Nachteile. Es ist also wichtig, bei der Auswahl einer Container-Orchestrierungsplattform für DevOps-Workflows Funktionsgruppen und Integrationen zu kennen. Mit der NetApp Astra Suite unterstützen wir die folgenden Plattformen für vollwertige DevOps-Anwendungsfälle:</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8 oder höher</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">Rancher</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5 und höher</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20 und höher</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">VMware Tanzu Kubernetes Grid</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4 und höher</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2 und höher</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">NetApp Storage-Systeme</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">NetApp Storage-Integrationen</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">Weiter: DevOps Übersicht.</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">Übersicht über NetApp Astra Control</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Eine ausführliche Installations- und Betriebsanleitung für das Astra Control Center finden Sie in der Dokumentation <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Astra Control Center Automatisierung</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Center verfügt über eine voll funktionsfähige REST-API für programmatischen Zugriff. Benutzer können jede beliebige Programmiersprache oder ein beliebiges Dienstprogramm verwenden, um mit den ASTRA Control REST-API-Endpunkten zu interagieren. Weitere Informationen zu dieser API finden Sie in der Dokumentation <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>.</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">Wenn Sie nach einem sofort einsatzbereiten Software-Entwicklungs-Toolkit für die Interaktion mit Astra Control REST APIs suchen, bietet NetApp ein Toolkit mit Astra Control Python SDK, das Sie herunterladen können <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">Wenn die Programmierung in Ihrer Situation nicht geeignet ist und Sie ein Konfigurationsmanagement-Tool verwenden möchten, können Sie die von NetApp veröffentlichten Ansible-Playbooks klonen und ausführen <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">Weiter: Use-Case Validierungen: DevOps mit NetApp Astra</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp bietet eine Reihe von Produkten, die unsere Kunden bei der Orchestrierung und dem Management persistenter Daten in Container-basierten Umgebungen unterstützen.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">Überblick über die NetApp Storage-Integration</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">Weiter: Use-Case Validierungen: DevOps mit NetApp Astra.</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Datensicherung in der CI/CD-Pipeline mit Astra Control Center</block>
  <block id="1c333560e2edbd1cefb05f127658b17f" category="doc">Datensicherung in der CI/CD-Pipeline mit Astra Control Center</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">Videos und Demos: DevOps mit NetApp Astra</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">In den folgenden Videos werden einige der in diesem Dokument beschriebenen Funktionen demonstriert:</block>
  <block id="47a3fe612643a48831699e345fc50086" category="inline-link-macro">Video: Integrieren Sie Datensicherung in die CI/CD-Pipeline mit Astra Control</block>
  <block id="b137de00495bfd71913e4fe2ecc2fbb5" category="list-text"><block ref="b137de00495bfd71913e4fe2ecc2fbb5" category="inline-link-macro-rx"></block></block>
  <block id="11a855b91bda336c24ae0014cf0b01aa" category="list-text"><block ref="11a855b91bda336c24ae0014cf0b01aa" category="inline-link-macro-rx"></block></block>
  <block id="760ebcab0161b35f2cbcee21a65a788a" category="list-text"><block ref="760ebcab0161b35f2cbcee21a65a788a" category="inline-link-macro-rx"></block></block>
  <block id="a7f77f303480f7b7143a247c228eaebb" category="doc">Beschleunigen Sie die Softwareentwicklung mit Astra Control und NetApp FlexClone Technologie</block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">Astra Control erleichtert die Nachkontrollen und stellt die Anwendung wieder her</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">Erster Anwendungsfall</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">Im <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>, Wir haben demonstriert, wie das NetApp Astra Control Center für die Sicherung Ihrer Applikationen in Kubernetes genutzt wird. Dieser Abschnitt beschreibt, wie Sie Applikations-Backups über Astra Control direkt mit dem Python SDK im NetApp Astra Toolkit in Ihren Entwicklungs-Workflow integrieren. Dieser Ansatz ermöglicht den Schutz von Entwicklungs- und Produktionsumgebungen durch die Automatisierung von On-Demand Backups während der kontinuierlichen Integration und Continuous Deployment (CI/CD)-Prozesse. Mit dieser zusätzlichen Schicht applikationskonsistenter Datensicherung, die der CI/CD-Pipeline und den Produktionsanwendungen hinzugefügt wird, sind die Entwicklungsprozesse sicher, wenn bei einem Prozess ein Fehler auftritt, was zu guten Business-Continuity-Verfahren führt.</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">In einem herkömmlichen Workflow würde das Entwicklungsteam versuchen, das Problem anhand von Fehlerberichten von Kunden in Echtzeit zu beheben, nachdem ein Fehler beim Upgrade der Anwendung auf eine neue Version aufgetreten ist. Alternativ könnte das Team bei der ersten Fehlermeldung versuchen, die Applikation in eine parallele Debugging-Umgebung neu zu implementieren, um diesen Prozess offline zu schalten. Sie könnten eine ältere Code-Basis von einer früheren Version in den Produktionsbetrieb wiederherstellen, um die Arbeitsreihenfolge der Applikation wiederherzustellen.</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">Herkömmlicher Workflow</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">Obwohl dieser Ansatz funktioniert, muss das Team sicherstellen, dass der Zustand der defekten Produktions-App mit der Version übereinstimmt, die in der Produktion gesehen wurde, als die Probleme aufgetreten sind. Sie müssten auch Zeit auf die Förderung des bekannten fehlerfreien Builds in die Produktion verwenden, indem sie Code aus ihrem Repository abrufen und die Machine-Images neu implementieren, um die Applikation in einem guten, ausgeführten Zustand wiederherzustellen. Auch in diesem Szenario wurde nicht berücksichtigt, ob die Produktionsdatenbank selbst durch den fehlerhaften Code beschädigt war. Im Idealfall gibt es separate Backup-Prozesse für die Datenbankdaten, aber müssen wir davon ausgehen, dass sie mit dem Zustand der Applikation, wie sie veröffentlicht wurde, konsistent sind? Hier zeigen die Vorteile statusbehafteter und applikationskonsistenter Backups, Restores und Klone mit Astra Control ihren Wert.</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">Erstens können wir Astra Control nutzen, um eine Nachmortem-Analyse über den Stand der Anwendung zu ermöglichen. Dazu klonen wir die Buggy-Produktionsversion auf applikationskonsistente Weise in einer parallelen Testumgebung. Wenn diese Umgebung in ihrem fehlergeritten Zustand beiseite gelegt wurde, können wir das Problem in Echtzeit beheben.</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">Darüber hinaus unterstützt Astra Control die Möglichkeit zur Wiederherstellung der vorhandenen Daten, mit der die Produktionsanwendung auf ein letztes akzeptables Backup wiederhergestellt werden kann (das der betroffenen Codeversion vorausging). Die wiederhergestellte Version übernimmt die Position der vorherigen, Buggy-Produktionsanwendung auf anwendungskonsistente und zustandsorientierte Weise, einschließlich der zuvor zugewiesenen Ingress-IP. Aus diesem Grund haben Kunden, die auf das Front-End zugreifen, den Übergang zur Backup-Version nicht bemerkt.</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">Workflow nach Abschluss eines Nachfalls</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Red hat OpenShift Container Platform</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp Astra Trident wird auf OpenShift mit einem Back-End-Konfiguration auf einem NetApp ONTAP-System installiert.</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">Eine Standardspeicherklasse mit Verweis auf ein NetApp ONTAP-Back-End ist konfiguriert.</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">NetApp Astra Control Center wird auf einem OpenShift-Cluster installiert.</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">OpenShift-Cluster wurde dem Astra Control Center als gemanagter Cluster hinzugefügt.</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins wird auf einem OpenShift-Cluster installiert.</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">Magento-Anwendung in der Produktionsumgebung installiert. Die Produktionsumgebung in diesem Anwendungsbeispiel ist ein Namespace namens „mento-Prod“ in einem Red hat OpenShift-Cluster.</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">Produktionsanwendung verwaltet durch Astra Control Center.</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Bekannte Backup(s) der Applikation in der Produktion, die mit Astra Control erfasst wurde.</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">Klon- und Restore-Pipeline</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">Angesichts des Upgrades der Applikation auf eine neue Version, der Applikation in der Produktionsumgebung <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>) Verhält sich nicht wie vorgesehen nach der Aktualisierung. Nehmen wir an, dass die Daten, die von Front-End-Abfragen zurückgegeben werden, nicht mit der Anfrage übereinstimmen oder dass die Datenbank tatsächlich beschädigt wurde. Um die Pipeline zu klonen und wiederherzustellen, gehen Sie wie folgt vor:</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">Fehlerhafte Anwendung</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Melden Sie sich bei Jenkins an und erstellen Sie eine Pipeline, indem Sie auf Neues Element und anschließend auf Pipeline klicken.</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Kopieren Sie die Pipeline aus der Jenkinsdatei<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>.</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">Füllen Sie die Parameter der Jenkins-Pipeline mit den entsprechenden Details wie der aktuellen Magento-Anwendungsversion in der Produktion, dem Astra Control Center FQDN, dem API-Token, der Instanz-ID und dem Anwendungsnamen oder dem Namespace der Produktions- und Debugumgebungen sowie den Quell- und Zielcluster-Namen aus. Für diesen Anwendungsfall ist die Produktionsumgebung ein Namespace namens „mento-Prod“ und die Debug-Umgebung ist ein Namespace namens „mento-Debug“, der auf einem Red hat OpenShift-Cluster konfiguriert ist.</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">Klicken Sie Auf Jetzt Erstellen. Die Pipeline beginnt mit der Ausführung und führt die einzelnen Schritte durch. Die Anwendung wird zuerst im aktuellen Status in einer Debug-Umgebung geklont, und die Anwendung wird dann auf das bekannte Backup wiederhergestellt.</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">Post-Sterbliche-Pipeline</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">Vergewissern Sie sich, dass es sich bei der geklonten Applikation um die Fehlerversion handelt.</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">Fehler Bei Geklonter App</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">Überprüfen Sie, ob die Produktionsumgebung in einem funktionierenden Backup wiederhergestellt wird und die Applikation in der Produktion wie erwartet funktioniert.</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">Prod-App Wurde Wiederhergestellt</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">Diese beiden Vorgänge beschleunigen gleichzeitig die Rückkehr zu den normalen Geschäftsabläufen. Sehen Sie sich das Video an, um diesen Anwendungsfall in Aktion zu sehen <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>.</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">Validierung von Anwendungsfällen: DevOps mit NetApp Astra</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">Folgende Anwendungsfälle wurden für DevOps mit NetApp Astra validiert:</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">Nutzen Sie Astra Control zur Unterstützung der Nachkontrollen und zur Wiederherstellung der Anwendung</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">Beschleunigung der Softwareentwicklung mit NetApp FlexClones</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">Als Nächstes: Übersicht zu NetApp Storage-Integrationen</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">Zusätzliche Informationen: DevOps mit NetApp Astra</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Ansible-Dokumentation</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Rancher-Dokumentation</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Kubernetes-Dokumentation</block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">Siehe Dokumentation <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Für die Installation und Verwendung von Astra Trident.</block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Advanced Cluster Management für Kubernetes: Red hat OpenShift mit NetApp</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">Für den Übergang von Container-Applikationen von der Entwicklung in die Produktion sind in vielen Unternehmen mehrere Red hat OpenShift Cluster erforderlich, um das Testen und die Implementierung dieser Applikation zu unterstützen. Dazu hosten Unternehmen in der Regel mehrere Anwendungen oder Workloads auf OpenShift-Clustern. Daher verwaltet jedes Unternehmen eine Reihe von Clustern. OpenShift-Administratoren müssen sich daher der zusätzlichen Herausforderung stellen, mehrere Cluster in einer Reihe von Umgebungen zu managen und zu warten, die sich auf mehrere lokale Datacenter und Public Clouds erstrecken. Um diese Herausforderungen zu bewältigen, hat Red hat das Advanced Cluster Management für Kubernetes eingeführt.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Mit Red hat Advanced Cluster Management für Kubernetes können Sie die folgenden Aufgaben ausführen:</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">Diverse Cluster lassen sich über Datacenter und Public Clouds hinweg erstellen, importieren und managen</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">Implementieren und managen Sie Applikationen oder Workloads über eine einzige Konsole auf mehreren Clustern</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">Überwachen und analysieren Sie den Zustand und den Status verschiedener Cluster-Ressourcen</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">Überwachung und Durchsetzung von Sicherheits-Compliance über mehrere Cluster hinweg</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red hat Advanced Cluster Management für Kubernetes wird als Add-on zu einem Red hat OpenShift-Cluster installiert und verwendet dieses Cluster als zentralen Controller für alle Vorgänge. Dieser Cluster wird als Hub-Cluster bezeichnet und stellt eine Managementebene bereit, über die Benutzer eine Verbindung zu Advanced Cluster Management herstellen können. Alle anderen OpenShift-Cluster, die entweder über die Advanced Cluster Management-Konsole importiert oder erstellt werden, werden vom Hub-Cluster gemanagt und werden als verwaltete Cluster bezeichnet. Es installiert einen Agent namens Klusterlet auf den gemanagten Clustern, um sie mit dem Hub-Cluster zu verbinden und Anfragen nach unterschiedlichen Aktivitäten im Zusammenhang mit Cluster Lifecycle Management, Applikations-Lifecycle-Management, Beobachtbarkeit und Sicherheits-Compliance zu erfüllen.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM-Architektur</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">Weitere Informationen finden Sie in der Dokumentation<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">ISCSI-Konfiguration von NetApp Element</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">Um die Trident Integration mit dem NetApp Element Storage-System zu aktivieren, müssen Sie ein Backend erstellen, das die Kommunikation mit dem Storage-System über das iSCSI-Protokoll ermöglicht.</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">Im heruntergeladenen Installationsarchiv stehen Beispiele für Backend-Dateien zur Verfügung<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> Ordnerhierarchie. Kopieren Sie für NetApp Element-Systeme, die iSCSI-Server bereitstellen, das<block ref="7989420add0b5baae954e866987ef264" prefix=" " category="inline-code"></block> Datei in Ihr Arbeitsverzeichnis und bearbeiten Sie die Datei.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">Bearbeiten Sie den Benutzer-, das Kennwort und den MVIP-Wert auf dem<block ref="b7ae24ea48e61624a7e4078daa60bd78" prefix=" " category="inline-code"></block> Linie.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">Bearbeiten Sie das<block ref="dcda39e13b00bf6bd40a507e1833a6f5" prefix=" " category="inline-code"></block> Wert:</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">Führen Sie mit dieser Back-End-Datei den folgenden Befehl aus, um Ihr erstes Backend zu erstellen.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">Es gibt ein optionales Feld mit dem Namen<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> Das ist in dieser Datei definiert. In iSCSI-Back-Ends kann dieser Wert auf einen bestimmten Linux-Dateisystem-Typ (XFS, ext4 usw.) gesetzt werden. OpenShift kann auch gelöscht werden, damit OpenShift entscheiden kann, welches Dateisystem verwendet werden soll.</block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Die Container-Plattform Red hat OpenShift vereint Entwicklungs- und IT-Abläufe auf einer einzigen Plattform, um Anwendungen konsistent in lokalen und Hybrid-Cloud-Infrastrukturen zu erstellen, bereitzustellen und zu managen. Red hat OpenShift basiert auf Open-Source-Innovationen und Branchenstandards, einschließlich Kubernetes und Red hat Enterprise Linux CoreOS, der weltweit führenden Linux-Distribution für Container-basierte Workloads.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift Übersicht</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Die Container-Plattform Red hat OpenShift vereint Entwicklungs- und IT-Abläufe auf einer einzigen Plattform, um Anwendungen konsistent in lokalen und Hybrid-Cloud-Infrastrukturen zu erstellen, bereitzustellen und zu managen. Red hat OpenShift basiert auf Open-Source-Innovationen und Branchenstandards, einschließlich Kubernetes und Red hat Enterprise Linux CoreOS, der weltweit führenden Linux-Distribution für Container-basierte Workloads. OpenShift ist Teil des CNCF-zertifizierten Kubernetes-Programms Cloud Native Computing Foundation (Cloud Native Computing Foundation) und bietet Portabilität und Interoperabilität für Container-Workloads.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red hat OpenShift bietet die folgenden Funktionen:</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">*Self-Service-Provisioning.* Entwickler können mit den Tools, die sie am meisten verwenden, schnell und einfach Anwendungen nach Bedarf erstellen, während der Betrieb die volle Kontrolle über die gesamte Umgebung behält.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">*Persistenter Storage.* durch die Unterstützung für persistenten Speicher ermöglicht die OpenShift Container Platform sowohl zustandsorientierte Anwendungen als auch Cloud-native statusfreie Anwendungen.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">*Continuous Integration und Continuous Development (CI/CD).* Diese Quellcode-Plattform verwaltet die Erstellung und Bereitstellung von Images nach Maß.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">*Open-Source-Standards* zu diesen Standards kommen neben anderen Open-Source-Technologien auch die Open-Container-Initiative (OCI) und Kubernetes zur Container-Orchestrierung zur Verfügung. Sie sind nicht auf die Technologie oder die Business-Roadmap eines bestimmten Anbieters beschränkt.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">* CI/CD-Pipelines.* OpenShift bietet sofort Unterstützung für CI/CD-Pipelines, sodass Entwicklungsteams jeden Schritt des Application Delivery-Prozesses automatisieren und sicherstellen können, dass es bei jeder Änderung, die an Code oder Konfiguration der Anwendung vorgenommen wird, ausgeführt wird.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">*Role-Based Access Control (RBAC).* Diese Funktion bietet Team- und Benutzerverfolgung, um eine große Entwicklergruppe zu organisieren.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">*Automatisiertes Erstellen und Bereitstellen.* OpenShift bietet Entwicklern die Möglichkeit, ihre Container-Anwendungen zu erstellen oder die Plattform die Container aus dem Anwendungsquellcode oder sogar den Binärdateien zu erstellen. Die Plattform automatisiert dann die Implementierung dieser Applikationen in der gesamten Infrastruktur anhand der für die Applikationen definierten Merkmale. Beispiel: Wie viele Ressourcen sollten zugewiesen werden und wo in der Infrastruktur sie implementiert werden sollen, damit sie mit Lizenzen von Drittanbietern konform sind?</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">*Konsistente Umgebungen.* OpenShift stellt sicher, dass die für Entwickler und über den gesamten Lebenszyklus der Anwendung bereitgestellte Umgebung vom Betriebssystem bis zu Bibliotheken, Laufzeitversion (z. B. Java Runtime) konsistent ist. Und sogar die Applikationslaufzeit (zum Beispiel Tomcat), um die Risiken aus inkonsistenten Umgebungen zu entfernen.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">*Konfigurationsmanagement.* das Konfigurations- und Management sensibler Daten ist in die Plattform integriert, um sicherzustellen, dass der Applikation eine konsistente und umgebungsinunabhängige Anwendungskonfiguration zur Verfügung gestellt wird, unabhängig davon, welche Technologien zur Erstellung der Anwendung oder in welcher Umgebung sie implementiert wird.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">*Anwendungsprotokolle und Metriken.* schnelles Feedback ist ein wichtiger Aspekt der Anwendungsentwicklung. Die integrierte Überwachungs- und Protokollverwaltung von OpenShift stellt Entwicklern sofort Kennzahlen zur Verfügung, um zu untersuchen, wie sich die Anwendung über Änderungen hinweg verhält, und Probleme so früh wie möglich im Applikationslebenszyklus beheben zu können.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">* Sicherheit und Container-Katalog.* OpenShift bietet Mandantenfähigkeit und schützt den Benutzer vor schädlicher Codeausführung durch die Nutzung der bewährten Sicherheit mit Security-Enhanced Linux (SELinux), CGroups und Secure Computing Mode (seccomp) zur Isolierung und zum Schutz von Containern. Darüber hinaus bietet es Verschlüsselung über TLS-Zertifikate für die verschiedenen Subsysteme sowie Zugriff auf Red hat zertifizierte Container (access.redhat.com/containers), die mit besonderem Schwerpunkt auf Sicherheit gescannt und bewertet werden, um Endbenutzern zertifizierte, vertrauenswürdige und sichere Anwendungs-Container bereitzustellen.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Bereitstellungsmethoden für Red hat OpenShift</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Ab Red hat OpenShift 4 umfassen die Bereitstellungsmethoden für OpenShift manuelle Bereitstellungen mithilfe von User Provisioned Infrastructure (UPI) für stark angepasste Bereitstellungen oder vollständig automatisierte Bereitstellungen mithilfe von Installer Provisioned Infrastructure (IPI).</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">Die IPI-Installationsmethode ist in den meisten Fällen die bevorzugte Methode, da sie die schnelle Implementierung von OCP-Clustern für Entwicklungs-, Test- und Produktionsumgebungen ermöglicht.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">IPI-Installation von Red hat OpenShift</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">Die Bereitstellung von OpenShift für die installierte Infrastruktur (Installer Provisioned Infrastructure, IPI) umfasst die folgenden grundlegenden Schritte:</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">Website</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Besuchen Sie Red hat OpenShift<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> Und melden Sie sich mit Ihren SSO-Anmeldedaten an.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Wählen Sie die Umgebung aus, in der Red hat OpenShift bereitgestellt werden soll.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">Laden Sie auf dem nächsten Bildschirm das Installationsprogramm, den eindeutigen Pull-Secret und die CLI-Tools zur Verwaltung herunter.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">Folgen Sie den<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Von Red hat zur Bereitstellung in Ihrer bevorzugten Umgebung bereitgestellt.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">Validierte OpenShift-Implementierungen durch NetApp</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp hat die Implementierung von Red hat OpenShift in seinen Labs mithilfe der Bereitstellungsmethode IPI (Installer Provisioning Infrastructure) in den folgenden Datacenter-Umgebungen getestet und validiert:</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">Cluster Lifecycle Management</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">Um unterschiedliche OpenShift-Cluster zu verwalten, können Sie sie entweder erstellen oder in Advanced Cluster Management importieren.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">Navigieren Sie zunächst zu „Automatisieren Sie Infrastrukturen“ &gt; „Cluster“.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">Gehen Sie wie folgt vor, um einen neuen OpenShift-Cluster zu erstellen:</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">Erstellen Sie eine Provider-Verbindung: Navigieren Sie zu Provider Connections und klicken Sie auf Add a Connection, geben Sie alle Details zum ausgewählten Provider-Typ an, und klicken Sie auf Add.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">Fügen Sie die Verbindung zum Anbieter hinzu</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">Navigieren Sie zum Erstellen eines neuen Clusters zu Clusters und klicken Sie auf Cluster hinzufügen &gt; Cluster erstellen. Geben Sie die Details für den Cluster und den entsprechenden Anbieter ein, und klicken Sie auf Erstellen.</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">Fügen Sie Cluster hinzu</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">Nach dem Erstellen des Clusters wird es in der Cluster-Liste mit dem Status „bereit“ angezeigt.</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">So importieren Sie ein vorhandenes Cluster:</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">Navigieren Sie zu Clusters, und klicken Sie auf Cluster hinzufügen &gt; vorhandenen Cluster importieren.</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">Geben Sie den Namen des Clusters ein, und klicken Sie auf Importieren speichern und Code generieren. Ein Befehl zum Hinzufügen des vorhandenen Clusters wird angezeigt.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Klicken Sie auf Copy Command und führen Sie den Befehl auf dem Cluster aus, der dem Hub-Cluster hinzugefügt werden soll. So wird die Installation der erforderlichen Agents im Cluster initiiert, und nach Abschluss dieses Vorgangs wird das Cluster in der Cluster-Liste mit Status Ready angezeigt.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">Importieren Sie ein vorhandenes Cluster</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">Nachdem Sie mehrere Cluster erstellt und importiert haben, können Sie diese von einer einzigen Konsole aus überwachen und managen.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">Weiter: Funktionen - Application Lifecycle Management.</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">Workload-Migration: Red hat OpenShift mit NetApp</block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">Workflows: Red hat OpenShift Virtualisierung mit NetApp ONTAP</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM-Live-Migration</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">Live Migration ist ein Prozess, bei dem eine VM-Instanz in einem OpenShift-Cluster ohne Ausfallzeit von einem Node zu einem anderen migriert wird. Damit die Live-Migration in einem OpenShift-Cluster funktioniert, müssen VMs mit Shared ReadWriteManche-Zugriffsmodus an PVCs gebunden sein. Astra Trident Back-End ist mit einer SVM auf einem NetApp ONTAP-Cluster konfiguriert, der für das NFS-Protokoll aktiviert ist und Shared ReadWriteViele Zugriffsmöglichkeiten für PVCs unterstützt. Daher können VMs mit PVCs, die über von Trident über NFS-fähige SVM bereitgestellt werden, ohne Ausfallzeiten migriert werden.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM Live Migration-Architektur</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">So erstellen Sie eine VM, die an PVCs mit gemeinsam genutzten ReadWriteViele Zugriffsmöglichkeiten gebunden ist:</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">Navigieren Sie zu Workloads &gt; Virtualisierung &gt; Virtuelle Maschinen, und klicken Sie auf Erstellen &gt; mit Assistenten.</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">Wählen Sie das gewünschte Betriebssystem aus, und klicken Sie auf Weiter. Nehmen wir an, dass auf dem ausgewählten Betriebssystem bereits eine Startquelle konfiguriert war.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">Wählen Sie im Bereich „Prüfen und Erstellen“ das Projekt aus, in dem Sie die VM erstellen möchten, und geben Sie die VM-Details an. Vergewissern Sie sich, dass die Startquelle für den Klon- und Bootvorgang von CD-ROM ausgewählt ist, wobei die entsprechende PVC für das ausgewählte Betriebssystem zugewiesen ist.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">Klicken Sie auf Virtual Machine anpassen und dann auf Storage.</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">Klicken Sie auf die Ellipsen neben der Rootdisk, und stellen Sie sicher, dass die mit Trident bereitgestellte Speicheraglass ausgewählt ist. Erweitern Sie den Eintrag Erweitert, und wählen Sie für den Zugriffsmodus den Eintrag Shared Access (RWX) aus. Klicken Sie dann auf Speichern.</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">Machen Sie den Datenträger RWX zugänglich</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">Klicken Sie auf Überprüfen und bestätigen und dann auf Virtuelle Maschine erstellen.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">Gehen Sie wie folgt vor, um eine VM manuell auf einen anderen Knoten im OpenShift-Cluster zu migrieren.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">Navigieren Sie zu Workloads &gt; Virtualisierung &gt; Virtual Machines.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">Klicken Sie für die zu migrierenden VMs auf die Auslassungspunkte, und klicken Sie dann auf die Virtual Machine migrieren.</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">Klicken Sie auf Migrieren, wenn die Meldung angezeigt wird, um zu bestätigen.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">Eine VM-Instanz in einem OpenShift-Cluster wird automatisch auf einen anderen Node migriert, wenn der ursprüngliche Node in den Wartungsmodus versetzt wird, wenn die „vertreiben“-Strategie auf „LiveMigrate“ gesetzt ist.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">Weiter: Workflows: Klonen von VMs.</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">Validierung</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">Führen Sie die folgenden Schritte aus, um die mandantenfähige Architektur zu validieren, die in den vorherigen Schritten konfiguriert wurde:</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">Validieren des Zugriffs zur Erstellung von VES oder Pods im zugewiesenen Projekt</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">Melden Sie sich als ocp-Project-1-user an, Entwickler in Projekt-1.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">Überprüfen Sie den Zugriff, um ein neues Projekt zu erstellen.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">Erstellen Sie in Projekt-1 ein PVC mit der Speicherklasse, die Projekt-1 zugewiesen ist.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">Überprüfen Sie das mit der PVC verbundene PV.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">Überprüfen, ob das PV und sein Volume in einer für Projekt-1 auf NetApp ONTAP dedizierten SVM erstellt werden.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">Erstellen Sie im Projekt-1 einen Pod, und mounten Sie den im vorherigen Schritt erstellten PVC.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">Überprüfen Sie, ob der POD läuft und ob er das Volume montiert hat.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">Validieren des Zugriffs zur Erstellung von PVCs oder Pods in einem anderen Projekt oder Verwenden von Ressourcen für ein anderes Projekt</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">Erstellen Sie in Projekt-1 ein PVC mit der Lagerhalle, die Projekt-2 zugewiesen ist.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">PVC in Projekt-2 erstellen.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">Stellen Sie sicher, dass PVCs vorhanden sind<block ref="1ff946dbad16e896f78812f54d491d28" prefix=" " category="inline-code"></block> Und<block ref="146dc2badf14b242d7e386acd7f9b2aa" prefix=" " category="inline-code"></block> Wurden nicht erstellt.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">Erstellen eines Pods in Projekt-2.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">Validieren des Zugriffs zum Anzeigen und Bearbeiten von Projekten, ResourceQuotas und StorageClasses</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">Zugriff prüfen, um neue Projekte zu erstellen.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">Validieren des Zugriffs auf Projekte</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">Überprüfen Sie, ob der Benutzer ResourceQuotas in Projekt-1 anzeigen oder bearbeiten kann.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">Überprüfen Sie, ob der Benutzer Zugriff hat, um die Speicherageklösse anzuzeigen.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">Überprüfen Sie den Zugriff, um die Lagerflächen zu beschreiben.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">Validieren Sie den Zugriff des Benutzers, um die Speicherageclasses zu bearbeiten.</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">Weiter: Skalierung.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Übersicht über VMware vSphere mit Tanzu</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">Mit VMware vSphere mit Tanzu, das auch vSphere Pods genannt wird, können Sie die ESXi Hypervisor-Nodes in Ihrer VMware vSphere Umgebung als „Worker Nodes“ in einer Bare-Metal-Kubernetes-Umgebung verwenden.</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">VMware vSphere mit Kubernetes</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Eine VMware vSphere mit Tanzu Umgebung wird unter Workload Management genau wie ein nativer TKGS-Cluster aktiviert.</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">Ein virtualisiertes Supervisor-Cluster wurde entwickelt, um eine hochverfügbare Kontrollebene für Kubernetes bereitzustellen. Zudem werden für jede Applikation individuelle Namespaces erstellt, um für die Isolierung von Ressourcen für Benutzer zu sorgen.</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Supervisor-Cluster</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Wenn VMware vSphere mit Tanzu aktiviert ist, wird für jeden ESXi-Host die Spherelet-Anwendung installiert und konfiguriert. So kann jeder Node in einer Kubernetes-Implementierung als „Worker“ fungieren und die auf jedem Node implementierten Pods managen.</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">Namespace</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">Derzeit unterstützt VMware vSphere mit Tanzu und vSphere Pods nur den lokalen vSphere CSI-Treiber. Dies erfolgt dadurch, dass Administratoren Storage-Richtlinien im vSphere Client erstellen müssen, die aus Storage-Zielen auswählen, die derzeit als vSphere Datastores verwendet werden können. Diese Richtlinien dienen dazu, persistente Volumes für Container-Applikationen zu erstellen.</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">Der NetApp Astra Trident CSI-Treiber unterstützt derzeit nicht den direkten Anschluss an externe ONTAP und Element Storage Arrays, doch werden diese NetApp Storage-Systeme häufig zur Unterstützung des primären Storage für die vSphere Umgebung eingesetzt. Die erweiterten Datenmanagement- und Storage-Effizienz-Tools von NetApp können auf diese Weise eingesetzt werden.</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">Wenn Sie mehr über VMware vSphere mit Tanzu lesen möchten, lesen Sie bitte die Dokumentation <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">Weiter: Überblick über NetApp Storage-Systeme.</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">Mit dem VMware Tanzu Kubernetes Grid Service (auch bekannt als vSphere mit Tanzu) können Sie Tanzu Kubernetes Cluster nativ in vSphere erstellen und betreiben. Außerdem können Sie kleinere Workloads direkt auf den ESXi Hosts ausführen.</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">Übersicht über den VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">Mit dem VMware Tanzu Kubernetes Grid Service (auch bekannt als vSphere mit Tanzu) können Sie Tanzu Kubernetes Cluster nativ in vSphere erstellen und betreiben. Außerdem können Sie kleinere Workloads direkt auf den ESXi Hosts ausführen. Damit haben Sie die Möglichkeit, vSphere in eine Plattform umzuwandeln, auf der Container-Workloads nativ auf der Hypervisor-Ebene ausgeführt werden können. Tanzu Kubernetes Grid Service implementiert bei Aktivierung ein Supervisor-Cluster auf vSphere, indem es die für die Workloads erforderlichen Cluster implementiert und betreibt. Es ist nativ in vSphere 7 integriert und nutzt viele zuverlässige vSphere Funktionen wie vCenter SSO, Content Library, vSphere Networking, vSphere Storage, vSphere HA und DRS sowie vSphere Sicherheit für eine reibungslosere Kubernetes-Erfahrung.</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">VSphere mit Tanzu bietet eine einzige Plattform für hybride Applikationsumgebungen, in denen Sie Ihre Applikationskomponenten entweder in Containern oder in VMs ausführen können. Dadurch lassen sich Entwickler, DevOps Engineers und vSphere Administratoren besser transparent machen und Vorgänge einfacher durchführen. VMware TKGS wird nur in vSphere 7 Umgebungen unterstützt und ist das einzige Angebot im Tanzu Kubernetes Operations Portfolio, mit dem Sie Pods direkt auf ESXi Hosts ausführen können.</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">VMware Tanzu Kubernetes Service</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Weitere Informationen zum Tanzu Kubernetes Grid Service finden Sie in der Dokumentation <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">Es gibt viele Architekturüberlegungen in Bezug auf Funktionen, Netzwerke usw. Je nach gewählter Architektur unterscheiden sich die Voraussetzungen und der Implementierungsprozess des Tanzu Kubernetes Grid Service. Um den Tanzu Kubernetes Grid Service in Ihrer Umgebung bereitzustellen und zu konfigurieren, folgen Sie dem Leitfaden <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>. Um sich darüber hinaus bei den über TKGS bereitgestellten Tanzu Kubernetes-Cluster-Nodes anzumelden, gehen Sie wie in diesem beschrieben vor<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>.</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp empfiehlt, aus Fehlertoleranz alle Produktionsumgebungen in mehreren Master-Implementierungen zu implementieren und dabei die Konfiguration von Mitarbeiter-Nodes auszuwählen, um die Anforderungen der geplanten Workloads zu erfüllen. Daher würde eine empfohlene VM-Klasse für einen hochintensiven Workload mindestens vier vCPUs und 12 GB RAM haben.</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Wenn Tanzu Kubernetes Cluster in einem Namespace erstellt werden, verwenden Benutzer diese<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> Oder<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> Mit Zugriffsrechten können Pods direkt in jedem Namespace mithilfe des Benutzerkontos erstellt werden. Der Grund dafür ist, dass Benutzer mit dem verwendet werden<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> Oder<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> Berechtigungen werden der Cluster-Administratorrolle zugewiesen. Wenn Sie jedoch Bereitstellungen, Daemon-Sets, Stateful-Sets oder andere in einem Namespace erstellen, müssen Sie den entsprechenden Servicekonten eine Rolle mit den erforderlichen Berechtigungen zuweisen. Dies ist erforderlich, da die Implementierungen oder Daemon Sets Service-Konten für die Implementierung der Pods nutzen.</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">Siehe das folgende Beispiel von ClusterRoleBinding, um allen Servicekonten im Cluster die Cluster-Administratorrolle zuzuweisen:</block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">Übersicht über VMware Tanzu Kubernetes Grid Integrated Edition (TKGI</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">Die VMware Tanzu Kubernetes Grid Integrated (TKGI) Edition, ehemals VMware Enterprise PKS, ist eine eigenständige Container-Orchestrierungsplattform auf der Basis von Kubernetes. Sie bietet Funktionen wie Lifecycle-Management, Cluster-Zustandsüberwachung, erweiterte Netzwerke, eine Container-Registry usw. TKGI stellt und verwaltet Kubernetes-Cluster über die TKGI-Kontrollebene, die aus BOSH und Ops Manager besteht.</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">Die TKGI kann auf On-Premises-Umgebungen mit vSphere oder OpenStack oder in allen wichtigen Public Clouds auf den jeweiligen IaaS-Angeboten installiert und betrieben werden. Darüber hinaus ermöglicht die Integration von TKGI in NSX-T und Harbour breitere Anwendungsfälle für Enterprise-Workloads. Um mehr über TKGI und seine Fähigkeiten zu erfahren, besuchen Sie die Dokumentation <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>.</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGI wird in einer Vielzahl von Konfigurationen auf einer Vielzahl von Plattformen basierend auf verschiedenen Anwendungsfällen und Designs installiert. Folgen Sie dem Leitfaden <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> So installieren und konfigurieren Sie TKGI und seine Voraussetzungen. TKGI verwendet Bosh VMs als Nodes für Tanzu Kubernetes Cluster, auf denen unveränderliche Konfigurations-Images ausgeführt werden, und jegliche manuellen Änderungen an Bosh VMs bleiben nach einem Neustart erhalten.</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">Wichtige Hinweise:</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Trident erfordert einen privilegierten Zugriff auf Container. Während der TKGI-Installation sollten Sie also das Kontrollkästchen privilegierte Container aktivieren im Schritt aktivieren, um Tanzu Kubernetes Cluster Node Plans zu konfigurieren.</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">Privilegierte Behälter in TKGI</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp empfiehlt, alle Produktionsumgebungen in mehreren Master-Implementierungen zu implementieren. Dies empfiehlt die Fehlertoleranz mit einer Auswahl an „Worker-Nodes“-Konfiguration, um die Anforderungen der geplanten Workloads zu erfüllen. Daher würde ein empfohlener TKGI-Clusterplan aus mindestens drei Meistern und drei Arbeitern mit mindestens vier vCPUs und 12 GB RAM für eine hochintensive Arbeitslast bestehen.</block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Damit das Astra Control Center Ihre Workloads managen kann, müssen Sie zuerst Ihre Tanzu Kubernetes-Cluster registrieren.</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">Registrieren Sie Ihre VMware Tanzu Kubernetes Cluster mit dem Astra Control Center</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">Registrieren Sie VMware Tanzu Kubernetes Cluster</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">Der erste Schritt besteht darin, die Tanzu Kubernetes Cluster zum Astra Control Center hinzuzufügen und zu verwalten. Gehen Sie zu Clusters und klicken Sie auf Cluster hinzufügen, laden Sie die kubeconfig-Datei für den Tanzu Kubernetes-Cluster hoch, und klicken Sie auf Storage auswählen.</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">Wenn der Cluster hinzugefügt wird, wechselt er in den Status Erkennung, während das Astra Control Center den Cluster prüft und die erforderlichen Agenten installiert. Der Cluster-Status ändert sich in<block ref="396d45b57c2fbe3318e7b93272a2686b" prefix=" " category="inline-code"></block> Nach der erfolgreichen Registrierung.</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Alle Tanzu Kubernetes Cluster, die von Astra Control Center verwaltet werden sollen, sollten Zugriff auf die Image Registry haben, die für die Installation verwendet wurde, da die auf den verwalteten Clustern installierten Agenten die Bilder aus dieser Registrierung ziehen.</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">Importieren Sie ONTAP-Cluster als Storage-Ressourcen, die vom Astra Control Center als Back-Ends gemanagt werden sollen. Wenn dem Astra Tanzu Kubernetes Cluster hinzugefügt werden und eine Speicheraglass konfiguriert ist, erkennt und inspiziert er den ONTAP Cluster automatisch auf der Lagerscheinwerfer, importiert ihn aber nicht in das zu verwaltende Astra Control Center.</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">Um die ONTAP-Cluster zu importieren, navigieren Sie zu Back Ends, klicken Sie auf das Dropdown-Menü und wählen Sie Verwalten neben dem zu verwaltenden ONTAP-Cluster aus. Geben Sie die ONTAP-Cluster-Anmeldeinformationen ein, klicken Sie auf Informationen überprüfen und klicken Sie dann auf Speicher-Backend importieren.</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">Nach dem Hinzufügen der Back-Ends ändert sich der Status in „verfügbar“. Diese Back-Ends enthalten nun Informationen über die persistenten Volumes im Tanzu Kubernetes Cluster und die entsprechenden Volumes auf dem ONTAP-System.</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Für Backups und Restores in Tanzu Kubernetes Clustern mit Astra Control Center müssen Sie einen Objekt-Storage-Bucket bereitstellen, der das S3-Protokoll unterstützt. Derzeit werden ONTAP S3, StorageGRID, AWS S3 und Microsoft Azure Blob Storage unterstützt. Im Rahmen dieser Installation wird ein AWS S3-Bucket konfiguriert. Wechseln Sie zu Buckets, klicken Sie auf „Bucket hinzufügen“ und wählen Sie „Allgemeines S3“ aus. Geben Sie die Details zum S3-Bucket und die Zugangsdaten ein, um darauf zuzugreifen, klicken Sie auf das Kontrollkästchen „Bucket als Standard-Bucket für die Cloud“ und klicken Sie dann auf „Hinzufügen“.</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">Zur Integration von NetApp ONTAP Storage-Systemen in VMware Tanzu Kubernetes-Cluster für persistente Volumes über iSCSI müssen die Nodes durch Anmeldung bei jedem Knoten vorbereitet und die iSCSI-Dienstprogramme bzw. -Pakete für das Mounten von iSCSI-Volumes konfiguriert werden.</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">Zur Integration von NetApp ONTAP Storage-Systemen in VMware Tanzu Kubernetes Cluster für persistente Volumes über iSCSI müssen die Nodes durch Anmeldung bei jedem Knoten vorbereitet und die iSCSI-Dienstprogramme bzw. -Pakete zum Mounten von iSCSI-Volumes konfiguriert werden. Befolgen Sie dazu das in diesem Verfahren beschriebene Verfahren <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>.</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp empfiehlt dieses Verfahren nicht für NAT'ed Implementierungen von VMware Tanzu Kubernetes Clustern.</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI verwendet Bosh VMs als Nodes für Tanzu Kubernetes Cluster, auf denen unveränderliche Konfigurations-Images ausgeführt werden. Jegliche manuellen Änderungen von iSCSI-Paketen auf Bosh VMs bleiben auch bei einem Neustart erhalten. NetApp empfiehlt daher den Einsatz von NFS Volumes für persistenten Storage für Tanzu Kubernetes Cluster, die von TKGI implementiert und betrieben werden.</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">Nachdem die Clusterknoten für iSCSI-Volumes vorbereitet sind, müssen Sie ein Back-End erstellen, das die Kommunikation mit dem Speichersystem ermöglicht. Wir haben in dieser Lösung ein Basis-Backend konfiguriert, aber wenn Sie nach mehr angepassten Optionen suchen, besuchen Sie die Dokumentation <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>.</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">Erstellen Sie eine SVM in ONTAP</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">Um eine SVM in ONTAP zu erstellen, gehen Sie wie folgt vor:</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">Melden Sie sich beim ONTAP System Manager an, navigieren Sie zu Storage &gt; Storage VMs, und klicken Sie auf Hinzufügen.</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">Geben Sie einen Namen für die SVM ein, aktivieren Sie das iSCSI-Protokoll und geben Sie anschließend Details für die Daten-LIFs ein.</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">ISCSI SVM Daten-LIFs</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">Geben Sie die Details für das SVM-Administratorkonto ein, und klicken Sie dann auf Speichern.</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">ISCSI SVM-Administration</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">Um die Aggregate der SVM zuzuweisen, wechseln Sie zu Storage &gt; Storage VMs. Klicken Sie auf die Ellipsen neben der neu erstellten SVM und klicken Sie dann auf Bearbeiten. Aktivieren Sie das Kontrollkästchen Volume-Erstellung auf bevorzugte lokale Tiers begrenzen und hängen Sie die erforderlichen Aggregate an.</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">SVM-Aggregatzuweisung</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">Back-Ends und StorageClasses erstellen</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">Erstellen Sie für NetApp ONTAP Systeme, die NFS bereitstellen, eine Back-End-Konfigurationsdatei auf dem Jumper Back-End mit BackendName, Management LIF, DatenLIF, svm, Benutzername, Kennwort und weitere Details.</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">Erstellen Sie das Trident-Back-End durch Ausführen des folgenden Befehls.</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">Nachdem Sie ein Backend erstellt haben, müssen Sie zunächst eine Speicherklasse erstellen. Die folgende Beispieldefinition für Speicherklassen zeigt die erforderlichen und grundlegenden Felder an. Der Parameter<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Sollte den Storage-Treiber aus dem neu erstellten Trident-Back-End widerspiegeln. Notieren Sie auch den Wert des Namensfelds, auf den in einem späteren Schritt verwiesen werden muss.</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">Es gibt ein optionales Feld mit dem Namen<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> Das ist in dieser Datei definiert. In iSCSI-Back-Ends kann dieser Wert auf einen bestimmten Linux-Dateisystem-Typ (XFS, ext4 usw.) gesetzt werden oder kann gelöscht werden, damit Tanzu Kubernetes-Cluster entscheiden können, welches Dateisystem verwendet werden soll.</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">Erstellen Sie die Storage-Klasse, indem Sie den Befehl kubectl ausführen.</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">Nach Erstellung der Storage-Klasse müssen Sie dann die erste Forderung für ein persistentes Volume (PVC) erstellen. Eine PVC-Beispieldefinition ist unten angegeben. Stellen Sie sicher, dass die<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> Feld stimmt mit dem Namen der gerade erstellten Speicherklasse überein. Die PVC-Definition kann je nach Bedarf weiter angepasst werden, je nach bereitgestelltem Workload.</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">Erstellen Sie das PVC mit dem Befehl kubectl. Die Erstellung kann je nach Größe des erstellten Sicherungsvolumens einige Zeit in Anspruch nehmen, sodass Sie den Prozess nach Abschluss beobachten können.</block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">Diese Seite enthält Links zu Videos, die einige der in diesem Dokument beschriebenen Funktionen demonstrieren.</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">Videos und Demos: VMware Tanzu mit NetApp</block>
  <block id="811263b3dba6ff02a02f70eb9730ca2e" category="inline-link-macro">Mit Astra Trident können Sie persistenten Storage in VMware Tanzu bereitstellen</block>
  <block id="6aa25c5e03abeab0ced9fac672bb2330" category="list-text"><block ref="6aa25c5e03abeab0ced9fac672bb2330" category="inline-link-macro-rx"></block></block>
  <block id="03a87e35f2de41c34385d72c2c717acf" category="inline-link-macro">Verwenden Sie Astra Control Center zum Klonen von Anwendungen in VMware Tanzu</block>
  <block id="591774815c932f725e0adbded50b634b" category="list-text"><block ref="591774815c932f725e0adbded50b634b" category="inline-link-macro-rx"></block></block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">Weiter: Weitere Informationen: VMware Tanzu mit NetApp.</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="945f7593bacdce2a986b2ea8ab58220b" category="summary">Diese Seite verweist auf eine Videovorführung, die zeigt, wie man Astra Control Center zum Klonen von Anwendungen in VMware Tanzu verwendet.</block>
  <block id="ff56b2be4aa6be0d45adf0bbeb76166d" category="doc">Nutzen Sie Astra Control Center zum Klonen von Applikationen in VMware Tanzu</block>
  <block id="db70f2aaf062f269f45b2fe61ad31160" category="admonition">Diese Demo wurde als Tech Preview mit Version 1.3.1 von TKG und Version 21.12 von Astra Control Center aufgenommen. In der Supportmatrix finden Sie weitere offizielle unterstützte Versionen.</block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">Nachdem Sie Ihre VMware Tanzu Kubernetes Cluster registriert haben, können Sie die Anwendungen ermitteln, die implementiert sind, und sie über das Astra Control Center verwalten.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">Wählen Sie die zu schützenden Applikationen aus</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Nachdem Sie Ihre Tanzu Kubernetes Cluster registriert haben, können Sie die Anwendungen ermitteln, die implementiert sind, und sie über das Astra Control Center verwalten.</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">Management von Applikationen</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Nachdem die Tanzu Kubernetes-Cluster und ONTAP-Back-Ends beim Astra Control Center registriert wurden, beginnt das Kontrollzentrum automatisch die Anwendungen in allen Namespaces zu erkennen, die die mit dem angegebenen ONTAP-Back-End konfigurierte Speicherageclass verwenden.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="image-alt">Astra Control Center-Anwendungen entdeckt</block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">Navigieren Sie zu Apps &gt; entdeckt, und klicken Sie auf das Dropdown-Menü neben der Anwendung, die Sie mit Astra verwalten möchten. Klicken Sie dann auf Verwalten.</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="image-alt">Astra Control Center managt Applikationen</block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">Die Anwendung wechselt in den Status „verfügbar“ und kann im Abschnitt „Apps“ unter der Registerkarte „verwaltet“ angezeigt werden.</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="image-alt">Astra Control Center-Anwendungen verfügbar</block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">Zum nächsten: Ihre Applikationen schützen.</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">Um die Trident Integration mit dem NetApp ONTAP Storage-System über NFS zu aktivieren, müssen Sie ein Backend erstellen, das die Kommunikation zum Storage-System ermöglicht. Wir konfigurieren in dieser Lösung ein Basis-Backend, aber wenn Sie nach mehr angepassten Optionen suchen, besuchen Sie die Dokumentation <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>.</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">Geben Sie einen Namen für die SVM ein, aktivieren Sie das NFS-Protokoll, aktivieren Sie das Kontrollkästchen NFS-Client-Zugriff zulassen und fügen Sie die Subnetze hinzu, die Ihre Worker-Nodes in den Exportrichtlinien-Regeln aktiviert sind, damit die Volumes als PVS in Ihren Workload-Clustern gemountet werden können.</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">SVM-Erstellung mit NFS</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">Wenn Sie NAT'ed-Bereitstellung von Benutzer-Clustern oder Workload-Clustern mit NSX-T verwenden, müssen Sie das Egress-Subnetz (im Fall von TKGS0 oder das schwimmende IP-Subnetz (im Fall von TKGI) zu den Exportrichtlinien hinzufügen.</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">Geben Sie die Details zu Daten-LIFs sowie die Details für das SVM-Administratorkonto an, und klicken Sie dann auf „Speichern“.</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">SVM-Daten-LIFs und SVM-Administration</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">Weisen Sie die Aggregate einer SVM zu. Navigieren Sie zu Storage &gt; Storage VMs, klicken Sie auf die Auslassungspunkte neben der neu erstellten SVM und klicken Sie dann auf Bearbeiten. Aktivieren Sie das Kontrollkästchen Volume-Erstellung auf bevorzugte lokale Tiers begrenzen und hängen Sie die erforderlichen Aggregate an.</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">Bei NAT-gestützten Implementierungen von Benutzer- oder Workload-Clustern, auf denen Trident installiert werden soll, kann die Storage-Mount-Anfrage aufgrund von SNAT von einem nicht standardmäßigen Port stammen. Standardmäßig erlaubt ONTAP nur Volume-Mount-Anfragen, wenn diese vom Root-Port stammen. Melden Sie sich daher bei der ONTAP CLI an und ändern Sie die Einstellung, um Anfragen von nicht standardmäßigen Ports zu mounten.</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">Wenn das Back-End erstellt wird, müssen Sie als nächstes eine Storage-Klasse erstellen. Die folgende Beispieldefinition für Speicherklassen zeigt die erforderlichen und grundlegenden Felder an. Der Parameter<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Sollte den Storage-Treiber aus dem neu erstellten Trident-Back-End widerspiegeln.</block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">Weiter: Videos und Demos: VMware Tanzu mit NetApp.</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">Das NetApp Astra Control Center bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für statusorientierte Kubernetes Workloads in einer On-Premises-Umgebung mit einer zuverlässigen Datensicherungstechnologie von NetApp.</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">Wenn Sie nach einem sofort einsatzbereiten Software-Entwicklungskit für die Interaktion mit Astra Control REST-APIs suchen, stellt NetApp ein Toolkit mit dem Astra Control Python SDK bereit, das Sie herunterladen können <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">Wenn die Programmierung in Ihrer Situation nicht geeignet ist und Sie ein Konfigurationsmanagement-Tool verwenden möchten, können Sie die von NetApp veröffentlichten Ansible-Playbooks klonen und ausführen <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Installationsvoraussetzungen für Astra Control Center</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">Die Installation von Astra Control Center erfordert die folgenden Voraussetzungen:</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">Ein oder mehrere Tanzu Kubernetes Cluster, die entweder von einem Management-Cluster oder TKGS oder TKGI gemanagt werden. TKG Workload Cluster 1.4+ und TKGI User Cluster 1.12.2+ werden unterstützt.</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">Astra Trident muss bereits auf jedem Tanzu Kubernetes Cluster installiert und konfiguriert sein.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">Mindestens ein NetApp ONTAP Storage-System mit ONTAP 9.5 oder höher</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">Eine Best Practice für jede Tanzu Kubernetes-Installation an einem Standort ist es, über eine dedizierte SVM für persistenten Storage zu verfügen. Implementierungen an mehreren Standorten erfordern zusätzliche Storage-Systeme.</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">Ein Trident Storage-Back-End muss für jeden Tanzu Kubernetes-Cluster mit einer SVM konfiguriert werden, die durch einen ONTAP-Cluster gesichert wird.</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">Eine Standard-StorageClass-Konfiguration auf jedem Tanzu Kubernetes Cluster mit Astra Trident als Storage-provisionierung.</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">Für jeden Tanzu Kubernetes Cluster muss auf jedem Tanzu Kubernetes ein Load Balancer installiert und konfiguriert werden, um den Lastausgleich zu ermöglichen und Astra Control Center auszusetzen, wenn Sie ingressType verwenden<block ref="0a3e1793e4eaf6bd67bdf43d1bca1c74" prefix=" " category="inline-code"></block>.</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">Ein Ingress-Controller muss auf jedem Tanzu Kubernetes Cluster installiert und konfiguriert werden, damit Astra Control Center verfügbar ist, wenn Sie ingressType verwenden<block ref="8045a0a6c688b0635e3caccc408a1446" prefix=" " category="inline-code"></block>.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">Eine private Image-Registrierung muss konfiguriert sein, um die NetApp Astra Control Center Images zu hosten.</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">Sie müssen Zugriff auf den Cluster-Administrator auf das Tanzu Kubernetes Cluster haben, in dem Astra Control Center installiert wird.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">Sie müssen Administratorzugriff auf NetApp ONTAP Cluster haben.</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">Eine RHEL- oder Ubuntu Admin-Workstation.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Installieren Sie Astra Control Center</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">Diese Lösung beschreibt ein automatisiertes Verfahren für die Installation von Astra Control Center mithilfe von Ansible Playbooks. Wenn Sie nach einem manuellen Verfahren zur Installation des Astra Control Centers suchen, folgen Sie der detaillierten Installations- und Betriebsanleitung <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Erstellen oder beziehen Sie die kubeconfig-Datei mit Administratorzugriff auf den Benutzer oder den Workload Tanzu Kubernetes Cluster, auf dem Astra Control Center installiert werden soll.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">Schritte Nach Der Installation</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">Die Installation kann einige Minuten dauern. Überprüfen Sie, ob alle Pods und Services im enthalten sind<block ref="cde5355ebfdfe468e0d3516b20d95313" prefix=" " category="inline-code"></block> Der Namespace ist betriebsbereit.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">Prüfen Sie die<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> Protokolle, um sicherzustellen, dass die Installation abgeschlossen ist.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">Die folgende Meldung zeigt die erfolgreiche Installation des Astra Control Centers an.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Der Benutzername für die Anmeldung beim Astra Control Center ist die E-Mail-Adresse des Administrators in der CRD-Datei und das Passwort ist eine Zeichenfolge<block ref="4e68cdd4eb0ff1a79e44dac42b52abd8" prefix=" " category="inline-code"></block> An die Astra Control Center UUID angehängt. Führen Sie den folgenden Befehl aus:</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">In diesem Beispiel lautet das Passwort<block ref="bf7a8daff076079f839129b59f2bb759" prefix=" " category="inline-code"></block>.</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">Holen Sie die Lastausgleichs-IP für den Trafik-Dienst ab, wenn der Typ AccTraefik ist.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Fügen Sie einen Eintrag im DNS-Server hinzu, der auf den in der Astra Control Center CRD-Datei angegebenen FQDN verweist<block ref="23edb0469b69e61c98ac7a9e1dca82e8" prefix=" " category="inline-code"></block> Des Schleppdienstes.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">DNS-Eintrag für ACC GUI hinzufügen</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Melden Sie sich bei der Astra Control Center-GUI an, indem Sie den FQDN durchsuchen.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra Control Center-Anmeldung</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">Wenn Sie sich zum ersten Mal über die in CRD angegebene Admin-E-Mail-Adresse bei der Benutzeroberfläche des Astra Control Center anmelden, müssen Sie das Passwort ändern.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra Control Center obligatorische Kennwortänderung</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Wenn Sie dem Astra Control Center einen Benutzer hinzufügen möchten, navigieren Sie zu Konto &gt; Benutzer, klicken Sie auf Hinzufügen, geben Sie die Details des Benutzers ein und klicken Sie auf Hinzufügen.</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center erstellt Benutzer</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Center erfordert eine Lizenz für alle Funktionen. Um eine Lizenz hinzuzufügen, navigieren Sie zu Konto &gt; Lizenz, klicken Sie auf Lizenz hinzufügen und laden Sie die Lizenzdatei hoch.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center Lizenz hinzufügen</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">Bei Problemen mit der Installation oder Konfiguration von NetApp Astra Control Center steht die Wissensdatenbank mit bekannten Problemen zur Verfügung<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>.</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">Als Nächstes: Registrieren Sie Ihre Tanzu Kubernetes Cluster.</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">Erstellen Sie einen Anwendungs-Snapshot</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">Ein Snapshot einer Applikation erstellt eine ONTAP Snapshot Kopie und eine Kopie der Applikationsmetadaten, mit denen Sie die Applikation auf Basis dieser Snapshot Kopie einem bestimmten Zeitpunkt wiederherstellen oder klonen können.</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">Erstellen eines Applikations-Backups</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">Um eine Anwendung wiederherzustellen, navigieren Sie zur Registerkarte Apps &gt; Managed und klicken Sie auf die betreffende Anwendung. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf Wiederherstellen.</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">Geben Sie die Details zum neuen Namespace ein, wählen Sie den Cluster aus, in dem Sie ihn klonen möchten, und legen Sie fest, ob er aus einem vorhandenen Snapshot, aus einem Backup oder aus dem aktuellen Status der Applikation geklont werden soll. Klicken Sie auf Weiter, und klicken Sie dann im Prüfungsfenster auf Klonen, nachdem Sie die Details geprüft haben.</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">Überblick über die Integration von NetApp Storage</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">Als Nächstes: Übersicht über NetApp Astra Control</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">Übersicht über VMware Tanzu Kubernetes Grid (TKG)</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">Mit VMware Tanzu Kubernetes Grid, das auch als TKG bekannt ist, können Sie Tanzu Kubernetes-Cluster in Hybrid-Cloud- oder Public-Cloud-Umgebungen implementieren. TKG wird als Management-Cluster installiert – ein Kubernetes Cluster selbst, der die Tanzu Kubernetes-Cluster implementiert und betreibt. Tanzu Kubernetes-Cluster sind der Workload, auf dem der tatsächliche Workload bereitgestellt wird.</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid baut auf einigen der vielversprechenden Upstream-Community-Projekte auf und liefert eine Kubernetes-Plattform, die von VMware entwickelt, vermarktet und unterstützt wird. Neben der Kubernetes-Distribution bietet Tanzu Kubernetes Grid zusätzliche Add-ons, die für produktionswichtige Services wie Registry, Lastausgleich, Authentifizierung usw. entscheidend sind. VMware TKG mit Management-Cluster ist in vSphere 6.7 Umgebungen weit verbreitet. Obwohl dies unterstützt wird, ist dies für vSphere 7 Umgebungen keine empfohlene Implementierung, da TKGS native Integrationsfunktionen für vSphere 7 bietet.</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">VMware Tanzu Kubernetes Grid mit Management-Cluster</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Weitere Informationen zu Tanzu Kubernetes Grid finden Sie in der Dokumentation <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>.</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">Je nachdem, ob Tanzu Kubernetes Grid vor Ort im vSphere Cluster oder in Cloud-Umgebungen installiert wird, bereiten Sie Tanzu Kubernetes Grid anhand des Installationsleitfadens vor und implementieren Sie diese <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>.</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Nachdem Sie das Management-Cluster für Tanzu Kubernetes Grid installiert haben, implementieren Sie die Benutzer-Cluster oder Workload-Cluster nach Bedarf anhand der Dokumentation <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>. Für das Management-Cluster für VMware TKG muss ein SSH-Schlüssel zur Installation und zum Betrieb von Tanzu Kubernetes-Clustern zur Verfügung gestellt werden. Dieser Schlüssel kann zur Anmeldung bei den Cluster-Nodes mithilfe von verwendet werden<block ref="5ef871b8f1f696f9bb22de1dff45a81c" prefix=" " category="inline-code"></block> Benutzer:</block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich VMware Tanzu.</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Astra Trident – Überblick</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Trident-Operator mit Helm implementieren</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">Fügen Sie das NetApp Astra Trident Helm Repository hinzu.</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Aktualisieren der Helm-Repositorys</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Erstellen Sie für die Installation von Trident einen neuen Namespace.</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">Erstellen Sie ein Geheimnis mit den DockerHub-Anmeldeinformationen, um die Astra Trident-Bilder herunterzuladen.</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">Für Benutzer- oder Workload-Cluster, die von TKGS (vSphere mit Tanzu) oder TKG mit Management-Cluster-Implementierungen verwaltet werden, gehen Sie zur Installation von Astra Trident wie folgt vor:</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">Stellen Sie sicher, dass der angemeldete Benutzer über die Berechtigungen zum Erstellen von Dienstkonten im Dreizack-Namespace verfügt und dass die Dienstkonten im Dreizack-Namespace über die Berechtigung zum Erstellen von Pods verfügen.</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">Führen Sie den folgenden Helm-Befehl aus, um den Trident Operator im erstellten Namespace zu installieren.</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">Führen Sie für einen Benutzer oder Workload-Cluster, der von TKGI-Implementierungen gemanagt wird, den folgenden Helm-Befehl aus, um den Trident Operator in dem erstellten Namespace zu installieren.</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Überprüfen Sie, ob die Trident Pods betriebsbereit sind.</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Nach Abschluss der Installation des Astra Trident Operator müssen Sie das Backend für die spezifische NetApp Storage-Plattform konfigurieren, die Sie verwenden. Folgen Sie den Links unten, um mit der Einrichtung und Konfiguration von Astra Trident fortzufahren.</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="40ef898131b1ea0532620ff9cb12840c" category="summary">Diese Seite enthält einen Link zu einer Videodemonstration über den Einsatz von Astra Trident zur Bereitstellung von persistentem Storage in VMware Tanzu.</block>
  <block id="e0d2648924bbf778345db6153fddf464" category="doc">Mit Astra Trident können Sie persistenten Storage in VMware Tanzu bereitstellen</block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzu ist ein Produktportfolio mit dem Unternehmen ihre Applikationen und ihre Infrastruktur modernisieren können. Der volle Funktionsumfang von VMware Tanzu vereint die Entwicklungs- und IT-Teams auf einer einzigen Plattform und ermöglicht so eine konsistente Modernisierung sowohl in ihren Applikationen als auch in ihrer Infrastruktur in On-Premises- und Hybrid-Cloud-Umgebungen, um kontinuierlich bessere Software für die Produktion bereitzustellen.</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">VMware Tanzu im Überblick</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">VMware Tanzu Portfolio</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Weitere Informationen zu den verschiedenen Angeboten und deren Fähigkeiten im Tanzu Portfolio finden Sie in der Dokumentation <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">In Bezug auf den Katalog Kubernetes Operations von Tanzu verfügt VMware über eine Vielzahl von Implementierungen für Tanzu Kubernetes Grid, die den Lebenszyklus von Tanzu Kubernetes Clustern auf verschiedenen Plattformen bereitstellen und verwalten. Ein Tanzu Kubernetes Cluster ist eine vollständige Kubernetes-Distribution, die von VMware entwickelt und unterstützt wird.</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp hat die Implementierung und Interoperabilität folgender Produkte aus dem VMware Tanzu Portfolio in seinen Labs getestet und validiert:</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="inline-link-macro">VMware Tanzu Kubernetes Grid (TKG)</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="inline-link-macro">VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated (TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphere mit Tanzu (vSphere Pods)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">Dieses Referenzdokument unterstützt bei der Implementierung verschiedene Varianten von VMware Tanzu Kubernetes Lösungen. Diese werden entweder als Tanzu Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) oder Tanzu Kubernetes Grid Integrated (TKGI) in verschiedenen Datacenter-Umgebungen eingesetzt, wie von NetApp validiert.</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166: VMware Tanzu mit NetApp</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">Dieses Referenzdokument unterstützt bei der Implementierung verschiedene Varianten von VMware Tanzu Kubernetes Lösungen. Diese werden entweder als Tanzu Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) oder Tanzu Kubernetes Grid Integrated (TKGI) in verschiedenen Datacenter-Umgebungen eingesetzt, wie von NetApp validiert. Sie beschreibt auch die Storage-Integration mit NetApp Storage-Systemen und den Astra Trident Storage-Orchestrator für das Management von persistentem Storage. Astra Control Center unterstützt Sie beim Backup und Klonen der statusorientierten Applikationen mit diesem persistenten Storage. Zu guter Letzt bietet das Dokument Video-Demos der Integration und Validierungen der Lösung.</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">Die Lösung VMware Tanzu mit NetApp wurde so konzipiert, dass sie Kunden in folgenden Anwendungsfällen einen hervorragenden Mehrwert bietet:</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">VMware Tanzu Kubernetes Grid-Angebote, die auf VMware vSphere implementiert und in NetApp Storage-Systeme integriert sind, lassen sich einfach implementieren und managen.</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">Die kombinierte Leistung von Enterprise-Containern und virtualisierten Workloads mit VMware Tanzu Kubernetes Grid-Angeboten.</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">Konfiguration und Anwendungsfälle in der Praxis, in denen die Funktionen von VMware Tanzu in Kombination mit NetApp Storage und der NetApp Astra Produktsuite hervorgehoben werden.</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">Applikationskonsistente Sicherung bzw. Migration von Container-Workloads, die auf VMware Tanzu Kubernetes Grid Clustern implementiert werden, deren Daten sich mit Astra Control Center auf NetApp Storage-Systemen befinden.</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">Implementierung in einem Hybrid-Cloud-Modell mit Containern, die sowohl in On-Premises-Datacentern als auch in der Cloud ausgeführt werden</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">VMware Tanzu mit NetApp erkennt diese Herausforderungen und präsentiert eine Lösung, die Kunden bei der Implementierung von VMware Tanzu Kubernetes-Angeboten in der gewünschten Hybrid-Cloud-Umgebung unterstützt.</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">Die VMware Tanzu mit NetApp Lösung besteht aus den folgenden Hauptkomponenten:</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">VMware Tanzu Kubernetes-Plattformen</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzu kommt in verschiedenen Ausführungen, die das Solutions Engineering Team von NetApp in unseren Labs validiert hat. Jede Tanzu Version lässt sich erfolgreich in das NetApp Storage-Portfolio integrieren und jede kann dabei helfen, bestimmte Infrastrukturanforderungen zu erfüllen. Die folgenden Punkte beschreiben die in diesem Dokument beschriebenen Funktionen und Angebote der einzelnen Tanzu-Versionen.</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">*VMware Tanzu Kubernetes Grid (TKG)*</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">In einer VMware vSphere Umgebung implementierte Standard-vorgelagerte Kubernetes-Umgebung.</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">Früher bekannt als Essential PKS (aus Heptio-Akquisition, Februar 2019).</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG wird mit einer separaten Management-Cluster-Instanz zur Unterstützung von vSphere 6.7U3 bereitgestellt.</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">TKG-Implementierungen können in der Cloud sowie mit AWS oder Azure implementiert werden.</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">Ermöglicht die Verwendung von Windows- oder Linux-Worker-Nodes (Ubuntu/Photon).</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">Für die Kontrollebene können NSX-T, HA Proxy, AVI-Networking oder Load Balancer eingesetzt werden.</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG unterstützt die MetalLB für die Anwendungs-/Datenebene.</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">Zudem können vSphere CSI ebenso wie CSI von Drittanbietern wie NetApp Astra Trident genutzt werden.</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">*VMware Tanzu Kubernetes Grid Service (TKGS)*</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGS wurde mit Supervisor-Cluster und Workload-Clustern nur auf vSphere 7.0U1 eingesetzt.</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS unterstützt MetalLB für Applikations-/Datenebene.</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">Bietet Unterstützung für vSphere Pods mit Tanzu und ermöglicht so die direkte Ausführung von Pods auf aktivierten ESXi Hosts in der Umgebung.</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">*VMware Tanzu Kubernetes Grid Integrated (TKGI)*</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">Früher unter dem Namen Enterprise PKS (aus der Heptio-Übernahme, Februar 2019) bekannt.</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">NSX-T, HA Proxy oder AVI können verwendet werden. Sie können auch einen eigenen Load Balancer bereitstellen.</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">Unterstützung ab vSphere 6.7U3 sowie AWS, Azure und GCP.</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">Einrichtung über Assistenten zur Vereinfachung der Implementierung</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">Führt Tanzu in kontrollierten, unveränderlichen VMs aus, die von BOSH gemanagt werden.</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">Kann vSphere CSI ebenso wie CSI von Drittanbietern wie NetApp Astra Trident verwenden (es gelten einige Bedingungen).</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*VSphere mit Tanzu (vSphere Pods)*</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">Die nativen vSphere Pods werden in einer Thin, Photon-basierten Ebene mit vorgeschriebener virtueller Hardware ausgeführt und stellen so eine vollständige Isolierung bereit.</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">Erfordert NSX-T, aber dies ermöglicht zusätzliche Unterstützung von Funktionen wie eine Harbour Image Registry.</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">Bereitstellung und Management in vSphere 7.0U1 Weiterführende Verwendung eines virtuellen Supervisor-Clusters wie TKGS. Führt Pods direkt auf ESXi Nodes aus.</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">Vollständig integriert, für höchste Transparenz und Kontrolle durch vSphere Administration.</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">Isolierte, CRX-basierte Pods für höchste Sicherheit.</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">Unterstützt nur vSphere CSI für persistenten Storage. Es werden keine Storage-Orchestrierungslösungen von Drittanbietern unterstützt.</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">Das NetApp Astra Control Center bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für statusorientierte Kubernetes Workloads, in einer lokalen Umgebung implementiert und mit der bewährten NetApp Datensicherungstechnologie unterstützt.</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident ist ein vollständig unterstützter Open-Source-Orchestrator für Container und Kubernetes-Distributionen, einschließlich VMware Tanzu.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">Aktuelle Support-Matrix für validierte Versionen</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">Applikationsspezifisches Datenmanagement</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">Storage-Orchestrierung</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4 und höher</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">VMware Tanzu Kubernetes Grid Service</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [vSphere Namespaces]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [Supervisor Cluster Kubernetes]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid integriert</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">Datacenter-Virtualisierung</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">VMware NSX-T Datacenter</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">Networking und Sicherheit</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">VMware NSX Advanced Load Balancer</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">Lastausgleich</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">Weiter: Überblick über VMware Tanzu.</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">Weitere Informationen: VMware Tanzu mit NetApp</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">VMware Tanzu Dokumentation</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">VMware Tanzu Kubernetes Grid Dokumentation</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">Dokumentation des VMware Tanzu Kubernetes Grid Service</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">Dokumentation der VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">Auf dieser Seite werden die Installations- und Konfigurationsanweisungen für den MetalLB Load Balancer beschrieben.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">Installation von MetalLB Load Balancer: Red hat OpenShift mit NetApp</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">Auf dieser Seite werden die Installations- und Konfigurationsanweisungen für den MetalLB Load Balancer aufgeführt.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB ist ein selbst gehosteter Network Load Balancer, der auf Ihrem OpenShift-Cluster installiert ist und das die Erstellung von OpenShift-Diensten vom Typ Load Balancer in Clustern ermöglicht, die nicht auf einem Cloud-Provider ausgeführt werden. Die zwei Hauptmerkmale der MetalLB, die zur Unterstützung der Load Balancer-Dienste zusammenarbeiten, sind Adresszuweisung und externe Ankündigung.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB-Konfigurationsoptionen</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">Basierend darauf, wie MetalLB die IP-Adresse ankündigt, die den Load Balancer-Diensten außerhalb des OpenShift-Clusters zugewiesen ist, arbeitet es in zwei Modi:</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">*Layer 2-Modus.* in diesem Modus übernimmt ein Knoten im OpenShift-Cluster die Verantwortung für den Service und antwortet auf ARP-Anfragen, damit er außerhalb des OpenShift-Clusters erreichbar ist. Da nur der Node die IP bereitstellt, kommt es zu einem Bandbreitenengpass und zu langsamen Failover-Einschränkungen. Weitere Informationen finden Sie in der Dokumentation <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">*BGP-Modus.* in diesem Modus etablieren alle Knoten im OpenShift-Cluster BGP-Peering-Sitzungen mit einem Router und werben die Routen an die Service-IPs weiter. Voraussetzung dafür ist die Integration von MetalLB in einen Router in dieses Netzwerk. Aufgrund des Hashing-Mechanismus in BGP hat es bestimmte Einschränkungen, wenn IP-zu-Node-Zuordnung für einen Service geändert wird. Weitere Informationen finden Sie in der Dokumentation <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">Im Rahmen dieses Dokuments konfigurieren wir MetalLB im Layer-2-Modus.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">Installieren des MetalLB Load Balancer</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">Laden Sie die MetalLB-Ressourcen herunter.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">Datei bearbeiten<block ref="130d214581bb0aa3e8759729c9fbc133" prefix=" " category="inline-code"></block> Und entfernen<block ref="635a57f17cd40dc65b36973c9e14f9d1" prefix=" " category="inline-code"></block> Von der Controller-Bereitstellung und dem Lautsprecher DemonSet.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">*Zu löschende Zeilen:*</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">Erstellen Sie die<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> Namespace.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">Erstellen Sie den MetalLB CR.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">Bevor Sie den MetalLB-Lautsprecher konfigurieren, gewähren Sie dem Lautsprecher DemonSet erhöhte Berechtigungen, damit er die für den Lastausgleich erforderliche Netzwerkkonfiguration ausführen kann.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">Konfigurieren Sie MetalLB, indem Sie eine erstellen<block ref="a941f8adb5ae079ebc739cb59407fd30" prefix=" " category="inline-code"></block> Im<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> Namespace.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">Wenn nun Load Balancer Dienste erstellt werden, weist MetalLB den Diensten eine externe IP zu und gibt die IP-Adresse durch Antwort auf ARP-Anfragen an.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">Wenn Sie MetalLB im BGP-Modus konfigurieren möchten, überspringen Sie Schritt 6 oben und befolgen Sie das Verfahren in der MetalLB-Dokumentation <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">Auch wenn die von NetApp ONTAP unterstützten Red hat OpenShift und Astra Trident standardmäßig keine Isolierung zwischen Workloads bieten, bieten sie zahlreiche Funktionen für die Konfiguration der Mandantenfähigkeit. Wenn wir uns ein besseres Bild davon machen möchten, wie eine mandantenfähige Lösung auf einem Red hat OpenShift-Cluster mit Astra Trident von NetApp ONTAP entworfen wird, können wir uns ein Beispiel mit einer Reihe von Anforderungen nehmen und die damit zu berücksichtigende Konfiguration beschreiben.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">Nehmen wir einmal an, dass ein Unternehmen zwei seiner Workloads auf einem Red hat OpenShift-Cluster ausführt. Dies ist Teil von zwei Projekten, an denen zwei verschiedene Teams arbeiten. Die Daten für diese Workloads liegen auf PVCs, die durch Astra Trident dynamisch auf einem NetApp ONTAP NAS-Back-End bereitgestellt werden. Das Unternehmen muss für diese beiden Workloads eine mandantenfähige Lösung entwerfen und die Ressourcen für diese Projekte isolieren, um sicherzustellen, dass Sicherheit und Performance erhalten bleiben. Dabei geht es vor allem um die Daten, die die Applikationen unterstützen.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">Die folgende Abbildung zeigt die mandantenfähige Lösung auf einem Red hat OpenShift-Cluster mit Astra Trident, der durch NetApp ONTAP unterstützt wird.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">Mandantenfähigkeit auf Red hat OpenShift-Cluster mit Astra Trident durch NetApp ONTAP unterstützt</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Technologieanforderungen erfüllt</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP Storage-Cluster</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red hat OpenShift-Cluster</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red hat OpenShift – Clusterressourcen</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Aus der Clusteransicht des Red hat OpenShift ist das Projekt die Ressource auf oberster Ebene. Ein OpenShift-Projekt kann als Clusterressource betrachtet werden, die das gesamte OpenShift-Cluster in mehrere virtuelle Cluster unterteilt. Daher bildet die Isolierung auf Projektebene eine Grundlage für die Konfiguration der Mandantenfähigkeit.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">Anschließend können Sie die RBAC im Cluster konfigurieren. Es empfiehlt sich, dass alle Entwickler an einem einzelnen Projekt oder Workload in einer einzelnen Benutzergruppe im Identitätsanbieter (IdP) konfiguriert werden. Red hat OpenShift ermöglicht die IdP-Integration und die Synchronisierung von Benutzergruppen. So können Benutzer und Gruppen aus dem IdP in das Cluster importiert werden. So können Cluster-Administratoren den Zugriff auf die für ein Projekt dedizierten Cluster-Ressourcen für eine Benutzergruppe oder -Gruppe, die an diesem Projekt arbeitet, trennen und dadurch unberechtigten Zugriff auf Cluster-Ressourcen einschränken. Weitere Informationen zur IdP-Integration mit Red hat OpenShift finden Sie in der Dokumentation<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">Es ist wichtig, den gemeinsam genutzten Speicher zu isolieren, der als persistenter Speicheranbieter für einen Red hat OpenShift-Cluster dient. Dadurch muss sichergestellt werden, dass die auf dem Speicher für jedes Projekt erstellten Volumes den Hosts so angezeigt werden, als ob sie in einem separaten Speicher erstellt werden. Erstellen Sie dazu auf NetApp ONTAP so viele SVMs (Storage Virtual Machines), wie es Projekte oder Workloads gibt, und weisen Sie jede SVM einem Workload zu.</block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">Nachdem Sie für verschiedene Projekte, die auf NetApp ONTAP erstellt wurden, unterschiedliche SVMs vorhanden sind, müssen Sie jede SVM einem anderen Trident-Back-End zuordnen. Die Back-End-Konfiguration auf Trident treibt die Zuweisung von persistentem Storage zu OpenShift-Cluster-Ressourcen an. Außerdem sind Details der SVM zu zugeordnet. Dies sollte mindestens der Protokolltreiber für das Backend sein. Optional können Sie damit definieren, wie die Volumes im Storage bereitgestellt werden, und Grenzen für die Größe von Volumes oder die Nutzung von Aggregaten festlegen. Details zur Definition der Trident Back-Ends finden sich<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red hat OpenShift – Speicherressourcen</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Nach der Konfiguration der Trident Back-Ends wird als nächster Schritt die Konfiguration von StorageClasses durchgeführt. Konfigurieren Sie so viele Storage-Klassen wie Back-Ends, wobei jede Storage-Klasse Zugriff erlaubt, Volumes nur an einem Back-End zu erweitern. Wir können die StorageClass einem bestimmten Trident Back-End zuordnen, indem wir während der Definition der Storage-Klasse den StoragePools Parameter verwenden. Die Details zur Definition einer Storage-Klasse sind verfügbar<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. Somit gibt es eine 1:1-Zuordnung von StorageClass zu Trident Back-End, die auf eine SVM verweist. So wird sichergestellt, dass alle Storage-Anforderungen über die StorageClass, die diesem Projekt zugewiesen ist, von der für dieses Projekt dedizierten SVM bedient werden.</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">Da Storage-Klassen keine Ressourcen mit Namespaces sind, wie stellen wir sicher, dass Storage-Forderungen für eine Storage-Klasse eines Projekts durch Pods in einem anderen Namespace oder Projekt abgelehnt werden? Die Antwort ist die Verwendung von ResourceQuotas. ResourceQuotas sind Objekte, die die Gesamtauslastung von Ressourcen pro Projekt steuern. Sie kann die Anzahl und die Gesamtanzahl der Ressourcen begrenzen, die von Objekten im Projekt verbraucht werden können. Mithilfe von ResourceQuotas lassen sich nahezu alle Ressourcen eines Projekts beschränken. Mit dieser effizienten Nutzung können Unternehmen Kosten und Ausfälle aufgrund von überdimensionierten Ressourcen oder überhöhten Ressourcen senken. Siehe Dokumentation<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">Bei diesem Anwendungsfall müssen wir die Pods in einem bestimmten Projekt beschränken, wenn wir Storage aus Storage-Klassen beanspruchen, die nicht für ihr Projekt reserviert sind. Um dies zu erreichen, müssen wir die Anforderungen für persistente Volumes für andere Speicherklassen durch Festlegung begrenzen<block ref="a21be23447e555ea751318f1aded4a38" prefix=" " category="inline-code"></block> Bis 0. Darüber hinaus muss ein Clusteradministrator sicherstellen, dass die Entwickler in einem Projekt keinen Zugriff haben, um die ResourceQuotas zu ändern.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">Als Nächstes: Konfiguration.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">Implementieren Sie eine Virtualisierung mit Red hat OpenShift mit NetApp ONTAP</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Ein Red hat OpenShift-Cluster (ab Version 4.6) wird auf Bare-Metal-Infrastrukturen mit RHCOS-Worker-Nodes installiert</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">Der OpenShift-Cluster muss über eine vom Installer bereitgestellte Infrastruktur (IPI) installiert werden</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">Implementieren Sie Machine Health Checks, um die HA für VMs aufrechtzuerhalten</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">Ein NetApp ONTAP Cluster</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">Astra Trident ist auf dem OpenShift-Cluster installiert</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">Ein Trident Back-End, das mit einer SVM auf ONTAP Cluster konfiguriert ist</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">StorageClass: Ist auf dem OpenShift-Cluster mit Astra Trident als bereitstellungsunternehmen konfiguriert</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Cluster-Admin-Zugriff auf Red hat OpenShift-Cluster</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">Administratorzugriff auf das NetApp ONTAP-Cluster</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">Eine Admin-Workstation mit den Tools tridentctl und oc installiert und zur €Pfad hinzugefügt</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">Da die OpenShift-Virtualisierung von einem auf dem OpenShift-Cluster installierten Operator gemanagt wird, entsteht zusätzlicher Overhead für Speicher, CPU und Speicher, der bei der Planung der Hardwareanforderungen für den Cluster berücksichtigt werden muss. Siehe Dokumentation<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> Entnehmen.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">Optional können Sie auch einen Teilbereich der OpenShift-Cluster-Nodes angeben, um die OpenShift-Virtualisierungsbetreiber, -Controller und -VMs zu hosten, indem Sie die Regeln für die Knotenplatzierung konfigurieren. Befolgen Sie die Dokumentation, um die Regeln für die Knotenplatzierung für OpenShift Virtualization zu konfigurieren<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">Für den von OpenShift Virtualization unterstützten Storage empfiehlt NetApp die Verwendung einer dedizierten StorageClass, die Storage von einem bestimmten Trident-Back-End anfordert. Diese wiederum wird durch eine dedizierte SVM unterstützt. Dies sorgt für eine weiterhin hohe Mandantenfähigkeit im Hinblick auf die Daten, die für VM-basierte Workloads im Cluster OpenShift zur Verfügung gestellt werden.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">Weiter: Über Operator bereitstellen.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">Um die OpenShift Virtualization zu installieren, gehen Sie wie folgt vor:</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">Melden Sie sich beim Bare-Metal-Cluster Red hat OpenShift mit Zugriff auf den Cluster-Administrator an.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Navigieren Sie zu Operators &gt; OperatorHub, und suchen Sie nach OpenShift Virtualization.</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">Wählen Sie die Kachel OpenShift Virtualization aus, und klicken Sie auf Installieren.</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift Virtualization Operator Kachel</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Lassen Sie auf dem Bildschirm Install Operator alle Standardparameter stehen, und klicken Sie auf Install.</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift Virtualization Operator Details</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift Virtualization Operator Installation</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">Klicken Sie nach der Installation des Operators auf Hyperconverged erstellen.</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - Hyperconverged erstellen</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">Klicken Sie im Bildschirm Hyperconverged erstellen auf Erstellen, um alle Standardparameter zu akzeptieren. In diesem Schritt wird die Installation von OpenShift Virtualization gestartet.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - Hyperconverged Details</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">Nachdem alle Pods in den Betriebszustand im Namespace openshift-cnv verschoben wurden und sich der OpenShift Virtualization Operator im Status erfolgreich befindet, ist der Operator betriebsbereit. VMs können jetzt im OpenShift-Cluster erstellt werden.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift Virtualization Operator Installation abgeschlossen</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">Als Nächstes: Workflows zur Erstellung von VMs</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">Konfiguration: Storage-Admin-Aufgaben</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">Die folgenden Ressourcen müssen von einem Storage-Administrator konfiguriert werden:</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">Melden Sie sich als Administrator bei dem NetApp ONTAP Cluster an.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Navigieren Sie zu Storage &gt; Storage VMs, und klicken Sie auf Hinzufügen. Erstellen Sie zwei SVMs, eine für Projekt-1 und die andere für Projekt-2, indem Sie die erforderlichen Details angeben. Erstellen Sie außerdem ein vsadmin-Konto, um die SVM und ihre Ressourcen zu managen.</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">SVM-Erstellung auf ONTAP</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">Melden Sie sich als Storage-Administrator beim Red hat OpenShift-Cluster an.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">Erstellen Sie das Back-End für Projekt-1, und ordnen Sie es der dem Projekt zugewiesenen SVM zu. NetApp empfiehlt, das vsadmin Konto des SVM zu verwenden, um das Back-End mit SVM zu verbinden, anstatt den ONTAP-Cluster-Administrator zu verwenden.</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">In diesem Beispiel verwenden wir den ontap-nas-Treiber. Verwenden Sie den entsprechenden Treiber, wenn Sie das Backend basierend auf dem Anwendungsfall erstellen.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">Ähnliches Erstellen des Trident-Back-End für Projekt-2 und Zuordnen dieses zu Projekt-2 zu der SVM.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">Erstellen Sie dann die Speicherklassen. Erstellen Sie die Storage-Klasse für Projekt-1, und konfigurieren Sie sie so, dass die Speicherpools vom Backend für Projekt-1 verwendet werden, indem Sie den StoragePools-Parameter einstellen.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">Erstellen Sie ebenso eine Storage-Klasse für Projekt-2, und konfigurieren Sie sie so, dass die Speicherpools vom Backend für Projekt-2 verwendet werden.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">Erstellen Sie ein ResourceQuota zur Einschränkung von Ressourcen im Projekt-1, in dem Storage aus Storage-Storage für andere Projekte angefordert wird.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">Erstellen Sie auch ein ResourceQuota zur Einschränkung von Ressourcen in Projekt-2, bei dem Storage aus Storage-Storage für andere Projekte angefordert wird.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">Weiter: Validierung.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">Ein Red hat OpenShift-Cluster (größer als Version 4.5) für den Hub-Cluster</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">Red hat OpenShift-Cluster (mehr als Version 4.4.3) für verwaltete Cluster</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Cluster-Admin-Zugriff auf den Red hat OpenShift-Cluster</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Eine Red hat Subskription für Advanced Cluster Management für Kubernetes</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management ist ein Add-On für den OpenShift-Cluster. Es gibt daher bestimmte Anforderungen und Einschränkungen für die Hardwareressourcen, die auf den Funktionen basieren, die auf dem Hub und den verwalteten Clustern verwendet werden. Sie müssen diese Probleme bei der Dimensionierung der Cluster berücksichtigen. Siehe Dokumentation<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> Entnehmen.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">Wenn optional der Hub-Cluster dedizierte Nodes für das Hosting von Infrastrukturkomponenten hat und erweiterte Cluster-Management-Ressourcen nur auf diesen Nodes installiert werden sollen, müssen diesen Nodes entsprechend Tolerationen und Selektoren hinzugefügt werden. Weitere Informationen finden Sie in der Dokumentation<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">Als Nächstes: Installation.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">Beschleunigen Sie die Softwareentwicklung mit Astra Control und NetApp FlexClone Technologie: Red hat OpenShift mit NetApp</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">Die NetApp Element Software bietet eine modulare, skalierbare Performance, bei der jeder Storage-Node garantierte Kapazität und Durchsatz für die Umgebung bietet. NetApp Element Systeme lassen sich von 4 bis 100 Nodes in einem einzigen Cluster skalieren und bieten zahlreiche erweiterte Storage-Managementfunktionen.</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">Die NetApp Element Software bietet eine modulare, skalierbare Performance, bei der jeder Storage-Node garantierte Kapazität und Durchsatz für die Umgebung bietet. NetApp Element Systeme lassen sich von 4 bis 100 Nodes in einem einzigen Cluster skalieren und bieten zahlreiche erweiterte Storage-Management-Funktionen.</block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">NetApp SolidFire Website</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">Weitere Informationen über NetApp Element Storage-Systeme finden Sie unter<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">ISCSI-Anmeldeumleitung und Funktionen zur Selbstreparatur</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">Die NetApp Element Software nutzt das iSCSI Storage-Protokoll. Hierbei handelt es sich um eine Standardart zur Einkapselung von SCSI-Befehlen in einem herkömmlichen TCP/IP-Netzwerk. Wenn sich die SCSI-Standards ändern oder die Performance von Ethernet-Netzwerken verbessert wird, profitiert das iSCSI-Storage-Protokoll von Vorteilen, ohne dass Änderungen erforderlich sind.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">Obwohl alle Storage-Nodes über eine Management-IP und eine Storage-IP verfügen, stellt die NetApp Element Software eine einzelne Storage-virtuelle IP-Adresse (SVIP-Adresse) für den gesamten Storage-Datenverkehr im Cluster bereit. Im Rahmen des iSCSI-Anmeldeprozesses kann Storage darauf reagieren, dass das Ziel-Volume auf eine andere Adresse verschoben wurde, und kann so den Verhandlungsprozess nicht fortsetzen. Der Host gibt die Anmeldeanforderung dann in einem Prozess, der keine Neukonfiguration auf Host-Seite erfordert, an die neue Adresse erneut aus. Dieser Prozess wird als iSCSI-Anmeldeumleitung bezeichnet.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">Die iSCSI-Login-Umleitung ist ein wichtiger Bestandteil des NetApp Element Software-Clusters. Wenn eine Host-Login-Anfrage eingeht, entscheidet der Node, welches Mitglied des Clusters den Datenverkehr auf Basis der IOPS und der Kapazitätsanforderungen für das Volume verarbeitet. Volumes werden über das NetApp Element Software-Cluster verteilt und neu verteilt, wenn ein einzelner Node zu viel Datenverkehr für seine Volumes verarbeitet oder ein neuer Node hinzugefügt wird. Dem gesamten Array werden mehrere Kopien eines bestimmten Volumes zugewiesen.</block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">Auf diese Weise wird beim Ausfall eines Node nach der Umverteilung des Volumes keine Auswirkung auf die Host-Konnektivität über die Abmeldung hinaus und die Anmeldung mit Umleitung zum neuen Speicherort verursacht. Dank der iSCSI-Anmeldeumleitung ist ein NetApp Element Software-Cluster eine selbstheilende und horizontal skalierbare Architektur, die unterbrechungsfreie Upgrades und den Betrieb ermöglicht.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element Software Cluster-QoS</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">Über ein NetApp Element Software-Cluster kann QoS dynamisch für einzelne Volumes konfiguriert werden. Mithilfe der QoS-Einstellungen pro Volume lässt sich die Storage Performance anhand von in Ihnen definierten SLAs steuern. Die QoS wird durch die folgenden drei konfigurierbaren Parameter definiert:</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">*Minimum IOPS.* die Mindestanzahl kontinuierlicher IOPS, die der NetApp Element Software Cluster einem Volume zur Verfügung stellt. Das für ein Volume konfigurierte Minimum an IOPS ist das garantierte Performance-Level für ein Volume. Die Performance pro Volume fällt nicht unter diese Ebene.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">*Maximale IOPS.* die maximale Anzahl kontinuierlicher IOPS, die der NetApp Element Software Cluster einem bestimmten Volume zur Verfügung stellt.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">*Burst IOPS.* die maximale Anzahl von IOPS in einem kurzen Burst Szenario erlaubt. Die Einstellung für die Burst-Dauer ist konfigurierbar, standardmäßig 1 Minute. Wenn ein Volume unter dem maximalen IOPS-Wert läuft, werden Burst Credits gesammelt. Wenn die Performance sehr hoch ist und viele gesteigert werden, sind auf dem Volume kurze IOPS-Spitzenlasten über die maximalen IOPS hinaus zulässig.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">Mandantenfähigkeit</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">Die sichere Mandantenfähigkeit wird durch folgende Funktionen erreicht:</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">*Sichere Authentifizierung.* das Challenge-Handshake Authentication Protocol (CHAP) wird für den sicheren Volumenzugriff verwendet. Das Lightweight Directory Access Protocol (LDAP) wird für den sicheren Zugriff auf das Cluster für Management und Reporting verwendet.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">*Volume Access Groups (Vags).* optional kann Vags anstelle der Authentifizierung verwendet werden, wobei eine beliebige Anzahl iSCSI Initiator-spezifischer iSCSI-qualifizierter Namen (IQNs) einem oder mehreren Volumes zugeordnet wird. Um auf ein Volume in einem VAG zuzugreifen, muss sich der IQN des Initiators in der Liste erlaubte IQN für die Gruppe von Volumes befinden.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">*Tenant Virtual LANs (VLANs).* auf Netzwerkebene wird die End-to-End-Netzwerksicherheit zwischen iSCSI-Initiatoren und dem NetApp Element-Software-Cluster durch VLANs erleichtert. Für jedes zur Isolierung eines Workloads oder Mandanten erstellte VLAN erstellt die NetApp Element Software eine separate iSCSI-Ziel-SVIP-Adresse, auf die nur über das spezifische VLAN zugegriffen werden kann.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">*VRF-fähige VLANs.* um die Sicherheit und Skalierbarkeit im Rechenzentrum weiter zu unterstützen, ermöglicht Ihnen die NetApp Element-Software, jedes Mandanten-VLAN für VRF-ähnliche Funktionen zu aktivieren. Diese Funktion erweitert die beiden wichtigsten Funktionen:</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">*L3 Routing zu einem Mieter SVIP-Adresse.* mit dieser Funktion können Sie iSCSI-Initiatoren in einem separaten Netzwerk oder VLAN aus dem des NetApp Element Software-Clusters platzieren.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">*Überlappende oder doppelte IP-Subnetze.* mit dieser Funktion können Sie eine Vorlage zu Mandantenumgebungen hinzufügen, sodass jedem jeweiligen Mandanten-VLAN IP-Adressen aus demselben IP-Subnetz zugewiesen werden können. Dies kann für in-Service-Provider-Umgebungen nützlich sein, in denen Skalierbarkeit und Erhaltung von IPspace wichtig sind.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">Enterprise Storage-Effizienzfunktionen</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">Der NetApp Element Software-Cluster steigert die allgemeine Storage-Effizienz und -Performance. Die folgenden Funktionen werden inline ausgeführt, sind immer aktiviert und erfordern keine manuelle Konfiguration durch den Benutzer:</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">*Deduplizierung.* das System speichert nur einzigartige 4K Blöcke. Doppelte 4-KB-Blöcke werden automatisch einer bereits gespeicherten Version der Daten zugeordnet. Die Daten befinden sich auf Blockebene und werden mithilfe der NetApp Element Software Helix Datensicherung gespiegelt. Dieses System reduziert den Kapazitätsverbrauch und die Schreibzugriffe innerhalb des Systems deutlich.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">*Komprimierung.* die Komprimierung wird inline ausgeführt, bevor Daten in den NVRAM geschrieben werden. Daten werden komprimiert, in 4-KB-Blöcken gespeichert und im System weiterhin komprimiert. Diese Komprimierung reduziert den Kapazitätsverbrauch, Schreibvorgänge und den Bandbreitenbedarf im gesamten Cluster deutlich.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">*Thin Provisioning.* Diese Funktion bietet zur richtigen Zeit den richtigen Storage und vermeidet den Kapazitätsverbrauch durch überprovisioniertes Volume oder nicht ausgelastete Volumes.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">*Helix.* die Metadaten für ein einzelnes Volume werden auf einem Metadatenlaufwerk gespeichert und aus Redundanzgründen auf ein sekundäres Metadatenlaufwerk repliziert.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element wurde für die Automatisierung entwickelt. Alle Storage-Funktionen sind über APIs verfügbar. Diese APIs sind die einzige Methode, die die Benutzeroberfläche zur Steuerung des Systems verwendet.</block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">Auf dieser Seite sind die Installations- und Konfigurationsanweisungen für den Seesaw-Load-Balancer aufgeführt.</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">Installieren von Seesaw-Load-Balancer</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">Auf dieser Seite werden die Installations- und Konfigurationsanweisungen für den vom Seesaw verwalteten Load Balancer aufgeführt.</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">Seesaw ist der Standard-verwaltete Netzwerk-Load-Balancer, der in einer Anthos-Cluster-Umgebung von Version 1.6 bis 1.10 installiert ist.</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">Installieren des Load Balancer für die Seifentäfer</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">Der Seesaw Load Balancer ist vollständig mit Anthos Clusters auf VMware integriert und hat eine automatisierte Implementierung als Teil der Admin- und User-Cluster-Setups durchgeführt. Im befinden sich Textblöcke<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> Konfigurationsdateien, die geändert werden müssen, um Informationen zum Load Balancer bereitzustellen. Vor der Cluster-Bereitstellung ist dann ein zusätzlicher Schritt erforderlich, um den Load Balancer mit dem integrierten bereitzustellen<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Werkzeug.</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">Seesaw Load Balancer können im HA- oder Non-HA-Modus eingesetzt werden. Im Rahmen dieser Validierung wurde der Seesaw-Load-Balancer im Non-HA-Modus eingesetzt, der Standardeinstellung. Für die Produktion empfiehlt NetApp die Implementierung von Seesaw in einer HA-Konfiguration, um Fehlertoleranz und Zuverlässigkeit zu gewährleisten.</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Integration in Anthos</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">In jeder Konfigurationsdatei gibt es einen Abschnitt, bzw. für das Admin-Cluster. In jedem Benutzer-Cluster können Sie den Load Balancer so konfigurieren, dass er von Anthos On-Premises gemanagt wird.</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">Der folgende Text ist ein Beispiel aus der Konfiguration der Partition für das GKE-Admin-Cluster. Die Werte, die nicht kommentiert und geändert werden müssen, werden in Fettdruck unten gesetzt:</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">Der Seesaw-Load-Balancer hat ebenfalls eine separate statische<block ref="d218bc0ba36a7fb2d7aea32df7659206" prefix=" " category="inline-code"></block> Datei, die Sie für jede Cluster-Implementierung bereitstellen müssen. Diese Datei muss sich im selben Verzeichnis im Verhältnis zum befinden<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> Die Bereitstellungsdatei oder der vollständige Pfad müssen im Abschnitt oben angegeben werden.</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">Eine Auswahl der<block ref="1db10b36979626249cbedcd8e8818146" prefix=" " category="inline-code"></block> Die Datei sieht wie das folgende Skript aus:</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">Diese Datei stellt das Gateway und die Netmask für das Netzwerk bereit, das der Load Balancer für das zugrunde liegende Cluster bereitstellt, sowie die Management-IP und den Hostnamen für die virtuelle Maschine, die zur Ausführung des Load Balancer bereitgestellt wird.</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident ist ein vollständig unterstützter Open-Source-Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Anthos.</block>
  <block id="c91efa18f13fad38864e99107352d0c5" category="paragraph">Astra Trident ist ein vollständig unterstützter Open-Source-Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Anthos. Trident kann mit dem gesamten NetApp Storage-Portfolio eingesetzt werden, einschließlich NetApp ONTAP und Element Storage-Systeme. Es unterstützt auch NFS- und iSCSI-Verbindungen. Trident beschleunigt den DevOps-Workflow, da Endbenutzer Storage über ihre NetApp Storage-Systeme bereitstellen und managen können, ohne dass ein Storage-Administrator eingreifen muss.</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">Ein Administrator kann verschiedene Storage-Back-Ends basierend auf den Projektanforderungen und Storage-Systemmodellen konfigurieren, die erweiterte Storage-Funktionen wie Komprimierung, bestimmte Festplattentypen und QoS-Level ermöglichen, die eine bestimmte Performance garantieren. Nach ihrer Definition können diese Back-Ends von Entwicklern in ihren Projekten verwendet werden, um persistente Volume Claims (PVCs) zu erstellen und persistenten Storage nach Bedarf an ihre Container anzubinden.</block>
  <block id="fbc20d9fb2c2f042edf73e3b39b3278a" category="paragraph"><block ref="fbc20d9fb2c2f042edf73e3b39b3278a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="239c66c0132fd8324d609e4f1ce89f79" category="paragraph">Die neueste Version von Astra Trident, 22.04, wurde im April 2022 veröffentlicht. Eine Support-Matrix, in der die Version von Trident getestet wurde, mit der Kubernetes Distribution zu finden ist<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">In der Version 22.04 wurde ein Helm Chart zur Erleichterung der Installation des Trident Operators zur Verfügung gestellt.</block>
  <block id="27bed77b9cf648bc4592d40c2806fb43" category="paragraph">Um die Installation von Trident auf dem implementierten Benutzer-Cluster zu automatisieren und ein persistentes Volume bereitzustellen, gehen Sie wie folgt vor:</block>
  <block id="c9c8f06cd5f25063dedfc6eea2b08fa7" category="inline-link">Helm-Installationsseite</block>
  <block id="c49053fbce1331670d3c2e81d9625fec" category="admonition">Helm ist auf der GKE-Admin-Workstation standardmäßig nicht installiert. Es kann in einem Binärformat heruntergeladen werden, das mit Ubuntu von der funktioniert<block ref="3d578643c15f985f07ca6d975ab0e791" category="inline-link-rx"></block>.</block>
  <block id="43eba64dcd06763432addbcf8db2d367" category="list-text">Trident Helm Repository hinzufügen:</block>
  <block id="6a05a869c72ac896a6f7473fba5c9b1e" category="paragraph">Um Trident manuell auf dem implementierten Benutzer-Cluster zu installieren und ein persistentes Volume bereitzustellen, führen Sie die folgenden Schritte aus:</block>
  <block id="79273cfc4ab66c2763755b11b14fedb9" category="list-text">Laden Sie das Installationsarchiv auf die Admin-Arbeitsstation herunter und extrahieren Sie den Inhalt. Die aktuelle Version von Trident ist 22.04, die heruntergeladen werden kann<block ref="c7e04c62da3fb5014b467863172d941c" category="inline-link-rx"></block>.</block>
  <block id="f0d8974fd014601f60573d339d525772" category="list-text">Legen Sie den Speicherort des Benutzer-Clusters fest<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Datei als Umgebungsvariable, damit Sie nicht darauf verweisen müssen, weil Trident keine Option hat, diese Datei zu übergeben.</block>
  <block id="deae9c61cc109057bffb21d54fd54cdc" category="paragraph">Nach Abschluss der Installation des Astra Trident Operator müssen Sie das Backend für die spezifische NetApp Storage-Plattform konfigurieren, die Sie verwenden. Folgen Sie dem folgenden Link, um mit der Einrichtung und Konfiguration von Astra Trident fortzufahren.</block>
  <block id="6ed9d9e6160cedf6c16c9fa74e9d08aa" category="inline-link-macro">Weiter: NetApp ONTAP NFS.</block>
  <block id="86beb69e1e89df92a89baa0d004b08b8" category="paragraph"><block ref="86beb69e1e89df92a89baa0d004b08b8" category="inline-link-macro-rx"></block></block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">Dieser Abschnitt richtet sich an Anpassungen, die reale Benutzer wahrscheinlich bei der Implementierung dieser Lösung in der Produktion ausführen müssen, wie z. B. die Implementierung benutzerdefinierter Load Balancer Instanzen.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="doc">Erweiterte Konfigurationsoptionen</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">In der Regel ist die am einfachsten zu implementierende Lösung am besten. In einigen Fällen sind jedoch erweiterte Anpassungen erforderlich, um die Anforderungen oder Spezifikationen einer bestimmten Applikation oder der Umgebung zu erfüllen, in der die Lösung implementiert wird. Zu diesem Zweck ermöglicht die Lösung Red hat OpenShift mit NetApp die folgenden Anpassungen, um diese Anforderungen zu erfüllen.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">In diesem Abschnitt haben wir einige erweiterte Konfigurationsoptionen dokumentiert, wie zum Beispiel Loadbalancer von Drittanbietern oder eine private Registry für das Hosting benutzerdefinierter Container-Images, die beide Voraussetzungen für die Installation des NetApp Astra Control Center sind.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">Auf den folgenden Seiten sind zusätzliche Informationen zu den erweiterten Konfigurationsoptionen verfügbar, die in Red hat OpenShift mit NetApp validiert sind:</block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">Nächster Abschnitt: Die Möglichkeiten Des Lastverteiler Erkunden.</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">Ein Backup einer Applikation erfasst den aktiven Status der Applikation und die Konfiguration ihrer Ressourcen. Es werden sie in Dateien abgelegt und in einem Remote-Objekt-Storage-Bucket gespeichert.</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">Gehen Sie wie folgt vor, um ein Anwendungsbackup zu erstellen:</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Um ein Backup der verwalteten Anwendung im Astra Control Center zu erstellen, navigieren Sie zu Apps &gt; Managed und klicken Sie auf die Anwendung, von der Sie ein Backup erstellen möchten. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf Backup.</block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">Geben Sie die Backup-Details ein, wählen Sie den Objekt-Storage-Bucket aus, der die Backup-Dateien enthält, und klicken Sie auf Weiter. Klicken Sie nach dem Überprüfen der Details auf Backup. Je nach Größe der Applikation und der Daten kann das Backup mehrere Minuten dauern. Der Status des Backups wird verfügbar, nachdem das Backup erfolgreich abgeschlossen wurde.</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">Um eine Anwendung wiederherzustellen, führen Sie die folgenden Schritte aus:</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">Navigieren Sie zu „Apps“ &gt; „Managed“, und klicken Sie auf die entsprechende App. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen, und klicken Sie auf Wiederherstellen.</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">Um eine Anwendung zu klonen, navigieren Sie zur Registerkarte „Apps“ &gt; „gemanagt“ und klicken Sie auf die betreffende Anwendung. Klicken Sie auf das Dropdown-Menü neben dem Anwendungsnamen und klicken Sie auf Klonen.</block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">Geben Sie die Details zum neuen Namespace ein, wählen Sie den Cluster aus, in dem Sie ihn klonen möchten, und legen Sie fest, ob er aus einem vorhandenen Snapshot, einem Backup oder dem aktuellen Status der Applikation geklont werden soll. Klicken Sie auf Weiter, und klicken Sie dann im Fenster Überprüfung auf Klonen, nachdem Sie die Details geprüft haben.</block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">Die neue Anwendung tritt in den Status Erkennung ein, während Astra Control Center die Anwendung auf dem ausgewählten Cluster erstellt. Nachdem alle Ressourcen der Anwendung installiert und vom Astra erkannt wurden, tritt die Anwendung in den verfügbaren Zustand.</block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp bietet verschiedene Produkte, die unsere Kunden bei der Orchestrierung und dem Management persistenter Daten in Container-basierten Umgebungen wie Anthos unterstützen.</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Anthos Ready Storage-Partnerprogramm.</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud bittet regelmäßig um aktualisierte Validierungen der Integration von Partner-Storage mit neuen Versionen von Anthos. Eine Liste der derzeit validierten Storage-Lösungen, CSI-Treiber, verfügbaren Funktionen und der unterstützten Versionen von Anthos finden Sie<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>.</block>
  <block id="ea3b8c601657928fee815e0d16908cf1" category="paragraph">NetApp hält vierteljährlich regelmäßig Compliance mit Anfragen zur Validierung unserer Astra Trident CSI-kompatiblen Storage-Orchestrierung und unserer ONTAP und Element Storage-Systeme mit Versionen von Anthos.</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">Die folgende Tabelle enthält die von NetApp und NetApp Partner Engineers getesteten Anthos Versionen zur Validierung von NetApp Astra Trident CSI-Treibern und -Funktionen im Rahmen des Anthos Ready Storage-Partnerprogramms:</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">Bereitstellungstyp</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">Storage-System</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Astra Trident Version</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">Multiwriter, Volume Expansion, Snapshots</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">San</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">RAW Block, Volume-Erweiterung, Snapshots</block>
  <block id="231afe47f3f37d3808096b36c28b4ded" category="cell">Element</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">Bare Metal</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp bietet verschiedene Produkte, mit denen Sie persistente Daten in Container-basierten Umgebungen wie Anthos orchestrieren und managen können.</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Trident ist ein vollständig unterstützter Open-Source-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Anthos. Weitere Informationen finden Sie auf der Astra Trident Website<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">Die folgenden Seiten enthalten zusätzliche Informationen zu NetApp Produkten, die für das Management von Applikationen und persistentem Storage in Anthos mit NetApp Lösung validiert wurden.</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">Als Nächstes: Überblick über NetApp Astra Trident</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">*NetApp SnapLock.* effiziente Verwaltung von nicht überschreibbaren Daten, indem sie auf spezielle Volumes geschrieben werden, die für einen festgelegten Zeitraum nicht überschrieben oder gelöscht werden können.</block>
  <block id="99634a0c579c45d299cfbb8b818c51bb" category="paragraph"><block ref="99634a0c579c45d299cfbb8b818c51bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp bietet robuste All-Flash (AFF) und horizontal skalierbare Hybrid (FAS) Storage-Plattformen, die auf latenzarme Performance, integrierte Datensicherung und Multiprotokoll-Unterstützung abgestimmt sind.</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">Beide Systeme werden durch die Datenmanagement-Software NetApp ONTAP unterstützt. Sie ist eine der fortschrittlichsten Datenmanagement-Software der Branche für das hochverfügbare, Cloud-integrierte, vereinfachte Storage-Management. Damit erhalten Sie die Geschwindigkeit, Effizienz und Sicherheit der Enterprise-Klasse, die Ihre Data-Fabric-Infrastruktur benötigt.</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">Weitere Informationen zu NETAPP AFF und FAS Plattformen finden Sie unter<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="0a180196354cfbb6ec70b20db067fa6b" category="inline-link-macro">Weiter: NetApp Element.</block>
  <block id="73978739caea0775c3c807ecfc27f0c0" category="paragraph"><block ref="73978739caea0775c3c807ecfc27f0c0" category="inline-link-macro-rx"></block></block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">Dieser Abschnitt befasst sich mit der Untersuchung von Load Balancer-Optionen für Benutzer, die ihre Anthos mit NetApp Implementierung anpassen möchten.</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">Die Load Balancer-Optionen werden untersucht</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Eine in Anthos implementierte Applikation ist der Welt durch einen Service ausgesetzt, der von einem Load Balancer in der On-Premises-Umgebung von Anthos bereitgestellt wird.</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">Die folgenden Seiten verfügen über zusätzliche Informationen zu den in Anthos mit NetApp validierten Load Balancer-Optionen:</block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="inline-link-macro">Installation von F5 BIG-IP Load Balancer</block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="inline-link-macro">Installation von MetalLB Load Balancer</block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">Weiter: Installation von F5 BIG-IP Load Balancer:</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">Es gibt ein optionales Feld mit dem Namen<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> Das ist in dieser Datei definiert. In iSCSI-Back-Ends kann dieser Wert auf einen bestimmten Linux-Dateisystem-Typ (XFS, ext4 usw.) gesetzt werden. Sie kann auch gelöscht werden, damit das Worker-Knoten-Betriebssystem entscheiden kann, welches Dateisystem verwendet werden soll.</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">Führen Sie die aus<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> Befehl zum Erstellen der Storage-Klasse.</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">Erstellen Sie das PVC, indem Sie die ausstellen<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> Befehl. Die Erstellung kann je nach Größe des erstellten Sicherungsvolumens einige Zeit in Anspruch nehmen, sodass Sie den Prozess nach Abschluss beobachten können.</block>
  <block id="06a9f54df07db88477918bd7c3f597de" category="inline-link-macro">Weiter: NetApp Element iSCSI.</block>
  <block id="dd8532ad7059feaef43031ffa5970de1" category="paragraph"><block ref="dd8532ad7059feaef43031ffa5970de1" category="inline-link-macro-rx"></block></block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="summary">F5 BIG-IP ist ein Application Delivery Controller (ADC), der eine breite Palette an fortschrittlichen, produktionsbereiten Traffic Management- und Sicherheitsservices wie L4-L7 Load Balancing, SSL/TLS-Entlastung, DNS, Firewall und vielem mehr bietet. Diese Services sorgen für eine signifikante Steigerung von Verfügbarkeit, Sicherheit und Performance der Applikationen.</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IP ist ein Application Delivery Controller (ADC), der eine breite Palette an fortschrittlichen, produktionsbereiten Traffic Management- und Sicherheitsservices wie L4-L7 Load Balancing, SSL/TLS-Entlastung, DNS, Firewall und mehr bietet. Diese Services sorgen für eine deutlich höhere Verfügbarkeit, Sicherheit und Performance Ihrer Applikationen.</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IP kann auf verschiedene Arten implementiert und genutzt werden, beispielsweise auf dedizierter Hardware, in der Cloud oder als virtuelle Appliance vor Ort. Lesen Sie die Dokumentation hier, um F5 BIG-IP zu erkunden und zu implementieren.</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IP war das erste Load Balancer-System, das bei Anthos On-Premises verfügbar war. Bei den ersten Anthos Ready Partner-Validierungen für Anthos mit NetApp Lösung wurde es eingesetzt.</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IP kann im Standalone- oder Cluster-Modus implementiert werden. Zum Zweck dieser Validierung wurde F5 BIG-IP im Standalone-Modus implementiert. Aus Produktionsgründen empfiehlt NetApp jedoch die Erstellung eines Clusters MIT BIG-IP-Instanzen, um Single Point of Failure zu vermeiden.</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">Diese Lösung nutzt die in VMware vSphere implementierte virtuelle Appliance. Die Netzwerkkonfigurationen für die virtuelle F5 Big-IP Appliance können je nach Netzwerkumgebung in Konfigurationen mit zwei oder drei bewaffneten Konfigurationen konfiguriert werden. Die Bereitstellung in diesem Dokument basiert auf der Konfiguration mit zwei Scharfstellen. Weitere Informationen zur Konfiguration der virtuellen Appliance für die Verwendung mit Anthos finden Sie hier<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>.</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">Das Solutions Engineering Team von NetApp hat die Versionen in der folgenden Tabelle für die On-Premises-Implementierung von Anthos validiert:</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">Make</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">Gehen Sie wie folgt vor, um F5 BIG-IP zu installieren:</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">Laden Sie die OVA-Datei (Open Virtual Appliance) der virtuellen Anwendung von F5 herunter<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>.</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">Um die Appliance herunterzuladen, muss sich ein Benutzer bei F5 registrieren. Sie stellen eine 30-Tage-Demo-Lizenz für den Big-IP Virtual Edition Load Balancer bereit. NetApp empfiehlt eine permanente 10-Gbit/s-Lizenz für die Implementierung einer Appliance in Produktionsumgebungen.</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">Klicken Sie mit der rechten Maustaste auf den Infrastruktur-Ressourcen-Pool, und wählen Sie OVF-Vorlage bereitstellen aus. Ein Assistent startet, mit dem Sie die OVA-Datei auswählen können, die Sie gerade in Schritt 1 heruntergeladen haben. Klicken Sie Auf Weiter.</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="inline-image-macro">Implementierung von Big-IP-Appliances</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">Klicken Sie auf Weiter, um die einzelnen Schritte fortzusetzen und die Standardwerte für jeden angezeigten Bildschirm zu akzeptieren, bis Sie den Bildschirm zur Speicherauswahl erreichen. Wählen Sie den VM_Datastore aus, für den Sie die virtuelle Maschine bereitstellen möchten, und klicken Sie dann auf Weiter.</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">Auf dem nächsten Bildschirm des Assistenten können Sie die virtuellen Netzwerke für die Verwendung in der Umgebung anpassen. Wählen Sie VM_Network für das Feld External aus, und wählen Sie Management_Network für das Feld Management aus. Interne Konfigurationen und HA werden für erweiterte Konfigurationen der F5 Big-IP Appliance verwendet und sind nicht konfiguriert. Diese Parameter können allein gelassen oder für die Verbindung mit verteilten Portgruppen ohne Infrastruktur konfiguriert werden. Klicken Sie Auf Weiter.</block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Bereitstellung von Big_IP-Appliance, Teil 2</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">Prüfen Sie den Übersichtsbildschirm für das Gerät und klicken Sie, wenn alle Informationen richtig sind, auf Fertig stellen, um die Bereitstellung zu starten.</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">Klicken Sie nach der Implementierung der virtuellen Appliance mit der rechten Maustaste, und schalten Sie sie ein. Er sollte eine DHCP-Adresse im Managementnetzwerk erhalten. Die Appliance ist auf Linux basiert und verfügt über VMware Tools, sodass Sie die im vSphere Client empfangenen DHCP-Adressen anzeigen können.</block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">Einsatz von Big-IP-Appliance, Teil 3</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">Öffnen Sie einen Webbrowser, und stellen Sie im vorherigen Schritt eine Verbindung mit dem Gerät unter der IP-Adresse her. Die Standardanmeldedaten sind admin/admin. Nach der ersten Anmeldung werden Sie umgehend aufgefordert, das Admin-Passwort zu ändern. Sie gelangen dann zu einem Bildschirm, auf dem Sie sich mit den neuen Anmeldedaten anmelden müssen.</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="inline-image-macro">Big-IP-Konfiguration</block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">Der erste Bildschirm fordert den Benutzer auf, das Setup-Dienstprogramm abzuschließen. Starten Sie das Dienstprogramm, indem Sie auf Weiter klicken.</block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">Big-IP-Konfiguration, Teil 2</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">Im nächsten Bildschirm wird die Aktivierung der Lizenz für das Gerät angezeigt. Klicken Sie zum Starten auf Aktivieren. Wenn Sie auf der nächsten Seite dazu aufgefordert werden, fügen Sie entweder den 30-Tage-Evaluierungslizenzschlüssel ein, den Sie bei der Anmeldung zum Download erhalten haben, oder die dauerhafte Lizenz, die Sie beim Kauf des Geräts erworben haben. Klicken Sie Auf Weiter.</block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">Big-IP-Konfiguration, Teil 3</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">Damit das Gerät die Aktivierung durchführen kann, muss das auf der Verwaltungsschnittstelle definierte Netzwerk in der Lage sein, das Internet zu erreichen.</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">Auf dem nächsten Bildschirm wird die Endbenutzer-Lizenzvereinbarung (End User License Agreement, EULA) angezeigt. Wenn die Bedingungen in der Lizenz akzeptabel sind, klicken Sie auf Akzeptieren.</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">Auf dem nächsten Bildschirm wird die verstrichene Zeit gezählt, während die bisherigen Konfigurationsänderungen überprüft werden. Klicken Sie auf Weiter, um mit der Erstkonfiguration fortzufahren.</block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">Big-IP-Konfiguration, Teil 4</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">Das Fenster Konfigurationsänderung wird geschlossen, und im Setup-Dienstprogramm wird das Menü Ressourcenbereitstellung angezeigt. In diesem Fenster werden die derzeit lizenzierten Funktionen sowie die aktuellen Ressourcenzuordnungen für die virtuelle Appliance und jeden laufenden Service aufgeführt.</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">Durch Klicken auf die Menüoption Plattform auf der linken Seite kann die Plattform zusätzlich geändert werden. Änderungen umfassen die Einstellung der Management-IP-Adresse, die mit DHCP konfiguriert ist, die Einstellung des Host-Namens und der Zeitzone, in der die Appliance installiert ist, sowie das Sichern der Appliance über den Zugriff über SSH.</block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">Big-IP-Konfiguration, Teil 6</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">Klicken Sie dann auf das Menü Netzwerk, mit dem Sie Standard-Netzwerkfunktionen konfigurieren können. Klicken Sie auf Weiter, um den Assistenten für die Standard-Netzwerkkonfiguration zu starten.</block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">Big-IP-Konfiguration, Teil 7</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">Auf der ersten Seite des Assistenten werden die Redundanz konfiguriert; lassen Sie die Standardeinstellungen, und klicken Sie auf Weiter. Auf der nächsten Seite können Sie eine interne Schnittstelle am Load Balancer konfigurieren. Schnittstelle 1.1 wird dem VMNIC namens Internal im OVF-Bereitstellungsassistenten zugeordnet.</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">Big-IP-Konfiguration, Teil 8</block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">Die Leerzeichen auf dieser Seite für Self IP Address, Netzmaske und Floating IP-Adresse können mit einer nicht routingfähigen IP-Adresse ausgefüllt werden, die als Platzhalter verwendet werden kann. Sie können auch mit einem internen Netzwerk gefüllt werden, das als verteilte Portgruppe für virtuelle Gäste konfiguriert wurde, wenn Sie die drei-bewaffnete Konfiguration bereitstellen. Sie müssen abgeschlossen sein, um mit dem Assistenten fortzufahren.</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">Auf der nächsten Seite können Sie ein externes Netzwerk konfigurieren, mit dem Services den in Kubernetes implementierten Pods zugeordnet werden können. Wählen Sie aus dem Bereich VM_Network eine statische IP, die entsprechende Subnetzmaske und eine unverankerte IP aus demselben Bereich aus. Schnittstelle 1.2 wird dem VMNIC namens External im OVF-Bereitstellungsassistenten zugeordnet.</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">Big-IP-Konfiguration, Teil 9</block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">Auf der nächsten Seite können Sie ein internes HA-Netzwerk konfigurieren, wenn Sie mehrere virtuelle Appliances in der Umgebung bereitstellen. Um fortzufahren, müssen Sie die Felder Self-IP Address und Netmasks ausfüllen. Sie müssen Schnittstelle 1.3 als VLAN Interface auswählen, das dem vom OVF-Vorlagenassistenten definierten HA-Netzwerk zugeordnet wird.</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">Big-IP-Konfiguration, Teil 10</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">Auf der nächsten Seite können Sie die NTP-Server konfigurieren. Klicken Sie dann auf Weiter, um mit dem DNS-Setup fortzufahren. Die DNS-Server und die Domänensuchliste sollten bereits vom DHCP-Server ausgefüllt werden. Klicken Sie auf Weiter, um die Standardeinstellungen zu übernehmen und fortzufahren.</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">Klicken Sie für den Rest des Assistenten auf Weiter, um das Advanced Peering Setup fortzusetzen, dessen Konfiguration über den Umfang dieses Dokuments hinausgeht. Klicken Sie anschließend auf Fertig stellen, um den Assistenten zu beenden.</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Erstellen Sie einzelne Partitionen für den Anthos Admin-Cluster und für jeden in der Umgebung implementierten Benutzer-Cluster. Klicken Sie im Menü auf der linken Seite auf System, navigieren Sie zu Benutzern, und klicken Sie auf Partitionsliste.</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">Big-IP-Konfiguration, Teil 11</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">Der angezeigte Bildschirm zeigt nur die aktuelle gemeinsame Partition an. Klicken Sie auf der rechten Seite auf Erstellen, um die erste zusätzliche Partition zu erstellen, und benennen Sie sie<block ref="7b8bd901f7c351d00688bb6fecf79a3c" prefix=" " category="inline-code"></block>. Klicken Sie dann auf Wiederholen, und benennen Sie die Partition<block ref="b328b4839c0f0e2bfc22ab6fca60065e" prefix=" " category="inline-code"></block>. Klicken Sie erneut auf die Schaltfläche Wiederholen, um die nächste Partition zu benennen<block ref="916e48fa5c2bc8c7765c99a8f011dccb" prefix=" " category="inline-code"></block>. Klicken Sie abschließend auf Fertig, um den Assistenten abzuschließen. Der Bildschirm Partitionsliste wird mit allen jetzt aufgeführten Partitionen angezeigt.</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">Big-IP-Konfiguration, Teil 12</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">In jeder Konfigurationsdatei gibt es einen Abschnitt, bzw. für das Admin-Cluster. Jedes Benutzer-Cluster, das Sie bereitstellen möchten, um den Load Balancer zu konfigurieren, sodass er von Anthos On-Premises gemanagt wird.</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">Das folgende Skript ist ein Beispiel aus der Konfiguration der Partition für den GKE-Admin-Cluster. Die Werte, die nicht kommentiert und geändert werden müssen, werden in Fettdruck unten gesetzt:</block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">Weiter: Installieren von MetalLB Load Balancer.</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">Dieser Abschnitt dient der Erstellung und Konfiguration einer privaten Image-Registry, die durch persistenten Storage von Astra Trident unterstützt wird.</block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">Erstellen von privaten Bildregistern</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">Quay.io</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Für die meisten Bereitstellungen von Red hat OpenShift verwenden Sie eine öffentliche Registrierung wie<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> Oder<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> Erfüllt die meisten Kundenanforderungen. Es gibt jedoch Zeiten, in denen ein Kunde seine eigenen privaten oder angepassten Bilder hosten möchte.</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">Dieses Verfahren dokumentiert die Erstellung einer privaten Image-Registry, die durch ein persistentes Volume von Astra Trident und NetApp ONTAP unterstützt wird.</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center erfordert eine Registrierung, um die Bilder zu hosten, die die Astra-Container benötigen. Im folgenden Abschnitt werden die Schritte zum Einrichten einer privaten Registrierung auf einem Red hat OpenShift-Cluster sowie das Drücken der Bilder beschrieben, die für die Installation des Astra Control Center erforderlich sind.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">Erstellen einer privaten Bildregistrierung</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">Entfernen Sie die Standardanmerkung aus der aktuellen Standard-Storage-Klasse und versehen Sie die Trident-gestützte Storage-Klasse als Standard für das OpenShift-Cluster.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">Bearbeiten Sie den Operator imageregistry, indem Sie die folgenden Speicherparameter in eingeben<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Abschnitt.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">Geben Sie die folgenden Parameter in das ein<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Abschnitt zum Erstellen einer OpenShift-Route mit einem benutzerdefinierten Hostnamen. Speichern und beenden.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">Die obige Routenkonfiguration wird verwendet, wenn Sie einen benutzerdefinierten Hostnamen für Ihre Route wünschen. Wenn OpenShift eine Route mit einem Standard-Hostnamen erstellen soll, können Sie dem die folgenden Parameter hinzufügen<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Abschnitt:<block ref="b09e8357c45c55a2c3ca685c9742fa6e" prefix=" " category="inline-code"></block>.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">Benutzerdefinierte TLS-Zertifikate</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">Wenn Sie einen benutzerdefinierten Hostnamen für die Route verwenden, wird standardmäßig die TLS-Standardkonfiguration des OpenShift Ingress-Operators verwendet. Sie können der Route jedoch eine benutzerdefinierte TLS-Konfiguration hinzufügen. Um das zu tun, führen Sie folgende Schritte durch.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">Erstellen Sie ein Geheimnis mit den TLS-Zertifikaten und dem Schlüssel der Route.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Bearbeiten Sie den Operator Imageregistry, und fügen Sie dem die folgenden Parameter hinzu<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Abschnitt.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">Bearbeiten Sie den Operator Imageregistry erneut, und ändern Sie den Verwaltungsstatus des Bedieners in das<block ref="80c202b1c3fd395a7bfe4d846c914bc3" prefix=" " category="inline-code"></block> Bundesland. Speichern und beenden.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">Wenn alle Voraussetzungen erfüllt sind, werden PVCs, Pods und Services für die private Image Registry erstellt. In wenigen Minuten sollte die Registrierung betriebsbereit sein.</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">Wenn Sie die standardmäßigen TLS-Zertifikate für die Registrierungsroute Ingress Operator OpenShift verwenden, können Sie die TLS-Zertifikate mit dem folgenden Befehl abrufen:</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">Damit OpenShift-Knoten auf die Bilder zugreifen und sie aus der Registrierung ziehen können, fügen Sie die Zertifikate dem Docker-Client auf den OpenShift-Knoten hinzu. Erstellen Sie im eine Konfigurationskarte<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Namespace mit den TLS-Zertifikaten und patchen Sie ihn mit der Konfiguration des Cluster-Images, um das Zertifikat vertrauenswürdig zu machen.</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">Die interne OpenShift-Registrierung wird durch Authentifizierung gesteuert. Alle OpenShift-Benutzer können auf die OpenShift-Registrierung zugreifen. Die Vorgänge, die der angemeldete Benutzer ausführen kann, sind jedoch von den Benutzerberechtigungen abhängig.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">Damit ein Benutzer oder eine Gruppe von Benutzern Bilder aus der Registrierung ziehen kann, müssen den Benutzern die Rolle Registry-Viewer zugewiesen sein.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">Damit ein Benutzer oder eine Benutzergruppe Bilder schreiben oder übertragen kann, muss dem/den Benutzer die Rolle des Registrierungs-Editors zugewiesen sein.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">Damit OpenShift-Knoten auf die Registrierung zugreifen und die Bilder per Push oder Pull übertragen können, müssen Sie einen Pull Secret konfigurieren.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">Dieses Pull-Secret kann dann auf Dienstkonten gepatcht oder in der entsprechenden Pod-Definition referenziert werden.</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">Führen Sie den folgenden Befehl aus, um es auf Dienstkonten zu patchen:</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">Um den Pull-Secret in der Pod-Definition zu referenzieren, fügen Sie dem den folgenden Parameter hinzu<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Abschnitt.</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">Gehen Sie wie folgt vor, um ein Bild vom OpenShift-Knoten zu trennen oder von Workstations zu ziehen:</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Fügen Sie die TLS-Zertifikate zum Docker-Client hinzu.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">Melden Sie sich über den oc-Anmeldebefehl bei OpenShift an.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">Melden Sie sich mit den OpenShift-Benutzeranmeldeinformationen über den Befehl podman/Docker bei der Registrierung an.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">Podman</block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">Wenn Sie verwenden<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> Benutzer, um sich bei der privaten Registrierung anzumelden, verwenden Sie dann ein Token anstelle eines Passworts.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">docker</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">Drücken oder ziehen Sie die Bilder.</block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">Weiter: NetApp ONTAP iSCSI.</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">Dieses Referenzdokument bietet eine Implementierungsvalidierung für Anthos mit NetApp Lösung, die in Umgebungen mit mehreren Datacentern implementiert wird, wie von NetApp und unseren Engineering-Partnern validiert.</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165: Anthos mit NetApp</block>
  <block id="e961a4cbc5c7e2be5e3f72a578aeb4da" category="paragraph">Alan Cowles und Nikhil Kulkarni, NetApp</block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">Dieses Referenzdokument bietet eine Implementierungsvalidierung von Anthos mit NetApp Lösung für Partner von NetApp, wenn sie in mehreren Datacenter-Umgebungen implementiert wird. Sie Details zur Storage-Integration mit NetApp Storage-Systemen mithilfe des Astra Trident Storage-Orchestrators für das Management von persistentem Storage. Und schließlich untersuchen und dokumentieren wir eine Reihe von Validierungen und Anwendungsfällen aus der Praxis.</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">Die Architektur der Anthos with NetApp Lösung bietet Kunden mit folgenden Anwendungsfällen einen hervorragenden Mehrwert:</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">Anthos Umgebung lässt sich einfach implementieren und managen, wenn sie bereitgestellt wird<block ref="f9d1b8d1854865b695167e2c5829f633" prefix=" " category="inline-code"></block> Werkzeug auf blankem Metall oder dem<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Tool auf VMware vSphere.</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">Kubevirt</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">Kombinierte Leistung von Enterprise-Containern und virtualisierten Workloads mit Anthos praktisch auf vSphere oder Bare Metal mit<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>.</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">Konfigurationsmöglichkeiten und Anwendungsfälle aus der Praxis zeigen die Anthos-Funktionen, wenn sie mit NetApp Storage und Astra Trident, dem Open-Source-Storage-Orchestrator für Kubernetes, verwendet werden.</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">Anthos with NetApp ist eine Lösung für diese Herausforderungen. Sie stellt eine Lösung vor, mit der alle Bedenken zerlegt werden können, indem Anthos On-Premises in der gewünschten Datacenter-Umgebung des Kunden vollständig automatisiert implementiert wird.</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">Die Anthos Lösung mit NetApp besteht aus den folgenden Hauptkomponenten:</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Anthos Vor Ort</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Anthos On Prem ist eine vollständig unterstützte Kubernetes-Plattform für Unternehmen, die im VMware vSphere Hypervisor oder in einer Bare-Metal-Infrastruktur Ihrer Wahl implementiert werden kann.</block>
  <block id="42fc2dc2813b6a8c6bbca7ebe6d3f51e" category="paragraph">Weitere Informationen zu Anthos finden Sie auf der Website von Anthos<block ref="bcfc39c80df16a8beb60f78ea034be9d" category="inline-link-rx"></block>.</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Anthos.</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">Dieser Abschnitt richtet sich an Anpassungen, die reale Benutzer wahrscheinlich bei der Implementierung dieser Lösung in der Produktion ausführen müssen, wie z. B. die Erstellung einer dedizierten privaten Image-Registrierung oder die Implementierung benutzerdefinierter Load Balancer-Instanzen.</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8, 9.9.1</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="cell">Anthos Cluster auf VMware</block>
  <block id="eb5d694ff9583283fe6d0190a39d5f7a" category="cell">6.7U3, 7.0U3</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">Weiter: Anthos Übersicht.</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="summary">Mit den hardwareunabhängigen Funktionen von Anthos auf Bare Metal können Sie eine Compute-Plattform auswählen, die für Ihren individuellen Anwendungsfall optimiert ist, und von vielen weiteren Vorteilen profitieren.</block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">Beispiele:</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*Bring deinen eigenen Server.* Sie können Server verwenden, die zu Ihrer bestehenden Infrastruktur passen, um Investitions- und Managementkosten zu senken.</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*Bring dein eigenes Linux-Betriebssystem mit.* mit dem Linux-Betriebssystem, das du deine Anthos-on-Bare-Metal-Umgebung bereitstellen möchtest, kannst du sicherstellen, dass sich die Anthos-Umgebung nahtlos in deine vorhandenen Infrastruktur- und Managementschemata einfügt.</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">*Höhere Performance und niedrigere Kosten.* ohne den Bedarf an einem Hypervisor fordern Anthos-on-Bare-Metal-Cluster den direkten Zugriff auf Server-Hardware-Ressourcen, einschließlich Performance-optimierter Hardware-Geräte wie GPUs.</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">*Höhere Netzwerk-Performance und geringere Latenz.* Da die Anthos-on-Bare-Metal-Server-Nodes direkt ohne virtualisierte Abstraktionsschicht mit dem Netzwerk verbunden sind, können sie für eine geringe Latenz und Performance optimiert werden.</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud fordert regelmäßig aktualisierte Validierungen von Partner-Serverplattformen mit neuen Versionen von Anthos über das Partner-Programm der Anthos Ready Plattform an. Eine Liste der aktuell validierten Serverplattformen und der unterstützten Versionen von Anthos finden Sie<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>.</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">Die folgende Tabelle enthält Serverplattformen, die von NetApp und seinen Engineers von NetApp Partnern für die Validierung von Anthos auf Bare-Metal-Implementierungen getestet wurden.</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">Hersteller</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">Proliant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">Anthos-on-Bare-Metal-Nodes können mit mehreren verschiedenen Linux-Distributionen konfiguriert werden. Die Auswahl erfolgt durch den Kunden, sodass die aktuelle Datacenter-Infrastruktur besser erreicht werden kann.</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">Die folgende Tabelle enthält eine Liste mit Linux Betriebssystemen, die von NetApp und unseren Partnern zur Validierung der Lösung verwendet wurden.</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">Freigabe</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Anthos-Versionen</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8.4</block>
  <block id="6a3bfb64d8c5e16ce63f46624e637b30" category="cell">18.04 LTS</block>
  <block id="d4a5ee60a5a19102b6c00749a050feaf" category="cell">20.04 LTS</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">Zusätzliche Hardware</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">Damit Anthos als vollständig validierte Lösung auf Bare Metal implementiert werden kann, wurden zusätzliche Datacenter-Komponenten für Netzwerk und Storage von NetApp und unseren Partner Engineers getestet.</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">Die folgende Tabelle enthält Informationen zu diesen zusätzlichen Infrastrukturkomponenten.</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">Hardwarename</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250, A220</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">Zusätzliche Software</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">Die folgende Tabelle enthält eine Liste zusätzlicher Softwareversionen, die in der Validierungsumgebung implementiert wurden.</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">Softwarename</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3 (5)</block>
  <block id="6ff97c39e8de9255f8ab9ffb6a483dce" category="cell">9.9.1, 9.10.1</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">Während der Validierung der Anthos Ready Plattform, die von NetApp und unserem Partner-Team bei World Wide Technology (WWT) durchgeführt wurde, basierte die Lab-Umgebung auf folgender Abbildung: Wir konnten die Funktionalität der einzelnen Servertypen, Betriebssysteme und Netzwerkgeräte testen. Und Storage-Systeme, die in der Lösung implementiert werden.</block>
  <block id="f8caba75d33af6e6a5a53160c246688e" category="paragraph"><block ref="f8caba75d33af6e6a5a53160c246688e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">Diese Multi-OS-Umgebung zeigt die Interoperabilität mit unterstützten Betriebssystemversionen für die Anthos-on-Bare-Metal-Lösung. Wir gehen davon aus, dass Kunden für ihre Implementierung ein oder mehrere Betriebssysteme standardisieren werden.</block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">Infrastruktur-Support-Ressourcen</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">Vor der Implementierung von Anthos auf Bare Metal sollte die folgende Infrastruktur vorhanden sein:</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">Mindestens ein DNS-Server, der eine vollständige Hostnamenauflösung bietet, auf die über das Managementnetzwerk zugegriffen werden kann.</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">Mindestens ein NTP-Server, auf den über das Managementnetzwerk zugegriffen werden kann.</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(Optional) ausgehende Internetverbindung sowohl für das bandinterne Managementnetzwerk.</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">In diesem Dokument gibt es ein Demo-Video zu einer Anthos on Bare Metal-Implementierung im Abschnitt Videos und Demos.</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">Dieses Referenzdokument bietet Implementierungsvalidierung für Google Cloud Anthos in verschiedenen Datacenter-Umgebungen, die von NetApp validiert wurden. Sie Details zur Storage-Integration mit NetApp Storage-Systemen dank des Astra Trident Storage-Orchestrators für das Management von persistentem Storage sowie des NetApp Astra Control Center für das Management und die Sicherung statusbehafteter Applikationen. Abschließend werden eine Reihe von Validierungen von Lösungen und Anwendungsbeispiele aus der Praxis untersucht und dokumentiert.</block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Um Astra Control Center mit Ansible-Playbooks zu implementieren, ist ein Ubuntu/RHEL-System erforderlich, auf dem Ansible installiert ist. Gehen Sie wie beschrieben vor<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Für Ubuntu und<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Für RHEL.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Erstellen oder beziehen Sie eine kubeconfig-Datei mit Administratorzugriff auf das OpenShift-Cluster, auf dem Astra Control Center installiert werden soll.</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">Ändern Sie das Verzeichnis in<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">Bearbeiten Sie die Datei Vars/Vars.yml und füllen Sie die Variablen mit den erforderlichen Informationen aus.</block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">Das Video, mit dem Sie auf dieser Seite verknüpft sind, zeigt einige der in diesem Dokument dokumentierten Funktionen.</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="doc">Videos und Demos</block>
  <block id="63e2e4c63022a2ca3a58778bd242195b" category="paragraph">Im folgenden Video werden einige der in diesem Dokument dokumentierten Funktionen gezeigt:</block>
  <block id="1adda60fb6ef5adf0c35c53442bdd87d" category="inline-link-macro">Video: Bereitstellung von Anthos auf Bare Metal</block>
  <block id="81082fb0b2db5311a27c6cd75db69481" category="paragraph"><block ref="81082fb0b2db5311a27c6cd75db69481" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos vereint Entwicklungs- und IT-Abläufe auf einer einzelnen Plattform, um Applikationen konsistent in On-Premises- und Hybrid-Cloud-Infrastrukturen zu erstellen, zu implementieren und zu managen. Anthos integriert GKE Kubernetes Cluster direkt in virtuelle oder Bare-Metal-Formate in die Datacenter-Umgebung.</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Anthos Übersicht</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">Anthos mit NetApp ist eine verifizierte Best-Practice-Hybrid-Cloud-Architektur für die Implementierung einer On-Premises-Umgebung mit der Google Kubernetes Engine (GKE) auf zuverlässige und zuverlässige Weise. Diese Referenzdokument für eine NetApp Verified Architecture dient als Design-Leitfaden und als Implementierungsvalidierung der Anthos mit NetApp Lösung, die in Bare-Metal- und virtuellen Umgebungen implementiert wird. Die in diesem Dokument beschriebene Architektur wurde von Experten von NetApp und Google Cloud validiert. Diese Experten haben die Vorteile, die Anthos in Ihrer Datacenter-Umgebung in Unternehmen bietet.</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos ist eine Kubernetes-Datacenter-Lösung für die Hybrid Cloud, mit der Unternehmen moderne Hybrid-Cloud-Infrastrukturen aufbauen und managen und flexible Workflows einführen können, die sich auf die Applikationsentwicklung konzentrieren. Anthos auf VMware ist eine Lösung, die auf Open-Source-Technologien basiert, kann On-Premises in einer auf VMware vSphere basierenden Infrastruktur ausgeführt werden. Die Verbindung mit Anthos GKE kann in der Google Cloud hergestellt und kompatibel sein. Die Einführung von Containern, Mesh-Diensten und anderen Transformationstechnologien ermöglicht Unternehmen konsistente Applikationsentwicklungszyklen und produktionsbereite Workloads in lokalen und Cloud-basierten Umgebungen. Die folgende Abbildung zeigt die Anthos Lösung und die Art und Weise, wie eine Implementierung in einem On-Premises-Datacenter mit der Infrastruktur in der Cloud verbindet.</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">*Google Cloud Marketplace für Kubernetes Applications.* ein Katalog von kuratierten Container-Anwendungen zur einfachen Bereitstellung verfügbar.</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">* Migrieren Sie nach Anthos.* Automatische Migration von physischen Services und VMs von lokalen Systemen in die Cloud.</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">*Stackdriver.* Management-Service von Google für die Protokollierung und Überwachung von Cloud-Instanzen.</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Implementierungsmethoden für Anthos</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">Anthos Cluster auf VMware</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">Anthos-Cluster, die in VMware vSphere Umgebungen implementiert werden, sind für die meisten Kubernetes-Workloads der Endbenutzer einfach zu implementieren, zu warten und schnell zu skalieren.</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">Weitere Informationen zu Anthos-Clustern auf VMware, die mit NetApp implementiert werden, finden Sie auf der Seite <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>.</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">Anthos-Cluster, die auf Bare-Metal-Servern implementiert sind, sind hardwareunabhängig. Sie können eine Compute-Plattform auswählen, die für Ihren personalisierten Anwendungsfall optimiert ist.</block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">Weitere Informationen zu Anthos auf Bare-Metal-Clustern, die mit NetApp implementiert werden, finden Sie unter <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>.</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">Als Nächstes: Anthos Cluster auf VMware.</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">NetApp Astra Trident – Dokumentation</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">Anthos Cluster auf der VMware-Dokumentation</block>
  <block id="f5266df5a7db89637cf0d7391221b756" category="inline-link"><block ref="f5266df5a7db89637cf0d7391221b756" category="inline-link-rx"></block></block>
  <block id="1bdc624c553dda22bc7a529bda2dd06b" category="paragraph"><block ref="1bdc624c553dda22bc7a529bda2dd06b" category="inline-link-rx"></block></block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Anthos auf Bare-Metal-Dokumentation</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">So stellen Sie eine Anwendung in Ihrem Anthos GKE-Cluster vor Ort mithilfe der Google Cloud Console bereit.</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Implementieren Sie eine Applikation über den Google Cloud Console Marketplace</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">Ein Anthos Cluster kann lokal implementiert und bei der Google Cloud Console registriert werden</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Ein in Ihrem Anthos Cluster konfigurierter MetalLB Load Balancer</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">Ein Konto mit Berechtigungen zum Bereitstellen von Anwendungen im Cluster</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">Ein Abrechnungskonto bei Google Cloud, wenn Sie eine Anwendung mit den damit verbundenen Kosten auswählen (optional)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">Implementieren einer Applikation</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">Für diesen Anwendungsfall stellen wir mit der Google Cloud Console eine einfache WordPress-Anwendung auf einen unserer Anthos-Cluster bereit. Bei der Implementierung wird persistenter Storage verwendet, der von NetApp ONTAP in einer vordefinierten storageclass bereitgestellt wird. Wir demonstrieren dann zwei verschiedene Methoden, um den Standardservice für Anwendungen so zu ändern, dass der MetalLB Load Balancer ihn mit einer IP-Adresse versorgt und der Welt zugänglich macht.</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">Um eine Anwendung auf diese Weise bereitzustellen, führen Sie folgende Schritte aus:</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">Vergewissern Sie sich, dass der zu implementierende Cluster in der Google Cloud Console verfügbar ist.</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">Registrierte Cluster</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">Wählen Sie im linken Menü die Option Anwendungen aus, wählen Sie oben das Optionsmenü mit drei Punkten aus, und wählen Sie aus dem Marketplace die Option Bereitstellen aus. Dort wird ein neues Fenster geöffnet, in dem Sie eine Anwendung aus dem Google Cloud Marketplace auswählen können.</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">Application Marketplace</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">Suchen Sie nach der Anwendung, die Sie installieren möchten, in diesem Fall WordPress.</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">Suche nach WordPress</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">Nachdem Sie die WordPress-Anwendung ausgewählt haben, wird ein Übersichtsbildschirm angezeigt. Klicken Sie auf die Schaltfläche Konfigurieren.</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">Bildschirm WordPress-Übersicht</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">Auf der nächsten Seite müssen Sie in unserem Fall Demo-Cluster den zu implementierenden Cluster auswählen. Wählen oder erstellen Sie einen neuen Namespace und einen Namen für die Anwendungsinstanz, und wählen Sie aus, welche Storage-Klassen und persistente Volume-Größen Sie sowohl für die WordPress-Anwendung als auch für die von MariaDB unterstützten Datenbank benötigen. In beiden Fällen haben wir uns für die Storage-Klasse ONTAP-NAS-CSI entschieden.</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">WordPress-Konfiguration</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">Wählen Sie keinen öffentlichen IP-Zugriff aktivieren aus. Dadurch wird ein Service vom Typ NodePort erstellt, der von einer lokalen Anthos-Implementierung nicht zugänglich ist.</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">Nachdem Sie auf die Schaltfläche Bereitstellen geklickt haben, erhalten Sie eine Seite mit Anwendungsdetails. Sie können diese Seite aktualisieren oder sich mithilfe der CLI beim Cluster anmelden, um den Status der Bereitstellung zu überprüfen.</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">Einzelheiten Zur Anwendung</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">Die CLI kann dazu verwendet werden, den Status der Applikation während ihrer Bereitstellung zu überprüfen, indem der Befehl zum Abrufen von POD-Informationen in unserem Applikations-Namespace ausgeführt wird:<block ref="f33e7514e1b666008863c58a5b3b8fc3" prefix=" " category="inline-code"></block>.</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Kubectl bekommt Stative</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">Beachten Sie in diesem Screenshot, dass ein Pod im Fehlerzustand vorhanden ist. Dies ist normal. Dieser POD ist ein Helfer-Pod, der von der Google Cloud Console verwendet wird, um die Anwendung bereitzustellen, die selbst beendet wird, wenn die anderen Pods ihren Initialisierungsprozess begonnen haben.</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">Stellen Sie nach wenigen Augenblicken sicher, dass Ihre Anwendung ausgeführt wird.</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">Applikation Wird Ausgeführt</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">Die Anwendung offenlegen</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">Nach der Bereitstellung der Anwendung stehen Ihnen zwei Methoden zur Verfügung, um ihr eine weltweit erreichbare IP zuzuweisen.</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Verwenden der Google Cloud Console</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">Sie können die Anwendung über die Google Cloud Console anzeigen und die YAML-Ausgabe für die Dienste in einem Browser bearbeiten, um eine öffentlich zugängliche IP festzulegen. Um das zu tun, führen Sie folgende Schritte aus:</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">Klicken Sie in der Google Cloud Console im linken Menü auf Services und Ingress.</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">Dienstleistungen und Ingress</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">Klicken Sie auf das<block ref="038c7925bdf387b6bedcaa4b32ec3a83" prefix=" " category="inline-code"></block> Service: Daraufhin wird der Bildschirm Servicedetails geöffnet. Klicken Sie oben auf die Schaltfläche Bearbeiten.</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">Servicedetails Bearbeiten</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">Die Seite „Service-Details bearbeiten“ wird geöffnet, die die YAML-Informationen für den Dienst enthält. Scrollen Sie nach unten, bis Sie das sehen<block ref="084d5d41838f6b2d8b0c1f1176d66d01" prefix=" " category="inline-code"></block> Und der<block ref="3190100143eef75fa97ee36e98fa3f8b" prefix=" " category="inline-code"></block> Wert, der auf festgelegt ist<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block>. Ändern Sie diesen Wert in<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> Und klicken Sie auf die Schaltfläche Speichern.</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">Geben Sie ClusterIP-Wert ein</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">Geben Sie den Wert für den Load Balancer ein</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">Wenn Sie zur Seite Service-Details zurückkehren, wird die angezeigt<block ref="e659b52eba1f0299b2d8ca3483919e72" prefix=" " category="inline-code"></block> Now-Listen<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> Und das<block ref="918d33b6c8dd822ec40bbef2e2f58f3e" prefix=" " category="inline-code"></block> Feld zeigt eine zugewiesene IP-Adresse aus dem MetalLB-Pool und den Port an, über den die Anwendung zugänglich ist.</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">Servicedetails Endgültig</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Patching the Service with kubectl</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">Sie können die Anwendung über die CLI und die freigeben<block ref="b40dfaf71508ce779421b1c4dde5f99f" prefix=" " category="inline-code"></block> Befehl zum Ändern der Bereitstellung und Festlegen einer öffentlich zugänglichen IP. Um das zu tun, führen Sie folgende Schritte aus:</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">Führen Sie die Services an, die mit den Pods in Ihrem Namespace mit dem verbunden sind<block ref="3841f6ce7a9f7be216fe99eef26477f6" prefix=" " category="inline-code"></block> Befehl.</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">Listendienste</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">Ändern Sie den Servicetyp von<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block> Nach Typ<block ref="5c89f521cbb8685d397906bd6ce0efa1" prefix=" " category="inline-code"></block> Verwenden des folgenden Befehls:</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">Diesem neuen Servicetyp wird automatisch eine verfügbare IP-Adresse aus dem MetalLB-Pool zugewiesen.</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">Patch Service zum Typ Load Balancer</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">Besuchen Sie die Anwendung an der freiliegenden externen IP</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">Nun, da Sie die Anwendung mit einer öffentlich zugänglichen IP-Adresse ausgesetzt haben, können Sie Ihre WordPress-Instanz mit einem Browser besuchen.</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">WordPress im Browser</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">Als Nächstes: Videos und Demos.</block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">Weiter: Erweiterte Konfigurationsoptionen.</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">Anthos Cluster auf VMware ist eine Erweiterung der Google Kubernetes Engine, die in einem privaten Rechenzentrum eines Endbenutzers bereitgestellt wird. Ein Unternehmen kann dieselben Applikationen implementieren, die für die Ausführung in Containern in Google Cloud in Kubernetes Clustern vor Ort entwickelt wurden. Anthos-Cluster auf VMware können in einer bestehenden VMware vSphere-Umgebung in Ihrem Datacenter implementiert werden, wodurch Investitionskosten eingespart und die Implementierung und Skalierung beschleunigt werden können.</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">Die Implementierung von Anthos-Clustern auf VMware umfasst die folgenden Komponenten:</block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">*Anthos Admin Workstation.* Ein Bereitstellungshost von dem aus<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Und<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> Befehle können ausgeführt werden, um Anthos-Bereitstellungen bereitzustellen und zu interagieren.</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*Admin-Cluster.* der anfängliche Cluster wird beim Einrichten von Anthos-Clustern auf VMware bereitgestellt. Dieser Cluster managt alle untergeordneten User Cluster-Aktionen, einschließlich Implementierung, Skalierung und Upgrade.</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*Benutzer-Cluster.* jedes Benutzer-Cluster wird mit einer eigenen Load Balancer-Instanz oder -Partition bereitgestellt, wodurch es als eigenständiger Kubernetes Cluster für einzelne Benutzer oder Gruppen fungiert und so eine vollständige Mandantenfähigkeit erreicht.</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">Die folgende Abbildung zeigt eine Beschreibung der Implementierung von Anthos-Cluster-on-VMware.</block>
  <block id="d17685a3ddd89e969b430984ce944772" category="paragraph"><block ref="d17685a3ddd89e969b430984ce944772" category="inline-image-macro-rx" type="image"></block></block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">Anthos Cluster auf VMware bietet folgende Vorteile:</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*Erweiterte Mandantenfähigkeit.* jeder Endanwender kann seinen eigenen Benutzer-Cluster zuweisen, der mit den für seine eigene Entwicklungsumgebung nötigen virtuellen Ressourcen implementiert wird.</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*Kosteneinsparungen.* Endanwender können erhebliche Kosteneinsparungen erzielen, indem sie mehrere Benutzer-Cluster in derselben physischen Umgebung bereitstellen und ihre eigenen physischen Ressourcen für ihre Applikationsimplementierungen verwenden, anstatt Ressourcen in ihrer Google Cloud-Umgebung oder auf großen Bare-Metal-Clustern bereitzustellen.</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*Entwickeln und veröffentlichen.* On-Premises-Bereitstellungen können während der Entwicklung von Anwendungen genutzt werden, die das Testen von Anwendungen in der Privatsphäre eines lokalen Rechenzentrums ermöglichen, bevor sie in der Cloud öffentlich verfügbar gemacht werden.</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">*VMware vSphere vMotion.* VMware vCenter ermöglicht die unterbrechungsfreie Migration von VMs zwischen Knoten im Cluster auf Anfrage.</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">*VSphere High Availability.* um Unterbrechungen bei Host-Ausfällen zu vermeiden, ermöglicht VMware vSphere die Clusterfähigkeit und Konfiguration von Hosts für hohe Verfügbarkeit. VMs, die durch einen Host-Ausfall unterbrochen werden, werden in Kürze auf anderen Hosts im Cluster neu gestartet, wodurch die Services wiederhergestellt werden.</block>
  <block id="44da02789c784d2615f858b0e9007c1d" category="inline-link">NetApp FlexPod</block>
  <block id="08edd2123939d5309dced149763a50ee" category="inline-link">NetApp HCI</block>
  <block id="58d64ca3570be3edd23e4165a8c0d9ee" category="paragraph">Die folgende Tabelle enthält Serverplattformen, die von NetApp und seinen Engineers von NetApp Partnern für die Validierung von Anthos Clustern auf VMware Implementierungen getestet wurden. Dabei handelt es sich um Lösungen wie die<block ref="5ea2f6a45afb6a8f064f7631dd737389" category="inline-link-rx"></block> Mit Cisco UCS Servern und der<block ref="3ff4d1b07fc6ed14e7fcf7636d0ad5aa" category="inline-link-rx"></block> Hybrid-Cloud-Infrastrukturplattform:</block>
  <block id="bcb24d33d2a22de9b0c3e9f38becc496" category="cell">HCI</block>
  <block id="9f80c25863c6e1e85d8d5492b437cb64" category="cell">C410</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">Anthos Cluster auf VMware können sowohl in vSphere 6 als auch in 7 Umgebungen implementiert werden, die vom Kunden ausgewählt werden, um die Anpassung der bestehenden Datacenter-Infrastruktur zu unterstützen.</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">Die folgende Tabelle enthält eine Liste der vSphere Versionen, die von NetApp und unseren Partnern zur Validierung der Lösung verwendet wurden.</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">Damit Anthos als vollständig validierte Lösung implementiert werden kann, wurden zusätzliche Datacenter-Komponenten für Netzwerk und Storage von NetApp und unseren Partner Engineers getestet.</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox</block>
  <block id="92666505ce75444ee14be2ebc2f10a60" category="cell">SN</block>
  <block id="d7a84628c025d30f7b2c52c958767e76" category="cell">2010</block>
  <block id="2f72e4f4112efeb63b9fb0ed1eefd1c9" category="cell">A250</block>
  <block id="bf07aaec06ff922b8a11ef624141bfdb" category="cell">S410</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">Die folgende Tabelle enthält eine Liste der in der Validierungsumgebung implementierten Softwareversionen.</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">Softwarename</block>
  <block id="3c537b8d673e06e2107129b600143391" category="cell">4.1(3e)</block>
  <block id="f932bed2d12442d21507b51d22b88dd7" category="cell">1.8</block>
  <block id="c1770c414b5c19c253a48e36fa2da50f" category="paragraph">Während der von NetApp durchgeführten Validierung der Anthos Ready Plattform wurde die Lab-Umgebung auf Basis des folgenden Diagramms aufgebaut, mit der wir mehrere implementierte Benutzer-Cluster sowie mehrere NetApp Storage-Systeme und Storage-Back-Ends testen konnten.</block>
  <block id="c1c59b2c25178eb5f3956ae189dc384b" category="paragraph"><block ref="c1c59b2c25178eb5f3956ae189dc384b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">Die folgende Infrastruktur sollte vor der Implementierung von Anthos vorhanden sein:</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">Ein DHCP-Server, der bei Bedarf Netzwerkadressen vermietet, sollte Cluster dynamisch skaliert werden müssen</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Implementieren Sie Anthos in ein ESXi-Cluster mit mindestens drei Nodes</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">Obwohl Anthos zu Demonstrations- oder Testzwecken in einem vSphere Cluster mit weniger als drei Nodes installiert werden kann, wird dies für Produktions-Workloads nicht empfohlen. Obwohl zwei Nodes eine grundlegende HA- und Fehlertoleranz ermöglichen, muss eine Anthos-Cluster-Konfiguration geändert werden, um die standardmäßige Host-Affinität zu deaktivieren. Diese Bereitstellungsmethode wird von Google Cloud nicht unterstützt.</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">Durch die Unterstützung der VM- und Host-Affinität können Anthos Cluster-Nodes über mehrere Hypervisor-Nodes verteilt werden.</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">Informationen zur Konfiguration von Affinitätsgruppen finden Sie unten den entsprechenden Link für Ihre VMware vSphere Version.</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">VSphere 7.0 Dokumentation: Nutzung von DRS Affinity Rules</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>.<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>.</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos verfügt über eine Konfigurationsoption für jede Person<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> Datei zur automatischen Erstellung von Regeln für die Knotenverwaltung, die basierend auf der Anzahl der ESXi Hosts in Ihrer Umgebung aktiviert oder deaktiviert werden können.</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">Weiter: Anthos auf Bare Metal.</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Nachdem Sie Ihre Red hat OpenShift-Cluster registriert haben, können Sie über das Astra Control Center die Anwendungen ermitteln, die bereitgestellt und verwaltet werden.</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">Nachdem die OpenShift-Cluster und ONTAP-Back-Ends beim Astra Control Center registriert wurden, beginnt das Kontrollzentrum automatisch die Anwendungen in allen Namespaces zu erkennen, die die mit dem angegebenen ONTAP-Backend konfigurierte Speicherageclass verwenden.</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp verfügt über verschiedene Storage-Plattformen, die sich mit Trident Storage Orchestrator für die Bereitstellung von Storage für auf Anthos implementierte Applikationen qualifizieren.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">NetApp Storage-Überblick</block>
  <block id="f623f7fc1ffb9cfc3afddcf52e2fec23" category="paragraph">NetApp verfügt über verschiedene Storage-Plattformen, die sich mit unserem Astra Trident Storage Orchestrator für die Bereitstellung von Storage für auf Anthos implementierte Applikationen qualifizieren.</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">Weiter: NetApp ONTAP.</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">Bevor Sie mit der Installation beginnen, schieben Sie die Astra Control Center-Bilder in eine Bildregistrierung. Sie können dies entweder mit Docker oder Podman tun. Anweisungen für beide werden in diesem Schritt angegeben.</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">Alternativ können Sie ein Service-Konto erstellen, dem Registry-Editor und/oder der Registry-Viewer-Rolle zuweisen (ob Sie Push/Pull-Zugriff benötigen) und sich mithilfe des Token des Service-Kontos bei der Registrierung anmelden.</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">Erstellen Sie eine Shell-Skriptdatei, und fügen Sie den folgenden Inhalt ein.</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">Wenn Sie das verwenden<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> Benutzer, um sich bei der privaten Registrierung anzumelden, dann ein Token anstelle eines Passworts verwenden -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">Alternativ können Sie ein Service-Konto erstellen, dem Registry-Editor und/oder der Registry-Viewer-Rolle zuweisen (ob Sie Push/Pull-Zugriff benötigen) und sich mithilfe des Token des Service-Kontos bei der Registrierung anmelden.</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">Wenn Sie eine interne OpenShift-Registrierung mit Standard-TLS-Zertifikaten vom Ingress Operator mit einer Route verwenden, müssen Sie den vorherigen Schritt dennoch befolgen, um die Zertifikate auf den Routing-Hostnamen zu patchen. Um die Zertifikate aus dem Ingress-Operator zu extrahieren, können Sie den Befehl verwenden<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">Erstellen Sie ein Geheimnis mit Anmeldeinformationen, um sich in der Bildregistrierung im anzumelden<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Namespace.</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">Wählen Sie die aus<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> kachel und klicken Sie auf Installieren.</block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">Übernehmen Sie im Bildschirm Operator installieren alle Standardparameter und klicken Sie auf Installieren.</block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">Wenn die Installation des Operators erfolgreich abgeschlossen ist, klicken Sie auf „View Operator“.</block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">Klicken Sie dann auf der Kachel Astra Control Center im Operator auf Instanz erstellen.</block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">Füllen Sie die aus<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> Formularfelder und klicken Sie auf Erstellen.</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Geben Sie einen Kontonamen für das Astra Control Center und die Administratordaten ein, z. B. Vorname, Nachname und E-Mail-Adresse.</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">Geben Sie in der Bildregistrierung den FQDN für Ihre Registrierung zusammen mit dem Namen der Organisation ein, den Sie erhalten haben, während Sie die Bilder in die Registrierung schieben (in diesem Beispiel<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>).</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">Wenn Sie eine Registrierung verwenden, für die eine Authentifizierung erforderlich ist, geben Sie den geheimen Namen im Abschnitt Image Registry ein.</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Konfigurieren Sie Skalierungsoptionen für die Ressourcen-Limits von Astra Control Center.</block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Registrieren Sie Ihre Red hat OpenShift-Cluster mit dem Astra Control Center</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">Der erste Schritt besteht darin, die OpenShift Cluster zum Astra Control Center hinzuzufügen und zu verwalten. Gehen Sie zu Clusters, klicken Sie auf Cluster hinzufügen, und laden Sie das hoch<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Datei für den OpenShift-Cluster und klicken Sie auf Storage auswählen.</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Für Backups und Restores in OpenShift-Clustern mit Astra Control Center müssen Sie einen Objekt-Storage-Bucket bereitstellen, der das S3-Protokoll unterstützt. Aktuell werden ONTAP S3, StorageGRID und AWS S3 unterstützt. Im Rahmen dieser Installation wird ein AWS S3-Bucket konfiguriert. Wechseln Sie zu Buckets, klicken Sie auf „Bucket hinzufügen“ und wählen Sie „Allgemeines S3“ aus. Geben Sie die Details zum S3-Bucket und die Zugangsdaten ein, um darauf zuzugreifen, klicken Sie auf das Kontrollkästchen Den Bucket als Standard-Bucket für die Cloud machen, und klicken Sie dann auf Hinzufügen.</block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">Wählen Sie dann die zu schützenden Anwendungen aus.</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">Auf dieser Seite werden die Installations- und Konfigurationsanweisungen für den von der MetalLB verwalteten Load Balancer aufgeführt.</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">Der MetalLB Load Balancer ist vollständig mit Anthos Clusters auf VMware integriert und hat eine automatisierte Bereitstellung als Teil der Admin- und User-Cluster-Setups ab der Version 1.11 durchgeführt. Es gibt Textblöcke in der jeweiligen<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> Konfigurationsdateien, die Sie ändern müssen, um Informationen zum Load Balancer bereitzustellen. Die Lösung wird automatisch auf Ihrem Anthos Cluster gehostet, anstatt externe Ressourcen wie die anderen unterstützten Load Balancer-Lösungen bereitzustellen. Sie können auch einen ip-Pool erstellen, der automatisch Adressen bei der Erstellung von Kubernetes-Services des Typs Load Balancer in Clustern zuweist, die nicht auf einem Cloud-Provider ausgeführt werden.</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Wenn Sie den MetalLB Load Balancer für Anthos Admin aktivieren, müssen Sie einige Zeilen im ändern<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> Abschnitt, der in vorhanden ist<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> Datei: Die einzigen Werte, die Sie ändern müssen, sind die Einstellung des<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block> Adresse und dann die einstellen<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> Als MetalLB. Ein Beispiel hierfür finden Sie im folgenden Code-Snippet:</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">Bei Aktivierung des MetalLB Load Balancer für Anthos-Benutzer-Cluster gibt es jeweils zwei Bereiche<block ref="aba03e96a3a4305fd83dc510e1607415" prefix=" " category="inline-code"></block> Datei, die aktualisiert werden muss. Erstens, in einer Weise ähnlich wie die<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> Datei, müssen Sie die ändern<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block>,<block ref="4fa041ebf362f3965af3570da03ef0fe" prefix=" " category="inline-code"></block>, und<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> Werte in der<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> Abschnitt. Ein Beispiel hierfür finden Sie im folgenden Code-Snippet:</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">Die ingressVIP IP-Adresse muss im Pool der IP-Adressen vorhanden sein, die dem MetalLB Load Balancer später in der Konfiguration zugewiesen wurden.</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">Dann müssen Sie zum navigieren<block ref="0ea77e636e8d12d9ce07b2dab6268822" prefix=" " category="inline-code"></block> Unterabschnitt und ändern Sie den<block ref="045d68a12437e8212f812d2bf506dbc0" prefix=" " category="inline-code"></block> Wenn Sie den Pool im benennen<block ref="146d8d83713f4abd99cafc739779598c" prefix=" " category="inline-code"></block> Variabel. Sie müssen außerdem einen Pool mit ip-Adressen erstellen, den MetalLB Services vom Typ Load Balancer zuweisen kann, indem Sie dem einen Bereich zur Verfügung stellen<block ref="336f9e008319434aa314ef3c1b8a682f" prefix=" " category="inline-code"></block> Variabel.</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">Der Adressenpool kann wie im Beispiel als Bereich bereitgestellt werden, indem er sich auf eine Anzahl von Adressen in einem bestimmten Subnetz beschränkt, oder er kann als CIDR-Notation bereitgestellt werden, wenn das gesamte Subnetz zur Verfügung gestellt wird.</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">Wenn Kubernetes-Services vom Typ loadbalancer erstellt werden, weist MetalLB den Diensten automatisch eine externe IP zu und gibt die IP-Adresse durch Antwort auf ARP-Anfragen an.</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">Weiter: Installieren von Seesaw Load Balancer.</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">Laden Sie anschließend die TLS-Zertifikate der Bildregistrierung auf die OpenShift-Knoten hoch. Erstellen Sie dazu im eine configmap<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Namespace mit den TLS-Zertifikaten und patchen Sie ihn mit der Konfiguration des Cluster-Images, um das Zertifikat vertrauenswürdig zu machen.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">Übersicht über das NetApp Astra Control Center</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">Das NetApp Astra Control Center kann auf einem Red hat OpenShift-Cluster installiert werden. Über den Astra Trident Storage-Orchestrator mit Storage-Klassen und Storage-Back-Ends für NetApp ONTAP Storage-Systeme implementiert und konfiguriert werden.</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">Dieses Dokument an</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Informationen zur Installation und Konfiguration von Astra Trident zur Unterstützung des Astra Control Center finden Sie unter <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>.</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">In einer Umgebung mit Cloud-Anbindung sorgt Astra Control Center mithilfe von Cloud Insights für erweitertes Monitoring und Telemetrie. Liegt keine Cloud Insights-Verbindung vor, ist eingeschränktes Monitoring und Telemetrie (7 Tage mit Kennzahlen) verfügbar und über offene metrische Endpunkte in die nativen Kubernetes-Monitoring-Tools (Prometheus und Grafana) exportiert.</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">Zusätzlich zur kostenpflichtigen Version des Astra Control Center ist eine 90-Tage-Evaluierungslizenz verfügbar. Die Evaluierungsversion wird durch E-Mail und den Slack Community-Kanal unterstützt. Kunden haben Zugriff auf diese Ressourcen, weitere Knowledge-Base-Artikel und Dokumentationen, die über das Produkt-Support-Dashboard verfügbar sind.</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">Besuchen Sie das NetApp Astra Control Center <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">Ein oder mehrere Red hat OpenShift-Cluster. Die Versionen 4.6 EUS und 4.7 werden derzeit unterstützt.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">Astra Trident muss bereits auf jedem Red hat OpenShift-Cluster installiert und konfiguriert sein.</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">Es ist eine Best Practice für jede OpenShift-Installation an einem Standort, die über eine dedizierte SVM für persistenten Storage verfügt. Implementierungen an mehreren Standorten erfordern zusätzliche Storage-Systeme.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Auf jedem OpenShift-Cluster muss ein Trident-Storage-Back-End mit einer durch einen ONTAP-Cluster gesicherten SVM konfiguriert werden.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">Eine Standard-StorageClass-Konfiguration auf jedem OpenShift-Cluster mit Astra Trident als Storage-provisionierung</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">Auf jedem OpenShift-Cluster muss ein Load Balancer installiert und konfiguriert werden, um den Lastausgleich zu ermöglichen und OpenShift Services offenzulegen.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">Siehe den Link <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> Weitere Informationen zu Load Balancer, die zu diesem Zweck validiert wurden.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">Siehe den Link <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> So installieren und konfigurieren Sie eine private OpenShift-Registrierung zu diesem Zweck.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Sie benötigen Cluster-Admin-Zugriff auf das Red hat OpenShift-Cluster.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Sie erhalten eine Admin-Workstation mit den Tools Docker oder Podman, tridentctl und oc oder kubectl, die Sie installiert und Ihrem €Pfad hinzugefügt haben.</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Docker-Installationen müssen über eine Docker-Version größer als 20.10 verfügen, und Podman-Installationen müssen eine Podman-Version größer als 3.0 haben.</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">OperatorHub wird verwendet</block>
  <block id="60e34857d044a02ae86f645c2e97e40f" category="paragraph">Unbehobene Richtlinie in &lt;stdin&gt; - include::Container/rh-os-n_overview_astra_cc_install_manual.adoc[]</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">Automatisiert [Ansible]</block>
  <block id="2b0a99e34b337bd6d8ed27dd9482c9e6" category="paragraph">Ungelöste Direktive in &lt;stdin&gt; - include::Container/rh-os-n_overview_astra_cc_install_ansible.adoc[]</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">Schritte nach der Installation</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">Prüfen Sie die<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> Protokolle, um zu überprüfen, ob die Installation abgeschlossen ist.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">Holen Sie die LastausgleichsIP für den Traefik-Dienst ab.</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">Wenn Sie sich zum ersten Mal über die in CRD angegebene Admin-E-Mail-Adresse bei der Astra Control Center-GUI anmelden, sollten Sie das Passwort ändern.</block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center erfordert eine Lizenz, damit alle Funktionalitäten der IT funktionieren können. Um eine Lizenz hinzuzufügen, navigieren Sie zu Konto &gt; Lizenz, klicken Sie auf Lizenz hinzufügen und laden Sie die Lizenzdatei hoch.</block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">Bei Problemen mit der Installation oder Konfiguration von NetApp Astra Control Center steht die Wissensdatenbank mit bekannten Problemen zur Verfügung<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">Als Nächstes: Registrieren Sie Ihre Red hat OpenShift-Cluster.</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="8a7ac28f4ab44e0d4f4da82c8faf774a" category="summary">Dieses Video, das von dieser Seite aus verlinkt ist, zeigt, wie Anthos auf einem Bare-Metal-Cluster bereitgestellt werden kann.</block>
  <block id="6ca531ff48fc42e961c1b239f4302fab" category="doc">Implementierung eines Anthos auf Bare-einem Metal-Cluster</block>
  <block id="cb0b7b75afe3f65d378ff6ab2c93d899" category="paragraph">In diesem Video erfahren Sie, wie Anthos auf einem Bare-Metal-Cluster bereitgestellt wird.</block>
  <block id="97c62d2df3f6258616bde0882c4b890e" category="inline-link-macro">Weiter: Weitere Informationen.</block>
  <block id="5866caac5ce4e920cd3e5d0cd82ea8b7" category="paragraph"><block ref="5866caac5ce4e920cd3e5d0cd82ea8b7" category="inline-link-macro-rx"></block></block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="summary">Die auf dieser Seite angegebenen Beispiele sind Lösungsvalidierungen und Anwendungsfälle für Anthos mit NetApp.</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="doc">Lösungsvalidierung und Anwendungsfälle</block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Installieren Sie eine Anwendung über die Google Cloud Console</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">Dieser Abschnitt enthält Anpassungen, die reale Benutzer wahrscheinlich bei der Implementierung dieser Lösung in der Produktion ausführen müssen, z. B. die Erstellung einer dedizierten Image-Registrierung oder die Implementierung benutzerdefinierter Load Balancer-Instanzen.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">Informationen Zu Load Balancer Options</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">Konfigurieren Von Privaten Bildregistrien</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">Nutzen Sie NetApp Astra Control, um eine Analyse nach der Sterblichen durchzuführen und Ihre Applikation Restores durchzuführen</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Informationen zur Installation und Konfiguration von Astra Trident zur Unterstützung des Astra Control Center finden Sie unter <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">Es ist Best Practice für jede OpenShift-Installation an einem Standort, die über eine dedizierte SVM für persistenten Storage verfügt. Implementierungen an mehreren Standorten erfordern zusätzliche Storage-Systeme.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Bei Docker-Installationen muss die Docker-Version größer als 20.10 sein, und Podman-Installationen müssen über eine Podman-Version von mehr als 3.0 verfügen.</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Erstellen oder beziehen Sie die kubeconfig-Datei mit Administratorzugriff auf das OpenShift-Cluster, auf dem Astra Control Center installiert werden soll.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">Als Nächstes: Registrieren Sie Ihre Red hat OpenShift Cluster: Red hat OpenShift mit NetApp.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">Lifecycle Management von Applikationen</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">Um eine Anwendung zu erstellen und sie über mehrere Cluster hinweg zu verwalten,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">Navigieren Sie in der Seitenleiste zu „Anwendungen verwalten“, und klicken Sie auf „Anwendung erstellen“. Geben Sie die Details der Anwendung an, die Sie erstellen möchten, und klicken Sie auf Speichern.</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">Anwendung erstellen</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">Nach der Installation der Anwendungskomponenten wird die Anwendung in der Liste angezeigt.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">Applikationsliste</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">Die Anwendung kann nun über die Konsole überwacht und verwaltet werden.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">Next: Features - Governance und Risk.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">Dieser Abschnitt erläutert die Schritte zur Implementierung einer kontinuierlichen Integration und kontinuierlichen Bereitstellung bzw. Bereitstellungs-Pipeline mit Jenkins zur Validierung des Lösungsbetriebs.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">Implementieren Sie eine Jenkins CI/CD-Pipeline mit persistentem Storage: Red hat OpenShift mit NetApp</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">Dieser Abschnitt erläutert die Schritte zur Implementierung einer CI/CD-Pipeline (Continuous Integration/Continuous Delivery) mit Jenkins zur Validierung des Lösungsbetriebs.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Erstellen Sie die Ressourcen, die für eine Implementierung mit Jenkins erforderlich sind</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Um die Ressourcen zu erstellen, die für die Implementierung der Jenkins-Applikation erforderlich sind, gehen Sie wie folgt vor:</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Erstellen Sie ein neues Projekt namens Jenkins.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">In diesem Beispiel haben wir Jenkins mit persistentem Storage implementiert. Um den Jenkins-Build zu unterstützen, erstellen Sie das PVC. Navigieren Sie zu Storage &gt; Persistent Volume Claims und klicken Sie auf Create Persistent Volume Claim. Wählen Sie die Speicherklasse aus, die erstellt wurde, stellen Sie sicher, dass der Name des Persistent Volume Claim jenkins ist, wählen Sie die entsprechende Größe und den entsprechenden Zugriffsmodus aus, und klicken Sie dann auf Erstellen.</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">Implementieren Sie Jenkins mit persistentem Storage</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">Um Jenkins mit persistentem Storage zu implementieren, gehen Sie wie folgt vor:</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">Ändern Sie in der oberen linken Ecke die Rolle von Administrator zu Entwickler. Klicken Sie auf + Hinzufügen und wählen Sie aus Katalog. Suchen Sie in der Suchleiste nach jenkins. Wählen Sie Jenkins Service mit persistentem Storage.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">Klicken Sie Auf<block ref="42dcbbaa226af66223d0680206ea8547" prefix=" " category="inline-code"></block>.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">Standardmäßig werden die Details für die Jenkins-Anwendung ausgefüllt. Ändern Sie die Parameter entsprechend Ihren Anforderungen, und klicken Sie auf Erstellen. Bei diesem Prozess werden alle erforderlichen Ressourcen zur Unterstützung von Jenkins auf OpenShift erstellt.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Die Jenkins-Pods dauern etwa 10 bis 12 Minuten, bis Sie in den Status „bereit“ versetzt wurden.</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">Navigieren Sie, nachdem die Pods instanziiert sind, zu Netzwerk &gt; Routen. Um die Jenkins Webseite zu öffnen, klicken Sie auf die URL für die jenkins Route.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Da OpenShift OAuth beim Erstellen der Jenkins-App verwendet wurde, klicken Sie auf Anmelden mit OpenShift.</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Autorisieren Sie das Jenkins Service-Konto, um auf die OpenShift-Benutzer zuzugreifen.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Die Jenkins Willkommensseite wird angezeigt. Da wir einen Maven-Build verwenden, füllen Sie zuerst die Maven-Installation aus. Navigieren Sie zu Manage Jenkins &gt; Global Tool Configuration, und klicken Sie dann im Maven-Unterkopf auf Add Maven. Geben Sie den Namen Ihrer Wahl ein, und stellen Sie sicher, dass die Option automatisch installieren ausgewählt ist. Klicken Sie auf Speichern .</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">Sie können jetzt eine Pipeline erstellen, um den CI/CD-Workflow zu demonstrieren. Klicken Sie auf der Startseite im linken Menü auf Neue Jobs oder Neues Element erstellen.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">Geben Sie auf der Seite Artikel erstellen den Namen Ihrer Wahl ein, wählen Sie Pipeline aus, und klicken Sie auf OK.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Wählen Sie die Registerkarte Pipeline aus. Wählen Sie im Dropdown-Menü Testprobe-Pipeline Github + Maven aus. Der Code wird automatisch ausgefüllt. Klicken Sie auf Speichern .</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">Klicken Sie auf Jetzt erstellen, um die Entwicklung durch die Vorbereitungs-, Build- und Testphase auszulösen. Es kann einige Minuten dauern, bis der gesamte Build-Prozess abgeschlossen ist und die Ergebnisse des Builds angezeigt werden.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">Bei Codeänderungen kann die Pipeline so neu aufgebaut werden, dass sie die neue Version der Software patcht, die kontinuierliche Integration und kontinuierliche Bereitstellung ermöglicht. Klicken Sie auf Letzte Änderungen, um die Änderungen von der vorherigen Version zu verfolgen.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Datensicherung in der CI/CD-Pipeline mit Astra Control Center</block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp bietet verschiedene Produkte, die unsere Kunden bei der Orchestrierung und dem Management persistenter Daten in Container-basierten Umgebungen wie Red hat OpenShift unterstützen.</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp bietet verschiedene Produkte, die Sie bei der Orchestrierung und dem Management persistenter Daten in Container-basierten Umgebungen wie Red hat OpenShift unterstützen.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control bietet eine umfassende Auswahl an Storage- und applikationsspezifischen Datenmanagement-Services für zustandsorientierte Kubernetes Workloads auf Basis der NetApp Datensicherungstechnologie. Der Astra Control Service unterstützt statusorientierte Workloads in Cloud-nativen Kubernetes-Implementierungen. Das Astra Control Center unterstützt statusorientierte Workloads in lokalen Implementierungen wie Red hat OpenShift. Weitere Informationen finden Sie auf der NetApp Astra Control Website<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident ist ein Open-Source- und vollständig unterstützter Storage-Orchestrator für Container und Kubernetes-Distributionen, einschließlich Red hat OpenShift. Weitere Informationen finden Sie auf der Astra Trident Website<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">Auf den folgenden Seiten finden Sie zusätzliche Informationen zu den NetApp Produkten, die für das Management von Applikationen und persistentem Storage in Red hat OpenShift mit NetApp validiert wurden:</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">Nächste: Überblick über das NetApp Astra Control Center</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">Erstellen Sie eine VM</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VMs sind statusorientierte Implementierungen, bei denen Volumes das Betriebssystem und die Daten hosten müssen. Da die VMs als Pods ausgeführt werden, werden die VMs mit PVS unterstützt, die über Trident auf NetApp ONTAP gehostet werden. Diese Volumes sind als Festplatten verbunden und speichern das gesamte Dateisystem einschließlich der Boot-Quelle der VM.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">Erstellung einer VM-Architektur</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">Gehen Sie wie folgt vor, um eine virtuelle Maschine im OpenShift-Cluster zu erstellen:</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">Wählen Sie das gewünschte Betriebssystem aus, und klicken Sie auf Weiter.</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">Wenn für das ausgewählte Betriebssystem keine Startquelle konfiguriert ist, müssen Sie es konfigurieren. Wählen Sie unter „Startquelle“ aus, ob Sie das BS-Image aus einer URL oder aus einer Registrierung importieren möchten, und geben Sie die entsprechenden Details an. Erweitern Sie Advanced und wählen Sie die Trident-gestützte StorageClass aus. Klicken Sie anschließend auf Weiter.</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">Boot-Quelle für VM erstellen</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">Wenn für das ausgewählte Betriebssystem bereits eine Startquelle konfiguriert ist, kann der vorherige Schritt übersprungen werden.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">Wenn Sie die virtuelle Maschine anpassen möchten, klicken Sie auf Virtuelle Maschine anpassen und ändern Sie die erforderlichen Parameter.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">Klicken Sie auf Virtual Machine erstellen, um die virtuelle Maschine zu erstellen. Dadurch wird ein entsprechender Pod im Hintergrund bereitgestellt.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">Wenn eine Startquelle für eine Vorlage oder ein Betriebssystem aus einer URL oder aus einer Registrierung konfiguriert ist, wird in der ein PVC erstellt<block ref="1f9b99deb0fa755d5d42404160cfd87f" prefix=" " category="inline-code"></block> Projizieren und Herunterladen des KVM-Gastabbilds auf das PVC. Sie müssen sicherstellen, dass Vorlagen-PVCs über genügend bereitgestellten Speicherplatz verfügen, um das KVM-Gast-Image für das entsprechende Betriebssystem unterzubringen. Diese VES werden dann geklont und als RootDisks an virtuelle Maschinen angehängt, wenn sie mit den entsprechenden Vorlagen in einem Projekt erstellt werden.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">Weiter: Workflows: VM Live Migration</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">Klonen von VMs</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">Das Klonen einer vorhandenen VM in OpenShift wird durch die Unterstützung der Funktion „Volume CSI“ von Astra Trident ermöglicht. Das Klonen von CSI-Volumes ermöglicht die Erstellung eines neuen PVC mithilfe einer vorhandenen PVC als Datenquelle durch die Duplizierung des PV. Nach der Erstellung des neuen PVC funktioniert es als separate Einheit und ohne Verbindung zur PVC-Quelle oder Abhängigkeit.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">Architektur zum Klonen von VMs</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">Das Klonen von CSI-Volumes unterliegt bestimmten Einschränkungen:</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">Die PVC-Quelle und das Ziel-PVC müssen sich im selben Projekt befinden.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">Klonen wird in derselben Storage-Klasse unterstützt.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">Das Klonen kann nur dann durchgeführt werden, wenn Quell- und Ziel-Volumes dieselbe VolumeMode-Einstellung verwenden. Ein Block-Volume kann beispielsweise nur auf einem anderen Block-Volume geklont werden.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">VMs in einem OpenShift-Cluster können auf zwei Arten geklont werden:</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">Durch Herunterfahren der Quell-VM</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">Indem die Quell-VM verfügbar bleibt</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">Durch Herunterfahren der Quell-VM</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">Das Klonen einer vorhandenen VM durch das Herunterfahren der VM ist eine native OpenShift-Funktion, die mit Unterstützung von Astra Trident implementiert wird. Führen Sie folgende Schritte durch, um eine VM zu klonen.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">Navigieren Sie zu Workloads &gt; Virtualisierung &gt; Virtual Machines und klicken Sie neben der zu klonenden virtuellen Maschine auf die Auslassungspunkte.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Klicken Sie auf Virtual Machine klonen, und geben Sie die Details für die neue VM ein.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">Klon-vm</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Klicken Sie auf Virtual Machine klonen. Dadurch wird die Quell-VM heruntergefahren und die Erstellung der Klon-VM initiiert.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">Nach Abschluss dieses Schritts können Sie auf den Inhalt der geklonten VM zugreifen und diesen überprüfen.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">Eine vorhandene VM kann auch geklont werden, indem das vorhandene PVC der Quell-VM geklont und dann mithilfe des geklonten PVC eine neue VM erstellt wird. Bei dieser Methode müssen Sie die Quell-VM nicht herunterfahren. Führen Sie die folgenden Schritte aus, um eine VM zu klonen, ohne sie herunterzufahren.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Navigieren Sie zu Storage &gt; PersistenzVolumeClaims und klicken Sie auf die Ellipse neben dem PVC, das an die Quell-VM angehängt ist.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Klicken Sie auf PVC klonen und geben Sie die Details für das neue PVC an.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">pvc klonen</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">Klicken Sie dann auf Klonen. Dadurch wird ein PVC für die neue VM erstellt.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">Navigieren Sie zu Workloads &gt; Virtualisierung &gt; Virtuelle Maschinen, und klicken Sie auf Erstellen &gt; mit YAML.</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">Hängen Sie im Abschnitt Spec &gt; Template &gt; Spec &gt; Volumes die geklonte PVC an anstatt der Container-Disk. Geben Sie alle anderen Details für die neue VM nach Ihren Anforderungen an.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Klicken Sie auf Erstellen, um die neue VM zu erstellen.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">Nachdem die VM erfolgreich erstellt wurde, zugreifen und überprüfen Sie, ob die neue VM ein Klon der Quell-VM ist.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">Weiter: Workflows: Erstellen Sie eine VM aus einem Snapshot.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element: Red hat OpenShift mit NetApp</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">Auf diese Weise wird beim Ausfall eines Node nach der Umverteilung des Volumes keine Auswirkung auf die Host-Konnektivität über die Abmeldung hinaus und die Anmeldung mit Umleitung zum neuen Speicherort verursacht. Dank iSCSI-Login-Umleitung ist ein NetApp Element Software-Cluster eine selbstheilende und horizontal skalierbare Architektur, die unterbrechungsfreie Upgrades und den Betrieb ermöglicht.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Konfiguration: Aufgaben für den Cluster-Admin</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Die folgenden Aufgaben werden vom Red hat OpenShift Cluster-Admin ausgeführt:</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Melden Sie sich als Cluster-Administrator beim Red hat OpenShift-Cluster an.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">Erstellen Sie zwei Projekte, die unterschiedlichen Projekten entsprechen.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">Erstellen Sie die Entwicklerrolle für Projekt-1.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">Die in diesem Abschnitt angegebene Rollendefinition ist nur ein Beispiel. Entwicklerrollen müssen auf Basis von Anforderungen des Endanwenders definiert werden.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">Erstellen Sie in ähnlicher Weise Entwicklerrollen für Project-2.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">Alle OpenShift- und NetApp-Storage-Ressourcen werden in der Regel durch einen Storage-Administrator gemanagt. Der Zugriff für Storage-Administratoren wird durch die bei der Installation von Trident erstellte Trident-Rolle gesteuert. Darüber hinaus benötigt der Storage Administrator Zugriff auf ResourceQuotas, um den Storage-Verbrauch zu steuern.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">Erstellen Sie eine Rolle zum Verwalten von ResourceQuotas in allen Projekten im Cluster, um sie an den Storage-Administrator anzuschließen.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">Stellen Sie sicher, dass der Cluster mit dem Identitätsanbieter der Organisation integriert ist und dass Benutzergruppen mit Clustergruppen synchronisiert werden. Das folgende Beispiel zeigt, dass der Identitäts-Provider in das Cluster integriert und mit den Benutzergruppen synchronisiert wurde.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">Clusterrollenbinden für Storage-Administratoren konfigurieren.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">Für Storage-Administratoren müssen zwei Rollen gebunden sein: trident-Operator und Ressourcen-Quotas.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Erstellen Sie RoleBindungen für Entwickler, die die Rolle Entwickler-Projekt-1 an die entsprechende Gruppe (ocp-Projekt-1) in Projekt-1 binden.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">Erstellen Sie in Projekt-2 auch Rollen für Entwickler, die die Entwicklerrollen an die entsprechende Benutzergruppe binden.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">Weiter: Storage-Administratoren.</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">Dieses Referenzdokument validiert die Red hat OpenShift-Lösung, die über IPI (Installer Provisioned Infrastructure) in verschiedenen Datacenter-Umgebungen bereitgestellt wird, wie von NetApp validiert. Sie Details zur Storage-Integration in NetApp Storage-Systeme dank des Astra Trident Storage-Orchestrator für das Management von persistentem Storage. Abschließend werden eine Reihe von Validierungen von Lösungen und Anwendungsbeispiele aus der Praxis untersucht und dokumentiert.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: Red hat OpenShift mit NetApp</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">Die Architektur von Red hat OpenShift mit NetApp bietet Kunden folgende Vorteile:</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">Einfache Bereitstellung und Verwaltung von Red hat OpenShift, bereitgestellt mit IPI (Installer Provisioned Infrastructure) auf Bare Metal, Red hat OpenStack Platform, Red hat Virtualization und VMware vSphere.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">Kombinierte Leistung von Enterprise-Containern und virtualisierten Workloads mit Red hat OpenShift, die virtuell auf OSP, RHV oder vSphere oder Bare Metal mit OpenShift Virtualization bereitgestellt wird</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">Konfigurationsmöglichkeiten in der Praxis und Anwendungsfälle, in denen die Funktionen von Red hat OpenShift im Einsatz mit NetApp Storage und Astra Trident, dem Open-Source-Storage-Orchestrator für Kubernetes, hervorgehoben werden.</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">Red hat OpenShift mit NetApp kennt diese Herausforderungen und präsentiert eine Lösung, mit der sich alle Bedenken lösen lassen. Hierzu wird die vollständig automatisierte Implementierung von RedHat OpenShift IPI in der vom Kunden gewünschten Datacenter-Umgebung implementiert.</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">Die Lösung Red hat OpenShift mit NetApp umfasst die folgenden Hauptkomponenten:</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red hat OpenStack Platform</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">Private Cloud-Infrastruktur</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat Virtualization</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">Weiter: Übersicht über Red hat OpenShift.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">Lösungsvalidierung und Anwendungsfälle: Red hat OpenShift mit NetApp</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">Die auf dieser Seite angegebenen Beispiele finden sich Lösungsvalidierung und Anwendungsfälle für Red hat OpenShift mit NetApp.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">Implementierung einer Jenkins CI/CD-Pipeline mit persistentem Storage</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">Konfigurieren Sie Mandantenfähigkeit auf Red hat OpenShift mit NetApp</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">Private Bildregistrien Werden Erstellt</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">Dieses Verfahren dokumentiert die Erstellung einer privaten Image-Registry, die durch ein persistentes Volume von Astra Trident und NetApp ONTAP unterstützt wird.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center erfordert eine Registrierung, um die Bilder zu hosten, die die Astra-Container benötigen. Im folgenden Abschnitt werden die Schritte zum Einrichten einer privaten Registrierung auf dem Red hat OpenShift-Cluster sowie das Drücken der Bilder beschrieben, die für die Installation des Astra Control Center erforderlich sind.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">Wenn Sie die standardmäßigen TLS-Zertifikate für die Registrierungsroute Ingress Operator OpenShift verwenden, können Sie die TLS-Zertifikate mit dem folgenden Befehl abrufen.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">Die interne OpenShift-Registrierung wird durch Authentifizierung gesteuert. Alle OpenShift-Benutzer können auf die OpenShift-Registrierung zugreifen, aber die Vorgänge, die der angemeldete Benutzer durchführen kann, sind von den Benutzerberechtigungen abhängig.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">Führen Sie den folgenden Befehl aus, um ihn auf Dienstkonten zu patchen.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">Führen Sie die folgenden Schritte aus, um ein Bild von den Arbeitsstationen getrennt vom OpenShift-Knoten zu schieben oder zu ziehen.</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ HINWEIS: Wenn Sie verwenden<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> Benutzer, um sich bei der privaten Registrierung anzumelden, dann Token statt Passwort verwenden.</block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Workload-Migration via Astra Control Center: Red hat OpenShift mit NetApp</block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp verfügt über mehrere Storage-Plattformen, die für Trident Storage Orchestrator geeignet sind, um Storage für auf Red hat OpenShift implementierte Applikationen bereitzustellen.</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp verfügt über verschiedene Storage-Plattformen, die sich für unseren Astra Trident Storage Orchestrator für die Bereitstellung von Storage für Applikationen eignen, die auf Red hat OpenShift implementiert sind.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">Auf den folgenden Seiten finden Sie zusätzliche Informationen zu den in Red hat OpenShift mit NetApp validierten NetApp Storage-Systemen:</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">Governance und Risiko</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">Mit dieser Funktion können Sie Compliance-Richtlinien für verschiedene Cluster definieren und sicherstellen, dass die Cluster diesen Anforderungen entsprechen. Sie können die Richtlinien so konfigurieren, dass Abweichungen oder Verstöße gegen die Regeln informiert oder korrigiert werden.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">Navigieren Sie über die Seitenleiste zu Governance und Risiko.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">Um Compliance-Richtlinien zu erstellen, klicken Sie auf Create Policy, geben Sie die Details der Richtlinienstandards ein, und wählen Sie die Cluster aus, die dieser Richtlinie entsprechen sollen. Wenn Sie die Verstöße dieser Richtlinie automatisch beheben möchten, aktivieren Sie das Kontrollkästchen Enforce, falls unterstützt, und klicken Sie auf Create.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">Erstellen einer Compliance-Richtlinie</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">Nachdem alle erforderlichen Richtlinien konfiguriert wurden, können alle Richtlinien oder Cluster-Verstöße über das Advanced Cluster Management überwacht und korrigiert werden.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">Richtlinienüberwachung</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">Weiter: Merkmale - Beobachtbarkeit.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP Cluster</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident wird auf dem Cluster installiert</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">Admin-Workstation mit installierten tridentctl- und oc-Tools, die zur €Pfad hinzugefügt wurden</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">Administratorzugriff auf ONTAP</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">Cluster-Admin-Zugriff auf OpenShift-Cluster</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">Cluster ist mit Identity Provider integriert</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">Der Identitätsanbieter ist so konfiguriert, dass er in verschiedenen Teams effizient zwischen Benutzern unterscheiden kann</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">Weiter: Cluster Administrator-Aufgaben.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Erstellen Sie eine VM aus einem Snapshot</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Mit Astra Trident und Red hat OpenShift können Benutzer in von ihr bereitgestellten Storage-Klassen einen Snapshot eines persistenten Volumes erstellen. Mit dieser Funktion können Benutzer eine zeitpunktgenaue Kopie eines Volumes erstellen oder dasselbe Volume in einen vorherigen Zustand zurückversetzen. Ob Rollback, Klonen oder Datenwiederherstellung – lassen sich in unterschiedlichen Anwendungsfällen einsetzen.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">Für Snapshot-Vorgänge in OpenShift müssen die Ressourcen VolumeSnapshotClass, VolumeSnapshot und VolumeSnapshotContent definiert werden.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">Ein VolumeSnapshotContent ist der tatsächliche Snapshot, der von einem Volume im Cluster erstellt wurde. Es handelt sich um eine Cluster-weite Ressource, die dem PersistenzVolume für Storage gleicht.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">Ein VolumeSnapshot ist eine Anforderung zum Erstellen des Snapshots eines Volumes. Es ist analog zu einem PersistentVolumeClaim.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">Mit VolumeSnapshotClass kann der Administrator verschiedene Attribute für einen VolumeSnapshot festlegen. Damit können Sie unterschiedliche Attribute für verschiedene Snapshots haben, die vom selben Volume erstellt wurden.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">VM aus der Snapshot Architektur</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">Um einen Snapshot einer VM zu erstellen, führen Sie die folgenden Schritte aus:</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">Erstellen Sie eine VolumeSnapshotKlasse, die dann zum Erstellen eines VolumeSnapshots verwendet werden kann. Navigieren Sie zu Storage &gt; VolumeSnapshotClasses und klicken Sie auf Create VolumeSnapshotClass.</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">Geben Sie den Namen der Snapshot-Klasse ein, geben Sie csi.trident.netapp.io für den Treiber ein, und klicken Sie auf Erstellen.</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Erstellen Sie die Snapshot-Klasse</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">Identifizieren Sie die PVC, die an die Quell-VM angeschlossen ist, und erstellen Sie dann einen Snapshot dieser PVC. Navigieren Sie zu<block ref="fbbf264c8665570001a09df2b42a9873" prefix=" " category="inline-code"></block> Und klicken Sie auf VolumeSnapshots erstellen.</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Wählen Sie das PVC aus, für das Sie den Snapshot erstellen möchten, geben Sie den Namen des Snapshots ein oder übernehmen Sie den Standardwert, und wählen Sie die entsprechende VolumeSnapshotClass aus. Klicken Sie dann auf Erstellen.</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Erstellen Sie Snapshot</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">Dadurch wird die Momentaufnahme des PVC zu diesem Zeitpunkt erstellt.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">Erstellen Sie aus dem Snapshot eine neue VM</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">Stellen Sie zuerst den Snapshot in einer neuen PVC wieder her. Navigieren Sie zu „Storage“ &gt; „VolumeSnapshots“, klicken Sie auf die Ellipsen neben dem Snapshot, den Sie wiederherstellen möchten, und klicken Sie auf „als neues PVC wiederherstellen“.</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">Geben Sie die Details des neuen PVC ein, und klicken Sie auf Wiederherstellen. Dadurch wird ein neues PVC erzeugt.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Wiederherstellung des Snapshots in einer neuen PVC</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">Erstellen Sie dann eine neue VM aus diesem PVC. Navigieren Sie zu Workloads &gt; Virtualisierung &gt; Virtuelle Maschinen, und klicken Sie auf Erstellen &gt; mit YAML.</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">Geben Sie im Abschnitt Spec &gt; Template &gt; spec &gt; Volumes das neue PVC an, das aus Snapshot erstellt wurde, anstatt von der Container-Festplatte aus. Geben Sie alle anderen Details für die neue VM nach Ihren Anforderungen an.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">Nachdem die VM erfolgreich erstellt wurde, können Sie auf die neue VM zugreifen und diese überprüfen, ob sie denselben Status hat wie die VM, deren PVC zum Zeitpunkt der Snapshot-Erstellung verwendet wurde.</block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">Der NetApp Virtual Desktop Service kann bei der Konnektivität zwischen lokalen Ressourcen und Cloud-Ressourcen auf den lokalen Storage erweitert werden. Unternehmen können die Verbindung zu Microsoft Azure über Express Route oder eine IPsec-VPN-Verbindung zwischen Standorten herstellen. Sie können auch Verbindungen zu anderen Clouds auf ähnliche Weise erstellen, entweder über eine dedizierte Verbindung oder über einen IPsec VPN-Tunnel.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">Hybrid Cloud-Umgebung</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">Für die Lösungsvalidierung verwendeten wir die in der folgenden Abbildung dargestellte Umgebung.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">Vor Ort hatten wir mehrere VLANs für das Management, Hosts zur Remote-Desktop-Session usw. Sie befanden sich im Subnetz 172.21.146-150.0/24 und wurden mithilfe des Microsoft Remote Routing Access Service an das Unternehmensnetzwerk weitergeleitet. Außerdem haben wir folgende Aufgaben ausgeführt:</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Wir haben die öffentliche IP des Microsoft Routing and Remote Access Servers (RRAS; identifiziert mit IPchicken.com) festgestellt.</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Wir haben eine Ressource für Virtual Network Gateway (Routing-basiertes VPN) auf Azure Subscription erstellt.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Wir haben die Verbindung erstellt, die die lokale Netzwerk-Gateway-Adresse für die öffentliche IP des Microsoft RRAS-Servers bereitstellt.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">Wir haben die VPN-Konfiguration auf RRAS abgeschlossen, um eine virtuelle Schnittstelle mit vorgemeinsamer Authentifizierung zu erstellen, die bei der Erstellung des VPN-Gateways bereitgestellt wurde. Bei korrekter Konfiguration sollte sich das VPN im Status „Verbunden“ befinden. Anstelle von Microsoft RRAS können Sie auch pfSense oder andere relevante Tools verwenden, um den Site-to-Site IPsec VPN-Tunnel zu erstellen. Da es sich um eine Routingbasierte handelt, wird der Datenverkehr anhand der konfigurierten Subnetze umgeleitet.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory bietet Identitätsauthentifizierung basierend auf OAuth. Für die Authentifizierung von Enterprise-Clients ist in der Regel eine NTLM- oder Kerberos-basierte Authentifizierung erforderlich. Microsoft Azure Active Directory-Domänendienste führen Passwort-Hash-Synchronisierung zwischen Azure Active Directory und lokalen Domänencontrollern mithilfe von ADConnect durch.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">Für diese Hybrid VDS-Lösungsvalidierung wurde zunächst in Microsoft Azure implementiert und dann noch ein zusätzlicher Standort mit vSphere hinzugefügt. Der Vorteil bei diesem Ansatz besteht darin, dass Plattformservices in Microsoft Azure implementiert und anschließend über das Portal ohne weiteres gesichert wurden. Auf Services kann von überall aus problemlos zugegriffen werden, selbst wenn die Site-Site-VPN-Verbindung nicht verfügbar ist.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">Zum Hinzufügen einer weiteren Site haben wir ein Tool namens DCConfig verwendet. Die Verknüpfung zur Anwendung ist auf dem Desktop der VM des Cloud Workspace Manager (CWMgr) verfügbar. Nachdem diese Anwendung gestartet wurde, navigieren Sie zur Registerkarte „DataCenter Sites“, fügen Sie den neuen Datacenter-Standort hinzu, und geben Sie die erforderlichen Informationen wie unten gezeigt ein. Die URL verweist auf die vCenter IP. Stellen Sie sicher, dass die CWMgr VM mit vCenter kommunizieren kann, bevor Sie die Konfiguration hinzufügen.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">Stellen Sie sicher, dass vSphere PowerCLI 5.1 auf CloudWorkspace Manager installiert ist, um die Kommunikation mit VMware vSphere Umgebung zu ermöglichen.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">Die folgende Abbildung zeigt die Konfiguration des Datacenter-Standorts vor Ort.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">Beachten Sie, dass Filteroptionen für Computing-Ressourcen auf Basis des jeweiligen Clusters, Host-Namens oder freien RAM-Speicherplatzes verfügbar sind. Die Filteroptionen für Storage-Ressourcen beinhalten den minimalen freien Speicherplatz auf Datastores oder die maximale Anzahl von VMs pro Datenspeicher. Datastores können mit regulären Ausdrücken ausgeschlossen werden. Klicken Sie auf die Schaltfläche Speichern, um die Konfiguration zu speichern.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">Um die Konfiguration zu validieren, klicken Sie auf die Schaltfläche Test oder klicken Sie auf Hypervisor laden und prüfen Sie die Dropdown-Liste unter vSphere. Er sollte mit entsprechenden Werten gefüllt werden. Es empfiehlt sich, den primären Hypervisor für den Standard-Bereitstellungsstandort auf „Ja“ gesetzt zu lassen.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">Die auf VMware vSphere erstellten VM-Vorlagen werden als Sammlungen auf VDS verwendet. Provisioning-Sammlungen haben zwei Formen: Shared IT und VDI. Der Sammeltyp für Shared Provisioning wird für Remote Desktop Services verwendet, bei denen eine einzelne Ressourcenrichtlinie auf alle Server angewendet wird. Der VDI-Typ wird für WVD-Instanzen verwendet, denen die Ressourcenrichtlinie individuell zugewiesen wird. Den Servern in einer Bereitstellungssammlung kann eine der folgenden drei Rollen zugewiesen werden:</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA.* Kombination von Terminal Services und Data Server-Rolle.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*TS.* Terminaldienste (Session Host).</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">* DATA.* File Server oder Database Server. Wenn Sie die Serverrolle definieren, müssen Sie die VM-Vorlage und den Storage (Datenspeicher) auswählen. Der ausgewählte Datenspeicher kann auf einen bestimmten Datenspeicher beschränkt werden. Alternativ kann die am wenigsten genutzte Option verwendet werden, bei der der Datenspeicher basierend auf der Datennutzung ausgewählt wird.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">Jede Implementierung verfügt über Standardeinstellungen für VM-Ressourcen für die Cloud-Ressourcenzuweisung basierend auf „aktiven Benutzern“, „Feste“, „Serverlast“ oder „Benutzeranzahl“.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">Nächster: Einzelserver-Lasttest mit Login VSI</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">Mit einer hybriden VDI mit NetApp VDS können Service-Provider und Virtual Desktop-Administratoren der Enterprise-Klasse Ressourcen problemlos auf andere Cloud-Umgebungen erweitern, ohne ihre Benutzer zu beeinträchtigen. Wenn On-Premises-Ressourcen mit NetApp HCI verfügbar sind, können die GPU-Ressourcen besser kontrolliert und Computing- oder Storage-Nodes nach Bedarf erweitert werden.</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">Mit einer hybriden VDI mit NetApp VDS können Service-Provider und Virtual Desktop-Administratoren der Enterprise-Klasse Ressourcen problemlos auf andere Cloud-Umgebungen erweitern, ohne ihre Benutzer zu beeinträchtigen. Das Vorhandensein von On-Premises-Ressourcen ermöglicht eine bessere Kontrolle von Ressourcen und bietet umfassende Auswahl an Optionen (Computing, GPU, Storage und Netzwerk) zur Erfüllung der Anforderungen.</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">Wechsel zur Cloud aufgrund von rasant anstiegendem Bedarf an Remote-Desktops und -Applikationen</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">Reduzieren der TCO für lange ausgeführte Remote-Desktops und Applikationen, indem sie lokal mit Flash-Storage- und GPU-Ressourcen gehostet werden</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">Einfaches Management von Remote-Desktops und -Applikationen in Cloud-Umgebungen</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">Erleben Sie Remote-Desktops und -Applikationen mit einem Software-als-Service-Modell mit On-Premises-Ressourcen</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">EUC-/VDI-Architekten, die die Anforderungen an ein hybrides VDS verstehen möchten</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">NetApp Partner, die Kunden bei ihren Remote-Desktop- und -Applikationsanforderungen unterstützen möchten</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">Vorhandene NetApp HCI Kunden, die Remote-Desktop- und -Applikationsanforderungen erfüllen möchten</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">Weiter: Übersicht über NetApp Virtual Desktop Services</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">Im Rahmen der Bereitstellung können Sie die File-Services-Methode auswählen, um das Benutzerprofil, die gemeinsam genutzten Daten und den Ordner Home Drive zu hosten. Es stehen File Server, Azure Files oder Azure NetApp Files zur Verfügung. Nach der Implementierung können Sie diese Option jedoch mit dem Command Center-Tool ändern, um auf eine beliebige SMB-Freigabe zu verweisen. Das Hosting mit NetApp ONTAP bietet verschiedene Vorteile.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">Datenmanagement</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">Das Hosting mit NetApp ONTAP bietet verschiedene Vorteile</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">Datenebene Ändern</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">Im Rahmen der Bereitstellung können Sie die File-Services-Methode auswählen, um das Benutzerprofil, die gemeinsam genutzten Daten und den Ordner Home Drive zu hosten. Es stehen File Server, Azure Files oder Azure NetApp Files zur Verfügung. Nach der Implementierung können Sie diese Option jedoch mit dem Command Center-Tool ändern, um auf eine beliebige SMB-Freigabe zu verweisen. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. Informationen zum Ändern der SMB-Freigabe finden Sie unter<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">Globaler Datei-Cache</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">Wenn Benutzer sich über mehrere Standorte innerhalb eines globalen Namespace verteilen, kann Global File Cache die Latenz für häufig genutzte Daten verringern. Die globale Dateicache-Bereitstellung kann mithilfe einer Bereitstellungssammlung und skriptgesteuerter Ereignisse automatisiert werden. Global File Cache wickelt die Lese- und Schreib-Caches lokal ab und unterhält Dateisperren über mehrere Speicherorte hinweg. Global File Cache kann mit allen SMB-File-Servern einschließlich Azure NetApp Files eingesetzt werden.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">Global File Cache erfordert Folgendes:</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">Management-Server (Lizenzverwaltungsserver)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">Kern</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">Edge mit genügend Festplattenkapazität, um die Daten im Cache zu speichern</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC-Dokumentation</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">Informationen zum Herunterladen der Software und zur Berechnung der Festplatten-Cache-Kapazität für Edge finden Sie im<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">Für unsere Validierung haben wir die Kern- und Management-Ressourcen in Azure auf derselben VM und Edge-Ressourcen in NetApp HCI implementiert. Beachten Sie bitte, dass der Core-Bereich der Datenzugriff mit hohen Datenmengen erforderlich ist und der Edge eine Untergruppe des Kerns ist. Nach der Installation der Software müssen Sie vor der Verwendung die Lizenz aktivieren. Um das zu tun, führen Sie folgende Schritte aus:</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">Verwenden Sie im Abschnitt Lizenzkonfiguration den Link Klicken Sie hier, um die Lizenzaktivierung abzuschließen. Dann registrieren Sie den Kern.</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">Geben Sie das Servicekonto an, das für den Global File Cache verwendet werden soll. Informationen zu den erforderlichen Berechtigungen für dieses Konto finden Sie im<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">Fügen Sie einen neuen Back-End-Dateiserver hinzu und geben Sie den Namen oder die IP des Dateiservers an.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">Am Rand muss das Cache-Laufwerk den Laufwerksbuchstaben D. haben Wenn dies nicht der Fall ist, verwenden Sie diskpart.exe, um das Volume auszuwählen und den Laufwerksbuchstaben zu ändern. Mit dem Lizenzserver als Edge registrieren.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">Wenn die automatische Kernkonfiguration aktiviert ist, werden die Kerninformationen automatisch vom Lizenzverwaltungsserver abgerufen.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">Von jedem Client-Rechner aus können die Administratoren, die zum Zugriff auf den Share auf dem Dateiserver verwendet wurden, über GFC Edge mithilfe von UNC Path auf ihn zugreifen<block ref="4fe16e12c05517e32740fd6ba0c0691f" prefix=" " category="inline-code"></block>. Administratoren können diesen Pfad in das Benutzerlogonskript oder GPO einschließen, um zu erreichen, dass Benutzer am Edge-Standort ihre Zuordnung vorantreiben.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">Um Benutzern weltweit einen transparenten Zugriff zu bieten, kann ein Administrator das Microsoft Distributed Filesystem (DFS) mit Links auf File Server Shares und Edge-Standorte einrichten.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">Wenn sich Benutzer basierend auf den Subnetzen anmelden, die der Site zugeordnet sind, wird der entsprechende Link vom DFS-Client zum Zugriff auf die Daten verwendet.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">Die Dateisymbole ändern sich je nach dem Cache einer Datei. Dateien, die nicht im Cache gespeichert sind, haben in der linken unteren Ecke des Symbols ein graues X. Nachdem ein Benutzer an einem Edge-Standort auf eine Datei zugreift, wird diese Datei im Cache gespeichert und das Symbol ändert sich.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">Wenn eine Datei geöffnet ist und ein anderer Benutzer versucht, dieselbe Datei von einem Randort aus zu öffnen, wird der Benutzer mit der folgenden Auswahl aufgefordert:</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">Wenn der Benutzer die Option zum Erhalt einer Benachrichtigung wählt, wenn die Originalversion verfügbar ist, wird der Benutzer wie folgt benachrichtigt:</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Video zu Talon und Azure NetApp Files Deployment</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">Weitere Informationen finden Sie unter<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS-Backup</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS bietet die Datensicherung für Salesforce und Microsoft Office 365, einschließlich Exchange, SharePoint und Microsoft OneDrive. Die folgende Abbildung zeigt, wie NetApp VDS SaaS Backup für diese Datenservices bereitstellt.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">Dieses Video</block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Eine Demonstration zur Datensicherung von Microsoft Office 365 finden Sie unter<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Eine Demonstration der Salesforce-Datensicherung finden Sie unter<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">Weiter: Betriebsmanagement</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI ist eine Hybrid-Cloud-Infrastruktur, die aus einer Kombination von Storage- und Compute-Nodes besteht. Und ist je nach Modell als Einheit mit zwei oder einem Rack erhältlich. Die zur Implementierung von VMs erforderliche Installation und Konfiguration werden mithilfe der NetApp Deployment Engine (nde) automatisiert. Compute-Cluster werden mit VMware vCenter gemanagt, während Storage-Cluster mit dem via nde bereitgestellten vCenter Plug-in gemanagt werden.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">Übersicht über NetApp HCI</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI ist eine Hybrid-Cloud-Infrastruktur, die aus einer Kombination von Storage- und Compute-Nodes besteht. Und ist je nach Modell als Einheit mit zwei oder einem Rack erhältlich. Die zur Implementierung von VMs erforderliche Installation und Konfiguration werden mithilfe der NetApp Deployment Engine (nde) automatisiert. Compute-Cluster werden mit VMware vCenter gemanagt, während Storage-Cluster mit dem via nde bereitgestellten vCenter Plug-in gemanagt werden. Als Teil der nde wird zudem eine Management-VM namens mNode bereitgestellt.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI übernimmt folgende Funktionen:</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">Versionsupgrades</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">Übermittlung von Ereignissen per Push an vCenter</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">VCenter Plug-in-Management</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">Ein VPN-Tunnel zur Unterstützung</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">Den NetApp Active IQ Collector</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">Die Erweiterung von NetApp Cloud Services auf On-Premises-Systeme (ermöglicht eine Hybrid-Cloud-Infrastruktur). In der folgenden Abbildung sind die HCI Komponenten dargestellt.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">Storage-Nodes</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">Storage-Nodes sind als Rack-Einheit in halber oder in voller Breite verfügbar. Zuerst sind mindestens vier Storage-Nodes erforderlich und ein Cluster kann auf bis zu 40 Nodes erweitert werden. Ein Storage-Cluster kann über mehrere Compute-Cluster hinweg gemeinsam genutzt werden. Alle Storage-Nodes verfügen zur Verbesserung der Schreib-Performance über einen Cache-Controller. Ein einzelner Node bietet entweder 50.000 oder 100.000 IOPS mit einer Blockgröße von 4 KB.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">Auf NetApp HCI Storage-Nodes wird die NetApp Element Software ausgeführt. Diese begrenzt-, maximal- und Burst-QoS-Limits. Das Storage-Cluster unterstützt eine Kombination aus Storage-Nodes, wobei ein Storage-Node jedoch ein Drittel der Gesamtkapazität nicht überschreiten darf.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">Compute-Nodes</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">VMware Compatability Guide</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp unterstützt seinen Storage, der mit den im aufgeführten Computing-Servern verbunden ist<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">Compute-Nodes sind in halber Breite, voller Breite und zwei Höheneinheiten verfügbar. Der NetApp HCI H410C und der H610C arbeiten mit skalierbaren Intel Skylake-Prozessoren. Der H615C arbeitet mit skalierbaren Intel Cascade Lake Prozessoren der zweiten Generation. Es sind zwei Compute-Modelle mit GPUs verfügbar: Der H610C enthält zwei NVIDIA M10-Karten und der H615C enthält drei NVIDIA T4-Karten.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">Die NVIDIA T4 enthält 40 RT-Cores, die die für das Echtzeit-Ray-Tracing erforderliche Rechenleistung liefern. Das von Designern und Ingenieuren häufig verwendete Server-Modell kann jetzt auch von Künstlern verwendet werden, um fotorealistische Bilder zu erstellen, bei denen das Licht von Oberflächen wie im wirklichen Leben von den Oberflächen abstrahlt. Diese RTX-fähige GPU erzeugt eine Echtzeit-Ray-Tracing-Performance von bis zu fünf GIGA-Rays pro Sekunde. In Kombination mit der Quadro Virtual Data Center Workstation-Software (Quadro VDWS) ermöglicht es die NVIDIA T4 Künstlern, an jedem Standort und auf jedem Gerät fotorealistische Designs mit exakten Schatten, Reflexionen und Brechungen zu gestalten.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Tensor Cores ermöglichen die Ausführung von Deep-Learning-Inferenz-Workloads. Wenn sie diese Workloads ausführen, kann ein NVIDIA T4 mit Quadro VDWS bis zu 25-mal schneller als eine VM, die von einem rein CPU-basierten Server angetrieben wird. Ein NetApp H615C mit drei NVIDIA T4-Karten in einer Rack-Einheit ist eine ideale Lösung für Grafik- und rechenintensive Workloads.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">In der folgenden Abbildung werden NVIDIA-GPU-Karten aufgeführt und deren Funktionen miteinander verglichen.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">M10 GPU bleibt die beste TCO-Lösung für Knowledge-Worker-Anwendungsfälle. Die T4 ist jedoch eine hervorragende Alternative, wenn beispielsweise im Unternehmen eine einheitliche GPU verwendet werden soll, die sich für verschiedene Anwendungsfälle eignet, beispielsweise für virtuelle Workstations, Grafikleistung, interaktives Echtzeit-Rendering und Inferenz. Dank der T4 können DIE IT-TECHNIKER die GPU-Ressourcen zur Durchführung unterschiedlicher Workloads nutzen―beispielsweise um tagsüber VDI und nachts Compute-Workloads auszuführen.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">Der H610C Compute-Node ist zwei Höheneinheiten groß. Der H615C ist eine Höheneinheit groß und verbraucht weniger Strom. Der H615C unterstützt H.264 und H.265 (High Efficiency Video Coding [HEVC]) 4:4:4-Codierung und -Dekodierung. Er unterstützt auch den zunehmend Mainstrean VP9-Dekoder. Selbst das von YouTube bereitgestellte WebM-Container-Paket verwendet den VP9-Codec für Videos.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">Die Anzahl der Nodes in einem Compute-Cluster wird von VMware vorgegeben und beträgt derzeit 96 Nodes mit VMware vSphere 7.0 Update 1. Die Kombination verschiedener Compute-Node-Modelle in einem Cluster wird unterstützt, wenn Enhanced vMotion Compatibility (EVC) aktiviert ist.</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">Als Nächstes: NVIDIA-Lizenzierung</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">Der NetApp Virtual Desktop Service bietet eine einfach zu nutzende Umgebung, in der virtuelle Desktop-Computer und Applikationen leicht zu belegen sind, und konzentriert sich auf geschäftliche Herausforderungen. Durch die Erweiterung von VDS mit NetApp HCI lassen sich leistungsstarke NetApp Funktionen in einer VDS-Umgebung nutzen, einschließlich Inline-Deduplizierung, Data-Compaction, Thin Provisioning und Komprimierung.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">Der NetApp Virtual Desktop Service bietet eine einfach zu nutzende Umgebung, in der virtuelle Desktop-Computer und Applikationen leicht zu belegen sind, und konzentriert sich auf geschäftliche Herausforderungen. Durch die Erweiterung von VDS auf die lokale ONTAP Umgebung können Unternehmen leistungsstarke NetApp Funktionen in einer VDS-Umgebung nutzen, darunter Rapid Clone, Inline-Deduplizierung, Data-Compaction, Thin Provisioning Und Komprimierung. Diese Funktionen senken die Storage-Kosten und verbessern die Performance mit All-Flash-Storage. Mit VMware vSphere Hypervisor, der die Server-Bereitstellung durch die Verwendung von Virtual Volumes und vSphere API für die Array-Integration auf ein Minimum reduziert Mithilfe der Hybrid Cloud wählen Kunden die richtige Umgebung für ihre anspruchsvollen Workloads und sparen Geld. Die Desktop-Session, bei der lokale Systeme ausgeführt wird, kann richtlinienbasiert auf Cloud-Ressourcen zugreifen.</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp bietet viele Cloud-Services, einschließlich der schnellen Bereitstellung von Virtual Desktop mit WVD oder Remote Applikationen, einschließlich der schnellen Integration mit Azure NetApp Files.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">NetApp Virtual Desktop Service – Überblick</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp bietet viele Cloud-Services an, darunter die schnelle Bereitstellung von Virtual Desktop mit WVD oder Remote-Applikationen und die schnelle Integration mit Azure NetApp Files.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">Üblicherweise dauert die Bereitstellung und Bereitstellung von Remote Desktop Services für Kunden Wochen. Abgesehen von der Provisionierung kann es schwierig sein, Applikationen, Benutzerprofile, gemeinsam genutzte Daten und Gruppenrichtlinienobjekte zu managen, um Richtlinien durchzusetzen. Firewall-Regeln können die Komplexität erhöhen und erfordern eigene Kenntnisse und Tools.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Mit dem Microsoft Azure Windows Virtual Desktop Service übernimmt Microsoft die Wartung der Komponenten von Remote Desktop Services, sodass Kunden sich auf die Bereitstellung von Workspaces in der Cloud konzentrieren können. Kunden müssen den gesamten Stack bereitstellen und managen, für den das Management von VDI-Umgebungen besondere Fähigkeiten erforderlich sind.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">Mit VDS können Kunden virtuelle Desktops schnell implementieren, ohne sich Gedanken darüber machen zu müssen, wo Komponenten wie Broker, Gateways, Agents usw. installiert werden müssen. Kunden, die die vollständige Kontrolle über ihre Umgebung benötigen, können mit einem Professional Services Team zusammenarbeiten, um ihre Ziele zu erreichen. Kunden nutzen VDS als Service und können sich somit auf ihre wichtigsten geschäftlichen Herausforderungen konzentrieren.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS ist ein Software-als-Service-Angebot für das zentrale Management mehrerer Implementierungen in AWS, Azure, GCP oder Private Cloud-Umgebungen. Microsoft Windows Virtual Desktop ist nur auf Microsoft Azure verfügbar. NetApp VDS orchestriert Microsoft Remote Desktop Services in anderen Umgebungen.</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft bietet Multisession unter Windows 10 ausschließlich für Windows Virtual Desktop-Umgebungen auf Azure an. Die Authentifizierung und Identität werden durch die Virtual Desktop-Technologie gehandhabt. WVD erfordert Azure Active Directory Synchronisiert (mit AD Connect) mit Active Directory und Session-VMs, die mit Active Directory verbunden sind. RDS erfordert Active Directory für die Benutzeridentität und Authentifizierung, während VM-Domänen beitreten und verwalten.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">Die folgende Abbildung zeigt eine Beispieltopologie für die Implementierung.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">Jede Bereitstellung ist mit einer Active Directory-Domäne verknüpft und stellt den Clients einen Zugriffspunkt für Arbeitsbereiche und Anwendungen zur Verfügung. Ein Service-Provider oder Unternehmen mit mehreren Active Directory-Domänen verfügt in der Regel über mehr Implementierungen. Eine einzelne Active Directory-Domäne, die mehrere Regionen umfasst, verfügt normalerweise über eine einzige Implementierung mit mehreren Standorten.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Für WVD in Azure bietet Microsoft eine Plattform als Service, die von NetApp VDS verbraucht wird. Für andere Umgebungen orchestriert NetApp VDS die Implementierung und Konfiguration von Microsoft Remote Desktop Services. NetApp VDS unterstützt sowohl WVD Classic ALS auch WVD ARM und kann auch für ein Upgrade vorhandener Versionen verwendet werden.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">Jede Implementierung verfügt über eigene Plattform-Services, die aus Cloud Workspace Manager (REST-API-Endpunkt), einem HTML 5 Gateway (Verbindung zu VMs über ein VDS-Managementportal), RDS Gateways (Access Point für Clients) und einem Domain Controller bestehen. Die folgende Abbildung zeigt die VDS Control Plane Architektur für die Implementierung von RDS.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">Bei RDS-Implementierungen ist der Zugriff auf NetApp VDS über Windows und Browser mithilfe der Client-Software möglich, die angepasst werden kann und das Kundenlogo und -Bilder enthält. Basierend auf den Benutzeranmeldeinformationen bietet es Benutzern Zugriff auf genehmigte Arbeitsbereiche und Anwendungen. Es müssen keine Gateway-Details konfiguriert werden.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">Die folgende Abbildung zeigt den NetApp VDS Client.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">In der Azure WVD-Implementierung übernimmt Microsoft den Zugriffspunkt für die Clients und kann von einem Microsoft WVD-Client genutzt werden, der nativ für verschiedene Betriebssysteme verfügbar ist. Sie ist auch über ein webbasiertes Portal zugänglich. Die Konfiguration der Client-Software muss vom Group Policy Object (GPO) oder auf andere Weise vom Kunden bevorzugt werden.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">Die folgende Abbildung zeigt die VDS Control Plane Architecture für Azure WVD-Implementierungen.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">Neben der Implementierung und Konfiguration der erforderlichen Komponenten übernimmt NetApp VDS auch das Management von Benutzern, das Applikations-Management, die Skalierung von Ressourcen und die Optimierung.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">NetApp VDS kann Benutzer erstellen oder bestehenden Benutzerkonten Zugriff auf Cloud-Workspace oder Applikationsservices gewähren. Das Portal kann auch für das Zurücksetzen von Kennwörtern und die Delegierung der Verwaltung einer Teilmenge von Komponenten verwendet werden. Helpdesk-Administratoren oder Level-3-Techniker können Benutzersitzungen zur Fehlerbehebung Schatten stellen oder eine Verbindung zu Servern innerhalb des Portals herstellen.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS kann die von Ihnen erstellten Bildvorlagen verwenden oder vorhandene vom Markt für die Cloud-basierte Bereitstellung nutzen. Um die Anzahl der zu managenden Images zu verringern, können Sie ein Basis-Image verwenden. Weitere Applikationen, die Sie benötigen, können Sie über das zur Verfügung gestellte Framework bereitstellen. Dazu gehören sämtliche Befehlszeilen-Tools wie Chocolatey, MSIX App-Attached, PowerShell usw. Sogar benutzerdefinierte Skripts können als Teil von Ereignissen des Maschinellen Lebenszyklus verwendet werden.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">Weiter: Übersicht über NetApp HCI</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">Bei Verwendung eines H610C oder H615C muss die Lizenz für die GPU von einem dafür autorisierten NVIDIA-Partner erworben werden.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA-Lizenzierung</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">PARTNERFINDER</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">Bei Verwendung eines H610C oder H615C muss die Lizenz für die GPU von einem dafür autorisierten NVIDIA-Partner erworben werden. NVIDIA-Partner finden Sie mit dem<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. Suche nach Kompetenzen wie Virtual GPU (vGPU) oder Tesla</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">Die NVIDIA vGPU-Software ist in vier Editionen verfügbar:</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC (GRID vPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID Virtual Applikationen (GRID vApps)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro Virtual Data Center Workstation (Quadro VDWS)</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer (vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">GRID Virtual PC</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">Dieses Produkt ist ideal für Benutzer, die einen virtuellen Desktop benötigen, der eine hohe Benutzerfreundlichkeit für Microsoft Windows Applikationen, Browser, HD-Video und Unterstützung für mehrere Monitore bietet. NVIDIA GRID Virtual PC bietet ein natives Arbeiten in einer virtuellen Umgebung, sodass Sie alle PC-Applikationen ohne jede Einschränkung ausführen können.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">GRID Virtual Applikationen</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">GRID vApps richten sich an Unternehmen, die einen RDSH (Remote Desktop Session Host) oder andere Applikations-Streaming- oder sitzungsbasierte Lösungen einsetzen. Auf Windows-Servern gehostete RDSH-Desktops, auf denen Microsoft Windows-Applikationen ohne Leistungseinschränkungen laufen, werden von GRID vApps ebenfalls unterstützt.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro Virtual Data Center Workstation</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">Diese Edition eignet sich ideal für große und anspruchsvolle Designer, die leistungsstarke Anwendungen zur Erstellung von 3D-Inhalten wie Dassault CATIA, SOLIDWORKS, 3DEXCITE, Siemens NX, PTC Creo, Schlumberger Petrel oder Autodesk Maya. NVIDIA Quadro VDWS ermöglicht es Nutzern, überall und auf jedem Gerät auf ihre professionellen Grafik-Applikationen mit vollständigen Funktionen und Performance zuzugreifen.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">In vielen Unternehmen werden rechenintensive Server-Workloads wie künstliche Intelligenz (KI), Deep Learning (DL) und Data Science ausgeführt. In diesen Einsatzbereichen virtualisiert die NVIDIA vComputeServer-Software die NVIDIA-GPU, die rechenintensive Server-Workloads mit Funktionen wie Fehlerkorrektur-Code, Page Retirement, Peer-to-Peer über NVLink und Multi-vGPU beschleunigt.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Eine Quadro VDWS-Lizenz berechtigt Sie zur Nutzung VON GRID vPC und NVIDIA vComputeServer.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">Next-Generation-Implementierung</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">Ein Arbeitsbereich besteht aus einer Desktop-Umgebung, die Remote-Desktop-Sitzungen nutzen kann, die lokal oder in einer beliebigen Cloud-Umgebung gehostet werden. Mit Microsoft Azure kann die Desktop-Umgebung mit Windows Virtual Desktops persistent sein. Jeder Arbeitsbereich ist einer bestimmten Organisation oder einem bestimmten Client zugeordnet.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">Workspace-Management</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">Ein Workspace besteht aus einer Desktop-Umgebung. Dieser kann Remote-Desktop-Sitzungen nutzen, die lokal oder in einer beliebigen unterstützten Cloud-Umgebung gehostet werden. Mit Microsoft Azure kann die Desktop-Umgebung mit Windows Virtual Desktops persistent sein. Jeder Arbeitsbereich ist einer bestimmten Organisation oder einem bestimmten Client zugeordnet. Optionen, die beim Erstellen eines neuen Arbeitsbereichs verfügbar sind, sind in der folgenden Abbildung zu sehen.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">Jeder Arbeitsbereich ist mit einer bestimmten Bereitstellung verknüpft.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">Arbeitsbereiche enthalten zugehörige Apps und App-Services, freigegebene Datenordner, Server und eine WVD-Instanz. Jeder Workspace kann Sicherheitsoptionen kontrollieren, wie beispielsweise Passwortkomplexität, Multi-Faktor-Authentifizierung, Dateiaudits usw. durchgesetzt werden.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">Arbeitsbereiche können den Workload-Zeitplan zum Einschalten zusätzlicher Server steuern, die Anzahl der Benutzer pro Server begrenzen oder den Zeitplan für die Ressourcen festlegen, die für einen bestimmten Zeitraum verfügbar sind (immer ein/aus). Die Ressourcen können auch so konfiguriert werden, dass sie bei Bedarf aktiviert werden können.</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">Der Arbeitsbereich kann bei Bedarf die Standardeinstellungen der VM-Ressourcen für die Implementierung außer Kraft setzen. Für WVD können WVD-Hostpools (die Session-Hosts und App-Gruppen enthalten) und WVD-Workspaces auch über das Portal der Cloud Workspace Management Suite gemanagt werden. Weitere Informationen über den WVD-Host-Pool finden Sie hier<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">Weiter: Applikationsmanagement</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">Mit NetApp VDS können Administratoren Aufgaben an andere delegieren. Sie können Verbindungen zu bereitgestellten Servern herstellen, um Fehler zu beheben, Protokolle anzuzeigen und Audit-Berichte auszuführen. Die Unterstützung von Kunden, Helpdesk-Techniker oder Technikern der Stufe 3 kann bei Bedarf Benutzersitzungen im Schatten stellen, Prozesslisten anzeigen und Prozesse abtöten.</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Belastungstest mit einem Server mit Login VSI</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">Der NetApp Virtual Desktop Service verwendet das Microsoft Remote Desktop Protocol für den Zugriff auf virtuelle Desktop-Sitzungen und -Applikationen. Das Login VSI Tool bestimmt die maximale Anzahl an Benutzern, die auf einem bestimmten Servermodell gehostet werden können. Login VSI simuliert Benutzeranmeldung in bestimmten Intervallen und führt Benutzervorgänge wie das Öffnen von Dokumenten, Lesen und Kompomieren von Mails, Arbeiten mit Excel und PowerPoint, Drucken von Dokumenten, Komprimieren von Dateien und das Erstellen zufälliger Pausen durch. Er misst dann Reaktionszeiten. Die Reaktionszeit der Benutzer ist bei niedriger Server-Auslastung gering und erhöht sich, wenn mehr Benutzersitzungen hinzugefügt werden. Login VSI bestimmt den Basisplan basierend auf den ersten Benutzeranmeldesessions und meldet die maximale Benutzersitzung, wenn die Benutzerantwort 2 Sekunden von der Baseline entfernt ist.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">Der NetApp Virtual Desktop Service verwendet das Microsoft Remote Desktop Protocol, um auf die virtuelle Desktop-Session und Applikationen zuzugreifen. Um die maximale Anzahl von Benutzern zu bestimmen, die auf einem bestimmten Servermodell gehostet werden können, haben wir das Login VSI-Tool verwendet. Login VSI simuliert Benutzeranmeldung in bestimmten Intervallen und führt Benutzervorgänge durch, wie z. B. das Öffnen von Dokumenten, Lesen und Komprimieren von Mails, Arbeiten mit Excel und PowerPoint, Drucken von Dokumenten, Komprimieren von Dateien, Zufallspausen usw. Er misst auch Reaktionszeiten. Die Reaktionszeit der Benutzer ist bei niedriger Server-Auslastung gering und erhöht sich, wenn mehr Benutzersitzungen hinzugefügt werden. Login VSI bestimmt den Basisplan basierend auf den ersten Benutzeranmeldesessions und meldet die maximalen Benutzersitzungen, wenn die Benutzerantwort 2 Sekunden von der Baseline entfernt ist.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">Die folgende Tabelle enthält die Hardware, die für diese Validierung verwendet wird.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">Zählen</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">Drei in einem Cluster für Launchers, AD, DHCP und so weiter. Ein Server für Auslastungstests.</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2x24C Intel Xeon Gold 6282 @2,1 GHz. 1,5 TB RAM:</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">Die folgende Tabelle enthält die für diese Validierung verwendete Software.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">Produkt</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM-Vorlage Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">Server-Betriebssystem für RDSH</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7, Update 3</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">Hypervisor</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 Update 3f</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware Management Tool</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Die Login VSI-Testergebnisse lauten wie folgt:</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM-Konfiguration</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI-Baseline</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI max</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">8 vCPUs, 48 GB RAM, 75 GB Festplatte, 8 Q vGPU-Profil</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">12 vCPUs, 128 GB RAM, 75 GB Festplatte</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">Da die Sub-NUMA-Grenzen und das Hyper-Threading berücksichtigt wurden, hängen die acht VMs, die für VM-Tests und -Konfiguration ausgewählt wurden, von den Kernen ab, die auf dem Host verfügbar sind.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">Wir haben auf dem H610C 10 Launcher VMs verwendet, die das RDP-Protokoll verwendet haben, um eine Verbindung zur Benutzersitzung herzustellen. Die folgende Abbildung zeigt die Login VSI-Verbindungsinformationen.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">Die folgende Abbildung zeigt die Login VSI Reaktionszeit gegenüber den aktiven Sitzungen für den H610C.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">In der folgenden Abbildung wird die Login VSI Reaktionszeit im Vergleich zu aktiven Sitzungen für den H615C angezeigt.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">Die Performance-Kennzahlen von Cloud Insights während der H615C Login VSI Tests für den vSphere Host und VMs werden in der folgenden Abbildung dargestellt.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">Weiter: Management Portal</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">Auf dieser Seite werden das DCConfig-Tool, die TestVdc-Tools und die Protokolldateien erläutert.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">Tools und Protokolle</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig-Tool</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">Das DCCconfig-Tool unterstützt die folgenden Hypervisor-Optionen zum Hinzufügen einer Site:</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">Workspace-spezifische Laufwerksbuchstaben-Zuordnung für gemeinsam genutzte Daten kann über GPO bearbeitet werden. Professional Services oder das Support-Team können über die Registerkarte „Advanced“ Einstellungen wie Active Directory-Organisationsnamen, die Option zum Aktivieren oder Deaktivieren der Bereitstellung von FSLogix, verschiedene Zeitlimits usw. anpassen.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Command Center (zuvor als TestVdc-Tools bekannt)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Command Center – Übersicht</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Informationen zum Starten von Command Center und der erforderlichen Rolle finden Sie im <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">Sie können folgende Vorgänge durchführen:</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">Ändern Sie den SMB-Pfad für einen Arbeitsbereich.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">Ändern Sie die Site für die Provisioning-Sammlung.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">Log-Dateien</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">Automatisierungsprotokolle</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>Prüfen <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">Betriebsmanagement</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">Seite „Fehlerbehebung bei fehlgeschlagenen VDA-Aktionen“</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">Informationen zu VDS-Logfiles finden Sie im<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">Seite VDA-Komponenten und Berechtigungen</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">Weitere Informationen zu den erforderlichen Mindestberechtigungen finden Sie im<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">Seite Klonen von Virtual Machines</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">Wenn Sie einen Server manuell klonen möchten, lesen Sie die<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">Feature-Seite „Automatische Vergrößerung des Festplattenspeicherplatz“</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">Informationen zur automatischen Vergrößerung der VM-Festplattenkapazität finden Sie im<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">Anforderungen für Endbenutzer</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">Informationen zur Identifizierung der Gateway-Adresse für die manuelle Konfiguration des Clients finden Sie im<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Einblicke in die Cloud</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights ist ein webbasiertes Monitoring Tool, mit dem Sie den vollständigen Überblick über Infrastrukturen und Applikationen erhalten, die auf NetApp und anderen Infrastrukturkomponenten von Drittanbietern ausgeführt werden. Cloud Insights unterstützt sowohl Private Cloud- als auch Public Clouds für Monitoring, Fehlerbehebung und Optimierung von Ressourcen.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">Nur die Erfassungseinheit-VM (kann Windows oder Linux sein) muss in einer privaten Cloud installiert werden, um Kennzahlen von Datensammlern zu sammeln, ohne dass Agenten erforderlich sind. Agenten-basierte Datensammler ermöglichen es Ihnen, benutzerdefinierte Metriken von Windows Performance Monitor oder von beliebigen Eingabemaagenten, die Telegraf unterstützt, zu holen.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">Die folgende Abbildung zeigt das Cloud Insights VDS Dashboard.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">Weitere Informationen zu NetApp Cloud Insights finden Sie unter<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">Als Nächstes: Tools und Protokolle</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">Das Portal der NetApp VDS Cloud Workspace Management Suite ermöglicht das zentrale Management verschiedener VDS-Implementierungen, darunter Standorte mit lokalen Ressourcen, administrativen Benutzern, Applikationskatalog und skriptbasierten Ereignissen. Das Portal wird auch von administrativen Benutzern für die manuelle Bereitstellung von Anwendungen verwendet, falls erforderlich, und für die Verbindung mit Maschinen zur Fehlerbehebung.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">Management Portal</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">Das Portal der NetApp VDS Cloud Workspace Management Suite ist verfügbar<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> Und die bevorstehende Version steht zur Verfügung<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">Das Portal ermöglicht das zentrale Management verschiedener VDS-Implementierungen, darunter Standorte für On-Premises-Benutzer, administrative Benutzer, den Applikationskatalog und skriptbasierte Ereignisse. Das Portal wird auch von administrativen Benutzern für die manuelle Bereitstellung von Anwendungen verwendet, falls erforderlich, und für die Verbindung mit Maschinen zur Fehlerbehebung.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">Über dieses Portal können Service-Provider ihren eigenen Channel-Partner hinzufügen, damit sie ihre eigenen Kunden verwalten können.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">Weiter: Benutzerverwaltung</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">NetApp VDS kann mithilfe einer Setup-Applikation, die auf der erforderlichen Codebase verfügbar ist, in Microsoft Azure implementiert werden.</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">NetApp VDS kann mithilfe einer Setup-Applikation, die basierend auf der erforderlichen Codebase verfügbar ist, in Microsoft Azure implementiert werden. Die aktuelle Version ist verfügbar<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> Und die Vorversion des bevorstehenden Produkts ist verfügbar<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">Siehe<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> Anleitungen zur Implementierung.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">Weiter: Hybrid Cloud-Umgebung</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS verwendet Azure Active Directory für die Identitätsauthentifizierung und Azure Active Directory Domain Services für NTLM/Kerberos-Authentifizierung. Das ADConnect Tool kann verwendet werden, um eine On-Prem Active Directory Domain mit Azure Active Directory zu synchronisieren.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">Benutzerverwaltung</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">Neue Benutzer können aus dem Portal hinzugefügt werden, oder Sie können Cloud Workspace für bestehende Benutzer aktivieren. Die Berechtigungen für Arbeitsbereiche und Anwendungsdienste können von einzelnen Benutzern oder Gruppen gesteuert werden. Über das Managementportal können Verwaltungsbenutzer definiert werden, um Berechtigungen für das Portal, die Arbeitsbereiche usw. zu kontrollieren.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">Die folgende Abbildung zeigt die Benutzerverwaltung im NetApp VDS.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">Jeder Workspace befindet sich in einer eigenen Active Directory-Organisationseinheit (OU) unter der OU des Cloud Workspace, wie in der folgenden Abbildung dargestellt.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">Weitere Informationen finden Sie unter<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> Auf Benutzerberechtigungen und Benutzermanagement in NetApp VDS.</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">Wenn eine Active Directory-Gruppe als CRAUserGroup definiert ist, die einen API-Aufruf für das Rechenzentrum verwendet, werden alle Benutzer in dieser Gruppe zur Verwaltung über die Benutzeroberfläche in den CloudWorkspace importiert. Wenn der Cloud-Arbeitsbereich für den Benutzer aktiviert ist, erstellt VDS Home-Ordner für Benutzer, Einstellungsberechtigungen, Aktualisierungen von Benutzereigenschaften usw.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">Wenn VDI-Benutzer aktiviert ist, erstellt VDS einen RDS-Rechner für einzelne Sitzungen, der diesem Benutzer zugewiesen ist. Sie werden zur Bereitstellung der Vorlage und des Datastores aufgefordert.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">Nächster: Workspace-Management</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPUs werden normalerweise für die Grafikvisualisierung (Rendering) verwendet, indem repetitive Rechenberechnungen durchgeführt werden. Diese sich wiederholende Computing-Funktion wird häufig für KI- und Deep-Learning-Anwendungsfälle eingesetzt.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">Überlegungen zu GPUs</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">Für grafikintensive Anwendungen bietet Microsoft Azure die NV Serie auf Basis der NVIDIA Tesla M60 Karte mit einem bis vier GPUs pro VM an. Jede NVIDIA Tesla M60 Karte verfügt über zwei Maxwell-basierte GPUs mit jeweils 8 GB GDDR5-Speicher und insgesamt 16 GB.</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">Eine NVIDIA-Lizenz ist in der NV Serie enthalten.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">Bei NetApp HCI enthält die H615C GPU drei NVIDIA Tesla T4-Karten. Jede NVIDIA Tesla T4-Karte verfügt über eine Touring-basierte GPU mit 16 GB GDDR6-Speicher. Wenn sie in einer VMware vSphere Umgebung verwendet werden, können Virtual Machines die GPU gemeinsam nutzen, wobei jede VM einen dedizierten Frame-Puffer-Speicher hat. Die GPUs auf dem NetApp HCI H615C sind für Ray-Tracing verfügbar, um realistische Bilder einschließlich Lichtreflexionen herzustellen. Bitte beachten Sie, dass Sie einen NVIDIA-Lizenzserver mit einer Lizenz für GPU-Funktionen benötigen.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">Um die GPU zu verwenden, müssen Sie den entsprechenden Treiber installieren, der vom NVIDIA-Lizenzportal heruntergeladen werden kann. In einer Azure-Umgebung ist der NVIDIA-Treiber als GPU-Treiber-Erweiterung verfügbar. Als Nächstes müssen die Gruppenrichtlinien im folgenden Screenshot aktualisiert werden, um GPU-Hardware für Remote-Desktop-Service-Sessions zu verwenden. Sie sollten den H.264-Grafikmodus priorisieren und die Encoder-Funktionalität aktivieren.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">Validierung der GPU-Performance-Überwachung mit Task Manager oder mithilfe der nvidia-smi-CLI bei der Ausführung von WebGL-Samples. Stellen Sie sicher, dass GPU-, Arbeitsspeicher- und Encoderressourcen verbraucht werden.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">Um sicherzustellen, dass die Virtual Machine in der NetApp HCI H615C mit Virtual Desktop Service implementiert wird, definieren Sie eine Site mit der vCenter Cluster-Ressource, die H615C Hosts enthält. Die VM-Vorlage muss das erforderliche vGPU-Profil aufweisen.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">In Shared-Umgebungen mit mehreren Sitzungen sollten mehrere homogene vGPU-Profile zugewiesen werden. Bei professionellen High-End-Grafikapplikationen ist es jedoch besser, jede VM dediziert einem Benutzer zu haben, um VMs voneinander zu isolieren.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">Der GPU-Prozessor kann durch eine QoS-Richtlinie gesteuert werden, und jedes vGPU-Profil kann über dedizierte Frame-Puffer verfügen. Der Encoder und der Decoder werden jedoch für jede Karte freigegeben. Die Platzierung eines vGPU-Profils auf einer GPU-Karte wird von der GPU-Zuweisungsrichtlinie des vSphere Hosts gesteuert, die die Performance (Spread VMs) oder die Konsolidierung (Gruppen-VMs) hervorheben kann.</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">Als Nächstes: Lösungen für die Branche.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">Grafikarbeitsplätze werden typischerweise in Branchen eingesetzt, zum Beispiel Fertigung, Gesundheitswesen, Energie, Medien und Unterhaltung, Bildung, Und so weiter. Häufig ist die Mobilität für grafikintensive Applikationen eingeschränkt.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">Lösungen für die Branche</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">Um das Problem der Mobilität zu lösen, bieten Virtual Desktop Services eine Desktop-Umgebung für alle Arten von Mitarbeitern, von Task Workers bis hin zu Experteneinsätzen, die Hardware-Ressourcen in der Cloud oder mit NetApp HCI verwenden, einschließlich Optionen für flexible GPU-Konfigurationen. MIT VDS können Benutzer von überall aus mit Laptops, Tablets und anderen mobilen Geräten auf ihre Arbeitsumgebung zugreifen.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">Zur Ausführung von Produktions-Workloads mit Software wie ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3ds Max, Dassault Systèmes SOLIDWORKS, Dassault Systèmes CATIA, PTC Creo, Siemens PLM NX usw., Die in verschiedenen Clouds verfügbaren GPUs (Stand Januar 2021) sind in der folgenden Tabelle aufgeführt.</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU-Modell</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute (GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Amazon Web Services (AWS)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">On-Premises (NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">Darüber hinaus sind auch gemeinsame Desktop-Sitzungen mit anderen Benutzern und dedizierte persönliche Desktops verfügbar. Virtual Desktops können über eine oder vier GPUs verfügen oder mit NetApp HCI TeilaufGPUs nutzen. Die NVIDIA T4 ist eine vielseitige GPU-Karte, die sich den Anforderungen eines breiten Spektrums an Benutzer-Workloads anpasst. Jede GPU-Karte auf dem NetApp HCI H615C verfügt über 16 GB Frame-Puffer-Speicher und drei Karten pro Server. Die Anzahl der Benutzer, die auf einem einzelnen H615C Server gehostet werden können, hängt von der Benutzer-Workload ab.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">Benutzer/Server</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">Licht (4 GB)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">Mittel (8 GB)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">Schwer (16 GB)</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">Zur Ermittlung des Benutzertyps führen Sie das GPU-Profiler-Tool aus, während Benutzer mit Anwendungen arbeiten, die typische Aufgaben ausführen. Der GPU-Profiler erfasst die Speicheranforderungen, die Anzahl der Anzeigen und die Auflösung, die Benutzer benötigen. Sie können dann das vGPU-Profil auswählen, das Ihre Anforderungen erfüllt.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">Virtuelle Desktops mit GPUs können eine Anzeigeauflösung von bis zu 8 KB unterstützen. Das Utility nView kann einen einzelnen Monitor in Regionen aufteilen und mit unterschiedlichen Datensätzen arbeiten.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">ONTAP File Storage bietet folgende Vorteile:</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">Ein Single Namespace kann bis zu 20 PB Storage mit 400 Milliarden Dateien anwachsen und dabei keinen großen administrativen Aufwand haben</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">Ein Namespace, der sich mit einem globalen File Cache weltweit erstrecken kann</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">Sichere Mandantenfähigkeit mit gemanagtem NetApp Storage</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">Migration von kalten Daten zu Objektspeichern mit NetApp FabricPool</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">Schnelle Dateistatistiken mit Dateisystemanalysen</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">Storage-Cluster auf bis zu 24 Nodes skalieren, was Kapazität und Performance erhöht</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">Storage-Platzbedarf lässt sich mithilfe von Kontingenten und garantierter Performance mit QoS-Limits kontrollieren</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">Sicherung von Daten durch Verschlüsselung</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">Erfüllen umfassender Anforderungen an Datensicherung und Compliance</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">Flexible Business Continuity-Optionen</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">ONTAP-Funktionen für Virtual Desktop Service:</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">ONTAP-Funktionen für Virtual Desktop Service</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">Die folgenden ONTAP Funktionen machen es zu einer attraktiven Wahl für einen virtuellen Desktop-Service.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">*Scale-out-Dateisystem.* ONTAP FlexGroup-Volumes können auf mehr als 20 PB groß sein und mehr als 400 Milliarden Dateien in einem Single Namespace enthalten. Das Cluster kann bis zu 24 Storage-Nodes enthalten, jedes mit einer flexiblen Anzahl von Netzwerkschnittstellenkarten, je nach verwendetem Modell.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">Die virtuellen Desktops und Home-Ordner der Benutzer, Container mit Benutzerprofilen, gemeinsam genutzte Daten können je nach Bedarf erweitert werden, ohne die Dateisystem-Einschränkungen zu bedenken.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">*Dateisystemanalyse.* mit dem XCP-Tool erhalten Sie Einblicke in gemeinsam genutzte Daten. Mit ONTAP 9.8+ und ActiveIQ Unified Manager können Kunden Dateimetadaten einfach abfragen und abrufen und inaktive Daten identifizieren.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* Cloud-Tiering* ermöglicht die Migration kalter Daten zu einem Objektspeicher in der Cloud oder zu jedem S3-kompatiblen Storage im Datacenter.</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">*Dateiversionen.* Benutzer können Dateien wiederherstellen, die durch NetApp ONTAP Snapshot-Kopien geschützt sind. ONTAP Snapshot Kopien sind sehr platzsparend, da sie nur geänderte Blöcke aufzeichnen.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">*Global Namespace.* die ONTAP FlexCache-Technologie ermöglicht das Remote-Caching von File Storage und vereinfacht das Management gemeinsam genutzter Daten an verschiedenen Standorten mit ONTAP Storage-Systemen.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">*Unterstützung für sichere Mandantenfähigkeit.* Ein einziger physischer Storage Cluster kann als mehrere virtuelle Storage Arrays mit jeweils eigenen Volumes, Storage-Protokollen, logischen Netzwerkschnittstellen, Identitäts- und Authentifizierungsdomäne, Management-Benutzern usw. bereitgestellt werden. Auf diese Weise können Sie das Storage-Array für mehrere Geschäftseinheiten oder Umgebungen nutzen, beispielsweise für Tests, Entwicklung und Produktion.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">Um Performance zu garantieren, können Sie mittels anpassungsfähiger QoS Performance-Level auf Basis von belegtem oder zugewiesenem Speicherplatz festlegen und die Storage-Kapazität mittels Quoten steuern.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">*VMware Integration.* ONTAP Tools für VMware vSphere bietet ein vCenter Plug-in zur Bereitstellung von Datastores, Implementierung von vSphere Host Best Practices und Überwachung von ONTAP Ressourcen.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP unterstützt vStorage APIs zur Array Integration (VAAI) zur Auslagerung von SCSI-/Dateivorgängen auf das Storage Array. ONTAP unterstützt auch vStorage APIs for Storage Awareness (VASA) und Virtual Volumes für Block- und Dateiprotokolle.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">Das SnapCenter Plug-in für VMware vSphere ermöglicht mithilfe der Snapshot Funktion in einem Storage Array das Sichern und Wiederherstellen von Virtual Machines.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager bietet End-to-End-Sichtbarkeit des Storage-Netzwerks in einer vSphere-Umgebung. Administratoren können problemlos alle Latenzprobleme identifizieren, die in virtuellen Desktop-Umgebungen, die auf ONTAP gehostet werden, auftreten können.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">*Einhaltung der Sicherheitsvorschriften* mit ActiveIQ Unified Manager können Sie mehrere ONTAP-Systeme mit Warnmeldungen auf Richtlinienverstöße überwachen.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* Multi-Protokoll-Unterstützung.* ONTAP unterstützt Block (iSCSI, FC, FCoE und NVMe/FC), Datei (NFSv3, NFSv4.1, SMB2.x und SMB3.x) und Storage-Protokolle für Objekte (S3).</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">*Automatisierungsunterstützung* ONTAP bietet REST-API, Ansible und PowerShell-Module zur Automatisierung von Aufgaben mit dem VDS-Verwaltungsportal.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">Weiter: Datenmanagement</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp Cloud</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS Produktdokumentation</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">Das lokale Netzwerk mit Azure verbinden Sie über VPN Gateway</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure-Portal</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows Virtual Desktop</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files-Anmeldung</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">Task Worker können schnell eine Anwendung aus der Liste der ihnen zur Verfügung gestellten Anwendungen starten. App Services veröffentlichen Anwendungen von den Remote Desktop Services-Sitzungshosts. Mit WVD bieten Anwendungsgruppen ähnliche Funktionen aus Windows 10-Hostpools mit mehreren Sitzungen.</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">EUC-/VDI-Lösungen (End User Computing)</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">Egal, ob Sie Virtual Desktops lokal oder in der Cloud implementieren: NetApp verfügt über zahlreiche EUC-/VDI-Lösungen, die Ihre Anforderungen erfüllen.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp Virtual Desktop Services (VDS)</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">Der NetApp Virtual Desktop Service (VDS) orchestriert die Remote Desktop Services (RDS) in führenden Public Clouds sowie auf Private Clouds.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">Verfügbare Lösungen für VDS:</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">Hybrid-Cloud-VDI mit NetApp Virtual Desktop Service</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">End User Computing with VMware Horizon</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp verfügt über verifizierte Architekturen für VMware Horizon mit verschiedenen Computing-Konfigurationen. Zu den verfügbaren Lösungen gehören:</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">End User Computing with VMware (Design Guide)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">End User Computing with VMware and NVIDIA GPUs (Design Guide)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">End User Computing with VMware and NVIDIA GPUs (Deployment Guide)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">Endbenutzer-Computing mit VMware für 3D-Grafik</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">Der NetApp Virtual Desktop Service (VDS) orchestriert die Remote Desktop Services (RDS) in führenden Public Clouds sowie auf Private Clouds. VDS unterstützt Windows Virtual Desktop (WVD) unter Microsoft Azure. VDS automatisiert viele Aufgaben, die nach der Implementierung von WVD oder RDS ausgeführt werden müssen, einschließlich der Einrichtung von SMB-Dateifreigaben (für Benutzerprofile, gemeinsam genutzte Daten und das Benutzer-Home-Laufwerk) sowie der Aktivierung von Windows-Funktionen, Applikations- und Agent-Installation, Firewall sowie Richtlinien usw.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861: Hybrid Cloud VDI mit Virtual Desktop Service</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">Suresh ThopPay, NetApp</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">Benutzer nutzen VDS für dedizierte Desktops, Shared Desktops und Remote-Applikationen. VDS bietet skriptbasierte Ereignisse zur Automatisierung des Anwendungsmanagements für Desktops und verringert die Anzahl der zu verwaltenden Images.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS bietet ein zentrales Management-Portal für den Umgang mit Implementierungen über Public und Private Cloud-Umgebungen hinweg.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">Mehrwert Für Den Kunden</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">Die explosionsartige Zunahme der Mitarbeiter an Remote-Standorten im Jahr 2020 hat die Anforderungen an Business Continuity geändert. IT-Abteilungen stehen bei der schnellen Bereitstellung virtueller Desktops vor neuen Herausforderungen. Sie müssen daher flexible Lösungen bei der Bereitstellung, Remote-Management und die TCO-Vorteile einer Hybrid Cloud benötigen, was die Bereitstellung von On-Premises- und Cloud-Ressourcen vereinfacht. Sie benötigen eine Hybrid-Cloud-Lösung mit folgenden Vorteilen:</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">Adressiert die Realität des Post-COVID-Arbeitsbereichs, um flexible Arbeitsmodelle mit globaler Dynamik zu ermöglichen</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">Schichtarbeit wird ermöglicht, indem die Bereitstellung von Arbeitsumgebungen für alle Mitarbeiter vereinfacht und beschleunigt wird, von Task Workers bis hin zu Power Usern</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">Mobilisiert Ihre Mitarbeiter, indem Sie umfassende, sichere VDI-Ressourcen bereitstellen, unabhängig vom physischen Standort</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">Vereinfachte Hybrid-Cloud-Implementierung</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">Automatisiert und vereinfacht das Management zur Risikominimierung</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">Weiter: Anwendungsfälle</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">Applikationsmanagement</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">Für Büromitarbeiter bis hin zu Power-Usern können die Applikationen, die sie benötigen, manuell über eine Service-Platine bereitgestellt werden. Sie können aber mithilfe der skriptbasierten Ereignisfunktion im NetApp VDS automatisch bereitgestellt werden.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">NetApp Application Berechtigungsseite</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">Weitere Informationen finden Sie im<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">Weiter: ONTAP Funktionen für Virtual Desktop Service</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">Erste Schritte</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">Was ist neu</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">Konvergente Infrastrukturen für KI-Workloads</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">ONTAP AI MIT NVIDIA</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">EF-Series AI mit NVIDIA</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">IBM Spectrum Skalierbarkeit mit NetApp E-Series Storage</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">KI-Inferenzierung am Edge – NetApp mit Lenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP und Lenovo ThinkSystem SR670 für KI</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">NetApp AFF A800 und Fujitsu Server PRIMERGY GX2570 M5 für KI</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">Data Lakes und Daten-Pipelines</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">StorageGRID Data Lake für Workloads für das autonome Fahren</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">Datenverschiebung mit E-Series und BeeGFS für KI</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">Hybrid Cloud AI mit Daten-Caching</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">Orchestation und Management</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">NetApp AI Control Plane für KI-Pipeline und Workspace Orchestation</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">MLRun-Pipeline mit Iguazio</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">NetApp Orchestrierungslösung mit Run:AI</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">Sentiment-Analyse</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">Click-Through-Rate Prediction – Distributed Training in Azure</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">Lane Detection: Verteiltes Training in Azure</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">Conversational AI mit NVIDIA Jarvis</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">Autonomes Fahren</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">Gesundheitswesen – Diagnostische Bildgebung</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">Betrugserkennung Per Kreditkarte</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD: Eine NetApp und NVIDIA Lösung</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">BeeGFS auf NetApp (Design-Leitfaden)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">BeeGFS auf NetApp (Deployment Guide)</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NVIDIA DGX SuperPOD mit NetApp (Design Guide)</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">Erste Schritte/Best Practices</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp und VMware: Erste Schritte</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">Vorteile von NetApp ONTAP für VMware vSphere Administratoren</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">Best Practices für VMware vSphere mit ONTAP</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">VMware in Public Cloud</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp für AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp für Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp für die Google Cloud Platform GSCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">Sicherheit Datensicherung</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware Site Recovery Manager (SRM) mit NetApp ONTAP 9</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">ONTAP-Tools für VMware vSphere - Produktsicherheit</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere Automation</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">Demos und Tutorials</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">Weitere Ressourcen</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Virtual Desktop-Lösungen</block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">NetApp Lösungen für VMware in Hyperscaler-Clouds</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">Unterstützte Storage-Optionen</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">Unterstützte Lösungen</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">Regionale Unterstützung für NFS-Datenspeicher</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp auf AWS (VMC)</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">NetApp Hybrid-Multi-Cloud mit VMware für VMC</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">Konfigurieren Sie die Virtualisierungsumgebung</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">FSX ONTAP als ergänzenden NFS-Datenspeicher: Übersicht</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP als Storage mit Anbindung des Gastsystems</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO als Storage mit Gastverbunden</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">Hybrid-Multi-Cloud-Lösungen für VMC</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">Unterstützung für NFS-Datastores in AWS</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp auf Azure (AVS)</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">NetApp Hybrid-Multi-Cloud mit VMware für AVS</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">ANF als ergänzender NFS Datastore: Überblick</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ANF als Guest Connected Storage</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">Hybrid-Multi-Cloud-Lösungen für AVS</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">Unterstützung für NFS-Datastores in Azure</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">NetApp auf der Google Cloud Platform (GCVE)</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">NetApp Hybrid-Multi-Cloud mit VMware für GCVE</block>
  <block id="8be166a6a918ed4074f79487db89b538" category="sidebar">Zusätzlicher NFS-Datenspeicher – private Vorschau</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS als Gastvernetzter Storage</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">Hybrid-Multi-Cloud-Lösungen für GCVE</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">Sicherheitsüberblick – NetApp CVS in Google Cloud</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">Tools</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">FSX für ONTAP + VMC TCO-Rechner</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">FSX für ONTAP + VMC Simulator</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">ANF + AVS TCO-RECHNER</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + AVS-Simulator</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">Zusätzliche NFS-Datastore-Übersicht</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">Zusätzliche NFS-Datastore-Optionen</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">Optionen Für Gast-Connected-Storage</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">Workload-Schutz-Lösungen</block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">Workload-Migrationslösungen</block>
  <block id="b2299b17275cb6ba71114e61d9bbae4e" category="sidebar">In Kürze...</block>
  <block id="10b6eb5523fab1d4b99c4fdfb54bf176" category="sidebar">Workload-Extend-Lösungen</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">Zusätzlicher NFS-Datenspeicher – öffentliche Vorschau (Microsoft)</block>
  <block id="860ab177fe05389a6d0ec0842bd1e818" category="sidebar">In Kürze...</block>
  <block id="d761cb8e8504381eb60fe9aea1bcb3e7" category="sidebar">Workload Migrate Solutions</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">Google Cloud VMware Engine mit NetApp Cloud Volumes Service</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">Sicherheitsüberblick – NetApp Cloud Volumes Service (CVS) in Google Cloud</block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">Zusätzlicher NFS Datastore: Überblick</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">Zusätzliche NFS-Datenspeicher: Optionen</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">VMware Cloud on AWS: Neue Region, externe Storage- und Kaufoptionen</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">Apache Spark Workload mit NetApp Storage Solution</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">Lösungen Für Moderne Datenanalysen Im Überblick</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">Best Practices In Sich Vereint</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Best Practices für Confluent Kafka</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 und Splunk Enterprise</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">NetApp EF600 mit Splunk Enterprise</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">Hybrid-Cloud-Lösungen – Spark und Hadoop Nutzungsfälle</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">Weitere Ressourcen</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog: Apache Spark spielt im NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog: Verwenden Sie XCP für die Datenmigration von einem Data Lake und HPC zu ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: Big Data Analytics Playlist</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">Oracle 19c RAC-Datenbanken auf FlexPod DataCenter</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">Technischer Bericht: SAP with Oracle on UNIX and NFS with NetApp Clustered Data ONTAP and SnapManager for SAP 3.4</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">Implementieren Sie Oracle Datenbanken auf NetApp ONTAP</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="sidebar">Automatisierte Implementierung von Oracle 19c für ONTAP auf NFS</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Automatisierte Oracle Datensicherung</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Oracle Datenbanken auf NetApp EF-Series</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">SQL Server geschult sind</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">SQL Server auf Azure NetApp Files</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">SAP with Microsoft SQL Server on Windows Using Clustered Data ONTAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Modernisieren von Microsoft SQL Server</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Best Practices Guide for Microsoft SQL Server with NetApp EF-Series</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">Hybrid-Cloud-Datenbanklösungen</block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">Best Practices für Oracle Database Deployment auf EC2/FSX</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">Hybrid-Cloud-Datenbanklösungen mit SnapCenter</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">Anthos mit NetApp</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="sidebar">Integration von NetApp Storage</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">Red hat OpenShift mit NetApp</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">VMware Tanzu mit NetApp</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">DevOps mit NetApp</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">Über unsere Ressourcen für Container</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">Über Unsere Partnerlösungen</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Anthos-Website</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Red hat OpenShift-Website</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">VMware Tanzu Website</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">Dokumentation für NetApp Lösungen</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="sidebar">Enterprise Applications</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP HANA</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod Lösungen</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">Alte NetApp HCI-Lösungen</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">Über NetApp Lösungen</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">Rechtliche Hinweise</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">Änderungsverlauf</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">Videos Demos</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">Lösungs-Landing Pages</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">Enterprise-Datenbanken</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">NetApp Hybrid-Multi-Cloud mit VMware</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP UND SAP HANA</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">Anfrageautomatisierung</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod – Eine Cisco NetApp Lösung</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">Technische Inhalte zu FlexPod Lösungen</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod Vertriebsseite</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">Schlagen Sie eine neue Lösung vor</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">Feedback Zu Lösungen Geben</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP Datenmigration</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">Best Practice-Richtlinien für NetApp XCP</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">CIFS-Datenmigration mit ACLs von einer Quell-Storage-Box zu ONTAP</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">KI-konvergente Infrastrukturen</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">Design-Leitfaden: ONTAP AI mit NVIDIA DGX A100 Systems</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">ONTAP AI mit NVIDIA DGX A100 Systems Deployment Guide</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">Design-Leitfaden: ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">Implementierungsleitfaden für ONTAP AI mit NVIDIA DGX A100-Systemen und Mellanox Spectrum Ethernet-Switches</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">EF-Series AI mit NVIDIA DGX A100 Systems und BeeGFS Design</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">EF-Series AI mit NVIDIA DGX A100 Systems und BeeGFS Deployment</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">BeeGFS mit NetApp E-Series Deployment Guide</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS mit NetApp E-Series Referenzarchitektur</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">Implementieren von IBM Spectrum Skalierbarkeit mit NetApp E-Series Storage</block>
  <block id="08479c0355c887a02e772206b0d5d7f5" category="sidebar">NetApp ONTAP und Lenovo ThinkSystem SR670 für Trainings-Workloads im KI- und ML-Modell</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">NetApp AFF A800 und Fujitsu Server PRIMERGY GX2570 M5 für Trainings-Workloads im KI- und ML-Modell</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">Daten-Pipelines, Data Lakes und Management</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">NetApp StorageGRID Data Lake für Workloads für das autonome Fahren</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident Implementierung</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">Datenverschiebung mit E-Series und BeeGFS für KI- und Analyse-Workflows</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">Verantwortungsvolle KI und vertrauliche Inferenz - NetApp AI mit Protopia Image Transformation</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">Sentiment-Analyse mit NetApp AI</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">Bereitstellung von Stimmungsanalysen im Support-Center</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Distributed Training in Azure – Click-Through-Rate Prediction</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">Datensatz- und Modellversionierung mit dem NetApp DataOps Toolkit</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Jupyter-Notebooks für Referenz</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Distributed Azure Training – Lane Detection</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">Lane-Erkennung – verteiltes Training mit RUN KI</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">Hybrides Cloud-KI-Betriebssystem mit Daten-Caching</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Verschieben von Daten von einer Big-Data-Umgebung in eine KI-Umgebung</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">KI-Inferenz am Edge - NetApp mit Lenovo ThinkSystem – Lösungsdesign</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">Umgangssprachlich AI mit NVIDIA</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">Optimale Cluster- und GPU-Auslastung bei AI-Ausführung</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">Führen Sie AI-Installation aus</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">Führen Sie AI-Dashboards und -Ansichten aus</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Jobs in Ausführen der KI-CLI senden</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">Solution Design: NetApp ONTAP AI für Workloads für das autonome Fahren</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">NetApp ONTAP AI Referenzarchitektur für das Gesundheitswesen: Diagnostische Bildgebung</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">NetApp ONTAP AI Referenzarchitektur für Financial-Services-Workloads</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">AI Deployment mit NetApp E-Series und BeeGFS</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">Quantum StorNext mit NetApp E-Series Systems Design Guide</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Quantum StorNext mit NetApp E-Series Systems Deployment Guide</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">Legen Sie los – mit NetApp und VMware</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">VMware Virtualisierung für ONTAP</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Richtlinienbasiertes Management für Virtual Volumes und Storage</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">VMware Site Recovery Manager mit NetApp ONTAP 9</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">Herkömmliche Bereitstellung Von Block Storage</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS – Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS – Fibre Channel over Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS – iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS – NVMe over Fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">Herkömmliche File Storage-Provisionierung</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS - v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS - v4.1</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware für Public Cloud</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">Anwendungsfälle für VMware Hybrid Cloud</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">Anwendungsfallübersicht</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">Virtual Desktops</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">Virtual Desktop Services (VDS)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Einzelserver-Lasttest mit Login VSI</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">Operation Management</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">Überlegungen zu GPU</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">Lösungen für Industrie</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">Technische Validierung von ESG: VDI auf Enterprise-Niveau mit NetApp Virtual Desktop Service</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">VMware Horizon</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod Lösungen für die Desktop-Virtualisierung</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E-Series und CommVault Data Platform V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">E-Series und EF-Series Referenzarchitektur und Storage Best Practices mit Veeam Backup Replication 9.5</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">Deploying Veritas NetBackup with NetApp E-Series Storage</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">NIST Security Controls for FISMA with HyTrust for Multitenant Infrastructure</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">Erste Schritte mit NetApp Lösungsautomatisierung und Ansible</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">Richten Sie die Automatisierungsumgebung ein</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatisierung von Anfragen</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">VMware Cloud auf Hyperscaler-Clouds</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">Unterstütze Konfigurationen</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">Konfiguration von VMC für AWS</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Konfigurieren Sie AVS für Azure</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">Konfigurieren Sie GCVE für GCP</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">NetApp Storage in Hyperscaler-Clouds</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">Zusätzlicher NFS-Datenspeicher für VMC</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">Zu Gast verbundener Speicher für VMC</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">Zusätzlicher NFS Datastore für AVS</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">Über den Gast verbundener Speicher für AVS</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">Über den Gast verbundener Speicher für GCVE</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">Zusammenfassung und Schlussfolgerung</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">NetApp für AWS/VMC</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">Schutz Von Workloads</block>
  <block id="146074e51d1a075fad5fd016dea017cc" category="sidebar">Lösungsüberblick</block>
  <block id="8d69f930e73398b81d052ad873efa8ab" category="sidebar">AWS Disaster Recovery für Storage mit Anbindung an den Gast-Service</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="sidebar">Disaster Recovery</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">Migration Von Workloads</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">Migration von Workloads zu FSX für ONTAP-Datenspeicher mithilfe von VMware HCX</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp für Azure/AVS</block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">Migrieren Sie Workloads mithilfe von VMware HCX in einen ANF-Datastore</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp für GCP/GCVE</block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">Disaster Recovery für Applikationen mit SnapCenter, CVO und Veeam Replication</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">Überblick über die Architektur</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">Andere NAS-Infrastruktur-Serviceabhängigkeiten (KDC, LDAP, DNS)</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Conflient Kafka mit NetApp ONTAP Storage Controllern</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Anwendungsfälle: Zusammenfassung</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">Big-Data-Analysedaten zu künstlicher Intelligenz</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS zu NFS - Detaillierte Schritte</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Best Practices für Confluent Kafka</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Conflient Self-Rebalancing Cluster</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp Hybrid-Cloud-Datenlösungen – Spark und Hadoop basierend auf Kundenanwendungsfällen</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Anwendungsfall 1 – Backup von Hadoop-Daten</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Anwendungsfall 2: Backup und Disaster Recovery von der Cloud in On-Premises-Systeme</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Anwendungsfall 3 – Enabling DevTest on Existing Hadoop Data</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Anwendungsfall 4: Datensicherung und Multi-Cloud-Konnektivität</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Anwendungsfall 5 – Beschleunigen Sie Analyse-Workloads</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Verschiedene Lösungen für verschiedene Analysestrategien – Lösungsüberblick</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID mit Splunk SmartStore</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark Workload mit NetApp Storage-Lösung (Deployment Guide)</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">Oracle 19c RAC-Datenbanken auf FlexPod DataCenter mit Cisco UCS und NetApp AFF A800 über FC</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Implementieren Von Oracle Database</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">Erste Schritte und Anforderungen</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Automatisierte Oracle 19c AWX/Tower-Implementierung</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Automatisierte Oracle 19c CLI-Implementierung</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Datensicherung Für Oracle Datenbanken</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">Automatisierter Oracle Data Protection für AWX/Tower</block>
  <block id="d42437507a421bfdd38119d600ab0014" category="sidebar">Implementierung von Oracle Database auf AWS EC2/FSX – Best Practices</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">Implementierungsverfahren</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">Datenbankmanagement</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">Datenbankmigration</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">Referenzdesign (High-Level-Design in Echtzeit)</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">Erste Schritte vor Ort</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">NetApp Storage-Systeme: Überblick</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">Überblick über NetApp Storage-Integrationen</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident – Überblick</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Erweiterte Konfigurationsoptionen Für Anthos</block>
  <block id="e131204502a58630f2f72937238604c8" category="sidebar">Videos/Demos</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">Übersicht über das NetApp Astra Control Center</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">Validierung Von Anwendungsfällen</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Übersicht Über Red Hat Openshift</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Registrieren Sie Ihre Red hat OpenShift-Cluster</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">Wählen Sie die zu schützenden Anwendungen aus</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">Schützen Sie Ihre Applikationen</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">Erweiterte Konfigurationsoptionen für OpenShift</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">Konfiguration der Mandantenfähigkeit auf Red hat OpenShift mit NetApp ONTAP</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">Cluster-Administrator-Aufgaben</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">Aufgaben Für Storage-Administratoren</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Skalierbarkeit</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">Bereitstellen über Operator</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">Workflows</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">Klonen von VMs</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">Application Lifecycle Management</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">Governance und Risiko</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">Erstellen Von Ressourcen</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">Übersicht über VMware TKG (Tanzu Kubernetes Grid)</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">Übersicht über VMware TKGS (Tanzu Kubernetes Grid Service</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">Übersicht über VMware TKGI (Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Registrieren Sie Ihre Tanzu Kubernetes Cluster</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">Archived Solutions</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp und VMware: Gemeinsam besser</block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">Was kommt als Nächstes?</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">12/06/2022</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">Zusätzliche 7 Videos zur Oracle Datenbankmodernisierung in der Hybrid Cloud mit Amazon FSX Storage</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">Künstliche Intelligenz (KI) und moderne Datenanalysen</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[Unterstreichen]#*Videos für die Modernisierung von Oracle mit Hybrid Cloud in AWS und FSX*#</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">Teil 1: Anwendungsfall und Lösungsarchitektur</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">Teil 2a: Datenbankmigration von lokalen in AWS mittels automatisierter PDB-Verlagerung bei maximaler Verfügbarkeit</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">Teil 2b: Datenbankmigration von lokalen Systemen zu AWS mithilfe der BlueXP Konsole über SnapMirror</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">Teil 3: Automatisiertes Setup für Datenbank-HA/DR-Replizierung, Failover, Neusynchronisierung</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">Teil 4a: Datenbankklon für Entwicklung/Tests mit der UI von SnapCenter aus replizierter Standby-Kopie</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">Teil 4b - Datenbank Backup, Wiederherstellung, Klonen mit SnapCenter UI</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">Teil 4c - Datenbank Backup, Wiederherstellung mit BlueXP SaaS Apps Backup und Recovery</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von NetApp CVO (Single-Node-Instanz) auf AWS</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">Verfahren</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">Rezepte:</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von NetApp CVO (HA-Paar) auf AWS</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">Terraform-Konfigurationsdateien zur Implementierung von NetApp ONTAP FSX auf AWS</block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">Rezepte:</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">Terraform Konfigurationsdateien für die Implementierung von ANF Volume auf Azure</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">Terraform Konfigurationsdateien für die Implementierung eines ANF-Volume mit Datensicherung auf Azure</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">Terraform Konfigurationsdateien für die Implementierung eines ANF Volume mit Dual-Protokoll auf Azure</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von ANF Volume aus Snapshot auf Azure</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von Single Node CVO auf Azure</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von CVO HA auf Azure</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von NetApp CVO (Single-Node-Instanz) auf GCP</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">Terraform-Konfigurationsdateien für die Implementierung von NetApp CVO (HA-Paar) auf GCP</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">Terraform Konfigurationsdateien für die Implementierung von NetApp CVS Volume auf GCP</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">Der Veeam Backup-Server, Backup-Repository und Backup-Proxy, der bereitgestellt werden muss, basieren auf einem Implementierungsszenario. In diesem Anwendungsfall müssen kein Objektspeicher für Veeam implementiert und auch kein Scale-out-Repository erforderlich sein.<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">12/15/2022</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">Zusätzlich wurde TR-4923: SQL Server auf AWS EC2 mit Amazon FSX für NetApp ONTAP hinzugefügt</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923: SQL Server auf AWS EC2 unter Verwendung von Amazon FSX für NetApp ONTAP</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">Autoren: Pat Sithusan und Niyaz Mohamed, NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">Viele Unternehmen, die Applikationen von lokalen Storage-Systemen und Cloud-Storage-Services migrieren möchten, stellen fest, dass sie diesem Aufwand durch die Unterschiede in den Funktionen von On-Premises-Storage-Systemen und Cloud-Storage-Services gedient haben. Diese Lücke hat die Migration von Enterprise-Applikationen wie Microsoft SQL Server erheblich problematisch gemacht. Insbesondere Mängel bei den Services, die zur Ausführung einer Enterprise-Applikation erforderlich sind, wie beispielsweise zuverlässige Snapshots, Storage-Effizienz-Funktionen, hohe Verfügbarkeit, Zuverlässigkeit und konsistente Performance, haben Kunden gezwungen, Kompromisse beim Design einzugehen oder Applikationsmigration zu gehen. Mit FSX für NetApp ONTAP müssen Kunden keine Kompromisse mehr eingehen. FSX für NetApp ONTAP ist ein nativer AWS-Service (vom ersten Anbieter), der von AWS vertrieben, unterstützt, abgerechnet und vollständig gemanagt wird. Mit der leistungsstarken ONTAP bietet diese Architektur dieselben Storage- und Datenmanagement-Funktionen der Enterprise-Klasse, die NetApp seit drei Jahrzehnten in AWS als Managed Service vor Ort bietet.</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">AWS FSX ONTAP</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">Mit SQL Server auf EC2 Instanzen können Datenbankadministratoren ihre Datenbankumgebung und das zugrunde liegende Betriebssystem aufrufen und anpassen. Eine SQL Server auf EC2-Instanz in Kombination mit<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> Zum Speichern der Datenbankdateien bietet das Unternehmen hohe Performance, Datenmanagement und einen einfachen und einfachen Migrationspfad über Replizierung auf Blockebene. Daher können Sie Ihre komplexe Datenbank auf AWS VPC mit einem einfachen „Lift-and-Shift“-Ansatz, weniger Klicks und keine Schemakonvertierung ausführen.</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">Vorteile bei der Verwendung von Amazon FSX für NetApp ONTAP mit SQL Server</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">Amazon FSX für NetApp ONTAP ist die ideale File-Storage-Lösung für SQL Server-Implementierungen in AWS. Dies bietet unter anderem folgende Vorteile:</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">Konsistent hohe Performance und hoher Durchsatz mit niedriger Latenz</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">Intelligentes Caching mit NVMe-Cache für bessere Performance</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">Flexible Dimensionierung, um Kapazität, Durchsatz und IOPS im Handumdrehen zu erhöhen oder zu reduzieren</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">Effiziente Block-Replizierung zwischen On-Premises-Systemen und AWS</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">Verwendung von iSCSI, einem bekannten Protokoll für die Datenbankumgebung</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">Storage-Effizienzfunktionen wie Thin Provisioning und Klone ohne zusätzlichen Platzbedarf</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">Verkürzung der Backup-Zeit von Stunden auf Minuten und dadurch Reduzierung der RTO</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">Granulares Backup und Recovery von SQL-Datenbanken mit der intuitiven SnapCenter UI von NetApp</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">Die Möglichkeit, vor der eigentlichen Migration mehrere Testmigrationen durchzuführen</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">Kürzere Ausfallzeiten während der Migration und Bewältigung von Migrationsherausforderungen mit Kopien auf Datei- oder I/O-Ebene</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">Verringerung der MTTR durch Ermittlung der Ursache nach einem Major Release oder Patch-Update</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">Die Implementierung von SQL Server Datenbanken auf FSX ONTAP mit dem iSCSI-Protokoll, wie in der Regel vor Ort, bietet eine ideale Storage-Umgebung für Datenbanken mit überlegener Performance, Storage-Effizienz und Datenmanagement-Funktionen. Es wurden mehrere iSCSI-Sitzungen verwendet, bei einer Arbeitsmenge von 5 %, vorausgesetzt, der Einsatz eines Flash Cache liefert über 100.000 IOPS mit dem FSX ONTAP Service. Diese Konfiguration bietet eine vollständige Kontrolle über die Performance für anspruchsvollste Applikationen. SQL Server, der auf kleineren EC2 Instanzen ausgeführt wird, die mit FSX für ONTAP verbunden sind, kann dieselben Vorgänge ausführen wie SQL Server, der auf einer viel größeren EC2 Instanz ausgeführt wird, da nur Bandbreitenbeschränkungen für Netzwerke auf FSX für ONTAP angewendet werden. Durch die Verringerung der Größe von Instanzen werden auch die Computing-Kosten gesenkt, wodurch eine TCO-optimierte Implementierung ermöglicht wird. Die Kombination von SQL mit iSCSI und SMB3.0 mit Multichannel-Freigaben für die kontinuierliche Verfügbarkeit auf FSX für ONTAP bietet große Vorteile für SQL-Workloads.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">Bevor Sie beginnen</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">Die Kombination von Amazon FSX für NetApp ONTAP und SQL Server auf EC2 Instanzen ermöglicht die Erstellung von Datenbank-Storage-Designs der Enterprise-Klasse, die die anspruchsvollsten Applikationsanforderungen bis heute erfüllen können. Zur Optimierung beider Technologien ist es wichtig, die I/O-Muster und Eigenschaften von SQL Server zu verstehen. Ein gut geplantes Storage-Layout für eine SQL Server Datenbank unterstützt die Performance von SQL Server und das Management der SQL Server Infrastruktur. Ein gutes Storage-Layout sorgt auch dafür, dass die ursprüngliche Implementierung erfolgreich ist und die Umgebung mit dem Laufe der Zeit reibungslos wachsen kann, wenn Ihr Unternehmen wächst.</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">Bevor Sie die Schritte in diesem Dokument ausführen, sollten Sie die folgenden Voraussetzungen erfüllen:</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">Ein AWS Konto</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">Entsprechende IAM-Rollen zur Bereitstellung von EC2 und FSX für ONTAP</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">Eine Windows Active Directory-Domäne auf EC2</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">Alle SQL Server-Knoten müssen miteinander kommunizieren können</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">Stellen Sie sicher, dass die DNS-Auflösung funktioniert und die Hostnamen aufgelöst werden können. Falls nicht, verwenden Sie den Eintrag für die Host-Datei.</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">Allgemeine Kenntnisse zur SQL Server-Installation</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">Weitere Informationen finden Sie auch in den NetApp Best Practices für Umgebungen mit SQL Server, um die beste Storage-Konfiguration zu gewährleisten.</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">Best Practice-Konfigurationen für SQL Server-Umgebungen auf EC2</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">Mit FSX ONTAP ist die Beschaffung von Speicher die einfachste Aufgabe und kann durch Aktualisierung des Dateisystems durchgeführt werden. Dieser einfache Prozess ermöglicht bei Bedarf dynamische Kosten- und Performance-Optimierung, sorgt für den Ausgleich des SQL Workloads und liefert außerdem Thin Provisioning. FSX ONTAP Thin Provisioning wurde entwickelt, um EC2-Instanzen, die SQL Server ausführen, mehr logischen Storage anzubieten, als im Filesystem bereitgestellt wird. Storage muss nicht im Voraus verteilt werden, sondern wird den einzelnen Volumes oder LUNs dynamisch beim Schreiben der Daten zugewiesen. In den meisten Konfigurationen wird freier Speicherplatz wieder freigegeben, wenn Daten auf dem Volume oder der LUN gelöscht werden (und nicht durch Snapshot Kopien gespeichert werden). Die folgende Tabelle enthält Konfigurationseinstellungen für die dynamische Zuweisung von Speicher.</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">Keine (standardmäßig festgelegt)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">LUN-Reservierung</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">Fraktionale_Reserve</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0% (standardmäßig festgelegt)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">Snap_Reserve</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">Autosize</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">Ein</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">Volume Tiering-Richtlinie</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">Nur Snapshot</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">Mit dieser Konfiguration kann die Gesamtgröße der Volumes größer sein als der tatsächlich im Dateisystem verfügbare Speicher. Wenn die LUNs oder Snapshot Kopien mehr Speicherplatz benötigen, als im Volume verfügbar ist, wachsen die Volumes automatisch und nehmen mehr Speicherplatz aus dem zugehörigen File-System in Anspruch. Autogrow ermöglicht FSX ONTAP, die Volume-Größe automatisch auf eine maximale Größe zu erhöhen, die Sie vorab bestimmen. Um das automatische Wachstum des Volumes zu unterstützen, muss im Filesystem Platz vorhanden sein. Bei aktiviertem Autogrow sollten Sie daher den freien Speicherplatz im Dateisystem überwachen und bei Bedarf das Dateisystem aktualisieren.</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">Speicherplatzzuweisung</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">Stellen Sie außerdem das ein<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> Option bei LUN aktivieren, damit FSX ONTAP den EC2-Host benachrichtigt, wenn der Speicherplatz des Volume knapp wird, und die LUN im Volume keine Schreibvorgänge akzeptieren kann. Mit dieser Option kann FSX für ONTAP außerdem automatisch Speicherplatz zurückgewinnen, wenn SQL Server auf EC2 Host Daten löscht. Die Option für die Speicherplatzzuweisung ist standardmäßig auf deaktiviert eingestellt.</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">Wenn eine space-reservierte LUN in einem ohne garantierte Performance-Volume erstellt wird, verhält sich die LUN wie eine nicht-space-reservierte LUN. Das liegt daran, dass ein nicht garantiertes Volume keinen Platz hat, der LUN zuzuweisen. Das Volume selbst kann aufgrund seiner keinen Garantie nur Speicherplatz zuweisen, da es geschrieben wird.</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">Mit dieser Konfiguration können FSX ONTAP-Administratoren die Größe des Volumes in der Regel so festlegen, dass sie den belegten Speicherplatz auf der LUN-Seite auf der Host-Seite und im Filesystem managen und überwachen müssen.</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">NetApp empfiehlt die Verwendung eines separaten Filesystems für SQL Server Workloads. Wenn das Dateisystem für mehrere Anwendungen verwendet wird, überwachen Sie die Speicherplatznutzung sowohl des Dateisystems als auch der Volumes innerhalb des Dateisystems, um sicherzustellen, dass die Volumes nicht auf verfügbaren Speicherplatz konkurrieren.</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">Snapshot Kopien, die zur Erstellung von FlexClone Volumes genutzt werden, werden durch die Option Autodelete nicht gelöscht.</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">Eine Überbelegung von Storage muss für eine geschäftskritische Applikation wie SQL Server sorgfältig geprüft und gemanagt werden. Selbst ein minimaler Ausfall ist nicht tolerierbar. In solch einem Fall ist es am besten, Trends in der Storage-Nutzung zu überwachen, um festzustellen, wie viel oder wann überhaupt eine Überbelegung akzeptabel ist.</block>
  <block id="d846da4dd06c448920cac63b79adc614" category="list-text">Für optimale Storage-Performance stellen Sie eine 1,5-mal so große Kapazität eines Filesystems für die gesamte Datenbanknutzung bereit.</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">Zur Vermeidung von Applikations-Downtime ist eine angemessene Überwachung sowie ein effektiver Aktionsplan mit Thin Provisioning erforderlich.</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">Achten Sie darauf, die Warnmeldungen zu CloudWatch und anderen Monitoring-Tools so einzurichten, dass jederzeit Kontakt mit Mitarbeitern aufgenommen wird, wenn der Storage gefüllt ist.</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">Konfiguration von Storage für SQL Server und Bereitstellung von SnapCenter für Backup-, Restore- und Klonvorgänge</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">Um SQL-Servervorgänge mit SnapCenter durchzuführen, müssen Sie zuerst Volumes und LUNs für SQL Server erstellen.</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">Erstellung von Volumes und LUNs für SQL Server</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">Führen Sie die folgenden Schritte aus, um Volumes und LUNs für SQL Server zu erstellen:</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">Öffnen Sie die Amazon FSX-Konsole bei<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">Erstellen Sie mit der Option „Standard erstellen“ unter „Erstellungsmethode“ ein Amazon FSX für das Filesystem von NetApp ONTAP. So können Sie FSxadmin- und vsadmin-Anmeldeinformationen definieren.</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">Geben Sie das Passwort für fsxadmin an.</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">Geben Sie das Passwort für SVMs an.</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">Erstellung eines Volumes auf FSX für NetApp ONTAP</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">Erstellen Sie Volumes, indem Sie den Schritt befolgen, der in aufgeführt ist<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>.</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">Deaktivieren Sie Zeitpläne für Storage Snapshot Kopien und Aufbewahrungsrichtlinien. Verwenden Sie stattdessen NetApp SnapCenter, um Snapshot Kopien der SQL Server Daten und Protokoll-Volumes zu koordinieren.</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">Konfigurieren Sie Datenbanken auf einzelnen LUNs auf separaten Volumes, um von einer schnellen und granularen Restore-Funktion zu profitieren.</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">Platzieren Sie Benutzerdatendateien (.mdf) auf separaten Volumes, da es sich um Workloads mit zufälligen Lese-/Schreibzugriffen handelt. Es ist üblich, Transaktions-Log-Backups häufiger zu erstellen als Datenbank-Backups. Aus diesem Grund legen Sie Transaktions-Log-Dateien (.ldf) auf ein separates Volume von den Datendateien ab, so dass für jedes einzelne unabhängige Backup-Zeitpläne erstellt werden können. Durch diese Trennung werden auch die I/O-Vorgänge bei sequenziellen Schreibvorgängen aus den I/O-Vorgängen für zufällige Lese-/Schreibzugriffe von Datendateien isoliert und die SQL Server Performance deutlich verbessert.</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">Tempdb ist eine Systemdatenbank, die von Microsoft SQL Server als temporärer Arbeitsbereich verwendet wird, insbesondere für I/O-intensive DBCC CHECKDB-Vorgänge. Platzieren Sie daher diese Datenbank auf einem dedizierten Volume. In großen Umgebungen, in denen die Volume-Anzahl eine Herausforderung ist, können Sie tempdb in weniger Volumes konsolidieren und im gleichen Volume wie andere Systemdatenbanken nach einer sorgfältigen Planung speichern. Datensicherung für tempdb ist keine hohe Priorität, da diese Datenbank bei jedem Neustart von Microsoft SQL Server neu erstellt wird.</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">Verwenden Sie den folgenden SSH-Befehl zum Erstellen von Volumes:</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Starten Sie den iSCSI-Dienst mit PowerShell unter Verwendung erhöhter Berechtigungen in Windows-Servern.</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Installieren Sie Multipath IO mit PowerShell unter Verwendung erhöhter Berechtigungen in Windows Servern.</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Suchen Sie den Windows-Initiatornamen mit PowerShell unter Verwendung von erhöhten Berechtigungen in Windows-Servern.</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">Stellen Sie eine Verbindung zu Storage Virtual Machines (SVM) mithilfe von putty her und erstellen Sie eine iGroup.</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">Verwenden Sie den folgenden SSH-Befehl, um LUNs zu erstellen:</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">Verwenden Sie Windows_2008 als empfohlenen LUN-Typ, um die I/O-Ausrichtung mit dem OS-Partitionierungsschema zu erreichen. Siehe<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> Finden Sie weitere Informationen.</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">Verwenden Sie den folgenden SSH-Befehl für die Zuordnung der Initiatorgruppe zu den LUNs, die Sie gerade erstellt haben.</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Führen Sie für eine freigegebene Festplatte, die Windows Failover Cluster verwendet, einen SSH-Befehl aus, um die gleiche LUN der Initiatorgruppe zuzuordnen, die zu allen Servern gehört, die am Windows Failover Cluster teilnehmen.</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">Windows Server mit einer SVM mit einem iSCSI-Ziel verbinden. Suchen Sie die Ziel-IP-Adresse aus dem AWS Portal.</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">Wählen Sie im Server Manager und im Menü Extras den iSCSI-Initiator aus. Wählen Sie die Registerkarte Ermittlung aus, und wählen Sie dann Portal ermitteln aus. Geben Sie im vorherigen Schritt die iSCSI-IP-Adresse ein, und wählen Sie Erweitert. Wählen Sie im lokalen Adapter Microsoft iSCSI Initiator aus. Wählen Sie in Initiator-IP die IP des Servers aus. Wählen Sie anschließend OK, um alle Fenster zu schließen.</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">Wiederholen Sie Schritt 12 für die zweite iSCSI-IP-Adresse der SVM.</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">Wählen Sie die Registerkarte *Ziele* aus, wählen Sie *Verbinden* und wählen Sie *muti-Pfad aktivieren*.</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">Fügen Sie für eine optimale Performance weitere Sitzungen hinzu. NetApp empfiehlt die Erstellung von fünf iSCSI-Sitzungen. Wählen Sie *Eigenschaften *&gt; *Sitzung hinzufügen *&gt; *Erweitert* aus, und wiederholen Sie Schritt 12.</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">Konfigurieren Sie fünf iSCSI-Sitzungen pro Zielschnittstelle, um eine optimale Performance zu erzielen.</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">Konfiguration einer Round Robin-Richtlinie zur besten iSCSI-Performance insgesamt</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">Stellen Sie beim Formatieren der LUNs sicher, dass die Zuordnungseinheit für Partitionen auf 64K eingestellt ist</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">Führen Sie den folgenden PowerShell-Befehl aus, um sicherzustellen, dass die iSCSI-Sitzung beibehalten wird.</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">Initialisieren Sie die Festplatten mit dem folgenden PowerShell-Befehl.</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">Führen Sie die Befehle Partition erstellen und Disk formatieren mit PowerShell aus.</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">Sie können die Erstellung von Volumes und LUNs mit dem PowerShell Skript aus Anhang B. automatisieren LUNs können auch mit SnapCenter erstellt werden.</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">Sobald die Volumes und LUNs definiert sind, müssen Sie SnapCenter einrichten, um die Datenbankvorgänge ausführen zu können.</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">Übersicht über SnapCenter</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter ist eine Datensicherungssoftware der nächsten Generation für Tier-1-Enterprise-Applikationen. Mit der zentralen Management-Oberfläche automatisiert und vereinfacht SnapCenter manuelle, komplexe und zeitintensive Prozesse, die im Zusammenhang mit Backup, Recovery und dem Klonen zahlreicher Datenbanken und anderer Applikations-Workloads anfallen. SnapCenter nutzt NetApp Technologien, darunter NetApp Snapshot, NetApp SnapMirror, SnapRestore und NetApp FlexClone. Dank dieser Integration können IT-Abteilungen ihre Storage-Infrastruktur skalieren, zunehmend anspruchsvolle SLA-Verpflichtungen erfüllen und die Produktivität der Administratoren im gesamten Unternehmen verbessern.</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">Anforderungen für SnapCenter Server</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">In der folgenden Tabelle sind die Mindestanforderungen für die Installation des SnapCenter-Servers und des Plug-ins unter Microsoft Windows Server aufgeführt.</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">Komponenten</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">Anforderungen</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">Minimale CPU-Anzahl</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">Vier Kerne/vCPUs</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">Minimum: 8 GB empfohlen: 32 GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">Speicherplatz</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">Minimaler Installationsspeicherplatz: 10 GB für das Repository: 10 GB</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">Unterstütztes Betriebssystem</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">Softwarepakete</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2 oder höher</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework (WMF) 4.0 oder höher</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 oder höher</block>
  <block id="427d30c4045ae36c0130a14658100185" category="paragraph">Ausführliche Informationen finden Sie unter Speicherplatz und Größenanforderung <block ref="bcc48263fbca83f546b0bc02edad3f56" category="inline-link-rx"></block></block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">Informationen zur Versionskompatibilität finden Sie im<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>.</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">Datenbank-Storage-Layout</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">Die folgende Abbildung zeigt einige Überlegungen beim Erstellen des Microsoft SQL Server Datenbank-Storage-Layouts beim Backup mit SnapCenter.</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">Platzieren Sie Datenbanken mit I/O-intensiven Abfragen oder einer großen Datenbankgröße (beispielsweise 500 GB oder mehr) auf einem separaten Volume, um eine schnellere Recovery zu ermöglichen. Dieses Volumen sollte auch durch separate Jobs gesichert werden.</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">Konsolidierung von Datenbanken kleiner bis mittlerer Größe, die weniger kritisch sind oder weniger I/O-Anforderungen auf ein einzelnes Volume haben Wenn eine große Anzahl von Datenbanken auf demselben Volume gesichert wird, benötigen Sie weniger Snapshot Kopien. Als Best Practice wird außerdem empfohlen, Microsoft SQL Server Instanzen zu konsolidieren, um dieselben Volumes zu verwenden, um die Anzahl der erstellten Backup-Snapshot-Kopien zu steuern.</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">Erstellen Sie separate LUNs, um Dateien zu vollständigen Text und Datei-Streaming zu speichern.</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Weisen Sie separate LUNs pro Host zu, um Microsoft SQL Server-Protokoll-Backups zu speichern.</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">Systemdatenbanken, in denen Metadaten des Datenbankservers konfiguriert und Einzelheiten zu Jobs gespeichert sind, werden nicht häufig aktualisiert. Legen Sie Systemdatenbanken/tempdb in separate Laufwerke oder LUNs. Platzieren Sie keine Systemdatenbanken auf demselben Volume wie die Benutzerdatenbanken. Benutzerdatenbanken haben eine andere Backup-Richtlinie, und die Häufigkeit der Backups in der Benutzerdatenbank ist bei Systemdatenbanken nicht identisch.</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Legen Sie für die Einrichtung der Microsoft SQL Server Availability Group Daten und Protokolldateien für Replikate in einer identischen Ordnerstruktur auf allen Knoten ab.</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">Neben dem Performance-Vorteil, den das Benutzerdatenbanklayout in verschiedene Volumes aufzuteilen, wirkt sich die Datenbank auch deutlich auf die für Backups und Restores erforderliche Zeit aus. Die Verwendung separater Volumes für Daten- und Log-Dateien verkürzt die Wiederherstellungszeit erheblich, im Vergleich zu einem Volume, das mehrere Benutzerdatendateien hostet. Außerdem sind Benutzerdatenbanken mit einer hohen I/O-intensiven Applikation anfällig für eine höhere Backup-Zeit. Eine ausführlichere Erläuterung der Backup- und Restore-Verfahren finden Sie weiter unten in diesem Dokument.</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">Beginnend mit SQL Server 2012 (11.x), Systemdatenbanken (Master, Model, MSDB und tempdb), Zudem können Datenbanken mit Database Engine Benutzern als Storage-Option mit einem SMB-Dateiserver installiert werden. Dies gilt sowohl für Standalone SQL Server als auch für SQL Server Failover Cluster-Installationen. Damit können Sie FSX für ONTAP mit sämtlichen Performance- und Datenmanagementfunktionen einsetzen, einschließlich Volume-Kapazität, Performance-Skalierbarkeit und Datensicherungsfunktionen, die SQL Server nutzen kann. Freigaben, die von den Applikationsservern verwendet werden, müssen mit der kontinuierlich verfügbaren Eigenschaft konfiguriert werden. Das Volume sollte dann mit dem NTFS-Sicherheitsstil erstellt werden. NetApp SnapCenter kann nicht zusammen mit Datenbanken verwendet werden, die auf SMB-Freigaben von FSX für ONTAP platziert sind.</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">Für SQL Server-Datenbanken, die keine Backups mit SnapCenter durchführen, empfiehlt Microsoft, die Daten und Log-Dateien auf separaten Laufwerken zu platzieren. Bei Anwendungen, die gleichzeitig Daten aktualisieren und anfordern, ist die Protokolldatei schreibintensiv und die Datendatei (je nach Anwendung) ist Lese-/schreibintensiv. Für den Datenabruf wird die Protokolldatei nicht benötigt. Daher können Datenanfragen aus der Datendatei auf dem eigenen Laufwerk bearbeitet werden.</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">Wenn Sie eine neue Datenbank erstellen, empfiehlt Microsoft, getrennte Laufwerke für die Daten und Protokolle anzugeben. Um Dateien nach der Datenbankerstellung zu verschieben, muss die Datenbank offline geschaltet werden. Weitere Empfehlungen von Microsoft finden Sie unter Daten und Protokolldateien auf separaten Laufwerken platzieren.</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">Installation und Einrichtung für SnapCenter</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">Installieren Sie den SnapCenter-Server</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">Installieren des SnapCenter Plug-ins für Microsoft SQL Server</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">Folgen Sie den<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> Und<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> Um SnapCenter zu installieren und einzurichten.</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">Führen Sie nach der Installation von SnapCenter die folgenden Schritte aus, um sie einzurichten.</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">Um Anmeldeinformationen einzurichten, wählen Sie *Einstellungen* &gt; *Neu* und geben Sie die Anmeldeinformationen ein.</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">Fügen Sie das Storage-System hinzu, indem Sie Storage-Systeme &gt; Neu auswählen und die entsprechende FSX für ONTAP-Storage-Informationen bereitstellen.</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">Fügen Sie Hosts hinzu, indem Sie *Hosts* &gt; *Add* auswählen und dann die Hostinformationen angeben. SnapCenter installiert das Windows und SQL Server Plug-in automatisch. Dieser Vorgang kann einige Zeit in Anspruch nehmen.</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">Nachdem alle Plug-ins installiert sind, müssen Sie das Protokollverzeichnis konfigurieren. Dies ist der Speicherort, an dem sich das Transaktions-Log-Backup befindet. Sie können das Protokollverzeichnis konfigurieren, indem Sie den Host auswählen und dann das Protokollverzeichnis konfigurieren auswählen.</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter verwendet ein Host-Protokollverzeichnis zum Speichern von Backup-Daten für Transaktionsprotokolle. Dieser Punkt befindet sich auf Host- und Instanzebene. Jeder von SnapCenter verwendete SQL Server-Host muss über ein Host-Protokollverzeichnis für die Durchführung von Protokoll-Backups verfügen. Bei SnapCenter gibt es ein Datenbank-Repository, sodass Metadaten, die mit Backup-, Restore- oder Klonvorgängen verbunden sind, in einem zentralen Datenbank-Repository gespeichert werden.</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">Die Größe des Host-Protokollverzeichnisses wird wie folgt berechnet:</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">Größe des Host-Log-Verzeichnisses = ((Größe der Systemdatenbank + (maximale DB LDF-Größe × tägliche Log-Änderungsrate %)) × (Snapshot-Kopie-Aufbewahrung) ÷ (1 – LUN-Overhead-Platz %)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">Die Größenformel für das Host-Protokoll-Verzeichnis setzt folgende voraus:</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">Eine Systemdatenbank-Sicherung, die die tempdb-Datenbank nicht enthält</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">Eine 10% LUN Overheadfläche somit ist das Host-Log-Verzeichnis auf einem dedizierten Volume oder einer LUN vorhanden. Die Datenmenge im Host-Log-Verzeichnis hängt von der Größe der Backups und der Anzahl der Tage ab, die Backups aufbewahrt werden.</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">Wenn die LUNs bereits bereitgestellt wurden, können Sie den Bereitstellungspunkt auswählen, der das Host-Protokollverzeichnis darstellt.</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">Sie können nun Backup-, Restore- und Klonvorgänge für SQL Server ausführen.</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">Backup der Datenbank mit SnapCenter</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">Nachdem Sie die Datenbank und die Protokolldateien auf den FSX ONTAP LUNs platziert haben, kann SnapCenter zum Sichern der Datenbanken verwendet werden. Mit den folgenden Prozessen wird ein vollständiges Backup erstellt.</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">In SnapCenter wird RPO als Backup-Häufigkeit identifiziert, beispielsweise wie oft das Backup geplant werden soll, damit sich der Datenverlust auf bis zu wenige Minuten reduzieren lässt. Mit SnapCenter lassen sich Backups alle fünf Minuten planen. Allerdings kann es einige Instanzen geben, in denen ein Backup während der Transaktionszeiten nicht innerhalb von fünf Minuten abgeschlossen wird, oder wenn die Änderungsrate der Daten in der gegebenen Zeit eher liegt. Als Best Practice empfiehlt es sich, häufige Transaktions-Log-Backups anstelle vollständiger Backups zu planen.</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">Es gibt zahlreiche Ansätze für RPO und RTO. Eine Alternative zu diesem Backup-Ansatz besteht darin, separate Backup-Richtlinien für Daten und Protokolle mit unterschiedlichen Intervallen zu verwenden. Von SnapCenter aus sollten Sie beispielsweise Backup-Protokolle in 15-Minuten-Intervallen planen und Daten-Backups in 6-Stunden-Intervallen durchführen.</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">Verwenden Sie eine Ressourcengruppe für eine Backup-Konfiguration zur Snapshot-Optimierung und zur Anzahl der zu verwaltenden Jobs.</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">Wählen Sie *Ressourcen*, und wählen Sie dann *Microsoft SQL Server *im Dropdown-Menü oben links. Wählen Sie *Ressourcen Aktualisieren*.</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">Wählen Sie die zu sichernde Datenbank aus, und wählen Sie dann *Weiter* und (*+*), um die Policy hinzuzufügen, falls noch keine erstellt wurde. Befolgen Sie die * Neue SQL Server Backup Policy*, um eine neue Richtlinie zu erstellen.</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">Wählen Sie ggf. den Überprüfungsserver aus. Dieser Server ist der Server, auf dem SnapCenter DBCC CHECKDB ausgeführt wird, nachdem eine vollständige Sicherung erstellt wurde. Klicken Sie auf *Weiter*, um eine Benachrichtigung zu erhalten, und wählen Sie zur Überprüfung *Zusammenfassung*. Klicken Sie nach der Überprüfung auf *Fertig stellen*.</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">Klicken Sie auf *Jetzt sichern*, um das Backup zu testen. Wählen Sie in den Popup-Fenstern die Option *Backup* aus.</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">Wählen Sie *Monitor*, um zu überprüfen, ob die Sicherung abgeschlossen wurde.</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">Sichern Sie das Transaktions-Log-Backup von SnapCenter, damit SnapCenter während des Wiederherstellungsprozesses alle Backup-Dateien lesen und automatisch nacheinander wiederherstellen kann.</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">Wenn Produkte von Drittanbietern für Backups verwendet werden, wählen Sie Backup in SnapCenter kopieren aus, um Probleme mit der Protokollsequenz zu vermeiden, und testen Sie die Wiederherstellungsfunktion, bevor Sie in die Produktion gehen.</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">Datenbank mit SnapCenter wiederherstellen</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">Einer der größten Vorteile von FSX ONTAP mit SQL Server auf EC2 ist die Möglichkeit, auf jeder Datenbankebene schnelle und granulare Wiederherstellungen durchzuführen.</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">Führen Sie die folgenden Schritte aus, um eine individuelle Datenbank auf einen bestimmten Zeitpunkt oder bis zu einer Minute mit SnapCenter wiederherzustellen.</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">Wählen Sie Ressourcen und dann die Datenbank aus, die Sie wiederherstellen möchten.</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">Wählen Sie den Backupnamen aus, von dem die Datenbank wiederhergestellt werden soll, und wählen Sie anschließend Wiederherstellen.</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">Folgen Sie den * Restore* Pop-up-Fenstern, um die Datenbank wiederherzustellen.</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">Wählen Sie *Monitor*, um zu überprüfen, ob der Wiederherstellungsprozess erfolgreich ist.</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">Überlegungen für eine Instanz mit einer großen Anzahl von Datenbanken kleiner bis großer Größe</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter kann eine große Anzahl an umfangreichen Datenbanken in einer Instanz oder Gruppe von Instanzen innerhalb einer Ressourcengruppe sichern. Die Größe einer Datenbank ist kein entscheidender Faktor für die Backup-Zeit. Die Dauer eines Backups kann je nach Anzahl der LUNs pro Volume, der Belastung von Microsoft SQL Server, der Gesamtzahl der Datenbanken pro Instanz und insbesondere der I/O-Bandbreite und -Nutzung variieren. Während Sie die Richtlinie für das Backup von Datenbanken aus einer Instanz oder Ressourcengruppe konfigurieren, empfiehlt NetApp, die maximal pro Snapshot-Kopie gesicherte Datenbank auf 100 pro Host einzuschränken. Stellen Sie sicher, dass die Gesamtzahl an Snapshot Kopien die Begrenzung von 1,023 Kopien nicht überschreitet.</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">NetApp empfiehlt zudem, die laufenden Backup-Jobs parallel zu begrenzen, indem Sie die Anzahl der Datenbanken gruppieren, anstatt für jede Datenbank oder jede Instanz mehrere Jobs zu erstellen. Für eine optimale Performance der Backup-Dauer ist die Anzahl der Backup-Jobs auf eine Anzahl reduziert, die rund 100 oder weniger Datenbanken gleichzeitig sichern kann.</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">Wie bereits erwähnt, ist die I/O-Nutzung ein wichtiger Faktor für den Backup-Prozess. Der Backup-Prozess muss warten, bis alle I/O-Vorgänge einer Datenbank abgeschlossen sind. Datenbanken mit sehr intensiven I/O-Vorgängen sollten auf eine andere Backup-Zeit zurückgestellt werden oder von anderen Backup-Jobs isoliert werden, um zu vermeiden, dass andere Ressourcen innerhalb derselben Ressourcengruppe, die gesichert werden soll, beeinträchtigt werden.</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">Setzen Sie für eine Umgebung mit sechs Microsoft SQL Server Hosts, die 200 Datenbanken pro Instanz hosten. Angenommen, vier LUNs pro Host und eine LUN pro erstelltem Volume sollten Sie die vollständige Backup-Richtlinie mit der maximalen Anzahl an Datenbanken, die pro Snapshot Kopie gesichert werden, auf 100 ein. Zweihundert Datenbanken auf jeder Instanz werden als 200 Datendateien verteilt auf zwei LUNs verteilt, und 200 Log-Dateien werden gleichmäßig auf zwei LUNs verteilt: 100 Dateien pro LUN pro Volume.</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">Planen Sie drei Backup-Jobs, indem Sie drei Ressourcengruppen erstellen, wobei jeweils zwei Instanzen mit insgesamt 400 Datenbanken gruppiert werden.</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">Alle drei Backup-Jobs werden parallel ausgeführt und sichern gleichzeitig 1,200 Datenbanken. Abhängig von der Last für den Server und der I/O-Nutzung können die Start- und Endzeit jeder Instanz variieren. In dieser Instanz werden insgesamt 24 Snapshot Kopien erstellt.</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">Zusätzlich zum vollständigen Backup empfiehlt NetApp, ein Transaktions-Log-Backup für kritische Datenbanken zu konfigurieren. Stellen Sie sicher, dass die Datenbankeigenschaft auf ein vollständiges Recovery-Modell eingestellt ist.</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">Nehmen Sie die tempdb-Datenbank nicht in ein Backup auf, da die darin enthaltenen Daten temporär sind. Platzieren Sie tempdb auf eine LUN oder eine SMB-Freigabe, die sich in einem Storage-System-Volume befindet, in dem keine Snapshot Kopien erstellt werden.</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">Eine Microsoft SQL Server Instanz mit einer hohen I/O-intensiven Applikation sollte in einem anderen Backup-Job isoliert werden, um die gesamte Backup-Zeit für andere Ressourcen zu reduzieren.</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">Begrenzen Sie die Anzahl der Datenbanken, die gleichzeitig auf etwa 100 gesichert werden sollen, und Staffeln Sie die übrigen Datenbank-Backups, um einen gleichzeitigen Prozess zu vermeiden.</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Verwenden Sie den Instanznamen für Microsoft SQL Server in der Ressourcengruppe anstelle mehrerer Datenbanken, da SnapCenter beim Erstellen neuer Datenbanken in der Microsoft SQL Server-Instanz automatisch eine neue Datenbank für das Backup berücksichtigt.</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">Wenn Sie die Datenbankkonfiguration ändern, wie beispielsweise das Datenbank-Recovery-Modell in das vollständige Recovery-Modell ändern, führen Sie sofort ein Backup durch, um up-to-the-minute-Wiederherstellungsvorgänge zu ermöglichen.</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter kann Transaktions-Log-Backups, die außerhalb von SnapCenter erstellt wurden, nicht wiederherstellen.</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">Stellen Sie beim Klonen von FlexVol Volumes sicher, dass ausreichend Speicherplatz für die Klon-Metadaten vorhanden ist.</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">Stellen Sie beim Wiederherstellen von Datenbanken sicher, dass auf dem Volume ausreichend Speicherplatz verfügbar ist.</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">Erstellen einer separaten Richtlinie für das Management und die Sicherung von Systemdatenbanken mindestens einmal pro Woche</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">Klonen von Datenbanken mit SnapCenter</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">Um eine Datenbank an einem anderen Standort in einer Entwicklungs- oder Testumgebung oder zur Erstellung einer Kopie für geschäftliche Analysen zu wiederherstellen, empfiehlt NetApp die Nutzung der Cloning-Methodik, um eine Kopie der Datenbank auf derselben Instanz oder einer alternativen Instanz zu erstellen.</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">Das Klonen von Datenbanken, die 500 GB auf einer iSCSI-Festplatte sind, die auf einer FSX für ONTAP-Umgebung gehostet wird, dauert normalerweise weniger als fünf Minuten. Nach Abschluss des Klonens kann der Benutzer anschließend alle erforderlichen Lese-/Schreibvorgänge für die geklonte Datenbank ausführen. Die meiste Zeit wird für das Scannen von Festplatten benötigt (diskpart). Das Klonverfahren von NetApp dauert unabhängig von der Größe der Datenbanken normalerweise weniger als 2 Minuten.</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">Das Klonen einer Datenbank kann mit der dualen Methode durchgeführt werden: Sie können einen Klon aus dem letzten Backup erstellen oder das Lebenszyklusmanagement von Klonen verwenden, mit dem die neueste Kopie auf der sekundären Instanz zur Verfügung gestellt werden kann.</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter ermöglicht Ihnen, die Klonkopie auf der erforderlichen Festplatte zu mounten, um das Format der Ordnerstruktur auf der sekundären Instanz beizubehalten und Backup-Jobs weiterhin zu planen.</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">Klonen von Datenbanken auf den neuen Datenbanknamen in derselben Instanz</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">Mit den folgenden Schritten können Datenbanken in derselben SQL Server Instanz geklont werden, die auf EC2 ausgeführt wird:</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">Wählen Sie Ressourcen und dann die Datenbank aus, die geklont werden soll.</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">Wählen Sie den Backup-Namen aus, den Sie klonen möchten, und wählen Sie Clone aus.</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">Befolgen Sie die Anweisungen zum Klonen im Backup-Fenster, um den Klonprozess abzuschließen.</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">Wählen Sie Überwachen, um sicherzustellen, dass das Klonen abgeschlossen ist.</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">Klonen von Datenbanken in der neuen SQL Server-Instanz, die auf EC2 ausgeführt wird</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">Mit dem folgenden Schritt werden Datenbanken zu der neuen SQL Server-Instanz geklont, die auf EC2 läuft:</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">Einen neuen SQL Server auf EC2 in derselben VPC erstellen.</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">Aktivieren Sie das iSCSI-Protokoll und MPIO, und richten Sie dann die iSCSI-Verbindung zu FSX für ONTAP ein, indem Sie Schritt 3 und 4 im Abschnitt „Volumes und LUNs für SQL Server erstellen“ befolgen.</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">Fügen Sie einen neuen SQL Server auf EC2 in SnapCenter durch folgen Sie Schritt 3 im Abschnitt „Installieren und Einrichten für SnapCenter.“</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">Wählen Sie Ressource &gt; Instanz anzeigen, und wählen Sie Ressource aktualisieren.</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">Wählen Sie Ressourcen und dann die Datenbank aus, die Sie klonen möchten.</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">Wählen Sie den Backup-Namen aus, den Sie klonen möchten, und wählen Sie dann Klonen aus.</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">Befolgen Sie die Anweisungen zum Klonen aus Backup, indem Sie die neue SQL Server Instanz auf EC2 und den Instanznamen angeben, um den Klonprozess abzuschließen.</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">Anhänge</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">Anhang A: YAML-Datei zur Verwendung in Cloud-Formationsvorlage</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">Die folgende .yaml-Datei kann mit der Cloud-Formationsvorlage in der AWS-Konsole verwendet werden.</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">Dieser GitHub-Link</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">Um DIE ISCSI-LUN-Erstellung und die NetApp SnapCenter-Installation mit PowerShell zu automatisieren, klonen Sie die repo von<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>.</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">Anhang B: PowerShell Skripte für die Bereitstellung von Volumes und LUNs</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">Das folgende Skript wird verwendet, um Volumes und LUNs bereitzustellen und iSCSI auf der Grundlage der oben angegebenen Anleitung einzurichten. Es gibt zwei PowerShell Skripte:</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">Führen Sie die Datei aus<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> Zuerst und das zweite Skript wird automatisch ausgeführt, nachdem der Server neu gestartet wurde. Diese PowerShell Skripte können aufgrund von Berechtigungen für den SVM entfernt werden, nachdem sie ausgeführt wurden.</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">Erste Schritte mit FSX für NetApp ONTAP</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">Überblick über die SnapCenter Schnittstelle</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">Tour durch Optionen im SnapCenter-Navigationsbereich</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">SnapCenter 4.0 für SQL Server Plug-in einrichten</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">So sichern und wiederherstellen Sie Datenbanken mit SnapCenter mit SQL Server Plug-in</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">Wie man eine Datenbank mit SnapCenter mit SQL Server Plug-in klonen kann</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">SQL Server auf AWS EC2 mit Amazon FSX für NetApp ONTAP</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">Zusammenfassend lässt sich sagen, dass die Umstellung von rotierenden Festplatten auf All-Flash-Systeme die Performance steigert. Die Anzahl der Computing-Nodes war nicht der Engpass. Mit NetApp All-Flash-Storage lässt sich die Runtime Performance gut skalieren.</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">Autoren: Chris Reno, Josh Powell und Suresh ThopPay – NetApp Solutions Engineering</block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">Annahmen, Voraussetzungen und Komponentenübersicht</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">Lesen Sie sich vor der Bereitstellung dieser Lösung die Übersicht über die Komponenten durch, welche Voraussetzungen für die Implementierung der Lösung und die Annahmen erfüllt sind, die bei der Dokumentation dieser Lösung zu beachten sind.</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">Anforderungen FÜR DR-Lösung, Anforderungen und Planung</block>
  <block id="7e5819b239532c950a0428a48f7be036" category="paragraph"><block ref="7e5819b239532c950a0428a48f7be036" category="inline-link-macro-rx"></block></block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">DR mit SnapCenter</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">Nachdem Sie sich bei der Konsole angemeldet haben, müssen Sie SnapCenter für Backup-SQL Server und Oracle-Datenbanken konfigurieren.</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">Bereitstellung eines sekundären Veeam Backup &amp; Amp; Replication Servers</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">Konfigurieren Sie den sekundären Veeam Backup &amp;amp; Replication Server</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Veeam Backup &amp; Replication</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp; Replication Server</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp; Replication-Konfiguration</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355: SnapCenter Plug-in VMware vSphere - Produktsicherheit</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Das NetApp SnapCenter Plug-in für VMware vSphere nutzt folgende sichere Entwicklungsaktivitäten:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Dynamic Application Security Testing (DAST).* Technologien, die entwickelt wurden, um gefährdete Bedingungen für Anwendungen in ihrem laufenden Zustand zu erkennen. DAST testet die freigesetzten HTTP- und HTML-Schnittstellen von Web-enable-Anwendungen.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Codewährung von Drittanbietern.* im Rahmen der Entwicklung von Software und der Verwendung von Open-Source-Software (OSS) ist es wichtig, Sicherheitslücken zu beheben, die mit OSS verbunden sein könnten, die in Ihr Produkt integriert wurden. Dies ist ein kontinuierlicher Aufwand, da bei der Version der OSS-Komponente eine neu entdeckte Sicherheitsanfälligkeit jederzeit gemeldet wird.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">*Penetrationstest.* Penetrationstest ist der Prozess, um ein System, eine Web-Anwendung oder ein Netzwerk zu evaluieren, um Sicherheitslücken zu finden, die von einem Angreifer ausgenutzt werden könnten. Penetrationstests (Penetrationstests) bei NetApp werden von einer Gruppe genehmigter und vertrauenswürdiger Drittanbieter durchgeführt. Ihr Testumfang umfasst die Einleitung von Angriffen gegen eine Anwendung oder Software wie feindliche Eindringlinge oder Hacker mit ausgereiften Exploitationsmethoden oder -Tools.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Product Security Incident Response Aktivität.* Sicherheitslücken werden sowohl intern als auch extern entdeckt und können ein ernsthaftes Risiko für NetAppâ €™s Ruf darstellen, wenn sie nicht rechtzeitig angesprochen werden. Zur Erleichterung dieses Prozesses meldet ein PSIRT (Product Security Incident Response Team) die Sicherheitsanfälligkeiten und verfolgt diese.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Das NetApp SnapCenter Plug-in für VMware vSphere umfasst die folgenden Sicherheitsfunktionen in jeder Version:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Eingeschränkter Shell-Zugriff.* SSH ist standardmäßig deaktiviert, und einmalige Anmeldungen sind nur erlaubt, wenn sie über die VM-Konsole aktiviert sind.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Zugangswarnung im Anmeldebanner.* das folgende Anmeldebanner wird angezeigt, nachdem der Benutzer einen Benutzernamen in die Anmeldeaufforderung eingegeben hat:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Nachdem der Benutzer die Anmeldung über den SSH-Kanal abgeschlossen hat, wird die folgende Ausgabe angezeigt:</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC).* NetApp ONTAP Tools verfügen über zwei Arten von RBAC-Steuerelementen:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Native vCenter Server-Berechtigungen.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Rollenbasierte Zugriffssteuerung (Role Based Access Control, RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Spezifische Berechtigungen für VMware vCenter Plug-in Weitere Informationen finden Sie unter<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Verschlüsselte Kommunikationskanäle.* Alle externen Kommunikation erfolgt über HTTPS mit TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">Die folgende Tabelle enthält die Details zum offenen Anschluss.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">TCP v4/v6-Portnummer</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">HTTPS-Verbindungen für OVA-GUI</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (standardmäßig deaktiviert)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (nur interne Verbindungen; externe Verbindungen standardmäßig deaktiviert)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (Datensicherungsservices)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Erstellen und/oder Importieren eines SSL-Zertifikats in das SnapCenter Plug-in für VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Unterstützung für Zertifizierungsstelle (CA) signierte Zertifikate.* SnapCenter Plug-in für VMware vSphere unterstützt die Funktion von CA signierten Zertifikaten. Siehe<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Passwortrichtlinien.* die folgenden Kennwortrichtlinien sind in Kraft:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Alle Anmeldeinformationen werden mit SHA256 Hashing gespeichert.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Basis Betriebssystem-Image.* das Produkt wird mit Debian Base OS für OVA ausgeliefert, mit eingeschränktem Zugriff und Shell-Zugriff. So wird die Angriffsfläche reduziert. Jedes Betriebssystem der SnapCenter Version wird mit den neuesten Sicherheits-Patches aktualisiert, die für maximale Sicherheit verfügbar sind.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp entwickelt Softwarefunktionen und Sicherheits-Patches zu den SnapCenter Plug-ins für die VMware vSphere Appliance und gibt sie anschließend dem Kunden als gebündelte Software-Plattform frei. Da diese Appliances bestimmte Linux Unterbetriebssystem-Abhängigkeiten sowie unsere proprietäre Software umfassen, empfiehlt NetApp, am Unterbetriebssystem keine Änderungen vorzunehmen, da dies ein hohes Potenzial hat, die NetApp Appliance zu beeinträchtigen. Dies könnte sich darauf auswirken, inwieweit NetApp die Appliance unterstützt. NetApp empfiehlt, unsere neueste Code-Version für Appliances zu testen und zu implementieren, da sie veröffentlicht werden, um sicherheitsbezogene Probleme zu patchen.</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">März 2022</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Wir haben eine Validierung des Hadoop Storage Tiering auf einem NetApp AFF Storage Controller und einem E-Series Storage Controller mit SSD- und SAS-Laufwerken mit unterschiedlichen Storage-Richtlinien durchgeführt. Das Spark-Cluster mit AFF A800 verfügt über vier Computing-Worker-Nodes, während das Cluster mit E-Series acht Nodes hat. Hauptsächlich wurde ein Vergleich der Performance von Solid State-Laufwerken (SSDs) und Festplatten (HDDs) durchgeführt.</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">Wir haben die Validierung des Hadoop Storage Tiering auf einem NetApp AFF Storage Controller und einem E-Series Storage Controller mit SSD- und SAS-Laufwerken mit unterschiedlichen Storage-Richtlinien durchgeführt. Das Spark-Cluster mit AFF A800 verfügt über vier Computing-Worker-Nodes, während das Cluster mit E-Series acht Nodes hat. Wir haben dies in erster Linie getan, um die Performance von Solid-State-Laufwerken mit Festplatten zu vergleichen. &gt;&gt;&gt;&gt;&gt;&gt;&gt; A51c9ddf73ca69e1120ce05edc7b09607b96eae</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">Mit TeraSort sortiert die SSD-Konfiguration 1 TB an Daten 1138.36-mal schneller als die NL-SAS-Konfiguration. Darüber hinaus verwendete die SSD-Konfiguration die Hälfte der Computing-Nodes und die Hälfte der Festplattenlaufwerke (insgesamt 24 SSD-Laufwerke). Daher war es pro Laufwerk ca. dreimal schneller als die NL-SAS-Konfiguration. &lt;&lt;&lt;&lt;&lt;&lt;&lt; KOPF</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">Die Schlussfolgerung lautet: Der Wechsel von rotierenden Festplatten zu All-Flash-Systemen verbessert die Performance. Die Anzahl der Computing-Nodes war nicht der Engpass. Mit dem All-Flash-Storage von NetApp lässt sich die Runtime Performance gut skalieren.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Mit NFS entsprach der Summe der Daten, die je nach Workload die Anzahl der Computing-Nodes reduzieren konnte. Die Apache Spark-Cluster-Benutzer müssen Daten nicht manuell neu verteilen, wenn sich die Anzahl der Computing-Nodes ändert.</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">Mit NFS waren die Daten in funktioneller Hinsicht gleichbedeutend mit den gemeinsamen Pools, wodurch sich die Anzahl der Computing-Nodes je nach Workload reduzieren ließ. Apache Spark-Cluster-Benutzer müssen die Daten nicht manuell neu verteilen, wenn sie die Anzahl der Computing-Nodes ändern. &gt;&gt;&gt;&gt;&gt;&gt;&gt; A51c9ddf73ca69e1120ce05edc7b09607b96eae</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">SnapCenter Plug-in VMware vSphere – Produktsicherheit</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP unterstützt alle maßgeblichen Storage-Protokolle für die Virtualisierung, beispielsweise iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) oder Non-Volatile Memory Express over Fibre Channel (NVMe/FC) für SAN-Umgebungen sowie NFS (v3 und v4.1) und SMB oder S3 für Gastverbindungen. Die Kunden können die für ihre Umgebung am besten geeigneten Protokolle auswählen und sie nach Bedarf in einem einzigen System kombinieren.</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP unterstützt alle maßgeblichen Storage-Protokolle für die Virtualisierung, beispielsweise iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) oder Non-Volatile Memory Express over Fibre Channel (NVMe/FC) für SAN-Umgebungen sowie NFS (v3 und v4.1) und SMB oder S3 für Gastverbindungen. Die Kunden können die für ihre Umgebung am besten geeigneten Protokolle auswählen und sie nach Bedarf in einem einzigen System kombinieren. Man kann beispielsweise die allgemeine Nutzung von NFS-Datenspeichern mit einigen iSCSI-LUNs oder Gast-Shares erweitern.</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">*NetApp Snapshot Kopien.* ONTAP bietet sofortige Snapshot Kopien einer VM oder eines Datastores ohne Performance-Einbußen bei der Erstellung oder Nutzung einer Snapshot Kopie. Sie können zur Erstellung eines Wiederherstellungspunkts für eine VM vor dem Patching oder zur einfachen Datensicherung verwendet werden. Beachten Sie, dass sich diese Unterschiede zu den VMware Snapshots (Konsistenz) unterscheiden. Die einfachste Möglichkeit zum Erzeugen von ONTAP Snapshot Kopien besteht darin, Backups von VMs und Datastores mit dem SnapCenter Plug-in für VMware vSphere zu erstellen.</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">*NetApp Volume Encryption und NetApp Aggregate Encryption.* NetApp Verschlüsselungsoptionen bieten einfache softwarebasierte Verschlüsselung zum Schutz von Daten im Ruhezustand.</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">*REST und Ansible.* Verwendung<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> Um das Storage- und Datenmanagement zu automatisieren, und<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> Zum Konfigurations-Management Ihrer ONTAP Systeme.</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">Einige ONTAP Funktionen sind nicht für vSphere Workloads geeignet. Die FlexGroup Technologie vor ONTAP 9.8 hatte beispielsweise keine vollständige Klonunterstützung und wurde nicht mit vSphere getestet (Informationen über Neuigkeiten zum Einsatz mit vSphere finden Sie im Abschnitt „FlexGroup“). FlexCache-Technologie ist auch nicht optimal für vSphere, da sie für vorwiegend gelesene Workloads konzipiert ist. Schreibzugriffe können problematisch sein, wenn der Cache vom Ursprung getrennt wird und auf beiden Seiten NFS-Datenspeicher-Fehler verursacht werden.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Die ONTAP Tools für VMware vSphere sind eine Reihe von Tools, die ONTAP Storage zusammen mit vSphere verwenden. Das vCenter Plug-in, ehemals Virtual Storage Console (VSC), vereinfacht Storage-Management- und Effizienzfunktionen, verbessert die Verfügbarkeit und senkt die Storage-Kosten und den Betriebsaufwand – sei es bei SAN oder NAS. Dieses Plug-in nutzt Best Practices für die Bereitstellung von Datastores und optimiert ESXi Hosteinstellungen für NFS- und Block-Storage-Umgebungen. Bei all diesen Vorteilen empfiehlt NetApp, bei der Verwendung von vSphere mit Systemen mit ONTAP Software diese ONTAP Tools als Best Practice zu verwenden. Sie umfasst eine Server-Appliance, Erweiterungen der Benutzeroberfläche für vCenter, VASA Provider und Storage Replication Adapter. Nahezu alles in ONTAP Tools lässt sich mithilfe einfacher REST-APIs automatisieren – auch mit den meisten modernen Automatisierungs-Tools nutzbar.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*VCenter UI Extensions.* die UI-Erweiterungen der ONTAP-Tools vereinfachen die Arbeit von Betriebsteams und vCenter Administratoren durch die Verwendung benutzerfreundlicher, kontextabhängiger Menüs zum Managen von Hosts und Storage, Informations-Portlets und nativen Alarmfunktionen direkt in der vCenter-Benutzeroberfläche für optimierte Workflows.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*VASA Provider für ONTAP.* der VASA Provider für ONTAP unterstützt das VMware vStorage APIs for Storage Awareness (VASA) Framework. Er wird im Rahmen von ONTAP Tools für VMware vSphere als eine einzelne virtuelle Appliance zur einfachen Implementierung bereitgestellt. VASA Provider verbindet vCenter Server mit ONTAP und erleichtert so die Bereitstellung und das Monitoring von VM-Storage. Es aktiviert die Unterstützung und das Management von Storage-Funktionsprofilen für VMware Virtual Volumes (VVols) und die VVols Performance für einzelne VMs sowie Alarme für die Monitoring-Kapazität und -Compliance mit den Profilen.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* SRA wird zusammen mit VMware Site Recovery Manager (SRM) zum Management der Datenreplizierung zwischen Produktions- und Disaster-Recovery-Standorten sowie zum unterbrechungsfreien Testen der DR-Replikate verwendet. Diese Software hilft bei der Automatisierung der Erkennungs-, Recovery- und Sicherungsaufgaben. Sie enthält sowohl eine SRA Server-Appliance als auch SRA Adapter für den Windows SRM Server und eine SRM Appliance.</block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">Das NetApp NFS Plug-in für VMware VAAI ist ein Plug-in für ESXi Hosts, mit dem diese VAAI Funktionen mit NFS-Datastores unter ONTAP verwenden können. Die Software unterstützt den Copy-Offload für Klonvorgänge, die Speicherplatzreservierung für Thick Virtual Disk Files und den Offload von Snapshot Kopien. Die Verlagerung von Kopiervorgängen in den Storage erfolgt nicht unbedingt schneller, sorgt aber dafür, dass die Anforderungen an die Netzwerkbandbreite reduziert werden und Host-Ressourcen wie CPU-Zyklen, Puffer und Warteschlangen verlagert werden. Sie können das Plug-in mithilfe von ONTAP Tools für VMware vSphere auf ESXi Hosts oder, sofern unterstützt, vSphere Lifecycle Manager (vLCM) installieren.</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">Neuerungen bei der VMware Virtualisierung</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">01/12/2023</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">Zusätzlicher Blog: Sichern Sie Ihre SQL Server Workloads mithilfe von NetApp SnapCenter mit Amazon FSX für NetApp ONTAP</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">Schützen Sie Ihre SQL Server-Workloads mit NetApp SnapCenter mit Amazon FSX für NetApp ONTAP</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
</blocks>