---
sidebar: sidebar 
permalink: ai/hcaios_executive_summary.html 
keywords: hybrid cloud, NetApp, AI 
summary:  
---
= TR-4841: Hybrides Cloud-KI-Betriebssystem mit Daten-Caching
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io

[role="lead"]
Das explosionsartige Datenwachstum und das exponentielle Wachstum VON ML und KI haben sich konvergiert, um eine Zettabyte-Wirtschaft mit einzigartigen Herausforderungen bei Entwicklung und Implementierung zu schaffen.

Es ist zwar allgemein bekannt, dass ML-Modelle datenintensiv sind und in Bezug auf Computing-Ressourcen hochperformanten Storage benötigen. In der Praxis ist es jedoch nicht ganz einfach, dieses Modell zu implementieren, insbesondere bei Hybrid Cloud- und elastischen Computing-Instanzen. In der Regel werden enorme Datenmengen in kostengünstigen Data Lakes gespeichert, auf denen hochperformante KI-Computing-Ressourcen wie GPUs nicht effizient zugreifen können. In einer Hybrid-Cloud-Infrastruktur, in der einige Workloads in der Cloud ausgeführt werden und einige sich vor Ort oder in einer anderen HPC-Umgebung vollständig befinden, wird dieses Problem verschärft.

In diesem Dokument stellen wir eine neue Lösung vor, mit der IT-Experten und Data Engineers eine echte Hybrid-Cloud-KI-Plattform erstellen können. Diese Plattform bietet einen Topologiefähigen Daten-Hub, mit dem Datenanalysten sofort und automatisch einen Cache ihrer Datensätze in der Nähe ihrer Computing-Ressourcen erstellen können. Wo immer sie sich befinden. Somit kann nicht nur das Training eines hochperformanten Modells durchgeführt werden, sondern es werden auch zusätzliche Vorteile erzielt, etwa die Zusammenarbeit mehrerer KI-Fachleute, die innerhalb eines Dataset-Version-Hubs sofortigen Zugriff auf Datensatz-Caches, -Versionen und -Lineages haben.
