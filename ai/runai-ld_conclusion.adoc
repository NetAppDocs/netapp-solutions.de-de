---
sidebar: sidebar 
permalink: ai/runai-ld_conclusion.html 
keywords: azure, lane, detection, run, ai, workloads 
summary: Bei der Entwicklung dieses technischen Berichts hat NetApp AI gemeinsam mit SEINER RUN KI die einzigartigen Funktionen der Azure NetApp Files zusammen mit einer KI-Plattform zur Vereinfachung der Orchestrierung von KI-Workloads demonstriert. 
---
= Schlussfolgerung
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


NetApp und RUN: KI haben bei der Erstellung dieses technischen Berichts gemeinsam die einzigartigen Funktionen der Azure NetApp Files zusammen MIT DER RUN-KI-Plattform zur Vereinfachung der Orchestrierung von KI-Workloads demonstriert. Dieser technische Bericht enthält eine Referenzarchitektur zur Optimierung des Prozesses von Daten-Pipelines und Workload-Orchestrierung für Distributed Lane-Erkennungstrainings.

Fazit: Was verteiltes Training nach Maß angeht (insbesondere in einer Public Cloud-Umgebung), ist die Ressourcenorchestrierung und die Storage-Komponente ein wesentlicher Bestandteil der Lösung. Sicherstellen, dass das Datenmanagement nie die Verarbeitung mehrerer GPUs beeinträchtigt, führt daher zu einer optimalen Auslastung der GPU-Zyklen. Damit wird das System für große verteilte Schulungszwecke so kosteneffizient wie möglich.

Mit der Data Fabric von NetApp können Data Scientists und Data Engineers On-Premises- und Cloud-Ressourcen miteinander verbinden, um synchrone Daten zu speichern – ohne manuelle Eingriffe. Mit anderen Worten: Die Data-Fabric-Infrastruktur gestaltet das Management von KI-Workflows, die über mehrere Standorte verteilt sind, reibungslos. Es erleichtert zudem die bedarfsgerechte Datenverfügbarkeit, indem die Daten näher an das Computing übertragen und Analysen, Training und Validierungen durchgeführt werden – wo und wann immer dies erforderlich ist. Dies ermöglicht nicht nur die Datenintegration, sondern auch Schutz und Sicherheit der gesamten Datenpipeline.
