---
sidebar: sidebar 
permalink: ai/aks-anf_jupyter_notebooks.html 
keywords: jupyter, notebook, reference 
summary: Dieser Abschnitt enthält Links zu zwei Jupyter-Notizbüchern, die für diesen technischen Bericht relevant sind. 
---
= Jupyter-Notebooks als Referenz
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aks-anf_dataset_and_model_versioning_using_netapp_dataops_toolkit.html["Früher: Dataset and Model Versioning Using NetApp DataOps Toolkit."]

Diesem technischen Bericht sind zwei Jupyter Notebooks zugeordnet:

* link:https://nbviewer.jupyter.org/github/NetAppDocs/netapp-solutions/blob/main/media/CTR-PandasRF-collated.ipynb["*CTR-PandasRF-collated.ipynb.*"] Dieses Notebook lädt Tag 15 aus dem Criteo Terabyte Click Protokolldatensatz, verarbeitet und formatiert Daten in einen Pandas DataFrame, trainiert ein Scikit-Learn Zufallswaldmodell, führt Vorhersage aus und berechnet Genauigkeit.
* link:https://nbviewer.jupyter.org/github/NetAppDocs/netapp-solutions/blob/main/media/criteo_dask_RF.ipynb["*criteo_dask_RF.ipynb.*"] Dieses Notebook lädt Tag 15 aus dem Criteo Terabyte Click Log Datensatz, verarbeitet und formatiert Daten in einen Damast CuDF, trainiert ein Dusk CuML Zufallswaldmodell, führt Vorhersage aus und berechnet Genauigkeit. Durch die Nutzung von mehreren Worker-Nodes mit GPUs ist dieser verteilte Daten- und Modellverarbeitungs- und Trainingsansatz äußerst effizient. Je mehr Daten Sie verarbeiten, desto größer ist die Zeitersparnis im Vergleich zu einem herkömmlichen ML-Ansatz. Dieses Notebook lässt sich in der Cloud, vor Ort oder in einer hybriden Umgebung bereitstellen, in der Ihr Kubernetes-Cluster Computing und Storage an verschiedenen Standorten enthält, sofern Ihr Netzwerk-Setup Daten und die Modellverteilung frei ermöglicht.


link:aks-anf_conclusion.html["Weiter: Fazit."]
