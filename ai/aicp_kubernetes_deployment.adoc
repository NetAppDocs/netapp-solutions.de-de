---
sidebar: sidebar 
permalink: ai/aicp_kubernetes_deployment.html 
keywords: NVIDIA, GPU, Kubernetes, Control Plane, Trident 
summary: Auf dieser Seite werden die Aufgaben beschrieben, die zur Implementierung eines Kubernetes-Clusters erforderlich sind, damit die NetApp AI Control Plane Lösung implementiert werden kann. Wenn Sie bereits einen Kubernetes Cluster besitzen, können Sie diesen Abschnitt überspringen, solange Sie eine von Kubeflow und NetApp Trident unterstützte Version von Kubernetes ausführen. 
---
= Kubernetes Deployment
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
In diesem Abschnitt werden die Aufgaben beschrieben, die zur Implementierung eines Kubernetes-Clusters erforderlich sind, in dem die NetApp AI Control Plane Lösung implementiert werden kann. Wenn Sie bereits einen Kubernetes Cluster besitzen, können Sie diesen Abschnitt überspringen, solange Sie eine von Kubeflow und NetApp Trident unterstützte Version von Kubernetes ausführen. Eine Liste der von Kubeflow unterstützten Kubernetes-Versionen finden Sie im https://www.kubeflow.org/docs/started/getting-started/["Offizielle Dokumentation von Kubeflow"^]. Eine Liste der von Trident unterstützten Kubernetes-Versionen finden Sie im https://netapp-trident.readthedocs.io/["Trident Dokumentation"^].

Für lokale Kubernetes-Implementierungen, die Bare-Metal-Nodes mit NVIDIA-GPU(s) einbinden, empfiehlt NetApp die Verwendung des NVIDIA DeepOps Kubernetes-Implementierungstools. In diesem Abschnitt wird die Bereitstellung eines Kubernetes-Clusters mit DeepOps beschrieben.



== Voraussetzungen

Bevor Sie die in diesem Abschnitt beschriebenen Bereitstellungsaufgaben ausführen, gehen wir davon aus, dass Sie bereits die folgenden Aufgaben ausgeführt haben:

. Sie haben bereits alle Bare-Metal-Kubernetes-Nodes (z. B. ein NVIDIA DGX-System, das Teil eines ONTAP AI Pods ist) gemäß den Standardkonfigurationsanweisungen konfiguriert.
. Sie haben ein unterstütztes Betriebssystem auf allen Kubernetes Master- und Worker-Nodes und auf einem Deployment Jump-Host installiert. Eine Liste der von DeepOps unterstützten Betriebssysteme finden Sie im https://github.com/NVIDIA/deepops["DeepOps GitHub-Website"^].




== Verwenden Sie NVIDIA DeepOps zum Installieren und Konfigurieren von Kubernetes

Um Ihren Kubernetes-Cluster mit NVIDIA DeepOps zu implementieren und zu konfigurieren, führen Sie die folgenden Aufgaben über einen Bereitstellungs-Jump-Host aus:

. Laden Sie NVIDIA DeepOps herunter, indem Sie den Anweisungen auf der folgen https://github.com/NVIDIA/deepops/tree/master/docs["Erste Schritte"^] Auf der NVIDIA DeepOps GitHub Website.
. Implementieren Sie Kubernetes in Ihrem Cluster, indem Sie die Anweisungen auf dem befolgen https://github.com/NVIDIA/deepops/tree/master/docs/k8s-cluster["Seite „Kubernetes Deployment Guide“"^] Auf der NVIDIA DeepOps GitHub Website.

