---
sidebar: sidebar 
permalink: ai/aipod_nv_intro.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NetApp AIPod mit NVIDIA DGX Systemen ist eine Referenzarchitektur für die Enterprise-Klasse basierend auf NVIDIA BasePOD für Deep Learning und künstliche Intelligenz mit NetApp ONTAP AFF Storage-Systemen, NVIDIA Netzwerken und DGX Systemen. 
---
= NVA-1173 NetApp AIPod mit NVIDIA DGX Systemen – Einführung
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


image:PoweredByNVIDIA.png["200,200,Fehler: Fehlendes Grafikbild"]

[role="lead"]
NetApp Solution Engineering



== Zusammenfassung

Das NetApp&#8482; AIPod mit NVIDIA DGX&#8482; Systemen und Cloud-vernetzten NetApp Storage-Systemen vereinfacht die Infrastrukturbereitstellung für Machine-Learning- (ML) und KI-Workloads (künstliche Intelligenz), indem Komplexität und Unsicherheiten bei der Systemaufsetzung beseitigt werden. Das Design basiert auf NVIDIA DGX BasePOD &#8482 und bietet außergewöhnliche Computing-Performance für Workloads der neuesten Generation. AIPod mit NVIDIA DGX Systemen fügt NetApp AFF Storage-Systeme hinzu. Damit können Kunden klein anfangen und unterbrechungsfrei wachsen. Gleichzeitig erhalten sie intelligente Datenmanagement-Funktionen, mit denen sich Daten zwischen Datenaufnahme, zentraler Datenplattform und Cloud frei verschieben lassen. NetApp AIPod ist Teil des größeren Portfolios an NetApp KI-Lösungen, wie in der Abbildung unten dargestellt.

_NetApp AI Lösungsportfolio_

image:aipod_nv_portfolio.png["Die Abbildung zeigt den Input/Output-Dialog oder die Darstellung des schriftlichen Inhalts"]

Dieses Dokument beschreibt die wichtigsten Komponenten der AIPod Referenzarchitektur, Informationen zur Systemkonnektivität und Konfiguration, die Ergebnisse der Validierungstests sowie Hinweise zur Dimensionierung der Lösung. Dieses Dokument richtet sich an Lösungstechniker von NetApp und Partnern sowie strategische Entscheidungsträger von Kunden, die an der Implementierung einer hochperformanten Infrastruktur für ML/DL- und Analyse-Workloads interessiert sind.
