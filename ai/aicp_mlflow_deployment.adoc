---
sidebar: sidebar 
permalink: ai/aicp_mlflow_deployment.html 
keywords: AI, control plane, MLOps, MLflow 
summary: Open-Source-MLOPs mit NetApp – MLflow-Bereitstellung 
---
= MLflow-Bereitstellung
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
In diesem Abschnitt werden die Aufgaben beschrieben, die Sie ausführen müssen, um MLflow in Ihrem Kubernetes-Cluster bereitzustellen.


NOTE: MLFlow kann auf anderen Plattformen als Kubernetes implementiert werden. Die Implementierung von MLFlow auf anderen Plattformen als Kubernetes ist nicht im Umfang dieser Lösung enthalten.



== Voraussetzungen

Bevor Sie die in diesem Abschnitt beschriebenen Bereitstellungsaufgaben ausführen, gehen wir davon aus, dass Sie bereits die folgenden Aufgaben ausgeführt haben:

. Sie verfügen bereits über einen funktionierenden Kubernetes-Cluster.
. Sie haben NetApp Astra Trident bereits in Ihrem Kubernetes-Cluster installiert und konfiguriert. Weitere Informationen zu Astra Trident finden Sie im link:https://docs.netapp.com/us-en/trident/index.html["Astra Trident-Dokumentation"^].




== Installieren Sie Helm

MLflow wird mit Helm implementiert, einem beliebten Paketmanager für Kubernetes. Bevor Sie MLflow implementieren, müssen Sie Helm auf Ihrem Kubernetes-Kontroll-Node installieren. Um Helm zu installieren, folgen Sie den https://helm.sh/docs/intro/install/["Installationsanweisungen"^] Anweisungen in der offiziellen Helm-Dokumentation.



== Standard-Kubernetes StorageClass festlegen

Bevor Sie MLflow implementieren, müssen Sie eine Standard-StorageClass innerhalb Ihres Kubernetes-Clusters festlegen. Befolgen Sie die Anweisungen im Abschnitt, um eine Standard-StorageClass innerhalb Ihres Clusters festzulegen link:aicp_kubeflow_deployment_overview.html["Kubeflow Deployment"] . Wenn Sie bereits eine Standard-StorageClass innerhalb Ihres Clusters festgelegt haben, können Sie diesen Schritt überspringen.



== Bereitstellen von MLflow

Sobald die Voraussetzungen erfüllt sind, können Sie mit der MLflow-Bereitstellung mit dem Helm-Diagramm beginnen.



=== Konfigurieren Sie die MLflow Helm Chart Deployment.

Bevor wir MLflow mit dem Helm-Diagramm bereitstellen, können wir die Bereitstellung so konfigurieren, dass sie NetApp Trident-Speicherklasse verwendet und andere Parameter entsprechend unseren Anforderungen mithilfe einer *config.yaml*-Datei ändern. Ein Beispiel für die Datei *config.yaml* finden Sie unter: https://github.com/bitnami/charts/blob/main/bitnami/mlflow/values.yaml[]


NOTE: Sie können die Trident storageClass unter dem Parameter *global.defaultStorageClass* in der Datei config.yaml einstellen (z.B. storageClass: "ontap-flexvol").



=== Installieren des Helm-Diagramms

Das Helm-Diagramm kann mit der benutzerdefinierten *config.yaml*-Datei für MLflow mit folgendem Befehl installiert werden:

[source, shell]
----
helm install oci://registry-1.docker.io/bitnamicharts/mlflow -f config.yaml --generate-name --namespace jupyterhub
----

NOTE: Der Befehl implementiert MLflow auf dem Kubernetes-Cluster in der benutzerdefinierten Konfiguration über die bereitgestellte *config.yaml*-Datei. MLflow wird im angegebenen Namespace implementiert und ein zufälliger Release-Name wird über kubernetes für die Version gegeben.



=== Implementierung Prüfen

Nach der Bereitstellung des Helm-Diagramms können Sie überprüfen, ob der Dienst über folgende Funktionen zugänglich ist:

[source, shell]
----
kubectl get service -n jupyterhub
----

NOTE: Ersetzen Sie *jupyterhub* durch den Namespace, den Sie während der Bereitstellung verwendet haben.

Folgende Dienste sollten angezeigt werden:

[source, shell]
----
NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)           AGE
mlflow-1719843029-minio           ClusterIP   10.233.22.4     <none>        80/TCP,9001/TCP   25d
mlflow-1719843029-postgresql      ClusterIP   10.233.5.141    <none>        5432/TCP          25d
mlflow-1719843029-postgresql-hl   ClusterIP   None            <none>        5432/TCP          25d
mlflow-1719843029-tracking        NodePort    10.233.2.158    <none>        30002:30002/TCP   25d
----

NOTE: Wir haben die config.yaml-Datei bearbeitet, um den NodePort-Dienst für den Zugriff auf MLflow auf Port 30002 zu verwenden.



=== Zugriff auf MLflow

Sobald alle mit MLflow verbundenen Dienste laufen, können Sie über die angegebene NodePort- oder loadbalancer-IP-Adresse darauf zugreifen (z.B. http://10.61.181.109:30002[])
