---
sidebar: sidebar 
permalink: ai/aipod_nv_storage.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NetApp AI Pod mit NVIDIA DGX Systemen – Leitfaden für Storage-Systemdesign und Sizing 
---
= NetApp AI Pod mit NVIDIA DGX Systemen – Leitfaden für Storage-Systemdesign und Sizing
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_architecture.html["Zurück: NetApp AI Pod mit NVIDIA DGX Systemen – Architektur."]



== Design von Storage-Systemen

Jedes AFF A800 Storage-System ist über vier 100-GbE-Ports von jedem Controller verbunden. Zwei Ports von jedem Controller werden für den Workload-Datenzugriff aus den DGX-Systemen verwendet. Zwei Ports von jedem Controller werden als LACP-Schnittstellengruppe konfiguriert, um den Zugriff über die Server der Managementebene für Cluster-Managementartefakte und Benutzer-Home Directorys zu unterstützen. Der gesamte Zugriff auf die Daten aus dem Storage-System erfolgt über NFS, wobei eine Storage Virtual Machine (SVM) dediziert für den KI-Workload-Zugriff und eine separate SVM für das Cluster-Management vorgesehen ist.

Die Workload-SVM ist mit insgesamt vier logischen Schnittstellen (LIFs) konfiguriert, wobei zwei LIFs für jedes Storage-VLAN vorhanden sind. Jeder physische Port hostet zwei LIFs, was zu zwei LIFs pro VLAN auf jedem Controller führt. Diese Konfiguration bietet maximale Bandbreite sowie die Möglichkeit für jede LIF ein Failover auf einen anderen Port desselben Controllers, sodass bei einem Netzwerkausfall beide Controller weiterhin aktiv bleiben. Diese Konfiguration unterstützt auch NFS über RDMA, um den GPUDirect-Storage-Zugriff zu aktivieren. Die Storage-Kapazität wird in Form eines einzelnen großen FlexGroup Volume bereitgestellt, das beide Controller umfasst. Dieser FlexGroup ist über jede der LIFs auf der SVM zugänglich. Mount-Punkte von den DGX A100 Systemen werden für den Lastausgleich über die verfügbaren LIFs verteilt.

Die Management SVM benötigt nur eine einzelne LIF, die sich auf den auf jedem Controller konfigurierten 2-Port-Schnittstellengruppen befindet. Andere FlexGroup Volumes werden auf der Management-SVM bereitgestellt, um Artefakte im Cluster-Management wie Cluster-Node-Images, Systemüberwachungsdaten und Home Directories der Endbenutzer zu beherbergen. Die nachfolgende Abbildung zeigt die logische Konfiguration des Storage-Systems.

image:oai_basepod1_logical.png["Fehler: Fehlendes Grafikbild"]



== Leitfaden Zur Größenbemessung Für Storage-Systeme

Diese Architektur dient als Referenz für Kunden und Partner, die eine DL-Infrastruktur mit NVIDIA DGX-Systemen und NetApp AFF Storage-Systemen implementieren möchten. In der folgenden Tabelle ist eine ungefähre Schätzung der Anzahl der unterstützten A100- und H100-GPUs für jedes AFF-Modell aufgeführt.

image:oai_sizing.png["Fehler: Fehlendes Grafikbild"]

Wie in gezeigt link:https://www.netapp.com/pdf.html?item=/media/21793-nva-1153-design.pdf["Frühere Versionen dieser Referenzarchitektur"]Das AFF A800 System unterstützt mühelos den DL-Trainings-Workload, der von acht DGX A100 Systemen generiert wird. Die Schätzungen für andere oben genannte Storage-Systeme wurden auf Basis dieser Ergebnisse berechnet. Schätzungen für H100-GPUs wurden durch das Verdoppeln des für A100-Systeme erforderlichen Storage-Durchsatzes berechnet.  Für größere Implementierungen mit höheren Anforderungen an die Storage-Performance können dem NetApp ONTAP Cluster bis zu 12 HA-Paare (24 Nodes) in einem einzelnen Cluster zusätzliche AFF Systeme hinzugefügt werden. Mithilfe der in dieser Lösung beschriebenen FlexGroup Technologie kann ein 24-Node-Cluster in einem Single Namespace über 40 PB und einen Durchsatz von bis zu 300 Gbit/s bereitstellen. Andere NetApp Storage-Systeme wie die AFF A400, A250 und C800 bieten Optionen für niedrigere Performance und/oder höhere Kapazität für kleinere Implementierungen zu geringeren Kosten. Da ONTAP 9 Cluster mit gemischten Modellen unterstützt, können Kunden mit einem kleineren anfänglichen Platzbedarf beginnen und bei wachsenden Kapazitäts- und Performance-Anforderungen weitere oder größere Storage-Systeme zum Cluster hinzufügen.
link:aipod_nv_conclusion.html["Weiter: NetApp AI Pod mit NVIDIA DGX Systemen – Fazit."]
