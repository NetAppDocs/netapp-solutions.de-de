---
sidebar: sidebar 
permalink: databases/automation_ora_c-series_nfs.html 
keywords: Database, Oracle, Azure, ANF, Ansible, Automation 
summary: Diese Lösung bietet einen Überblick und Details zur automatisierten Oracle-Implementierung in der NetApp AFF C-Serie als primären Datenbank-Storage mit NFS-Protokoll. Die Oracle-Datenbank wird als Container-Datenbank implementiert, bei der dNFS aktiviert ist. 
---
= TR-4992: Vereinfachte, automatisierte Oracle-Implementierung auf NetApp C-Series mit NFS
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Allen Cao, Niyaz Mohamed, NetApp

[role="lead"]
Diese Lösung bietet einen Überblick und Details zur automatisierten Oracle-Implementierung in der NetApp AFF C-Serie als primären Datenbank-Storage mit NFS-Protokoll. Die Oracle-Datenbank wird als Container-Datenbank implementiert, bei der dNFS aktiviert ist.



== Zweck

Bei der NetApp AFF C-Series handelt es sich um einen Flash-Storage mit hoher Kapazität, der den Zugriff auf All-Flash-Storage erleichtert und gleichzeitig für Unified Storage erschwinglich macht. Diese Performance reicht für viele Tier-1- oder Tier-2-Oracle-Datenbank-Workloads aus. Systeme der AFF C-Serie mit NetApp ONTAP Datenmanagement-Software bieten branchenführende Effizienz, überlegene Flexibilität, erstklassige Datenservices und Cloud-Integration. So können Sie Ihre IT-Infrastruktur skalieren, das Datenmanagement vereinfachen sowie Storage- und Stromkosten senken.

In dieser Dokumentation wird die vereinfachte Implementierung von Oracle-Datenbanken in der NetApp C-Series über NFS-Mounts mithilfe von Ansible-Automatisierung demonstriert. Die Oracle Datenbank wird in einer Konfiguration mit Container-Datenbank (CDB) und steckbaren Datenbanken (PDB) implementiert, wobei das Oracle dNFS-Protokoll aktiviert ist, um die Performance zu steigern. Darüber hinaus bietet die Lösung Best Practices zur Einrichtung von Storage Networking und Storage Virtual Machine (SVM) mit NFS-Protokoll auf Storage Controllern der C-Series. Darüber hinaus enthält die Lösung mit dem UI-Tool NetApp SnapCenter Informationen zum schnellen Backup, zur Wiederherstellung und zum Klonen von Oracle-Datenbanken.

Diese Lösung eignet sich für folgende Anwendungsfälle:

* Automatisierte Implementierung von Oracle Container-Datenbanken auf NetApp Storage Controllern der C-Serie.
* Sicherung und Klonen von Oracle Datenbanken auf C-Series mit dem SnapCenter UI Tool




== Zielgruppe

Diese Lösung ist für folgende Personen gedacht:

* Ein DBA, der Oracle auf der NetApp C-Serie einsetzen möchte.
* Ein Solution Architect für Datenbanken, der Oracle-Workloads auf der NetApp C-Series testen möchte.
* Ein Storage-Administrator, der eine Oracle Datenbank auf NetApp C-Series implementieren und managen möchte.
* Applikationseigentümer, die eine Oracle Datenbank auf der NetApp C-Serie einrichten möchten.




== Test- und Validierungsumgebung der Lösung

Die Lösung wurde in einer Testumgebung getestet und validiert. Siehe Abschnitt <<Wichtige Faktoren für die Implementierung>> Finden Sie weitere Informationen.



=== Der Netapp Architektur Sind

image::automation_ora_c-series_nfs_archit.png[Dieses Bild zeigt ein detailliertes Bild der Oracle-Implementierungskonfiguration in AWS Public Cloud mit iSCSI und ASM.]



=== Hardware- und Softwarekomponenten

[cols="33%, 33%, 33%"]
|===


3+| *Hardware* 


| NetApp C400 der C-Serie | ONTAP Version 9.13.1P3 | Zwei Festplatten-Shelfs/24 Festplatten mit 278 tib Kapazität 


| VM für DB-Server | 4 vCPUs, 16 gib RAM | Zwei Linux VM-Instanzen für die gleichzeitige Bereitstellung 


| VM für SnapCenter | 4 vCPUs, 16 gib RAM | Eine Windows VM-Instanz 


3+| *Software* 


| Redhat Linux | RHEL Linux 8.6 (LVM) – x64 Gen2 | Bereitstellung der RedHat Subscription für Tests 


| Windows Server | 2022 DataCenter x64 Gen2 | Hosting von SnapCenter-Servern 


| Oracle Datenbank | Version 19.18 | RU-Patch p34765931_190000_Linux-x86-64.zip angewendet 


| Oracle OPatch | Version 12.2.0.1.36 | Neuestes Patch p6880880_190000_Linux-x86-64.zip 


| SnapCenter Server | Version 5.0 | Workgroup-Bereitstellung 


| Öffnen Sie JDK | Version java-11-openjdk | Anforderungen für SnapCenter Plugin auf DB VMs 


| NFS | Version 3.0 | Oracle dNFS aktiviert 


| Ansible | Kern 2.16.2 | Python 3.6.8 
|===


=== Konfiguration der Oracle-Datenbank in der Laborumgebung

[cols="33%, 33%, 33%"]
|===


3+|  


| *Server* | * Datenbank* | *DB-Speicher* 


| ora_01 | NTAP1(NTAP1_PDB1,NTAP1_PDB2,NTAP1_PDB3) | /U01, /u02, /u03 NFS-Mounts auf C400-Volumes 


| ora_02 | NTAP2(NTAP2_PDB1,NTAP2_PDB2,NTAP2_PDB3) | /U01, /u02, /u03 NFS-Mounts auf C400-Volumes 
|===


=== Wichtige Faktoren für die Implementierung

* *Speicherlayout der Oracle-Datenbank.* in dieser automatisierten Oracle-Implementierung stellen wir drei Datenbankvolumes für jede Datenbank bereit, um standardmäßig Oracle-Binärdaten, -Daten und -Protokolle zu hosten. Die Volumes werden auf Oracle DB Server als /u01 - binär, /u02 - Data, /u03 - logs via NFS eingebunden. Dual-Control-Dateien werden auf den Mount-Punkten /u02 und /u03 für Redundanz konfiguriert.
* *Implementierung mehrerer DB-Server.* die Automatisierungslösung kann eine Oracle-Container-Datenbank auf mehreren DB-Servern in einem einzelnen Ansible-Playbook bereitstellen. Unabhängig von der Anzahl der DB-Server bleibt die Playbook-Ausführung gleich. Sie können mehrere Container-Datenbanken auf einer einzelnen VM-Instanz implementieren, indem Sie die Implementierung mit unterschiedlichen Datenbankinstanzkennungen (Oracle SID) wiederholen. Stellen Sie jedoch sicher, dass auf dem Host ausreichend Speicher zur Unterstützung der bereitgestellten Datenbanken vorhanden ist.
* *DNFS-Konfiguration.* mit dNFS (verfügbar seit Oracle 11g) kann eine auf einer DB VM laufende Oracle-Datenbank deutlich mehr I/O-Vorgänge erzeugen als der native NFS-Client. Die automatisierte Oracle-Implementierung konfiguriert dNFS standardmäßig auf NFSv3.
* *Lastenausgleich auf C400 Controller-Paar.* Platzieren Sie Oracle Datenbank-Volumes auf C400 Controller-Knoten gleichmäßig, um den Workload auszugleichen. DB1 auf Controller 1, DB2 auf Controller 2, und so weiter. Stellen Sie die DB-Volumes in seine lokale LIF-Adresse ein.
* *Datenbanksicherung.* NetApp bietet eine SnapCenter Software Suite für Datenbank-Backup, -Wiederherstellung und -Klonen mit einer benutzerfreundlichen Benutzeroberfläche. NetApp empfiehlt die Implementierung eines solchen Managementtools, um Snapshots schnell (unter einer Minute), schnelle Datenbank-Restores (in Minuten) und Datenbankklone zu ermöglichen.




== Lösungsimplementierung

Die folgenden Abschnitte enthalten schrittweise Verfahren für die automatisierte Oracle 19c-Bereitstellung sowie Informationen zum Schutz der Oracle-Datenbank und zum Klonen nach der Bereitstellung.



=== Voraussetzungen für die Bereitstellung

[%collapsible]
====
Die Bereitstellung erfordert die folgenden Voraussetzungen.

. Ein Storage-Controller-Paar der NetApp C-Serie ist im Rack montiert, gestapelt und die neueste Version des ONTAP Betriebssystems ist installiert und konfiguriert. Beachten Sie bei Bedarf diese Installationsanleitung: https://docs.netapp.com/us-en/ontap-systems/c400/install-detailed-guide.html#step-1-prepare-for-installation["Ausführliche Anleitung - AFF C400"^]
. Zwei Linux-VMs als Oracle-DB-Server bereitstellen Details zur Umgebungs-Einrichtung finden Sie im Architekturdiagramm im vorherigen Abschnitt.
. Stellen Sie einen Windows-Server bereit, um das UI-Tool NetApp SnapCenter mit der neuesten Version auszuführen. Details finden Sie unter folgendem Link: link:https://docs.netapp.com/us-en/snapcenter/install/task_install_the_snapcenter_server_using_the_install_wizard.html["Installieren Sie den SnapCenter-Server"^]
. Stellen Sie eine Linux VM als Ansible-Controller-Node mit der neuesten Version von Ansible und Git bereit. Details finden Sie unter folgendem Link: link:../automation/getting-started.html["Erste Schritte mit der Automatisierung von NetApp Lösungen"^] In Abschnitt -
`Setup the Ansible Control Node for CLI deployments on RHEL / CentOS` Oder
`Setup the Ansible Control Node for CLI deployments on Ubuntu / Debian`.
+
Aktivieren Sie SSH-Authentifizierung für öffentlichen/privaten Schlüssel zwischen dem Ansible-Controller und Datenbank-VMs.

. Klonen Sie über das Ansible Controller-Admin-Home-Verzeichnis eine Kopie des NetApp Toolkit zur Automatisierung der Implementierung von Oracle für NFS.
+
[source, cli]
----
git clone https://bitbucket.ngage.netapp.com/scm/ns-bb/na_oracle_deploy_nfs.git
----
. Stellen Sie die folgenden Oracle 19c-Installationsdateien auf das DB VM /tmp/Archive-Verzeichnis mit 777-Berechtigung auf.
+
....
installer_archives:
  - "LINUX.X64_193000_db_home.zip"
  - "p34765931_190000_Linux-x86-64.zip"
  - "p6880880_190000_Linux-x86-64.zip"
....


====


=== Konfigurieren Sie Networking und SVM auf C-Series für Oracle

[%collapsible]
====
Dieser Abschnitt des Implementierungsleitfadens zeigt Best Practices zur Einrichtung von Networking und Storage Virtual Machine (SVM) auf einem C-Series Controller für Oracle-Workload mit NFS-Protokoll über die Benutzeroberfläche von ONTAP System Manager.

. Melden Sie sich beim ONTAP System Manager an, um zu überprüfen, ob nach der ersten ONTAP-Cluster-Installation Broadcast-Domänen mit den korrekten ethernet-Ports der jeweiligen Domäne konfiguriert wurden. Im Allgemeinen sollte es eine Broadcast-Domäne für Cluster, eine Broadcast-Domäne für das Management und eine Broadcast-Domäne für Workloads wie Daten geben.
+
image::automation_ora_c-series_nfs_net_01.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Klicken Sie in NETWORK - Ethernet Ports auf `Link Aggregate Group` Um einen Gruppenport für LACP Link Aggregate a0a zu erstellen, der Lastausgleich und Failover zwischen den Mitgliedsports im Gruppenport des Aggregats bereitstellt. Es gibt 4 Daten Ports - e0e, e0f, e0g, e0h auf C400 Controllern verfügbar.
+
image::automation_ora_c-series_nfs_net_02.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Wählen Sie die ethernet-Ports in der Gruppe aus, `LACP` Für den Modus, und `Port` Zur Lastverteilung.
+
image::automation_ora_c-series_nfs_net_03.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Validierung der von LACP-Port a0a erstellten und Broadcast-Domäne `Data` Arbeitet jetzt am LACP Port.
+
image::automation_ora_c-series_nfs_net_04.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

+
image::automation_ora_c-series_nfs_net_05.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Von `Ethernet Ports`Klicken Sie auf `VLAN` Jedem Controller-Node ein VLAN für Oracle-Workload auf NFS-Protokoll hinzufügen.
+
image::automation_ora_c-series_nfs_net_06.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

+
image::automation_ora_c-series_nfs_net_07.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

+
image::automation_ora_c-series_nfs_net_08.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Melden Sie sich bei C-Series Controllern über die Cluster-Management-IP über ssh an, um zu überprüfen, ob Netzwerk-Failover-Gruppen korrekt konfiguriert sind. ONTAP erstellt und managt Failover-Gruppen automatisch.
+
....

HCG-NetApp-C400-E9U9::> net int failover-groups show
  (network interface failover-groups show)
                                  Failover
Vserver          Group            Targets
---------------- ---------------- --------------------------------------------
Cluster
                 Cluster
                                  HCG-NetApp-C400-E9U9a:e0c,
                                  HCG-NetApp-C400-E9U9a:e0d,
                                  HCG-NetApp-C400-E9U9b:e0c,
                                  HCG-NetApp-C400-E9U9b:e0d
HCG-NetApp-C400-E9U9
                 Data
                                  HCG-NetApp-C400-E9U9a:a0a,
                                  HCG-NetApp-C400-E9U9a:a0a-3277,
                                  HCG-NetApp-C400-E9U9b:a0a,
                                  HCG-NetApp-C400-E9U9b:a0a-3277
                 Mgmt
                                  HCG-NetApp-C400-E9U9a:e0M,
                                  HCG-NetApp-C400-E9U9b:e0M
3 entries were displayed.

....
. Von `STORAGE - Storage VMs`Klicken Sie auf +Hinzufügen, um eine SVM für Oracle zu erstellen.
+
image::automation_ora_c-series_nfs_svm_01.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Benennen Sie Ihre Oracle SVM, prüfen Sie `Enable NFS` Und `Allow NFS client access`.
+
image::automation_ora_c-series_nfs_svm_02.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. NFS-Exportrichtlinie hinzufügen `Default` Regeln.
+
image::automation_ora_c-series_nfs_svm_03.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. In `NETWORK INTERFACE`, Geben Sie die IP-Adresse auf jedem Knoten für NFS-LIF-Adressen ein.
+
image::automation_ora_c-series_nfs_svm_04.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Validieren, ob die SVM für Oracle betriebsbereit ist und der NFS-Status aktiv ist
+
image::automation_ora_c-series_nfs_svm_05.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

+
image::automation_ora_c-series_nfs_svm_06.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Von `STORAGE-Volumes` Um NFS-Volumes für die Oracle-Datenbank hinzuzufügen.
+
image::automation_ora_c-series_nfs_vol_01.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Benennen Sie das Volume, weisen Sie Kapazität zu und führen Sie ein Performance-Level durch.
+
image::automation_ora_c-series_nfs_vol_02.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. In `Access Permission`Wählen Sie die Standardrichtlinie aus, die aus dem vorherigen Schritt erstellt wurde. Deaktivieren Sie `Enable Snapshot Copies` Da wir es vorziehen, SnapCenter zu verwenden, um applikationskonsistente Snapshots zu erstellen.
+
image::automation_ora_c-series_nfs_vol_03.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

. Erstellen Sie drei DB-Volumes für jeden DB-Server: Server_Name_u01 - Binary, Server_Name_u02 - Data, Server_Name_u03 - logs.
+
image::automation_ora_c-series_nfs_vol_04.png[Dieses Bild zeigt einen Screenshot zur Controller-Konfiguration der C-Serie]

+

NOTE: Die Namenskonvention für DB-Volumes sollten das oben genannte Format strikt befolgen, damit die Automatisierung korrekt funktioniert.



Damit ist die Controller-Konfiguration der C-Serie für Oracle abgeschlossen.

====


=== Automatisierungsparameter-Dateien

[%collapsible]
====
In dem Playbook „Ansible“ werden die Installations- und Konfigurationsaufgaben von Datenbanken mit vordefinierten Parametern ausgeführt. Für diese Oracle-Automatisierungslösung gibt es drei benutzerdefinierte Parameterdateien, die vor der Ausführung des Playbooks Benutzereingaben erfordern.

* Hosts: Legen Sie Ziele fest, für die das Automatisierungs-Playbook ausgeführt wird.
* vars/vars.yml - die globale Variablendatei, die Variablen definiert, die für alle Ziele gelten.
* Host_VARs/Host_Name.yml - die lokale Variablendatei, die Variablen definiert, die nur auf ein benanntes Ziel angewendet werden. In unserem Anwendungsbeispiel handelt es sich um die Oracle DB-Server.


Zusätzlich zu diesen benutzerdefinierten Variablendateien gibt es mehrere standardmäßige Variablendateien, die Standardparameter enthalten, die nicht geändert werden müssen, sofern dies nicht erforderlich ist. In den folgenden Abschnitten wird die Konfiguration der benutzerdefinierten Variablendateien erläutert.

====


=== Konfiguration von Parameterdateien

[%collapsible]
====
. Ansible Ziel `hosts` Dateikonfiguration:
+
[source, shell]
----
# Enter Oracle servers names to be deployed one by one, follow by each Oracle server public IP address, and ssh private key of admin user for the server.
[oracle]
ora_01 ansible_host=10.61.180.21 ansible_ssh_private_key_file=ora_01.pem
ora_02 ansible_host=10.61.180.23 ansible_ssh_private_key_file=ora_02.pem

----
. Weltweit `vars/vars.yml` Dateikonfiguration
+
[source, shell]
----
######################################################################
###### Oracle 19c deployment user configuration variables       ######
###### Consolidate all variables from ONTAP, linux and oracle   ######
######################################################################

###########################################
### ONTAP env specific config variables ###
###########################################

# Prerequisite to create three volumes in NetApp ONTAP storage from System Manager or cloud dashboard with following naming convention:
# db_hostname_u01 - Oracle binary
# db_hostname_u02 - Oracle data
# db_hostname_u03 - Oracle redo
# It is important to strictly follow the name convention or the automation will fail.


###########################################
### Linux env specific config variables ###
###########################################

redhat_sub_username: XXXXXXXX
redhat_sub_password: XXXXXXXX


####################################################
### DB env specific install and config variables ###
####################################################

# Database domain name
db_domain: solutions.netapp.com

# Set initial password for all required Oracle passwords. Change them after installation.
initial_pwd_all: XXXXXXXX

----
. Lokaler DB-Server `host_vars/host_name.yml` Konfiguration wie ora_01.yml, ora_02.yml ...
+
[source, shell]
----
# User configurable Oracle host specific parameters

# Enter container database SID. By default, a container DB is created with 3 PDBs within the CDB
oracle_sid: NTAP1

# Enter database shared memory size or SGA. CDB is created with SGA at 75% of memory_limit, MB. The grand total of SGA should not exceed 75% available RAM on node.
memory_limit: 8192

# Local NFS lif ip address to access database volumes
nfs_lif: 172.30.136.68

----


====


=== Ausführung des Playbook

[%collapsible]
====
Das Automatisierungs-Toolkit enthält insgesamt fünf Playbooks. Jede führt unterschiedliche Aufgabenblöcke aus und erfüllt unterschiedliche Zwecke.

....
0-all_playbook.yml - execute playbooks from 1-4 in one playbook run.
1-ansible_requirements.yml - set up Ansible controller with required libs and collections.
2-linux_config.yml - execute Linux kernel configuration on Oracle DB servers.
4-oracle_config.yml - install and configure Oracle on DB servers and create a container database.
5-destroy.yml - optional to undo the environment to dismantle all.
....
Es gibt drei Optionen, um Playbooks mit den folgenden Befehlen auszuführen.

. Führen Sie alle Playbooks für die Implementierung in einem kombinierten Durchlauf aus.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml
----
. Führen Sie Playbooks einzeln mit der Zahlenfolge von 1 bis 4 aus.
+
[source, cli]]
----
ansible-playbook -i hosts 1-ansible_requirements.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 2-linux_config.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 4-oracle_config.yml -u admin -e @vars/vars.yml
----
. Führen Sie 0-all_Playbook.yml mit einem Tag aus.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ansible_requirements
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t linux_config
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t oracle_config
----
. Die Umgebung rückgängig machen
+
[source, cli]
----
ansible-playbook -i hosts 5-destroy.yml -u admin -e @vars/vars.yml
----


====


=== Validierung nach der Ausführung

[%collapsible]
====
Melden Sie sich nach der Ausführung des Playbook bei der VM des Oracle DB Servers an, um zu überprüfen, ob Oracle installiert und konfiguriert ist und eine Container-Datenbank erfolgreich erstellt wurde. Im Folgenden finden Sie ein Beispiel für die Validierung von Oracle-Datenbanken auf DB VM ora_01 oder ora_02.

. Validieren von NFS-Mounts
+
....

[admin@ora_01 ~]$ cat /etc/fstab

#
# /etc/fstab
# Created by anaconda on Wed Oct 18 19:43:31 2023
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rhel-root   /                       xfs     defaults        0 0
UUID=aff942c4-b224-4b62-807d-6a5c22f7b623 /boot                   xfs     defaults        0 0
/dev/mapper/rhel-swap   none                    swap    defaults        0 0
/root/swapfile swap swap defaults 0 0
172.21.21.100:/ora_01_u01 /u01 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u02 /u02 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u03 /u03 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0


[admin@ora_01 tmp]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  62% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.100:/ora_01_u01   50G  8.7G   42G  18% /u01
172.21.21.100:/ora_01_u02  200G  384K  200G   1% /u02
172.21.21.100:/ora_01_u03  100G  320K  100G   1% /u03

[admin@ora_02 ~]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  63% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.101:/ora_02_u01   50G  7.8G   43G  16% /u01
172.21.21.101:/ora_02_u02  200G  320K  200G   1% /u02
172.21.21.101:/ora_02_u03  100G  320K  100G   1% /u03

....
. Oracle Listener validieren
+
....

[admin@ora_02 ~]$ sudo su
[root@ora_02 admin]# su - oracle
[oracle@ora_02 ~]$ lsnrctl status listener.ntap2

LSNRCTL for Linux: Version 19.0.0.0.0 - Production on 29-MAY-2024 12:13:30

Copyright (c) 1991, 2022, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER.NTAP2
Version                   TNSLSNR for Linux: Version 19.0.0.0.0 - Production
Start Date                23-MAY-2024 16:13:03
Uptime                    5 days 20 hr. 0 min. 26 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /u01/app/oracle/product/19.0.0/NTAP2/network/admin/listener.ora
Listener Log File         /u01/app/oracle/diag/tnslsnr/ora_02/listener.ntap2/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=ora_02.cie.netapp.com)(PORT=5500))(Security=(my_wallet_directory=/u01/app/oracle/product/19.0.0/NTAP2/admin/NTAP2/xdb_wallet))(Presentation=HTTP)(Session=RAW))
Services Summary...
Service "192551f1d7e65fc3e06308b43d0a63ae.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925529a43396002e06308b43d0a2d5a.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925530776b76049e06308b43d0a49c3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2XDB.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb1.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
The command completed successfully
[oracle@ora_02 ~]$

....
. Oracle-Datenbank und dNFS validieren
+
....

[oracle@ora-01 ~]$ cat /etc/oratab
#
# This file is used by ORACLE utilities.  It is created by root.sh
# and updated by either Database Configuration Assistant while creating
# a database or ASM Configuration Assistant while creating ASM instance.

# A colon, ':', is used as the field terminator.  A new line terminates
# the entry.  Lines beginning with a pound sign, '#', are comments.
#
# Entries are of the form:
#   $ORACLE_SID:$ORACLE_HOME:<N|Y>:
#
# The first and second fields are the system identifier and home
# directory of the database respectively.  The third field indicates
# to the dbstart utility that the database should , "Y", or should not,
# "N", be brought up at system boot time.
#
# Multiple entries with the same $ORACLE_SID are not allowed.
#
#
NTAP1:/u01/app/oracle/product/19.0.0/NTAP1:Y


[oracle@ora-01 ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu Feb 1 16:37:51 2024
Version 19.18.0.0.0

Copyright (c) 1982, 2022, Oracle.  All rights reserved.


Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.18.0.0.0

SQL> select name, open_mode, log_mode from v$database;

NAME      OPEN_MODE            LOG_MODE
--------- -------------------- ------------
NTAP1     READ WRITE           ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 NTAP1_PDB1                     READ WRITE NO
         4 NTAP1_PDB2                     READ WRITE NO
         5 NTAP1_PDB3                     READ WRITE NO
SQL> select name from v$datafile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/system01.dbf
/u02/oradata/NTAP1/sysaux01.dbf
/u02/oradata/NTAP1/undotbs01.dbf
/u02/oradata/NTAP1/pdbseed/system01.dbf
/u02/oradata/NTAP1/pdbseed/sysaux01.dbf
/u02/oradata/NTAP1/users01.dbf
/u02/oradata/NTAP1/pdbseed/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/users01.dbf

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/NTAP1_pdb2/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/users01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/users01.dbf

19 rows selected.

SQL> select name from v$controlfile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/control01.ctl
/u03/orareco/NTAP1/control02.ctl

SQL> select member from v$logfile;

MEMBER
--------------------------------------------------------------------------------
/u03/orareco/NTAP1/onlinelog/redo03.log
/u03/orareco/NTAP1/onlinelog/redo02.log
/u03/orareco/NTAP1/onlinelog/redo01.log

SQL> select svrname, dirname from v$dnfs_servers;

SVRNAME
--------------------------------------------------------------------------------
DIRNAME
--------------------------------------------------------------------------------
172.21.21.100
/ora_01_u02

172.21.21.100
/ora_01_u03

172.21.21.100
/ora_01_u01


....
. Melden Sie sich bei Oracle Enterprise Manager Express an, um die Datenbank zu validieren.
+
image::automation_ora_c-series_nfs_em_01.png[Dieses Bild zeigt den Anmeldebildschirm für Oracle Enterprise Manager Express an]

+
image::automation_ora_c-series_nfs_em_02.png[Dieses Bild bietet eine Ansicht der Container-Datenbank von Oracle Enterprise Manager Express]

+
image::automation_ora_c-series_nfs_em_03.png[Dieses Bild bietet eine Ansicht der Container-Datenbank von Oracle Enterprise Manager Express]



====


=== Backup, Wiederherstellung und Klonen von Oracle mit SnapCenter

[%collapsible]
====
NetApp empfiehlt das UI-Tool SnapCenter für das Management der in C-Series implementierten Oracle Datenbank. Siehe TR-4979 link:aws_ora_fsx_vmc_guestmount.html#oracle-backup-restore-and-clone-with-snapcenter["Vereinfachtes, selbstverwaltetes Oracle in VMware Cloud on AWS mit Gast-Mounted FSX ONTAP"^] Abschnitt `Oracle backup, restore, and clone with SnapCenter` Bietet Details zur Einrichtung von SnapCenter und zur Ausführung von Datenbank-Backup-, Wiederherstellungs- und Klon-Workflows.

====


== Wo Sie weitere Informationen finden

Weitere Informationen zu den in diesem Dokument beschriebenen Daten finden Sie in den folgenden Dokumenten bzw. auf den folgenden Websites:

* NetApp AFF C-Serie
+
link:https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf["https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf"^]

* NetApp Lösungen für Enterprise Database
+
link:https://docs.netapp.com/us-en/netapp-solutions/databases/index.html["https://docs.netapp.com/us-en/netapp-solutions/databases/index.html"^]

* Bereitstellung von Oracle Direct NFS
+
link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2["https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2"^]


