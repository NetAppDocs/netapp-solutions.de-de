---
sidebar: sidebar 
permalink: data-analytics/kafka-nfs-performance-overview-and-validation-in-aws.html 
keywords: AWS cloud, ha pair, high availability, openmessage benchmarking, architectural setup 
summary: Ein Kafka-Cluster mit einer auf NetApp NFS gemounteten Storage-Ebene wurde in der AWS Cloud hinsichtlich Performance getestet. Die Benchmarking-Beispiele sind in den folgenden Abschnitten beschrieben. 
---
= Performance-Übersicht und Validierung in AWS
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:kafka-nfs-why-netapp-nfs-for-kafka-workloads.html["Zurück: Warum NetApp NFS für Kafka-Workloads?."]

[role="lead"]
Ein Kafka-Cluster mit einer auf NetApp NFS gemounteten Storage-Ebene wurde in der AWS Cloud hinsichtlich Performance getestet. Die Benchmarking-Beispiele sind in den folgenden Abschnitten beschrieben.



== Kafka in der AWS-Cloud mit NetApp Cloud Volumes ONTAP (Hochverfügbarkeitspaar und einzelner Node)

Ein Kafka-Cluster mit NetApp Cloud Volumes ONTAP (HA-Paar) wurde hinsichtlich der Performance in der AWS-Cloud gemessen. Dieses Benchmarking wird in den folgenden Abschnitten beschrieben.



=== Einrichtung der Architektur

In der folgenden Tabelle wird die Umgebungskonfiguration für ein Kafka-Cluster mithilfe von NAS gezeigt.

|===
| Plattformkomponente | Umgebungskonfiguration 


| Kafka 3.2.3  a| 
* 3 x Zookeeper – t2.small
* 3 x Broker Server – i3en.2xlarge
* 1 x Grafana – c5n.2xlarge
* 4 x Hersteller/Verbraucher -- c5n.2xlarge *




| Betriebssystem auf allen Knoten | RHEL8.6 


| NetApp Cloud Volumes ONTAP Instanz | INSTANZ EINES HA-Paars – m5dn.12xLarge x 2-Node-Instanz eines einzelnen Knotens – m5dn.12xLarge x 1 Node 
|===


=== Einrichtung des NetApp Cluster Volume ONTAP

. Für das Cloud Volumes ONTAP HA-Paar erstellten wir zwei Aggregate mit drei Volumes auf jedem Aggregat auf jedem Storage Controller. Für einen einzelnen Cloud Volumes ONTAP Node erstellen wir sechs Volumes in einem Aggregat.
+
image:kafka-nfs-image25.png["Dieses Bild zeigt die Eigenschaften von aggr3 und aggr22."]

+
image:kafka-nfs-image26.png["Dieses Bild zeigt die Eigenschaften von aggr2."]

. Um eine bessere Netzwerk-Performance zu erzielen, haben wir sowohl für das HA-Paar als auch für den einzelnen Node High-Speed-Networking ermöglicht.
+
image:kafka-nfs-image27.png["Diese Bilder zeigen, wie Sie Hochgeschwindigkeitsnetzwerke aktivieren."]

. Wir bemerkten, dass der ONTAP NVRAM mehr IOPS hatte, also änderten wir die IOPS für das Cloud Volumes ONTAP Root-Volume auf 2350. Die Root-Datenträger in Cloud Volumes ONTAP waren 47 GB groß. Der folgende ONTAP-Befehl gilt für das HA-Paar und derselbe Schritt gilt für den einzelnen Node.
+
....
statistics start -object vnvram -instance vnvram -counter backing_store_iops -sample-id sample_555
kafka_nfs_cvo_ha1::*> statistics show -sample-id sample_555
Object: vnvram
Instance: vnvram
Start-time: 1/18/2023 18:03:11
End-time: 1/18/2023 18:03:13
Elapsed-time: 2s
Scope: kafka_nfs_cvo_ha1-01
    Counter                                                     Value
    -------------------------------- --------------------------------
    backing_store_iops                                           1479
Object: vnvram
Instance: vnvram
Start-time: 1/18/2023 18:03:11
End-time: 1/18/2023 18:03:13
Elapsed-time: 2s
Scope: kafka_nfs_cvo_ha1-02
    Counter                                                     Value
    -------------------------------- --------------------------------
    backing_store_iops                                           1210
2 entries were displayed.
kafka_nfs_cvo_ha1::*>
....
+
image:kafka-nfs-image28.png["Diese Bilder zeigen, wie Sie Volume-Eigenschaften ändern."]



In der folgenden Abbildung ist die Architektur eines NAS-basierten Kafka-Clusters dargestellt.

* *Compute.* Wir benutzten einen drei-Knoten-Kafka-Cluster mit einem drei-Knoten-Zookeeper-Ensemble, das auf dedizierten Servern läuft. Jeder Broker hatte zwei NFS-Mount-Punkte zu einem einzelnen Volume auf der Cloud Volumes ONTAP Instanz über eine dedizierte LIF.
* *Monitoring.* für eine Prometheus-Grafana-Kombination haben wir zwei Knoten verwendet. Zur Generierung von Workloads haben wir ein separates Cluster mit drei Nodes verwendet, das für diesen Kafka-Cluster erzeugt und genutzt werden kann.
* *Storage.* Wir verwendeten eine HA-Paar-Cloud Volumes ONTAP-Instanz mit einem 6 TB GP3 AWS-EBS Volume auf der Instanz gemountet. Das Volume wurde dann mit einem NFS-Mount in den Kafka-Broker exportiert.


image:kafka-nfs-image29.png["Diese Abbildung stellt die Architektur eines NAS-basierten Kafka-Clusters dar."]



=== OpenMessage Benchmarking-Konfigurationen

. Für eine bessere NFS Performance benötigen wir mehr Netzwerkverbindungen zwischen dem NFS Server und dem NFS Client, die man mit nconnect erstellen kann. Mit dem folgenden Befehl mounten Sie die NFS-Volumes auf den Broker-Nodes mit der Option nconnect:
+
....
[root@ip-172-30-0-121 ~]# cat /etc/fstab
UUID=eaa1f38e-de0f-4ed5-a5b5-2fa9db43bb38/xfsdefaults00
/dev/nvme1n1 /mnt/data-1 xfs defaults,noatime,nodiscard 0 0
/dev/nvme2n1 /mnt/data-2 xfs defaults,noatime,nodiscard 0 0
172.30.0.233:/kafka_aggr3_vol1 /kafka_aggr3_vol1 nfs defaults,nconnect=16 0 0
172.30.0.233:/kafka_aggr3_vol2 /kafka_aggr3_vol2 nfs defaults,nconnect=16 0 0
172.30.0.233:/kafka_aggr3_vol3 /kafka_aggr3_vol3 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol1 /kafka_aggr22_vol1 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol2 /kafka_aggr22_vol2 nfs defaults,nconnect=16 0 0
172.30.0.242:/kafka_aggr22_vol3 /kafka_aggr22_vol3 nfs defaults,nconnect=16 0 0
[root@ip-172-30-0-121 ~]# mount -a
[root@ip-172-30-0-121 ~]# df -h
Filesystem                       Size  Used Avail Use% Mounted on
devtmpfs                          31G     0   31G   0% /dev
tmpfs                             31G  249M   31G   1% /run
tmpfs                             31G     0   31G   0% /sys/fs/cgroup
/dev/nvme0n1p2                    10G  2.8G  7.2G  28% /
/dev/nvme1n1                     2.3T  248G  2.1T  11% /mnt/data-1
/dev/nvme2n1                     2.3T  245G  2.1T  11% /mnt/data-2
172.30.0.233:/kafka_aggr3_vol1   1.0T   12G 1013G   2% /kafka_aggr3_vol1
172.30.0.233:/kafka_aggr3_vol2   1.0T  5.5G 1019G   1% /kafka_aggr3_vol2
172.30.0.233:/kafka_aggr3_vol3   1.0T  8.9G 1016G   1% /kafka_aggr3_vol3
172.30.0.242:/kafka_aggr22_vol1  1.0T  7.3G 1017G   1% /kafka_aggr22_vol1
172.30.0.242:/kafka_aggr22_vol2  1.0T  6.9G 1018G   1% /kafka_aggr22_vol2
172.30.0.242:/kafka_aggr22_vol3  1.0T  5.9G 1019G   1% /kafka_aggr22_vol3
tmpfs                            6.2G     0  6.2G   0% /run/user/1000
[root@ip-172-30-0-121 ~]#
....
. Überprüfen Sie die Netzwerkverbindungen in Cloud Volumes ONTAP. Der folgende ONTAP-Befehl wird über den einzelnen Cloud Volumes ONTAP Node verwendet. Derselbe Schritt gilt für das Cloud Volumes ONTAP HA-Paar.
+
....
Last login time: 1/20/2023 00:16:29
kafka_nfs_cvo_sn::> network connections active show -service nfs* -fields remote-host
node                cid        vserver              remote-host
------------------- ---------- -------------------- ------------
kafka_nfs_cvo_sn-01 2315762628 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762629 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762630 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762631 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762632 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762633 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762634 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762635 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762636 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762637 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762639 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762640 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762641 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762642 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762643 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762644 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762645 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762646 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762647 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762648 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762649 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762650 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762651 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762652 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762653 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762656 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762657 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762658 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762659 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762660 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762661 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762662 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762663 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762664 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762665 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762666 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762667 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762668 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762669 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762670 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762671 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762672 svm_kafka_nfs_cvo_sn 172.30.0.72
kafka_nfs_cvo_sn-01 2315762673 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762674 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762676 svm_kafka_nfs_cvo_sn 172.30.0.121
kafka_nfs_cvo_sn-01 2315762677 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762678 svm_kafka_nfs_cvo_sn 172.30.0.223
kafka_nfs_cvo_sn-01 2315762679 svm_kafka_nfs_cvo_sn 172.30.0.223
48 entries were displayed.
 
kafka_nfs_cvo_sn::>
....
. Wir benutzen folgende Kafka `server.properties` In allen Kafka-Brokern für das Cloud Volumes ONTAP HA-Paar. Der `log.dirs` Die Eigenschaft ist für jeden Broker unterschiedlich, und die restlichen Eigenschaften sind für Broker üblich. Für Broker1 ist die `log.dirs` Der Wert ist wie folgt:
+
....
[root@ip-172-30-0-121 ~]# cat /opt/kafka/config/server.properties
broker.id=0
advertised.listeners=PLAINTEXT://172.30.0.121:9092
#log.dirs=/mnt/data-1/d1,/mnt/data-1/d2,/mnt/data-1/d3,/mnt/data-2/d1,/mnt/data-2/d2,/mnt/data-2/d3
log.dirs=/kafka_aggr3_vol1/broker1,/kafka_aggr3_vol2/broker1,/kafka_aggr3_vol3/broker1,/kafka_aggr22_vol1/broker1,/kafka_aggr22_vol2/broker1,/kafka_aggr22_vol3/broker1
zookeeper.connect=172.30.0.12:2181,172.30.0.30:2181,172.30.0.178:2181
num.network.threads=64
num.io.threads=64
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
replica.fetch.max.bytes=524288000
background.threads=20
num.replica.alter.log.dirs.threads=40
num.replica.fetchers=20
[root@ip-172-30-0-121 ~]#
....
+
** Für Broker2 ist die `log.dirs` Der Eigenschaftswert ist wie folgt:
+
....
log.dirs=/kafka_aggr3_vol1/broker2,/kafka_aggr3_vol2/broker2,/kafka_aggr3_vol3/broker2,/kafka_aggr22_vol1/broker2,/kafka_aggr22_vol2/broker2,/kafka_aggr22_vol3/broker2
....
** Für Broker3 ist die `log.dirs` Der Eigenschaftswert ist wie folgt:
+
....
log.dirs=/kafka_aggr3_vol1/broker3,/kafka_aggr3_vol2/broker3,/kafka_aggr3_vol3/broker3,/kafka_aggr22_vol1/broker3,/kafka_aggr22_vol2/broker3,/kafka_aggr22_vol3/broker3
....


. Für den einzelnen Cloud Volumes ONTAP-Node ist die Kafka `servers.properties` Ist das gleiche wie für das Cloud Volumes ONTAP HA-Paar mit Ausnahme des `log.dirs` Eigenschaft.
+
** Für Broker1 ist die `log.dirs` Der Wert ist wie folgt:
+
....
log.dirs=/kafka_aggr2_vol1/broker1,/kafka_aggr2_vol2/broker1,/kafka_aggr2_vol3/broker1,/kafka_aggr2_vol4/broker1,/kafka_aggr2_vol5/broker1,/kafka_aggr2_vol6/broker1
....
** Für Broker2 ist die `log.dirs` Der Wert ist wie folgt:
+
....
log.dirs=/kafka_aggr2_vol1/broker2,/kafka_aggr2_vol2/broker2,/kafka_aggr2_vol3/broker2,/kafka_aggr2_vol4/broker2,/kafka_aggr2_vol5/broker2,/kafka_aggr2_vol6/broker2
....
** Für Broker3 ist die `log.dirs` Der Eigenschaftswert ist wie folgt:
+
....
log.dirs=/kafka_aggr2_vol1/broker3,/kafka_aggr2_vol2/broker3,/kafka_aggr2_vol3/broker3,/kafka_aggr2_vol4/broker3,/kafka_aggr2_vol5/broker3,/kafka_aggr2_vol6/broker3
....


. Der Workload im OMB ist mit den folgenden Eigenschaften konfiguriert: `(/opt/benchmark/workloads/1-topic-100-partitions-1kb.yaml)`.
+
....
topics: 4
partitionsPerTopic: 100
messageSize: 32768
useRandomizedPayloads: true
randomBytesRatio: 0.5
randomizedPayloadPoolSize: 100
subscriptionsPerTopic: 1
consumerPerSubscription: 80
producersPerTopic: 40
producerRate: 1000000
consumerBacklogSizeGB: 0
testDurationMinutes: 5
....
+
Der `messageSize` Kann je nach Anwendungsfall variieren. In unserem Performance-Test haben wir 3.000 verwendet.

+
Wir haben zwei verschiedene Treiber verwendet, Sync oder Throughput, von OMB, um den Workload auf dem Kafka-Cluster zu generieren.

+
** Die yaml-Datei, die für die Eigenschaften des Sync-Treibers verwendet wird, ist wie folgt `(/opt/benchmark/driver- kafka/kafka-sync.yaml)`:
+
....
name: Kafka
driverClass: io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver
# Kafka client-specific configuration
replicationFactor: 3
topicConfig: |
  min.insync.replicas=2
  flush.messages=1
  flush.ms=0
commonConfig: |
  bootstrap.servers=172.30.0.121:9092,172.30.0.72:9092,172.30.0.223:9092
producerConfig: |
  acks=all
  linger.ms=1
  batch.size=1048576
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  max.partition.fetch.bytes=10485760
....
** Die yaml-Datei, die für die Eigenschaften des Durchsatztreibers verwendet wird, ist wie folgt `(/opt/benchmark/driver- kafka/kafka-throughput.yaml)`:
+
....
name: Kafka
driverClass: io.openmessaging.benchmark.driver.kafka.KafkaBenchmarkDriver
# Kafka client-specific configuration
replicationFactor: 3
topicConfig: |
  min.insync.replicas=2
commonConfig: |
  bootstrap.servers=172.30.0.121:9092,172.30.0.72:9092,172.30.0.223:9092
  default.api.timeout.ms=1200000
  request.timeout.ms=1200000
producerConfig: |
  acks=all
  linger.ms=1
  batch.size=1048576
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  max.partition.fetch.bytes=10485760
....






== Methodik des Testens

. Ein Kafka-Cluster wurde gemäß der oben beschriebenen Spezifikation mit Terraform und Ansible bereitgestellt. Terraform wird verwendet, um die Infrastruktur mit AWS-Instanzen für den Kafka-Cluster zu erstellen, und Ansible baut auf diesen den Kafka-Cluster.
. Ein OMB-Workload wurde mit der oben beschriebenen Workload-Konfiguration und dem Sync-Treiber ausgelöst.
+
....
Sudo bin/benchmark –drivers driver-kafka/kafka- sync.yaml workloads/1-topic-100-partitions-1kb.yaml
....
. Ein anderer Workload wurde mit dem Durchsatztreiber mit derselben Workload-Konfiguration ausgelöst.
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-throughput.yaml workloads/1-topic-100-partitions-1kb.yaml
....




== Beobachtung

Es wurden zwei unterschiedliche Treibertypen verwendet, mit denen Workloads für die Performance einer Kafka-Instanz generiert werden, die auf NFS ausgeführt wird. Der Unterschied zwischen den Treibern ist die Eigenschaft log flush.

Bei einem Cloud Volumes ONTAP HA-Paar:

* Der Gesamtdurchsatz, der konsistent vom Sync-Treiber generiert wird: ~1236 Mbps.
* Gesamtdurchsatz für den Durchsatztreiber: Spitze ~1412 Mbps.


Für einen einzelnen Cloud Volumes ONTAP-Node:

* Der Gesamtdurchsatz, der vom Sync-Treiber konsistent generiert wird: ~ 1962MBps.
* Gesamtdurchsatz des Durchsatztreibers: Spitze ~1660 MB/s


Der Sync-Treiber kann einen konsistenten Durchsatz generieren, da die Protokolle umgehend auf die Festplatte gespeichert werden, während der Durchsatztreiber bei der umfangreichen Protokollüberweise auf die Festplatte führt.

Diese Durchsatzwerte werden für die jeweilige AWS-Konfiguration generiert. Um höhere Performance-Anforderungen zu erfüllen, können die Instanztypen vertikal skaliert und weiter optimiert werden, um einen besseren Durchsatz zu erzielen. Der Gesamtdurchsatz oder die Gesamtrate ist die Kombination von Erzeugerrate und Verbraucherrate.

image:kafka-nfs-image30.png["Vier verschiedene Grafiken werden hier vorgestellt. CVO-HA-Paar-Durchsatztreiber. CVO-HA-Paar-Sync-Treiber. CVO-Single-Node-Durchsatztreiber. CVO-Single-Node Sync Treiber"]

Prüfen Sie den Storage-Durchsatz, wenn Sie ein Benchmarking des Durchsatzes oder der Synchronisationstreiber durchführen.

image:kafka-nfs-image31.png["Dieses Diagramm zeigt die Performance in den Bereichen Latenz, IOPS und Durchsatz."]



== Apache Kafka in AWS FSxN



=== Überblick

Network File System (NFS) ist ein weit verbreitetes Netzwerkdateisystem zur Speicherung großer Datenmengen. In den meisten Unternehmen werden Daten zunehmend durch Streaming-Applikationen wie Apache Kafka generiert. Für diese Workloads sind Skalierbarkeit, niedrige Latenz und eine robuste Datenaufnahmearchitektur mit modernen Storage-Funktionen erforderlich. Für Echtzeitanalysen und zur Bereitstellung verwertbarer Erkenntnisse ist eine gut konzipierte und äußerst leistungsfähige Infrastruktur erforderlich.

Kafka funktioniert nach dem Design mit POSIX-konformem Filesystem und verarbeitet Dateivorgänge mithilfe des Filesystems. Beim Speichern von Daten auf einem NFSv3-Filesystem kann der Kafka-Broker NFS-Client Dateivorgänge jedoch anders als ein lokales Dateisystem wie XFS oder Ext4 interpretieren. Ein häufiges Beispiel ist die dumme NFS-Umbenennung, die Kafka-Broker fehlschlagen ließ, wenn sie Cluster erweitern und Partitionen neu zuordnen. Um dieser Herausforderung zu begegnen, hat NetApp den Open-Source-Linux-NFS-Client mit Änderungen aktualisiert, die nun allgemein in RHEL8.7, RHEL9.1 verfügbar sind und von der aktuellen FSX for ONTAP-Version, ONTAP 9.12.1, unterstützt werden.

Amazon FSX für NetApp ONTAP bietet ein vollständig gemanagtes, skalierbares und hochleistungsfähiges NFS-Dateisystem in der Cloud. Kafka-Daten auf FSX für NetApp können für die Verarbeitung großer Datenmengen skaliert werden und Fehlertoleranz gewährleisten. NFS bietet zentralisiertes Storage-Management und Datensicherung für kritische und sensible Datensätze.

Durch diese Verbesserungen können AWS-Kunden die Vorteile von FSX for ONTAP nutzen, wenn sie Kafka-Workloads auf AWS-Computing-Services ausführen. Diese Vorteile sind:
* Verringerung der CPU-Auslastung zur Verringerung der I/O-Wartezeit
* Schnellere Recovery-Zeit für Kafka Broker
* Zuverlässigkeit und Effizienz
* Skalierbarkeit und Performance
* Multi-Availability Zone Verfügbarkeit
* Datenschutz



=== Performance-Übersicht und Validierung in AWS FSxN

Ein Kafka-Cluster mit einer Storage-Ebene, die auf NetApp NFS gemountet ist, wurde in der AWS FSxN für die Performance getestet. Die Benchmarking-Beispiele sind in den folgenden Abschnitten beschrieben.



==== Kafka in AWS FSxN (aktiv passiv)

Ein Kafka-Cluster mit AWS FSxN wurde hinsichtlich der Performance in der AWS-Cloud gemessen. Dieses Benchmarking wird in den folgenden Abschnitten beschrieben.



==== Einrichtung der Architektur

In der folgenden Tabelle wird die Umgebungskonfiguration für ein Kafka-Cluster mit AWS FSxN gezeigt.

|===
| Plattformkomponente | Umgebungskonfiguration 


| Kafka 3.2.3  a| 
* 3 x Zookeeper – t2.small
* 3 x Broker Server – i3en.2xlarge
* 1 x Grafana – c5n.2xlarge
* 4 x Hersteller/Verbraucher -- c5n.2xlarge *




| Betriebssystem auf allen Knoten | RHEL8.6 


| AWS FSxN | Aktive passive Instanz mit 4 GB/s Durchsatz und 160000 IPS 
|===


==== NetApp FSxN-Einrichtung

. Für unsere ersten Tests haben wir ein FSX für NetApp ONTAP-Dateisystem mit 2 TB und 40000 IOPS für 2 GB/s Durchsatz erstellt.
. In FSX for NetApp ONTAP beträgt die maximal erreichbare iops für ein 2 GB/s Durchsatz-Dateisystem in unserer Testregion (US-East-1) 80,000 iops. Der maximale IOPS-Wert für ein FSX für NetApp ONTAP-Dateisystem beträgt insgesamt 160,000 iops, wofür eine 4-GB/s-Durchsatzbereitstellung erforderlich ist, die wir später in diesem Dokument demonstrieren werden
+
....
[root@ip-172-31-33-69 ~]# aws fsx create-file-system --region us-east-2  --storage-capacity 2048 --subnet-ids <desired subnet 1> subnet-<desired subnet 2> --file-system-type ONTAP --ontap-configuration DeploymentType=MULTI_AZ_HA_1,ThroughputCapacity=2048,PreferredSubnetId=<desired primary subnet>,FsxAdminPassword=<new password>,DiskIopsConfiguration="{Mode=USER_PROVISIONED,Iops=40000"}
....
+
Detaillierte Kommandozeilen-Syntax für FSX „create-file-System“ finden Sie hier: https://docs.aws.amazon.com/cli/latest/reference/fsx/create-file-system.html[]
Zum Beispiel können Sie einen bestimmten KMS-Schlüssel im Gegensatz zum Standard-FSX-Master-Schlüssel angeben, der verwendet wird, wenn kein KMS-Schlüssel angegeben wird.

. Warten Sie, bis sich der Status „Lebenszyklus“ in Ihrer JSON-Rückgabe in „VERFÜGBAR“ ändert, nachdem Sie Ihr Dateisystem wie folgt beschrieben haben:
+
....
[root@ip-172-31-33-69 ~]# aws fsx describe-file-systems  --region us-east-1 --file-system-ids fs-02ff04bab5ce01c7c
....
. Das Passwort für fsxadmin ist das Passwort, das beim ersten Erstellen des Dateisystems konfiguriert wurde.
. Validieren Sie die Anmeldeinformationen durch Anmeldung bei FsxN über fsxadmin
+
....
[root@ip-172-31-33-69 ~]# ssh fsxadmin@198.19.250.244
The authenticity of host '198.19.250.244 (198.19.250.244)' can't be established.
ED25519 key fingerprint is SHA256:mgCyRXJfWRc2d/jOjFbMBsUcYOWjxoIky0ltHvVDL/Y.
This key is not known by any other names
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added '198.19.250.244' (ED25519) to the list of known hosts.
(fsxadmin@198.19.250.244) Password:

This is your first recorded login.
....
. Erstellen Sie die virtuelle Speichermaschine auf dem FSxN
+
....
[root@ip-172-31-33-69 ~]# aws fsx --region us-east-1 create-storage-virtual-machine --name svmkafkatest --file-system-id fs-02ff04bab5ce01c7c
....
. SSH in das neu erstellte FSX für NetApp ONTAP-Dateisystem und erstellen Volumes in Storage Virtual Machine mit dem Beispielbefehl unten und ähnlich erstellen wir 6 Volumen für diese Validierung. Ausgehend von unserer Validierung bietet die Aufbewahrung der Standardkomponente (8) oder weniger Komponenten eine bessere Performance für kafka.
+
....
FsxId02ff04bab5ce01c7c::*> volume create -volume kafkafsxN1 -state online -policy default -unix-permissions ---rwxr-xr-x -junction-active true -type RW -snapshot-policy none  -junction-path /kafkafsxN1 -aggr-list aggr1
....
. Erweitern Sie das Volume auf 2 TB und mounten Sie es über den Verbindungspfad.
+
....
FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN1 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN1" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN2 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN2" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN3 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN3" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN4 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN4" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN5 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN5" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume size -volume kafkafsxN6 -new-size +2TB
vol size: Volume "svmkafkatest:kafkafsxN6" size set to 2.10t.

FsxId02ff04bab5ce01c7c::*> volume show -vserver svmkafkatest -volume *
Vserver   Volume       Aggregate    State      Type       Size  Available Used%
--------- ------------ ------------ ---------- ---- ---------- ---------- -----
svmkafkatest
          kafkafsxN1   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN2   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN3   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN4   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN5   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          kafkafsxN6   -            online     RW       2.10TB     1.99TB    0%
svmkafkatest
          svmkafkatest_root
                       aggr1        online     RW          1GB    968.1MB    0%
7 entries were displayed.

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN1 -junction-path /kafkafsxN1

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN2 -junction-path /kafkafsxN2

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN3 -junction-path /kafkafsxN3

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN4 -junction-path /kafkafsxN4

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN5 -junction-path /kafkafsxN5

FsxId02ff04bab5ce01c7c::*> volume mount -volume kafkafsxN6 -junction-path /kafkafsxN6
....
. Wir erweitern die FSxN-Durchsatzkapazität von 2 GB/s auf 4 GB/s und IOPS auf 160000
+
....
[root@ip-172-31-33-69 ~]# aws fsx update-file-system --region us-east-1  --storage-capacity 5120 --ontap-configuration 'ThroughputCapacity=4096,DiskIopsConfiguration={Mode=USER_PROVISIONED,Iops=160000}' --file-system-id fs-02ff04bab5ce01c7c
....
+
Detaillierte Kommandozeilen-Syntax für FSX „Update-file-System“ finden Sie hier:
https://docs.aws.amazon.com/cli/latest/reference/fsx/update-file-system.html[]

. Die FSxN-Volumes werden mit nconnect und Standardopionen in kafkar-Brokern gemountet
+
image:aws-fsx-kafka-arch1.png["Dieses Bild zeigt die Architektur eines FSxN-basierten Kafka-Clusters."]

+
** Computing: Wir nutzten einen drei-Knoten-Kafka-Cluster mit einem drei-Knoten-Zookeeper-Ensemble, das auf dedizierten Servern lief. Jeder Broker hatte sechs NFS-Mount-Punkte auf sechs Volumes in der FSxN-Instanz.
** Monitoring: Wir haben zwei Knoten für eine Prometheus-Grafana Kombination verwendet. Zur Generierung von Workloads haben wir ein separates Cluster mit drei Nodes verwendet, das für diesen Kafka-Cluster erzeugt und genutzt werden kann.
** Storage: Wir verwendeten einen FSxN mit sechs 1-TB-Volumes. Das Volume wurde dann mit einem NFS-Mount in den Kafka-Broker exportiert.






==== OpenMessage Benchmarking-Konfigurationen.

Wir haben dieselbe Konfiguration für das NetApp Cloud Volume ONTAP verwendet und ihre Details sind hier -
https://docs.netapp.com/us-en/netapp-solutions/data-analytics/kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup[]



==== Methodik des Testens

. Ein Kafka-Cluster wurde gemäß der oben beschriebenen Spezifikation mit Terraform und ansible bereitgestellt. Terraform wird verwendet, um die Infrastruktur mit AWS-Instanzen für den Kafka-Cluster zu erstellen, und ansible baut auf diesen den Kafka-Cluster.
. Ein OMB-Workload wurde mit der oben beschriebenen Workload-Konfiguration und dem Sync-Treiber ausgelöst.
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-sync.yaml workloads/1-topic-100-partitions-1kb.yaml
....
. Ein anderer Workload wurde mit dem Durchsatztreiber mit derselben Workload-Konfiguration ausgelöst.
+
....
sudo bin/benchmark –drivers driver-kafka/kafka-throughput.yaml workloads/1-topic-100-partitions-1kb.yaml
....




==== Beobachtung

Es wurden zwei unterschiedliche Treibertypen verwendet, mit denen Workloads für die Performance einer Kafka-Instanz generiert werden, die auf NFS ausgeführt wird. Der Unterschied zwischen den Treibern ist die Eigenschaft log flush.

Für einen kafka-Replikationsfaktor 1 und den FSxN:

* Gesamtdurchsatz, der konsistent vom Sync-Treiber generiert wird: ~ 3218 Mbit/s und Spitzenleistung in ~ 3652 Mbit/s.
* Gesamtdurchsatz, der konsistent vom Durchsatztreiber generiert wird: ~ 3679 Mbit/s und Spitzenleistung in ~ 3908 Mbit/s.


Für kafka mit Replikationsfaktor 3 und FSxN :

* Gesamtdurchsatz, der konsistent vom Sync-Treiber generiert wird: ~ 1252 Mbit/s und Spitzenleistung in ~ 1382 Mbit/s.
* Gesamtdurchsatz, der konsistent vom Durchsatztreiber generiert wird: ~ 1218 Mbit/s und Spitzenleistung in ~ 1328 Mbit/s.


Im Kafka-Replikationsfaktor 3 fand der Lese- und Schreibvorgang dreimal auf dem FSxN statt, im Kafka-Replikationsfaktor 1 ist der Lese- und Schreibvorgang einmalig auf dem FSxN, sodass wir bei beiden Validierungen den maximalen Durchsatz von 4 GB/s erreichen können.

Der Sync-Treiber kann einen konsistenten Durchsatz generieren, da die Protokolle umgehend auf die Festplatte gespeichert werden, während der Durchsatztreiber bei der umfangreichen Protokollüberweise auf die Festplatte führt.

Diese Durchsatzwerte werden für die jeweilige AWS-Konfiguration generiert. Um höhere Performance-Anforderungen zu erfüllen, können die Instanztypen vertikal skaliert und weiter optimiert werden, um einen besseren Durchsatz zu erzielen. Der Gesamtdurchsatz oder die Gesamtrate ist die Kombination von Erzeugerrate und Verbraucherrate.

image:aws-fsxn-performance-rf-1-rf-3.png["Dieses Bild zeigt die Performance von kafka mit RF1 und RF3"]

Das folgende Diagramm zeigt die FSxn-Leistung von 2 GB/s und die Leistung von 4 GB/s für den kafka-Replizierungsfaktor 3. Der Replikationsfaktor 3 führt den Lese- und Schreibvorgang dreimal auf dem FSxN-Speicher aus. Die Gesamtrate für den Durchsatztreiber beträgt 881 MB/s, was den kafka-Betrieb ungefähr 2.64 GB/s auf dem FSxN-Dateisystem mit 2 GB/s liest und schreibt. Die Gesamtrate für den Durchsatztreiber beträgt 1328 MB/s, was den kafka-Betrieb ungefähr 3.98 GB/s liest und schreibt. Die Performance von Kafka ist linear und skalierbar basierend auf dem FSxN-Durchsatz.

image:aws-fsxn-2gb-4gb-scale.png["Dieses Bild zeigt die Scale-out-Leistung von 2 GB/s und 4 GB/s."]

Das folgende Diagramm zeigt die Leistung zwischen EC2-Instanz und FSxN (Kafka Replication Factor : 3)

image:aws-fsxn-ec2-fsxn-comparition.png["Dieses Bild zeigt den Leistungsvergleich zwischen EC2 und FSxN in RF3."]

link:kafka-nfs-performance-overview-and-validation-with-aff-on-premises.html["Weiter: Performance-Übersicht und Validierung mit AFF On-Premises."]
